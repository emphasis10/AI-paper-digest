# BLADE: Enhancing Black-box Large Language Models with Small Domain-Specific Models
## TL;DR
## Summary
이 논문은 "BLADE: Large Language Models를 위한 Small Domain-Specific Models를 통한 강화"라는 제목으로, 대규모 언어 모델(Large Language Models, LLMs)을 특정 도메인에 맞게 적응시키기 위한 새로운 프레임워크를 제안합니다. 주요 내용을 요약하면 다음과 같습니다.

### 1. 소개 및 배경
- 최근 LLMs는 광범위한 작업에서 뛰어난 능력을 보여주고 있지만, 법률, 의학과 같은 특정 분야에서는 도메인 특화 지식이 부족하여 성능이 떨어질 수 있습니다.
- 기존의 접근 방식은 도메인별 데이터로 LLMs를 지속적으로 사전 훈련시키거나, 검색 증강을 통해 LLMs를 지원하는 것이었습니다. 하지만 이러한 방식은 비용이 많이 들거나 실제 응용 프로그램에서 신뢰할 수 없는 경우가 많았습니다.
- 이를 해결하기 위해 저자들은 BLADE라는 프레임워크를 제안합니다. 이는 소형 도메인 특화 언어 모델을 활용해 대규모 언어 모델의 도메인 적응 능력을 향상시키는 방식입니다.

### 2. 관련 작업
- LLMs의 발전과 도메인 적응에 대한 기존 연구들을 검토합니다. 특히, BERT와 GPT와 같은 모델들이 어떻게 광범위한 언어 이해 및 생성 능력을 가지게 되었는지 설명합니다.
- 도메인 적응을 위한 기존 방법론들, 특히 지속적인 사전 훈련과 검색 증강 방식에 대해 논의합니다.

### 3. 방법론
- **도메인 특화 사전 훈련(Domain-specific Pre-training, DP)**: 특정 도메인 데이터를 사용하여 소형 모델을 사전 훈련시켜 도메인 지식을 내재화합니다.
- **지식 지시 튜닝(Knowledge Instruction Tuning, KIT)**: 소형 모델이 특정 쿼리에 맞는 지식을 생성할 수 있도록 합니다. 이를 위해 사전 훈련된 대형 모델을 활용하여 유사 데이터를 생성하고, 이를 소형 모델의 튜닝에 사용합니다.
- **베이지안 프롬프트 최적화(Bayesian Prompted Optimization, BPO)**: 대형 모델과 소형 모델 간의 출력을 조정하여, 소형 모델이 생성한 지식이 대형 모델의 이해와 일치하도록 최적화합니다.

### 4. 실험
- 법률 및 의학 분야에서의 질의응답(QA) 작업을 통해 BLADE의 유효성을 검증합니다. BLADE는 기존 방법론들과 비교하여 뛰어난 성능을 보여줍니다.

### 5. 결론
- BLADE는 소형 도메인 특화 모델을 활용하여 LLMs의 도메인 적응 능력을 향상시키는 효과적인 방법임을 입증합니다. 향후, 이 방법론을 다양한 도메인과 작업에 적용하여 그 범용성을 더욱 확장할 계획입니다.

이 연구는 특정 도메인에 대한 대규모 언어 모델의 적응력을 향상시킬 수 있는 새로운 방법론을 제시하며, 이를 통해 AI와 기계 학습 분야의 발전에 기여할 수 있습니다.