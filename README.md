# Paper List
## 2404
#### [BRAVE: Broadening the visual encoding of vision-language models](summaries/2404.07204.md)
#### [RealmDreamer: Text-Driven 3D Scene Generation with Inpainting and Depth Diffusion](summaries/2404.07199.md)
#### [Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](summaries/2404.07143.md)
#### [DreamScene360: Unconstrained Text-to-3D Scene Generation with Panoramic Gaussian Splatting](summaries/2404.06903.md)
#### [Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior](summaries/2404.06780.md)
#### [Adapting LLaMA Decoder to Vision Transformer](summaries/2404.06773.md)
#### [RULER: What's the Real Context Size of Your Long-Context Language Models?](summaries/2404.06654.md)
#### [InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD](summaries/2404.06512.md)
#### [Reconstructing Hand-Held Objects in 3D](summaries/2404.06507.md)
#### [Magic-Boost: Boost 3D Generation with Mutli-View Conditioned Diffusion](summaries/2404.06429.md)
#### [MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies](summaries/2404.06395.md)
#### [MuPT: A Generative Symbolic Music Pretrained Transformer](summaries/2404.06393.md)
#### [OmniFusion Technical Report](summaries/2404.06212.md)
#### [Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models](summaries/2404.06209.md)
#### [Revising Densification in Gaussian Splatting](summaries/2404.06109.md)
#### [Hash3D: Training-free Acceleration for 3D Generation](summaries/2404.06091.md)
#### [LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders](summaries/2404.05961.md)
#### [Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence](summaries/2404.05892.md)
#### [CodecLM: Aligning Language Models with Tailored Synthetic Data](summaries/2404.05875.md)
#### [SambaLingo: Teaching Large Language Models New Languages](summaries/2404.05829.md)
#### [MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding](summaries/2404.05726.md)
#### [Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs](summaries/2404.05719.md)
#### [SwapAnything: Enabling Arbitrary Object Swapping in Personalized Visual Editing](summaries/2404.05717.md)
#### [MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation](summaries/2404.05674.md)
#### [YaART: Yet Another ART Rendering Technology](summaries/2404.05666.md)
#### [UniFL: Improve Stable Diffusion via Unified Feedback Learning](summaries/2404.05595.md)
#### [MagicTime: Time-lapse Video Generation Models as Metamorphic Simulators](summaries/2404.05014.md)
#### [ByteEdit: Boost, Comply and Accelerate Generative Image Editing](summaries/2404.04860.md)
#### [BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion](summaries/2404.04544.md)
#### [DATENeRF: Depth-Aware Text-based Editing of NeRFs](summaries/2404.04526.md)
#### [Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models](summaries/2404.04478.md)
#### [Aligning Diffusion Models by Optimizing Human Utility](summaries/2404.04465.md)
#### [PhysAvatar: Learning the Physics of Dressed 3D Avatars from Visual Observations](summaries/2404.04421.md)
#### [Koala: Key frame-conditioned long video-LLM](summaries/2404.04346.md)
#### [SpatialTracker: Tracking Any 2D Pixels in 3D Space](summaries/2404.04319.md)
#### [Sigma : Siamese Mamba Network for Multi-Modal Semantic Segmentation](summaries/2404.04256.md)
#### [Robust Gaussian Splatting](summaries/2404.04211.md)
#### [Social Skill Training with Large Language Models](summaries/2404.04204.md)
#### [Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model](summaries/2404.04167.md)
#### [No “Zero-Shot” Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance](summaries/2404.04125.md)
#### [CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues](summaries/2404.03820.md)
#### [Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences](summaries/2404.03715.md)
#### [Stream of Search (SoS): Learning to Search in Language](summaries/2404.03683.md)
#### [RL for Consistency Models: Faster Reward Guided Text-to-Image Generation](summaries/2404.03673.md)
#### [CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept Matching](summaries/2404.03653.md)
#### [AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent](summaries/2404.03648.md)
#### [Training LLMs over Neurally Compressed Text](summaries/2404.03626.md)
#### [ReFT: Representation Finetuning for Language Models](summaries/2404.03592.md)
#### [PointInfinity: Resolution-Invariant Point Diffusion Models](summaries/2404.03566.md)
#### [CodeEditorBench: Evaluating Code Editing Capability of Large Language Models](summaries/2404.03543.md)
#### [MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens](summaries/2404.03413.md)
#### [Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks?](summaries/2404.03411.md)
#### [RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis](summaries/2404.03204.md)
#### [LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models](summaries/2404.03118.md)
#### [Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction](summaries/2404.02905.md)
#### [ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline](summaries/2404.02893.md)
#### [On the Scalability of Diffusion-based Text-to-Image Generation](summaries/2404.02883.md)
#### [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](summaries/2404.02575.md)
#### [Mixture-of-Depths: Dynamically allocating compute in transformer-based language models](summaries/2404.02258.md)
#### [Advancing LLM Reasoning Generalists with Preference Trees](summaries/2404.02078.md)
#### [Long-context LLMs Struggle with Long In-context Learning](summaries/2404.02060.md)
#### [HyperCLOVA X Technical Report](summaries/2404.01954.md)
#### [Poro 34B and the Blessing of Multilinguality](summaries/2404.01856.md)
#### [Octopus v2: On-device language model for super agent](summaries/2404.01744.md)
#### [LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models](summaries/2404.01617.md)
#### [Are large language models superhuman chemists?](summaries/2404.01475.md)
#### [LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model](summaries/2404.01331.md)
#### [HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach](summaries/2404.01094.md)
## 2403
#### [BLADE: Enhancing Black-box Large Language Models with Small Domain-Specific Models](summaries/2403.18365.md)
#### [Fully-fused Multi-Layer Perceptrons on Intel Data Center GPUs](summaries/2403.17607.md)
#### [Gemma: Open Models Based on Gemini Research and Technology](summaries/2403.08295.md)
#### [Learning to Decode Collaboratively with Multiple Language Models](summaries/2403.03870.md)
## 2402
#### [The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](summaries/2402.17764.md)
#### [When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method](summaries/2402.17193.md)
#### [Training Neural Networks from Scratch with Parallel Low-Rank Adapters](summaries/2402.16828.md)
#### [Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models](summaries/2402.14714.md)
#### [DoRA: Weight-Decomposed Low-Rank Adaptation](summaries/2402.09353.md)
#### [More Agents Is All You Need](summaries/2402.05120.md)
## 2401
#### [Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads](summaries/2401.10774.md)
#### [Tuning Language Models by Proxy](summaries/2401.08565.md)
## 2312
#### [SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling](summaries/2312.15166.md)
#### [LoRAMoE: Alleviate World Knowledge Forgetting in Large Language Models via MoE-Style Plugin](summaries/2312.09979.md)
## 2311
#### [MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training](summaries/2311.17049.md)
#### [FlashDecoding++: Faster Large Langauge Model Inference on GPUs](summaries/2311.01282.md)
## 2310
#### [EELBERT: Tiny Models through Dynamic Embeddings](summaries/2310.20144.md)
## 2308
#### [Fast Feedforward Networks](summaries/2308.14711.md)
#### [EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models](summaries/2308.14352.md)
## 2304
#### [Visual Instruction Tuning](summaries/2304.08485.md)
## 2302
#### [Full Stack Optimization of Transformer Inference: a Survey](summaries/2302.14017.md)
## 2202
#### [cosFormer: Rethinking Softmax in Attention](summaries/2202.08791.md)
## 2106
#### [LoRA: Low-Rank Adaptation of Large Language Models](summaries/2106.09685.md)
