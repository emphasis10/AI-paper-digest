# Full Stack Optimization of Transformer Inference: a Survey
## TL;DR
## Summary
- [https://arxiv.org/pdf/2302.14017.pdf](https://arxiv.org/pdf/2302.14017.pdf)

이 논문은 트랜스포머 모델의 추론 성능을 최적화하는 다양한 방법을 조사하고 분석합니다. 구체적으로, 모델의 아키텍처, 하드웨어 설계, 최적화 기법, 작업 할당 방법에 이르기까지, 트랜스포머 모델의 추론 효율을 높이기 위한 전반적인 접근 방식을 탐구합니다. 이 논문은 UC 버클리의 연구자들에 의해 작성되었으며, Gemmini라는 오픈 소스 DNN 가속기 생성기에 적용된 최적화 방법을 사례 연구로 제시합니다. 이 사례 연구를 통해, 다양한 최적화 기법이 트랜스포머 추론에 미치는 영향을 살펴보고, 이러한 접근 방식이 Gemmini의 벤치마크 결과를 어떻게 개선하는지 보여줍니다. 연구 결과, 트랜스포머 모델을 위한 전체 스택 최적화 방식을 사용하여 추론 속도를 최대 88.7배 향상시킬 수 있음을 발견했습니다.

### 요약

1. **서론**:
    - 딥러닝 모델은 막대한 계산과 메모리 요구사항으로 인해, 특히 엣지 디바이스에서의 효율적인 실행이 중요한 과제가 되었습니다.
    - 트랜스포머 모델의 등장으로 NLP 작업에서 뛰어난 성능을 달성했지만, 이들의 복잡성과 크기는 추론 효율성을 높이기 위한 새로운 도전을 제시합니다.
2. **트랜스포머 모델 아키텍처와 성능 병목**:
    - 트랜스포머 모델의 구성 요소와 성능에 영향을 미치는 주요 병목 현상을 분석합니다.
3. **하드웨어 설계**:
    - DNN 가속기의 일반적인 구조를 소개하고, 트랜스포머 모델을 위한 가속기 설계에 대해 논의합니다.
4. **모델 최적화**:
    - 트랜스포머 모델의 추론 성능을 향상시키기 위한 다양한 최적화 기법을 조사합니다.
5. **하드웨어 매핑**:
    - 트랜스포머 모델을 하드웨어에 매핑하는 과정을 탐구하고, 이를 최적화하는 방법에 대해 설명합니다.
6. **결론**:
    - 트랜스포머 모델의 추론 성능을 최적화하기 위한 다양한 접근 방식을 종합적으로 평가하고, 향후 연구 방향을 제시합니다.

이 논문은 트랜스포머 모델의 추론 효율을 극대화하기 위한 종합적인 접근 방식을 제공합니다. 또한, 실제 하드웨어 가속기에 적용된 최적화 기법을 통해, 이론적인 연구가 실제 성능 향상으로 어떻게 연결될 수 있는지 보여줍니다.