# Tuning Language Models by Proxy
## TL;DR
## Summary
이 문서는 대규모 사전 훈련된 언어 모델이 추가적인 미세조정을 통해 원하는 동작을 더 잘 달성할 수 있다는 점에서 출발합니다. 모델 가중치가 비공개인 경우 이러한 모델의 튜닝은 점점 더 자원 집약적이거나 불가능해지고 있습니다. 이에 대응하여, 이 연구팀은 "프록시 튜닝(proxy-tuning)"이라는 경량의 디코딩 시간 알고리즘을 소개합니다. 이 방법은 모델의 내부 가중치에 접근하지 않고도, 작은 모델을 튜닝한 뒤, 그 차이를 이용하여 큰 모델의 예측을 조정함으로써 미세조정과 동일한 결과를 달성합니다. 프록시 튜닝은 LLAMA2-70B 모델을 사용한 실험에서 지식, 추론, 안전 벤치마크를 통틀어 진정한 튜닝 버전과의 성능 격차의 88%를 해소했음을 보여줍니다. 특히, 진실성을 평가하는 TruthfulQA에서는 프록시 튜닝이 직접 튜닝된 모델보다 더 진실되게 답변함을 보여주었습니다. 이는 디코딩 시간의 지도가 모델의 사실 지식을 더 잘 보존할 수 있음을 시사합니다.

### 1. 소개

최근 대규모 사전 훈련된 언어 모델의 일반화 능력이 향상되었지만, 추가적인 미세조정을 통해 특정 도메인, 작업, 지침을 따르는 능력 등 원하는 동작을 더 잘 달성할 수 있습니다. 그러나 이러한 모델을 튜닝하는 것은 점점 더 많은 자원을 요구하며, 모델 가중치가 비공개일 경우 튜닝이 불가능할 수 있습니다. 연구팀은 이 문제를 해결하기 위해 프록시 튜닝을 제안합니다. 이는 모델의 예측만을 사용하여, 작은 모델을 튜닝한 뒤 이 차이를 큰 모델의 예측에 적용함으로써 미세조정과 유사한 결과를 달성하는 방법입니다.

### 2. 방법

프록시 튜닝은 미세조정된 소규모 모델(전문가 모델)과 미세조정되지 않은 버전(반전문가 모델)의 예측 차이를 이용합니다. 이 차이는 큰 모델의 기본 예측에 적용되어 튜닝 방향으로 예측을 조정합니다. 이 방법은 디코딩 시간에만 적용되며, 모델의 내부 가중치는 수정하지 않습니다.

### 3. 실험

연구팀은 지식, 추론, 안전성을 평가하는 다양한 벤치마크를 통해 프록시 튜닝의 효과를 검증했습니다. 결과는 프록시 튜닝이 큰 모델(LLAMA2-70B)의 예측을 작은 모델(LLAMA2-7B)의 튜닝 효과에 가깝게 만들 수 있음을 보여줍니다. 특히, TruthfulQA에서는 프록시 튜닝 모델이 직접 튜닝된 모델보다 더 진실되게 답변하는 결과를 보였습니다.

### 결론

이 연구는 대규모 언어 모델을 효율적으로 맞춤화할 수 있는 새로운 방법을 제시합니다. 프록시 튜닝은 디코딩 시간에 적용되어 추가적인 훈련 없이도 모델의 예측을 원하는 방향으로 조정할 수 있습니다. 이는 특히 모델 가중치가 비공개인 경우 유용할 수 있으며, 다양한 도메인과 작업에 대한 모델의 적응성을 높이는 데 기여할 것입니다.