# Octopus v2: On-device language model for super agent
## TL;DR
## Summary
**1. 섹션별 요약 및 중요 내용**

이 논문은 "Octopus v2: On-device language model for super agent"라고 명명된 인공지능(AI) 및 머신러닝(ML) 연구에 관한 것입니다.

- **서론 및 관련 연구(Sections: Introduction, Related works)**
  - 서론에서는 대형 언어 모델이 소프트웨어 산업 내 AI 에이전트의 발전에 크게 기여했다고 언급됩니다. 클라우드 기반 모델에 대한 의존도가 높아지면서 프라이버시, 비용, Wi-Fi 연결 필요성과 같은 문제가 대두되고 있습니다.

- **기기 내 언어 모델 배포(Deployment of on-device language models)**
  - 기기 내 언어 모델 배포는 메모리 한계와 더뎌진 추론 속도 때문에 어려움을 겪고 있습니다. 그럼에도 불구하고, 2B부터 7B까지의 작은 규모의 대형 언어 모델(Large Language Models, LLMs)을 기기 내에서 구동하기 위한 여러 시도가 진행 중입니다.

- **언어 모델에서의 함수 호출(Function calling in language models)**
  - 7B와 13B 모델이 외부 API를 호출하는 능력에 대한 빠른 발전이 있었으며, 이는 GPT-4와 비슷한 수준입니다. Octopus v1 프로젝트는 2B 모델이 GPT-4와 동등한 성능을 내도록 했습니다.

- **방법론(Methodology)**
  - 모델은 함수명을 예측하고 정확한 함수를 호출하기 위해 새로운 토큰들을 도입함으로써 기능명 예측의 정확도를 향상시키고 필요한 토큰 수를 감소시킵니다.

- **실험(Experiments)**
  - 해당 모델의 적용 사례로 안드로이드 시스템 함수 호출을 선택하였습니다 . 이는 함수 호출의 정확도와 지연 시간을 중점적으로 다룹니다. Octopus 모델은 1000개의 데이터 포인트를 샘플링한 결과 평가 데이터셋에서 99.524%의 정확도를 보여주었습니다.

- **토론 및 미래 작업(Discussion and future works)**
  - 연구는 어떠한 특정 함수도 새로운 용어인 "기능적 토큰"으로 포장할 수 있음을 입증합니다. 이는 비용 효과적인 훈련 과정을 통해 높은 정확도와 낮은 지연 시간을 갖춘 AI 에이전트의 배치를 가능하게 합니다. 미래에는 기기 내 추론에 전념하는 모델을 개발할 계획이며, 이는 클라우드 배포와 로컬 배포 모두에서 사용자의 다양한 요구를 만족시키는 데 목표를 두고 있습니다.

**2. 전체 요약**

이 연구는 대형 언어 모델이 소프트웨어 산업의 AI 에이전트 발전에 중요하고 비판적인 역할을 수행함을 확인합니다. 특히 클라우드 기반 모델이 프라이버시 및 비용과 관련된 문제점을 안고 있는 가운데, 이 논문은 기기 내에서 동작하는 선진적 언어 모델인 'Octopus v2'를 제시합니다. 이 모델은 GPT-4를 능가하는 정확도와 지연 시간을 달성하며, 동시에 고려된 새로운 방식의 함수 호출을 통해 효율성을 크게 향상시킵니다. 각 섹션은 모델 개발과 실험을 통해 이러한 주장을 뒷받침하며, 마지막으로 논문은 AI 에이전트의 미래 발전 방향과 기술적 진보에 대한 영향을 논의합니다. 이러한 발견은 애플리케이션 개발자와 운영 체제 내에서의 모델 적용 가능성을 포함하여, 연구 결과의 광범위한 영향력을 시사합니다.