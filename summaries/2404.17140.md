# Small Language Models Need Strong Verifiers to Self-Correct Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.17140.pdf](https://arxiv.org/pdf/2404.17140.pdf)

### 1. 논문 각 섹션 요약 및 주요 기여

#### 1.1 서론
이 논문은 소규모 언어 모델이 자기 수정을 통해 추론 성능을 향상시킬 수 있는지에 대한 내용을 다룹니다. 주요 기여는 소규모 언어 모델이 강력한 언어 모델의 도움 없이도 자기 수정 능력을 학습할 수 있는 새로운 파이프라인인 SCORE를 제안한 것입니다.

#### 1.2 관련 연구
이 논문에서는 자기 수정과 관련된 최근 연구를 소개합니다. 대형 언어 모델이 스스로 문제를 해결하는 방법과 소규모 모델의 잠재력을 탐색합니다.

#### 1.3 SCORE 방법론
SCORE는 두 가지 주요 단계로 구성된 파이프라인입니다:
1. **비판 생성 및 필터링**: 소규모 언어 모델이 스스로 오류를 비판하도록 유도하고, 생성된 비판을 필터링하여 품질 높은 데이터를 확보합니다.
2. **정련자의 감독 하에 미세 조정**: 필터링된 비판 데이터를 사용하여 소규모 언어 모델을 미세 조정합니다.

#### 1.4 실험 결과
이 논문은 다양한 데이터셋과 소규모 언어 모델(LLaMA-2-13B-chat 및 Gemma-7B-it)을 사용하여 SCORE 파이프라인의 효과를 평가합니다. 주요 발견점은 다음과 같습니다:
1. SCORE 파이프라인을 사용하면 모델의 자기 수정 능력이 크게 향상됩니다.
2. 소규모 모델이 자기 수정 능력을 학습하는 데 강력한 검증자가 필요함을 보여줍니다.

#### 1.5 논의
자기 수정은 추론 성능을 극대화하는 데 있어 중요한 요소임을 강조합니다. 또한, 검증자의 강도가 모델의 성능에 미치는 영향을 분석합니다.

#### 1.6 결론 및 향후 연구
SCORE 파이프라인이 소규모 언어 모델의 자기 수정 능력을 향상시킬 수 있음을 결론 짓고, 다음 단계로 강력한 검증자를 어떻게 더 효과적으로 통합할 수 있을지에 대한 방향을 제시합니다.

### 2. 전체 요약

이 논문은 소규모 언어 모델이 자기 수정 능력을 향상시키기 위한 새로운 방법론인 SCORE를 제안합니다. 핵심 기여는 다음과 같습니다:
1. **SCORE 파이프라인**: 소규모 언어 모델이 스스로 생성한 비판 데이터를 이용하여 자기 수정 능력을 미세 조정합니다.
2. **실험 결과**: 다양한 데이터셋에서 SCORE 파이프라인을 통해 소규모 모델의 자기 수정 성능이 크게 향상됨을 입증했습니다. 특히 강력한 검증자(GPT-4)를 사용했을 때 성능이 더욱 향상되었습니다.
3. **미래 연구 방향**: 검증자의 강도를 높이는 방법과 더 나은 비판 데이터를 생성하는 방법을 제시합니다.

이 논문의 주요 혁신은 소규모 언어 모델이 강력한 언어 모델의 도움 없이도 자기 수정 능력을 학습할 수 있다는 점을 입증했다는 것입니다. 이는 향후 AI 개발에 있어 중요한 발판이 될 것입니다.

## Similar Papers
- [Estimating Knowledge in Large Language Models Without Generating a Single Token](2406.12673.md)
- [Large Language Monkeys: Scaling Inference Compute with Repeated Sampling](2407.21787.md)
- [Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning](2407.18248.md)
- [Large Language Models Are Reasoning Teachers](2212.10071.md)
- [LiteSearch: Efficacious Tree Search for LLM](2407.00320.md)
- [Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer Selection in Large Language Models](2405.12939.md)
- [Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought](2404.03414.md)
- [ExtraNeRF: Visibility-Aware View Extrapolation of Neural Radiance Fields with Diffusion Models](2406.06133.md)
- [Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs](2406.18629.md)
