# Inside-Out: Hidden Factual Knowledge in LLMs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2503.15299.pdf](https://arxiv.org/pdf/2503.15299.pdf)

1. 각 섹션 요약:

   - **서론(Introduction)**:
     이 논문은 대형 언어 모델(LLM)이 내재적(hidden) 지식을 파라미터 내에 얼마나 저장하고 있는지를 평가하는 새로운 프레임워크를 제시합니다. 이는 이전 연구에서 다루지 않았던 개념으로, 모델이 출력에서 표현하는 정보 이상으로 내부에 더 많은 사실적 정보를 보유할 수 있음을 보여줍니다.

   - **지식의 정의와 시스템(Defining Knowledge System)**:
     지식을 정의하는 방법을 제안하며, 모델이 묻는 질문에 대해 정확한 답을 제공하는 능력을 평가하는 방법론을 제공합니다. 이는 추후 숨겨진 지식을 탐구하는 데 중요한 토대를 형성합니다.

   - **숨겨진 지식(Hidden Knowledge)**:
     자체 평가 시스템을 통해 LLM이 얼마나 많은 지식을 내부적으로 저장하고 있는지를 측정합니다. 연구 결과, 모델이 종종 답을 알고 있지만 명백하게 표현하지 못하는 경우가 밝혀졌습니다.

   - **사례 연구(Case Study)**:
     구체적인 사례를 통해 모델이 실제로 알고 있는 정보와 생성 과정 간의 격차를 조명합니다. 예시로 주어진 질문에 대한 내부 점수가 올바른 답을 더 높게 평가하면서도, 실제 출력물에서는 이를 재현하지 못하는 경우를 설명합니다.

   - **결론 및 향후 연구(Conclusion and Future Research)**:
     LLM의 지식이 외부 표현을 넘어서는 부분에 대한 틀을 확립하고 이를 평가하는 중요성을 강조합니다. 또한, 향후 연구에서 모델의 내부 지식을 더 잘 드러낼 수 있는 방법을 개발하는 것이 중요함을 논의합니다.

2. 전체 요약:
   
   이 논문은 대형 언어 모델(LLM)이 외부적으로 표현하는 정보 외에 내부적으로 더 많은 지식을 저장할 가능성을 최초로 체계적으로 평가한 연구입니다. 저자들은 명확한 지식 정의를 통해 내부적 평가와 외부적 표현 간의 차이를 강조하며, 이러한 숨겨진 지식을 드러내는 것이 다음 세대 AI 모델의 해석력과 신뢰성을 증진시킬 수 있음을 보여줍니다. 모델이 알고 있는 것을 더 잘 사용할 수 있도록 설계하는 것이 중요하며, 쉽게 드러나지 않는 지식을 효과적으로 활용할 수 있는 방법론이 제시되었습니다.