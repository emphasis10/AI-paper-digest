# SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with Text-Rich Visual Comprehension
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.16790.pdf](https://arxiv.org/pdf/2404.16790.pdf)

이 논문에서는 SEED-Bench-2-Plus 벤치마크를 소개합니다. 이 벤치마크는 다양한 시각적 맥락에서 텍스트를 풍부하게 포함한 시나리오의 이해를 평가하기 위해 설계되었으며, 주로 차트, 지도, 웹 페이지를 포함합니다. 이 벤치마크는 특히 다중 모달 대규모 언어 모델(MLLMs)의 시각적 이해 능력을 테스트하기 위한 것입니다. 다음은 각 섹션의 주요 내용 요약입니다.

1. **서론 및 관련 작업**:
   - 대규모 언어 모델(LLMs)을 활용하여 다양한 시각적 맥락에서의 텍스트 이해능력을 강조하고, 이를 실세계 시나리오에 적용하는 것이 중요합니다.
   - 기존의 벤치마크들이 일반적인 시각적 이해에 초점을 맞춘 반면, SEED-Bench-2-Plus는 텍스트-풍부한 시나리오에서 MLLMs의 능력을 평가하기 위해 특별히 설계되었습니다.

2. **SEED-Bench-2-Plus 벤치마크**:
   - 총 2.3K개의 다지선다형 문제를 포함하며, 이는 차트, 지도, 웹 페이지와 같은 63가지의 다양한 데이터 유형을 커버합니다.
   - 각 질문은 정밀한 인간의 주석이 달린 정답을 포함하여 신뢰성을 보장합니다.

3. **데이터 출처 및 평가 전략**:
   - 데이터는 인터넷에서 수집된 텍스트 정보가 풍부한 이미지들로 구성됩니다.
   - 평가 전략은 각 선택지에 대해 MLLM이 주어진 질문에 따라 이 선택지의 내용을 생성할 가능성을 계산하고, 가장 높은 가능성을 보이는 선택지를 모델의 예측으로 선택합니다.

4. **실험 및 결과**:
   - 34개의 주요 MLLMs를 평가하여 현재 모델들이 텍스트-풍부한 정보를 이해하는 데에 있어서의 한계와 강점을 밝혀냈습니다.
   - 결과는 텍스트-풍부한 데이터에서 모델들의 성능 차이를 보여주며, 일부 모델은 특히 높은 성능을 보였습니다.

이 벤치마크는 MLLMs의 텍스트-풍부한 시각 데이터 이해 능력을 포괄적으로 평가하고, 이 분야에서의 추가적인 연구를 촉진하기 위한 중요한 기여를 합니다.