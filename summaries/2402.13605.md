# KorNAT: LLM Alignment Benchmark for Korean Social Values and Common Knowledge
## TL;DR
## Summary
- [https://arxiv.org/pdf/2402.13605.pdf](https://arxiv.org/pdf/2402.13605.pdf)

### 논문의 주요 내용 요약

#### 1. 서론 (Introduction)
이 논문은 대형 언어 모델(LLMs)을 특정 국가에 효과적으로 배치하기 위해 국가의 문화와 기본 지식을 이해해야 한다는 점을 강조합니다. 이를 위해 한국의 사회적 가치 및 공통 지식과의 정렬을 측정하는 KorNAT라는 벤치마크를 소개합니다. 사회적 가치 정렬은 모델이 국가 특정 사회적 가치를 얼마나 잘 이해하는지를 평가하고, 공통 지식 정렬은 모델이 국가와 관련된 기본 지식을 얼마나 잘 포착하는지를 평가합니다.

#### 2. KorNAT
KorNAT는 한국과의 국가 정렬을 측정하는 최초의 벤치마크입니다. 사회적 가치 데이터셋은 6,174명의 한국 참가자로부터 대규모 설문 조사를 통해 얻은 라벨로 구성되었습니다. 공통 지식 데이터셋은 한국 교과서 및 GED 참조 자료를 기반으로 샘플을 구성했습니다. KorNAT는 각각 4K와 6K의 객관식 질문을 포함하고 있습니다. 데이터셋 생성 과정은 통계적 샘플링 이론을 기반으로 설계되었으며, 여러 차례의 인간 검토를 통해 세련되었습니다.

#### 3. 사회적 가치 정렬 (Social Value Alignment)
사회적 가치 정렬은 LLM이 한국의 사회적 가치에 얼마나 잘 맞추어져 있는지를 평가합니다. 이 데이터셋은 다양한 연령과 성별 그룹에서 수집된 설문 조사 데이터를 기반으로 합니다. 실험 결과, 대부분의 모델이 기준 점수에 미치지 못했음을 보여줍니다.

#### 4. 공통 지식 정렬 (Common Knowledge Alignment)
공통 지식 정렬은 LLM이 한국의 기본 지식을 얼마나 잘 이해하고 있는지를 평가합니다. 이 데이터셋은 한국 교과서와 GED 자료를 기반으로 합니다. 실험 결과, 일부 모델만이 기준 점수에 도달했음을 보여줍니다.

#### 5. 실험 (Experiments)
실험은 Llama-2, GPT-3.5-Turbo, GPT-4, Claude-1, HyperCLOVA X, PaLM-2, Gemini Pro 등 7개의 모델을 대상으로 수행되었습니다. 실험에서는 다섯 가지 다른 프롬프트를 사용하여 모델의 응답을 평가하였습니다. 결과적으로, 대부분의 모델이 KorNAT의 기준 점수에 미치지 못했음을 확인했습니다.

#### 6. 결론 (Conclusion)
KorNAT는 한국과의 국가 정렬을 측정하는 유용한 벤치마크로서, 모델이 한국의 사회적 가치와 공통 지식을 얼마나 잘 이해하는지 평가할 수 있는 도구를 제공합니다. 실험 결과, 대부분의 모델이 기준 점수에 미치지 못했으며, 이는 모델의 성능을 향상시킬 수 있는 여지가 있음을 시사합니다.

### 전체 요약
이 논문은 한국의 사회적 가치와 공통 지식에 맞추어 대형 언어 모델(LLMs)의 성능을 평가하기 위한 KorNAT 벤치마크를 소개합니다. KorNAT는 사회적 가치 정렬과 공통 지식 정렬 두 가지 측면에서 LLM의 성능을 평가하며, 이는 대규모 설문 조사와 교과서 기반 데이터를 통해 구성되었습니다. 7개의 다양한 모델을 대상으로 한 실험 결과, 대부분의 모델이 기준 점수에 미치지 못했으며, 이는 모델 성능을 향상시킬 수 있는 가능성을 보여줍니다. 이 연구는 LLM이 특정 국가의 문화와 지식을 이해하는 데 중요한 기여를 할 수 있으며, 앞으로 더 많은 연구와 개선이 필요함을 강조합니다.

## Similar Papers
- [BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval](2407.12883.md)
- [DialSim: A Real-Time Simulator for Evaluating Long-Term Dialogue Understanding of Conversational Agents](2406.13144.md)
- [EHRCon: Dataset for Checking Consistency between Unstructured Notes and Structured Tables in Electronic Health Records](2406.16341.md)
- [Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction](2404.12957.md)
- [ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline](2404.02893.md)
- [LAB-Bench: Measuring Capabilities of Language Models for Biology Research](2407.10362.md)
- [Click-Gaussian: Interactive Segmentation to Any 3D Gaussians](2407.11793.md)
- [ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers](2206.01861.md)
- [LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report](2405.00732.md)
