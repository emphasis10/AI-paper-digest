# Beyond LLaVA-HD: Diving into High-Resolution Large Multimodal Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.08487.pdf](https://arxiv.org/pdf/2406.08487.pdf)

### 개별 섹션 요약

#### 1. 소개 (Introduction)
이 문서에서는 대규모 멀티모달 모델(LMMs)의 발전을 탐구합니다. 특히 고해상도 이미지를 활용한 시도가 복잡한 시각적 인식 및 추론 작업을 개선할 수 있음을 보여줍니다. 기존의 방법들은 이미지 해상도를 높이기 위해 구획화 전략을 사용하나 높은 계산 비용으로 인해 어려움이 따릅니다. 이를 해결하기 위해, 전역 정보와 지역 정보를 모두 보존하면서 데이터를 처리하는 새로운 프레임워크를 제안합니다.

#### 2. 방법론 (Methodology)
**슬라이스 및 스케일링 (Adaptive Slicing)**: 이미지를 다양한 그리드로 나눠 세밀하게 처리.
**전문가 혼합 (Mixture of Experts)**: 서로 다른 전문가 모델을 사용해 전역 맥락을 추출.
**지역 특징 압축 (Local Feature Compression)**: 쿼리 트랜스포머를 활용해 지역 이미지를 압축.
**텍스트-가이드 라우터 (Text-Guided Router)**: 텍스트 입력에 따라 중요한 이미지 토큰을 선택.
에너지 병렬 최적화를 위해, 전역 맥락과 지역 특징을 각각 다룰 수 있도록 설계되었습니다.

#### 3. 실험 (Experiments)
새로운 프레임워크인 SliME을 통한 실험을 통해 대규모 언어 모델(LLMs)과의 결합에서 높은 성능을 보였습니다. 주된 실험 결과는 다음과 같습니다:
- 다양한 벤치마크에서 선두 성능을 보여, 기존 모델과 유사하거나 더 나은 결과를 도출.
- 한정된 데이터로도 효율적인 학습 가능.

#### 4. 결론 (Conclusion)
제안된 프레임워크 SliME은 고해상도 이미지 처리 능력을 바탕으로 뛰어난 성능을 입증했습니다. 이는 전역 정보와 지역 정보를 동시에 처리하는 능력 덕분으로, 멀티모달 모델의 발전에 중요한 기여를 할 것으로 기대됩니다.

### 주요 기여 및 혁신 부분 요약

이 연구는 대규모 멀티모달 모델의 새로운 프레임워크를 제안하여, 고해상도 이미지 처리에서의 전역 및 지역 정보의 동시 활용이 가능하도록 합니다. 
- **주요 기여**: 전역 맥락을 보존하면서 지역 특징도 효율적으로 처리하는 새로운 방법론 제안.
- **혁신적 요소**: 전문가는 혼합하고 쿼리 트랜스포머를 사용해 이미지 토큰을 최적화하여, 모델의 계산 효율성을 높이며 동시에 성능을 개선.

### 전체 요약

이 논문에서는 대규모 멀티모달 모델의 고해상도 이미지 이해 능력을 개선하기 위한 새로운 프레임워크(SliME)를 제안합니다. 이를 통해 전역 맥락을 보존하면서 지역 이미지를 효율적으로 압축하고 처리할 수 있는 방법을 소개합니다. 실험 결과, 이 접근법은 다양한 설정에서 뛰어난 성능을 보였으며, 이는 멀티모달 모델의 발전에 중요한 기여를 할 것으로 예상됩니다. 각 섹션에 대한 상세한 분석과 함께, 고해상도 이미지 처리에서의 혁신적인 방법론이 제안되었습니다. 