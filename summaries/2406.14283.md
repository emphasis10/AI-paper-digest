# Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.14283.pdf](https://arxiv.org/pdf/2406.14283.pdf)

### Section Summaries and Contributions

#### 1. Introduction
대규모 언어 모델(LLMs)은 다양한 자연어 작업에서 놀라운 성능을 보여주지만, 자동회귀 생성 과정에서 다단계 추론 시 오류, 환각, 일관성 없는 진술을 생성할 가능성이 높습니다. 본 논문은 Q*라는 일반적이고 다목적적인 프레임워크를 소개하여, LLMs가 다단계 추론을 수행할 때 계획적인 지식을 통합하여 더 나은 성과를 내는 방법을 제안합니다. Q*는 높게 평가된 다음 단계를 선택토록 안내하여 LLMs 성능을 향상시키며, 특정 작업에 대해 LLMs을 미세 조정할 필요 없이 높은 성능을 제공합니다.

#### 2. Related Works
기존의 연구들에서는 LLMs의 추론 능력을 향상시키기 위해 여러 기법들이 적용되었지만, 대부분이 특정 작업에 대한 의견 제공에 초점을 맞추거나 인간 피드백을 기반으로 한 보상 모델을 학습하는 방식입니다. 이에 반해, Q*는 별도의 코퍼스를 필요로 하지 않으며, 다양한 작업에서 보편적으로 적용 가능한 방식을 제공합니다.

#### 3. Preliminary
LLM의 다단계 추론 문제를 마르코프 결정 과정(MDP)으로 공식화합니다. 상태는 입력 프롬프트와 지금까지 생성된 추론 단계이며, 행동은 다음 추론 단계이고, 보상은 작업 수행의 정도를 측정합니다. 이 공식화는 Q* 프레임워크의 기반을 제공하며, 최적의 Q값을 추정하여 더 나은 추론 경로를 찾는 방법론을 상세히 설명합니다.

#### 4. Formulate the Multi-step Reasoning of LLMs as an MDP
다단계 추론을 해결하기 위해 LLMs의 상태-행동 쌍에 대해 최적 Q값을 추정하는 여러 접근법을 제시합니다. 여기에는 오프라인 강화 학습, 롤아웃에서 최적 시퀀스 선택, 더 강력한 LLMs로 완료 등의 방법이 포함됩니다. 이러한 방법들은 대규모 코퍼스 없이도 다양한 추론 작업에 쉽게 적용될 수 있습니다.

#### 5. A* Search
LLM의 최적의 Q-값 모델을 기반으로 A* 검색을 수행하여 LLMs가 최적의 다음 추론 단계를 선택하도록 안내합니다. 이 프레임워크는 계산 집약적인 롤아웃을 수행하지 않고도 효과적인 결과를 제공합니다.

#### 6. Experiments
Q* 프레임워크의 효과를 수학적 추론 및 코드 생성 작업에서 실험적으로 평가합니다. 실험 결과, Q* 프레임워크는 기존의 베이스라인보다 뛰어난 성능을 보여줍니다. 특히 수학 문제 해결과 코드 생성 작업에서 Q*가 상당한 성능 향상을 이루었다고 보고합니다.

### Overall Summary

논문은 Q*라는 다목적 프레임워크를 통해 LLMs의 다단계 추론 성능을 향상시키는 방법을 제안합니다. Q*는 특정 작업에 대해 LLMs을 미세 조정할 필요 없이, 오프라인 강화 학습과 A* 검색을 통해 최적의 추론 단계를 선택하도록 안내합니다. 실험 결과, 수학적 추론 및 코드 생성 작업에서 Q*가 현저한 성능 향상을 보여줬습니다. Q*의 주요 기여는 다단계 추론 문제를 마르코프 결정 과정(MDP)으로 공식화하고, 이를 기반으로 최적의 Q값을 추정하여 효과적인 추론 단계를 찾는 방식입니다. 이 방법은 기존의 많은 계산 자원을 필요로 하지 않으며, 다양한 작업에 쉽게 적용될 수 있다는 장점이 있습니다.

## Similar Papers
- [Scaling Synthetic Data Creation with 1,000,000,000 Personas](2406.20094.md)
- [Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B](2406.07394.md)
- [NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing](2406.06523.md)
- [How Far Are We From AGI](2405.10313.md)
- [ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools](2406.12793.md)
- [Prompt Sketching for Large Language Models](2311.04954.md)
- [EXAONE 3.0 7.8B Instruction Tuned Language Model](2408.03541.md)
- [Live2Diff: Live Stream Translation via Uni-directional Attention in Video Diffusion Models](2407.08701.md)
- [Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models](2407.19914.md)
