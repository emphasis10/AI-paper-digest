# Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.07973.pdf](https://arxiv.org/pdf/2404.07973.pdf)

Ferret-v2에 대해 요약하면 다음과 같습니다:

### 1. 서론
이 논문은 다양한 시각적 과제에 대응할 수 있는 향상된 언어 모델, Ferret-v2를 소개합니다. 이전 모델인 Ferret는 이미지의 지역을 이해하고 이를 통해 언어 모델의 참조 및 정합(grounding) 기능을 향상시키는 데 초점을 맞췄지만, 낮은 해상도의 이미지 인코더에 제한되어 더 세밀한 시각적 이해에 어려움이 있었습니다【18†source】.

### 2. 배경
Ferret는 다양한 시각적 형태와 디테일을 자연 이미지에 적용할 수 있는 공간 참조 및 정합 능력에서 뛰어납니다. 이 모델은 지역을 참조하기 위해 이산 좌표 토큰과 연속 지역 기능의 조합을 사용하며, 이를 통해 텍스트와 밀접하게 연결된 시각적 정보를 처리할 수 있습니다【18†source】.

### 3. 방법론
Ferret-v2는 높은 해상도의 이미지를 처리할 수 있는 ‘어떤 해상도든’ 접근 방식을 사용합니다. 이는 이미지를 여러 하위 패치로 나누어 각각을 처리함으로써, 전역 컨텍스트와 고해상도 패치를 시각 임베딩에 통합합니다. 또한, DINOv2 인코더를 추가하여 세밀한 시각적 정보를 더 잘 인식할 수 있도록 합니다【18†source】.

### 4. 훈련 패러다임
Ferret-v2는 세 단계의 훈련 과정을 거칩니다. 첫 번째 단계에서는 이미지-캡션 정렬을 통해 효율적인 이미지 처리를 수행하고, 두 번째 단계에서는 고해상도 밀도 정렬을 통해 더 정밀한 공간 인식을 목표로 합니다. 마지막으로, 시각적 지시어 미세조정을 통해 사용자 의도를 더 잘 해석하도록 합니다【18†source】.

### 5. 실험
Ferret-v2는 다양한 시각적 질의응답 및 모던 MLLM 벤치마크에서 우수한 성능을 보여 줍니다. 이 모델은 높은 해상도 이미지를 사용하여 기존 모델들을 능가하는 결과를 달성하며, 특히 지역 참조 및 정합 작업에서 뛰어난 성능을 보입니다【18†source】.

### 결론
Ferret-v2는 어떤 해상도에서든 효과적으로 참조 및 정합을 수행하며, 다중 세분성 시각 인코딩과 새로운 세 단계 훈련 전략을 통해 이미지의 높은 해상도 및 세부 정보를 처리하고 이해하는 데 탁월한 능력을 보여 줍니다【18†source】.