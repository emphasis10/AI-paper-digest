# LEOPARD : A Vision Language Model For Text-Rich Multi-Image Tasks
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.01744.pdf](https://arxiv.org/pdf/2410.01744.pdf)

1. 섹션별 요약:

   - **요약**:
     LEOPARD라는 새로운 대규모 멀티모달 모델은 텍스트가 풍부한 다중 이미지 작업 처리를 위해 설계되었습니다. LEOPARD는 두 가지 주요 혁신을 도입했습니다: 하나는 다양한 텍스트-리치, 다중 이미지 지침을 포함하는 방대한 데이터세트인 LEOPARD-INSTRUCT, 또 다른 하나는 다중 고해상도 이미지를 효율적으로 처리할 수 있는 적응형 이미지 인코딩 모듈입니다. 

   - **서론**:
     멀티모달 대형언어모델(MLLM)은 이미지 캡션 생성과 객체 탐지 등 다양한 비전-언어 작업에서 혁신을 불러일으킬 수 있었습니다. 특히 텍스트가 풍부한 이미지들을 인식하며, 이러한 비전-언어 모델들은 기존의 OCR 중심 파이프라인을 대체함으로써 효율성과 정확성을 향상시킵니다. 

   - **실험 결과**:
     LEOPARD는 다양한 벤치마크에서 현상임을 보여주며, 강력한 성과를 나타냈습니다. 특기할 만한 것은 LEOPARD가 텍스트-리치, 다중 이미지 벤치마크에서 평균 9.61점의 점수 향상을 이끌어 낸 것입니다. 이 모델은 또한 싱글 이미지 작업에서도 매우 경쟁력 있는 결과를 얻었습니다. 

2. 전체 요약:

   LEOPARD는 텍스트가 많은 다중 이미지 작업을 처리하는 데 특화된 새로운 멀티모달 대형언어모델입니다. 이 논문에서는 LEOPARD가 크게 두 가지 혁신을 통해 성능을 보유하고 있음을 설명합니다: 첫째, LEOPARD-INSTRUCT라 불리는 대규모 데이터세트를 수집하여, 텍스트가 풍부한 다중 이미지 입력을 지원하도록 하였습니다. 둘째, 적응형 이미지 인코딩 모듈을 통해, 높은 해상도의 다중 이미지를 세부사항을 잃지 않고도 효율적으로 처리할 수 있도록 하였습니다. 실험 결과를 통해 LEOPARD의 뛰어난 성능이 입증되어 다중모드 연구에 기여를 했으며, 다양한 멀티모달 응용 프로그램에서 강력한 성능을 자랑합니다.  이러한 혁신은 미래의 AI 발전을 이끌기 위한 중요한 걸음을 내디뎠습니다.