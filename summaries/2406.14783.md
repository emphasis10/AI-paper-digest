# Evaluating RAG-Fusion with RAGElo: an Automated Elo-based Framework
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.14783.pdf](https://arxiv.org/pdf/2406.14783.pdf)

### 1. 각 섹션 요약

#### 1. 소개 (Introduction)
이 논문은 대화형 질문-응답(QA) 시스템에서 발생하는 고유한 문제를 다룹니다. 특히, Retrieval-Augmented Generation (RAG) 시스템이 도메인 지식이 필요할 때 발생하는 불일치 문제를 해결하는 방법을 제안합니다. Infineon Technologies의 예를 통해, 기업 내부 문서를 사용한 시스템을 설명하고, 이를 위한 평가 프레임워크인 RAGElo를 소개합니다.

#### 2. 관련 연구 (Related Work)
RAG 시스템의 기존 평가 방법에 대한 한계를 설명하고, 다양한 평가 메트릭스 및 프레임워크를 소개합니다. 여기에는 Facts as a Function (FaaF)와 같은 정확도 높은 평가 도구들이 포함됩니다.

#### 3. 랭크 융합을 통한 Retrieval-Augmented QA (Retrieval Augmented QA with rank fusion)
기존의 단일 쿼리 기반 검색과 달리, RAG-Fusion (RAGF)은 원본 사용자 쿼리의 변형을 생성하여 각 변형의 랭킹을 조합함으로써 더 나은 결과를 도출하는 방법을 사용합니다. 이를 통해 검색 결과의 다양성과 품질이 향상됩니다.

#### 4. 합성 테스트 세트 개발 (Development of a synthetic test set)
이 논문에서는 기존 문서에서 구절을 추출해 LLM을 사용해 사용자가 물을 법한 질문을 생성하는 방법을 사용해 고품질의 합성 쿼리 세트를 개발합니다. 이를 통해 실제 사용자 질문과 유사한 질문들로 테스트 세트를 구성합니다.

#### 5. RAG 파이프라인을 위한 LLM-as-a-Judge (LLM-as-a-Judge for RAG pipelines)
LLM을 판사로 활용해 생성된 답변의 품질을 평가하는 방법을 설명합니다. 이는 두 가지 다른 RAG 파이프라인이 생성한 답변을 비교해 더 나은 답변을 선택하도록 유도합니다.

#### 6. 실험 (Experiments)
Infineon의 전통적인 RAG와 RAGF 시스템을 비교 실험합니다. 여기에는 BM25, Dense Retrieval, 혼합 검색 등의 다양한 검색 방법을 사용하여 결과를 비교합니다.

#### 7. 토론 (Discussion)
실험 결과를 토대로 RAGElo의 평가 프레임워크가 실제 인력 평가와 잘 일치하는지, 그리고 RAGF 접근 방식이 더 나은 답변을 생성하는지 논의합니다. 또한 향후 연구 방향을 제안합니다.

#### 8. 결론 (Conclusion)
연구 결과를 종합하여, RAGF 접근 방식의 유용성과 RAGElo 평가 프레임워크의 효과를 강조합니다. 이들이 기업 환경에서 RAG 시스템의 성능을 향상시키는 데 어떻게 기여할 수 있는지 논의합니다.

### 2. 전체 요약
이 논문은 대화형 질문-응답(QA) 시스템에서 발생하는 도메인 지식의 부재와 평가의 어려움을 해결하기 위해 Infineon Technologies 사례를 중심으로 RAG-Fusion(RAGF) 방법론과 평가 프레임워크인 RAGElo를 제안합니다. RAGF는 사용자 쿼리의 변형을 생성하여 검색 결과의 다양성과 품질을 높이는 방법을 사용하고, RAGElo는 이 결과를 평가하는 LLM 기반 도구입니다. 이를 통해 기업 내부 문서의 충분한 활용과 고성능 QA 시스템 개발이 가능함을 확인했습니다. 

RAGElo는 도메인 전문가의 평가와 잘 일치하는 자동화된 평가 도구로서 빠르고 일관성 있는 평가를 가능하게 합니다. RAGF는 질문 변형 생성과 랭크 융합을 통해 검색 품질을 최적화하여 더 나은 답변을 제공합니다.