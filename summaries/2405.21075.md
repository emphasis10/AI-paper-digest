# Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.21075.pdf](https://arxiv.org/pdf/2405.21075.pdf)

### 소개
최근 몇 년간 다중 모드 대형 언어 모델(Multi-modal Large Language Models, MLLMs)의 급속한 발전은 다양한 다중 모드 벤치마크에서 인상적인 인식 및 인지 능력을 보여주었습니다. 그러나 현재 MLLMs 및 그 평가 주안점은 정적 시각 데이터 이해에 집중되어 있으며, 이는 시간에 따른 객체 간의 복잡한 상호 작용을 포함한 동적인 현실 세계를 제대로 반영하지 못합니다. 이러한 현실 세계 시나리오를 더 정확하게 반영하기 위해서는 연속적인 시각 데이터를 통한 MLLMs의 역량을 탐구하고 평가하는 것이 중요합니다.

### 관련 연구
많은 초기 연구들은 MLLMs의 비디오 이해 가능성을 탐구했으며, 기존의 비디오 기반 벤치마크는 여전히 성능을 완전히 드러내지 못하는 경우가 많습니다. 이러한 벤치마크는 비디오 유형의 다양성 부족, 시간적 역학의 불충분한 커버리지, 단일 모달리티에 대한 좁은 초점 등 한계가 있습니다.

### Video-MME 소개
이를 해결하기 위해 우리는 비디오 분석에서 MLLMs의 성능을 평가하기 위해 처음으로 종합적인 다중 모드 평가 벤치마크인 Video-MME를 소개합니다. Video-MME는 다양한 시나리오에서 900개의 비디오와 비디오당 3개의 고품질 객관식 질문 세트를 포함하여 총 2,700개의 질문을 갖춘 데이터셋을 신중하게 큐레이션합니다. 이 데이터셋은 6개의 주요 시각 도메인과 30개의 세부 카테고리를 포함하며, 비디오 길이는 11초에서 1시간까지 다양하여 MLLMs의 적응력을 평가합니다. 또한, Video-MME는 자막 및 오디오 트랙을 포함하여 다중 모드 입력 분석을 강화합니다.

### 실험
우리는 Video-MME 벤치마크에서 다양한 최신 MLLMs를 평가했습니다. GPT-4 시리즈와 Gemini 1.5 Pro와 같은 상용 모델뿐만 아니라 InternVL-Chat-V1.5와 LLaVA-NeXT-Video와 같은 오픈 소스 이미지 및 비디오 모델도 평가에 포함되었습니다. 실험 결과 Gemini 1.5 Pro가 평균 정확도 75.7%로 상용 모델 중 가장 뛰어난 성능을 보였습니다. 반면, 오픈 소스 모델은 상용 모델에 비해 상당한 성능 격차를 보였습니다. 예를 들어, LLaVA-NeXT-Video는 전체 정확도가 52.5%에 그쳤습니다.

### 결과 및 논의
우리의 평가 결과는 자막과 오디오 정보가 비디오 이해에 상당한 향상을 가져올 수 있음을 보여줍니다. 예를 들어, 자막과 오디오를 추가하면 Gemini 1.5 Pro의 성능이 각각 5.9% 및 4.7% 향상되었습니다. 비디오 길이가 길어질수록 MLLMs의 성능이 저하되는 경향도 관찰되었습니다. 이는 긴 비디오 시퀀스를 처리하는 데 있어 여전히 한계가 있음을 시사합니다.

### 결론
이 논문에서는 비디오 작업을 위한 MLLMs 평가를 위해 설계된 최초의 종합적인 다중 모드 벤치마크인 Video-MME를 소개했습니다. 우리의 벤치마크는 다양한 비디오 유형, 시간적 지속 시간 및 다중 데이터 모달리티를 통합하여 고품질의 전문가가 라벨링한 질문 세트를 포함합니다. 상용 및 오픈 소스 모델에 대한 광범위한 평가 결과, 상용 모델, 특히 Gemini 1.5 Pro가 오픈 소스 모델에 비해 우수한 성능을 보였습니다. 자막과 오디오 트랙의 통합이 특히 긴 비디오에서 비디오 이해를 크게 향상시켰습니다. 그러나 비디오 길이가 길어짐에 따라 성능이 저하되는 경향이 관찰되었습니다. 이는 긴 다중 모드 데이터를 처리하는 데 있어 추가적인 발전이 필요함을 시사합니다. 우리는 Video-MME가 MLLMs의 성능 향상을 위한 향후 연구와 개발에 영감을 주기를 기대합니다.

### 종합 요약
Video-MME는 다양한 시나리오와 모달리티를 포함하는 종합적인 다중 모드 비디오 평가 벤치마크입니다. 이 벤치마크는 다양한 최신 MLLMs의 성능을 평가하며, 상용 모델이 오픈 소스 모델보다 우수한 성능을 보임을 확인했습니다. 자막과 오디오 트랙의 통합이 비디오 이해를 크게 향상시키며, 비디오 길이가 길어질수록 MLLMs의 성능이 저하되는 경향이 관찰되었습니다. 이는 긴 비디오 시퀀스를 처리하는 데 있어 여전히 한계가 있음을 시사합니다. Video-MME는 MLLMs의 성능 향상을 위한 향후 연구와 개발에 중요한 기여를 할 것입니다.