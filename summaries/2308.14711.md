# Fast Feedforward Networks
## TL;DR
## Summary
- [https://arxiv.org/pdf/2308.14711.pdf](https://arxiv.org/pdf/2308.14711.pdf)

본 논문은 "Fast Feedforward Networks"라는 제목으로, 피터 벨착(Peter Belcak)과 로저 와튼호퍼(Roger Wattenhofer)에 의해 ETH Zurich에서 작성되었습니다. 이 연구는 피드포워드 네트워크의 계층 크기와 추론 비용 사이의 선형 관계를 깨뜨리는 새로운 아키텍처인 빠른 피드포워드(FFF) 아키텍처를 소개합니다. FFF는 로그 시간 대안으로서 기존의 피드포워드 네트워크보다 최대 220배 빠른 추론 속도를 제공합니다. 또한, FFF는 비전 트랜스포머에서 레이어 뉴런의 1%만을 사용하면서 예측 성능의 94.2%를 유지할 수 있음을 보여줍니다.

### 주요 내용 및 혁신점

1. **빠른 피드포워드(FFF) 아키텍처 소개**: FFF는 입력 공간을 분리된 영역으로 나누고, 이러한 각 영역에 할당된 뉴런 블록의 학습을 동시에 수행합니다. 이는 트리 기반 조건부 실행을 통해 달성되며, 노드 뉴런의 소수가 최종 출력을 생성하기 위해 계산될 잎 뉴런 블록의 혼합을 결정하는 데 사용됩니다. 훈련이 진행됨에 따라 영역 경계가 강화되고 혼합은 로그 시간에 접근 가능한 단일 잎을 선택하는 경향을 보입니다.
2. **추론 속도 향상**: FFF 아키텍처는 기존 피드포워드 네트워크에 비해 추론 속도를 현저히 향상시킵니다. 이는 FFF가 입력 공간의 다른 영역을 활성화하는 다양한 뉴런 세트를 사용한다는 사실에서 비롯됩니다. FFF는 전체 네트워크의 뉴런을 학습에 사용할 수 있지만, 어떤 입력에 대해서도 출력을 계산하기 위해 단 하나의 잎 너비만을 요구합니다.
3. **모델 분할 및 해석 가능성**: FFF의 학습된 영역은 입력 공간의 분할로 사용될 수 있어 모델 해석 가능성, 모델 편집, 재해석 방지, 재생 데이터 예산 감소 등에 활용될 수 있습니다.

### 전체 요약

이 연구는 추론 속도와 모델 해석 가능성을 개선하기 위한 새로운 아키텍처인 빠른 피드포워드(FFF) 아키텍처를 제안합니다. FFF는 기존의 피드포워드 네트워크와 비교하여 추론 속도를 현저히 향상시키며, 입력 공간을 분리된 영역으로 나누어 각 영역에 대한 뉴런 블록의 동시 학습을 가능하게 합니다. 이 아키텍처는 특히 비전 트랜스포머와 같은 복잡한 아키텍처의 일부로 사용될 때 추론 속도를 크게 향상시킬 수 있음을 보여줍니다.

## Similar Papers
- [Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch](2311.03099.md)
- [Mixture of A Million Experts](2407.04153.md)
- [On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey](2406.15126.md)
- [A Closer Look into Mixture-of-Experts in Large Language Models](2406.18219.md)
- [Cost-Effective Hallucination Detection for LLMs](2407.21424.md)
- [Self-Recognition in Language Models](2407.06946.md)
- [Pushing Mixture of Experts to the Limit: Extremely Parameter Efficient MoE for Instruction Tuning](2309.05444.md)
- [VCR: Visual Caption Restoration](2406.06462.md)
- [ReLU$^2$ Wins: Discovering Efficient Activation Functions for Sparse LLMs](2402.03804.md)
