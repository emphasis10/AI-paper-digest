# Preference Tuning For Toxicity Mitigation Generalizes Across Languages
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.16235.pdf](https://arxiv.org/pdf/2406.16235.pdf)

### 1. 섹션별 주요 내용 요약 및 설명

#### 1. 서론 (Introduction)
본 논문은 대형 언어 모델(LLM)의 다국어 독성(multi-lingual toxicity)에 대한 문제를 다루고 있습니다. 목표는 영어로 학습된 선호 조정(preference tuning)만으로 여러 언어에 걸쳐 독성 생성 확률을 현저히 줄이는 것입니다. 사례로 mGPT-1.3B은 독성 생성 확률이 46.8%에서 3.9%로 감소하였으며, 이는 다른 다국어 언어 모델에서도 유사하게 나타났습니다.
- **주요 기여**: 영어 데이터만을 사용하여 다양한 언어에서의 독성을 줄일 수 있도록 한 선호 조정 방법론을 제시했습니다.

#### 2. 관련 연구 (Related Work)
기존 연구들은 인간 피드백(RLHF)이나 AI 피드백(RLAIF)을 이용한 선호 조정의 제로샷 다국어 일반화에 대해 다루었지만, 이는 과업별로 다르게 나타납니다. 예를 들어 질문 응답(QA)에서 멀티 언어 학습 데이터가 필요합니다.
- **주요 기여**: 다른 연구들과 대비하여 제로샷으로 다국어 독성 감소를 달성했음을 강조했습니다.

#### 3. 크로스링걸 독성 완화 (Cross-lingual Toxicity Mitigation)
영어 데이터를 사용한 직접 선호 최적화(DPO)를 통해 독성 생성 확률을 줄이는 방법을 논의하였습니다. 5개의 다국어 기반 LLM들(예: mGPT, BLOOM, Aya-23, Llama2, Llama3)을 사용해 평가하였으며, 주로 QLoRA 어댑터를 이용해 모델을 미세 조정했습니다.
- **주요 기여**: 독성 완화에 있어 다국어 일반화를 위한 선호 조정의 첫 번째 사례를 보여주었습니다.

#### 4. 결과 (Results)
독성 완화 후 모델들이 다양한 언어에서 독성 생성 확률이 감소하는 것을 실험 결과로 보여주었습니다. 또한, 영어 선호 조정이 특정 언어로 일반화될 수 있는지를 예측할 수 있는 이중 다국어 특성을 발견하였습니다.
- **주요 기여**: 이중 다국어 특성을 정의하고 이를 통해 영어 선호 조정의 다국어 일반화 메커니즘을 설명하였습니다.

#### 5. 한계 및 논의 (Conclusion & Limitations)
영어 데이터만으로 다국어 독성 완화가 가능하지만, 저자원 언어에 대해서는 독성 감소 효과가 적다는 한계를 논의했습니다. 미래 연구 방향으로 다른 선호 조정 알고리즘(PPO, KTO 등)을 탐색할 필요성을 제안했습니다.
- **주요 기여**: 연구의 한계와 향후 연구 방향을 명확히 제시하였습니다.

### 2. 전체 요약
본 논문은 다국어 대형 언어 모델(LLM)의 독성을 줄이기 위해 영어 데이터만을 사용한 직접 선호 최적화(DPO) 방법을 제안합니다. 연구 결과 독성 생성 확률이 크게 감소하였으며, 이는 mGPT, BLOOM, Aya-23, Llama2, Llama3 등 다양한 언어 모델에서도 확인되었습니다. 이중 다국어 특성에 의해 여러 언어로 일반화되는 메커니즘을 발견하였으며, 이는 영어 선호 조정이 다국어로 일반화될 수 있음을 입증하였습니다.

- **주요 혁신**: 영어 데이터만으로 다국어 독성을 줄일 수 있는 새로운 선호 조정 방법론 제시 및 그 메커니즘 규명
- **향후 과제**: 저자원언어에 대한 독성 감소 효과 개선 및 다른 선호 조정 알고리즘 탐색

이 연구는 다국어 환경에서의 AI 안전성을 높이기 위한 중요한 기여를 합니다.

      

## Similar Papers
- [Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages](2407.03321.md)
- [CoverBench: A Challenging Benchmark for Complex Claim Verification](2408.03325.md)
- [On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey](2406.15126.md)
- [SambaLingo: Teaching Large Language Models New Languages](2404.05829.md)
- [A Closer Look into Mixture-of-Experts in Large Language Models](2406.18219.md)
- [SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages](2406.10118.md)
- [Fast Feedforward Networks](2308.14711.md)
- [Whispering Experts: Neural Interventions for Toxicity Mitigation in Language Models](2407.12824.md)
- [Zero-Shot Tokenizer Transfer](2405.07883.md)
