# Discrete Flow Matching
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.15595.pdf](https://arxiv.org/pdf/2407.15595.pdf)

### 1. 섹션별 요약内容
#### Introduction
이 논문에서는 연속 변수(이미지, 비디오) 생성에서 강력한 생성 모델로 활용되는 플로우 매칭과 확산 모델이 고차원 이산 데이터(예: 언어)에서 부족한 성능을 보이는 문제를 다루고 있습니다. 'Discrete Flow Matching'이라는 새로운 이산 플로우 패러다임을 도입하여 다음과 같은 주요 기여를 합니다:
1. 출발 및 도착 분포 사이의 확률 경로를 보편적인 방식으로 처리할 수 있습니다.
2. 학습된 사후 확률을 사용하여 이 확률 경로에서 샘플링할 수 있는 일반적인 공식 제공합니다.
3. 특정 스케줄러를 사용한 확률 경로를 선택하면 기존의 이산 확산 및 플로우 모델에 비해 생성 퍼블렉시티(Generative Perplexity)를 크게 향상시킵니다.

#### Setup and Notations
모델 설정과 관련된 기초적인 정의와 표기법에 대해 설명합니다. 여기서는 소스 및 타겟 분포에서 출발하여 확률 경로와 확률 속도(모델이 예측하는 변화율)에 대한 기본 개념을 다룹니다. 이는 'Flow Matching'을 통해 다양한 이산 데이터 생성 문제를 해결하는 데 토대를 제공합니다.

#### Source and Target Distributions
이 섹션에서는 소스와 타겟 분포 사이의 관계와 상호작용에 대해 설명합니다. 단일 포스터리어를 학습하는 손실 함수와 그 최소화 과정에 대해 논의합니다. 이는 데이터 생성 과정의 출발점과 도착점을 정의하는 중요한 부분입니다.

#### Generating Probability Velocities
이는 핵심적인 수학적 공식들이 도입되는 부분으로, 확률 속도를 통해 이산 데이터 생성을 위한 플로우 매칭 프로세스를 구현합니다. 이 공식들은 샘플링 정확성을 높이는 데 중요한 역할을 합니다.

#### Experiments
##### Language Modeling
텍스트 생성을 실험하면서 이전의 생성 퍼블렉시티 메트릭과 비교합니다. 다양한 모델 크기(150M 및 1.7B 파라미터)를 사용하여 언어 모델링 성능을 평가합니다. 실험 결과, 제안된 모델이 기존 비자기회귀(non-autoregressive) 모델보다 뛰어난 성능을 보였습니다.

##### Code Generation
코드 생성을 목표로 하는 모델을 훈련시키고 HumanEval 및 MBPP(1-shot) 벤치마크에서 평가합니다. 제안된 모델은 비자기회귀 맥락에서 최초로 실질적인 코딩 작업을 수행하는 성과를 거둡니다.

##### Image Generation
CIFAR10 데이터셋을 사용하여 완전한 이산 이미지 생성을 실험합니다. MaskGit 및 다른 기존 모델들과 비교한 결과, 제안된 모델이 높은 생성 품질을 제공합니다.

#### Conclusion and Future Work
이 논문은 'Discrete Flow Matching'이라는 새로운 패러다임을 통해 이산 데이터를 생성하는 방법을 제안합니다. 해당 모델은 언어와 코드 생성에서 현존 비자기회귀 모델과의 격차를 좁히고 있습니다. 실험적 성과는 앞으로의 연구 개발 방향성에 중요한 기초 자료가 됩니다.

### 2. 전체 요약
이 논문은 'Discrete Flow Matching'이라는 새로운 패러다임을 도입하여 고차원 이산 데이터(예: 언어, 코드)를 생성하는 방법을 제안합니다. 해당 패러다임은 다양한 확률 경로를 통해 데이터 생성을 수행하며, 기존의 이산 확산 및 플로우 모델보다 뛰어난 생성 퍼블렉시티(Generative Perplexity)를 제공합니다. 실험 결과, 제안된 모델은 언어 모델링, 코드 생성, 이미지 생성 등 다양한 영역에서 뛰어난 성능을 입증하였습니다. 이 연구는 기존의 비자기회귀 모델의 한계를 극복할 수 있는 새로운 접근 방식을 제시하며, 향후 연구 방향에 중요한 영향을 미칠 것입니다.