# Swallowing the Bitter Pill: Simplified Scalable Conformer Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2311.17932.pdf](https://arxiv.org/pdf/2311.17932.pdf)

### 1. 논문 섹션 요약

#### 서론
CLIP(Contrastive Language-Image Pretraining)은 웹 크롤링 데이터를 활용하여 이미지와 텍스트를 정렬시키는 대조 학습 방법을 사용하여 훈련됩니다. CLIP은 데이터 분포 변화에 강인하며, 새로운 데이터셋에서 인상적인 제로샷 및 크로스 모달 검색 능력을 보입니다. 그러나 CLIP는 객체의 위치를 파악하는 능력이 부족하여, 텍스트와 이미지를 정확하게 매칭하는 데 어려움을 겪습니다. 이 논문에서는 CLIP 모델에 모델 동물원의 특정 작업 모델을 추가하여 이러한 시각적 표현을 향상시키는 방법을 제안합니다. 이 접근 방식은 웹 스케일 이미지-텍스트 데이터셋에서 하드 가상 라벨을 생성하고, 이를 여러 목적을 가지고 훈련함으로써 이루어집니다.

#### 관련 연구
비전 기반 기초 모델(FMs)은 대규모 데이터셋에서 학습하여 컴퓨터 비전 분야에 확장 가능한 트랜스포머 모델을 도입했습니다. 대표적인 사례로 CLIP이 있으며, 이는 이미지와 텍스트 쌍을 정렬하는 데 뛰어납니다. 그러나 텍스트와 개별 객체를 매칭하는 데 어려움을 겪습니다. 가상 감독(pseudo-supervision)은 레이블이 없는 데이터에 대해 전문가가 생성한 가상 라벨을 활용하여 모델 학습을 돕는 방법입니다.

#### CLIPTeX 방법론
CLIPTeX는 CLIP 모델의 시각적 표현을 개선하기 위해 객체 위치 파악, 깊이 추정, 표면 법선 추정을 전문으로 하는 전문가 모델을 활용하는 방법입니다. 웹 스케일 이미지-텍스트 데이터셋에서 하드 가상 라벨을 생성하고, 이를 여러 목적을 가지고 훈련하여 시각적 표현을 크게 향상시킵니다. 이 접근 방식은 다양한 비전 작업과 데이터셋에서 최대 16.3%의 향상을 가져옵니다.

#### 실험 설정 및 결과
CLIPTeX의 효과를 입증하기 위해 다양한 탐침(probes)을 사용하여 여러 비전 작업 및 데이터셋에서 실험을 수행했습니다. PASCAL VOC와 ADE20k에서의 세그멘테이션, COCO에서의 객체 감지, NYU-v2에서의 깊이 추정, ImageNet-1k와 Places-365에서의 분류, 그리고 NYU-v2에서의 표면 법선 추정 작업에서 CLIPTeX가 뛰어난 성능을 보였습니다.

#### 결론
CLIPTeX는 기존의 CLIP 모델의 능력을 유지하면서도 시각적 표현을 향상시킵니다. 이를 통해 다양한 컴퓨터 비전 작업에서 더욱 뛰어난 성능을 발휘할 수 있습니다. 이러한 결과는 기초 모델의 공개성과 전문 모델의 활용 가능성을 잘 보여줍니다.

### 2. 전체 요약

이 논문에서는 CLIP 모델의 시각적 표현을 개선하기 위해 모델 동물원의 특정 작업 전문가 모델을 활용하는 방법을 제안합니다. 웹 스케일 이미지-텍스트 데이터셋에서 하드 가상 라벨을 생성하고, 이를 여러 목적을 가지고 훈련함으로써 다양한 비전 작업에서 최대 16.3%의 성능 향상을 달성했습니다. CLIPTeX는 CLIP의 기존 능력을 유지하면서도 다양한 컴퓨터 비전 작업에서 뛰어난 성능을 보입니다. 이 연구는 기초 모델의 공개성과 전문 모델의 활용 가능성을 보여주며, 향후 컴퓨터 비전 분야의 연구에 중요한 기여를 할 것입니다.

## Similar Papers
- [Manifold Diffusion Fields](2305.15586.md)
- [Masked Attention is All You Need for Graphs](2402.10793.md)
- [Position: Foundation Agents as the Paradigm Shift for Decision Making](2405.17009.md)
- [$\nabla^2$DFT: A Universal Quantum Chemistry Dataset of Drug-Like Molecules and a Benchmark for Neural Network Potentials](2406.14347.md)
- [SLAB: Efficient Transformers with Simplified Linear Attention and Progressive Re-parameterized Batch Normalization](2405.11582.md)
- [Probabilistic Conceptual Explainers: Trustworthy Conceptual Explanations for Vision Foundation Models](2406.12649.md)
- [Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures](2407.09468.md)
- [KV-Runahead: Scalable Causal LLM Inference by Parallel Key-Value Cache Generation](2405.05329.md)
- [Learning Molecular Representation in a Cell](2406.12056.md)
