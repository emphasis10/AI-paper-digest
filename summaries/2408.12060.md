# Evidence-backed Fact Checking using RAG and Few-Shot In-Context Learning with LLMs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.12060.pdf](https://arxiv.org/pdf/2408.12060.pdf)

### 1. 각 섹션 요약

#### 서론
현대 사회에서 소셜 미디어를 통한 허위 정보와 가짜 뉴스의 확산은 큰 문제로 대두되고 있습니다. 허위 정보는 폭동이나 생명 손실과 같은 심각한 결과를 초래할 수 있습니다. 이에 따라 수동으로 모든 정보를 검증하는 것은 불가능해졌으며 자동화된 사실 검증 시스템의 필요성이 요구됩니다.

#### 관련 연구
최근에는 가짜 뉴스 탐지와 자동화된 사실 검증에 대한 연구가 활발히 진행되고 있습니다. 다양한 연구들이 BERT와 같은 딥러닝 모델을 사용해 사실 검증을 시도하였지만, 대부분 증거를 제공하지 않는 문제점이 있습니다.

#### 데이터셋
이 논문에서는 Averitec 데이터셋을 사용하여 사실 검증 시스템을 평가합니다. 각 주장에는 증거 데이터가 포함되어 있으며, 지원(S), 반박(R), 증거 부족(N), 상충되는 증거(C)의 라벨 중 하나가 부여됩니다. 데이터셋은 클래스 불균형을 나타내며, 반박 클래스가 가장 많습니다.

#### 방법론
이 시스템은 주요 3단계로 구성됩니다: 문서 검색, 증거 추출, 사실 여부 예측. 문서 검색 단계에서는 주장을 임베딩하여 관련 문서를 찾고, 증거 추출 단계에서는 해당 문서에서 유의미한 문장을 추출합니다. 마지막으로, 몇 가지 예제만으로 대규모 언어 모델을 사용하여 사실 여부를 예측합니다.

#### 실험 설정
여러 LLM을 다양한 크기와 조건에서 실험하였으며, 그 결과 Mixtral 모델이 가장 뛰어난 성능을 나타내었습니다. 평가 지표로는 Hungarian METEOR 방법을 사용하였으며, 정밀한 증거 예측만이 높은 점수를 받는 방식입니다.

#### 결과 및 분석
Mixtral 모델은 개발 세트에서 높은 Averitec 점수를 기록했으며, 특히 잘못된 증거/상충되는 증거와 증거 부족 클래스에서 모델의 성능이 떨어지는 것을 확인했습니다. 또한, 단일 모델이 모든 클래스에서 일관되게 우수한 성능을 발휘하지는 못했습니다.

#### 결론 및 향후 연구
본 논문에서는 RAG와 ICL을 기반으로 한 증거 기반의 자동화된 사실 검증 시스템을 제안했습니다. 향후 연구에서는 PEFT 기법을 사용하여 LLM을 미세 조정하고, 멀티모달 사실 검증을 포함하는 방향으로 나아가야 합니다.

### 2. 전체 요약
이 논문은 허위 정보와 가짜 뉴스의 확산을 막기 위한 자동화된 사실 검증 시스템을 제안합니다. 이 시스템은 매우 적은 훈련 데이터로도 높은 정확도의 사실 검증을 가능하게 하는데, 이는 주로 최근의 대형 언어 모델(LLM) 및 RAG와 ICL 기술을 사용하여 증거를 기반으로 합니다. 논문에서는 다양한 모델의 성능을 비교하고, 그 중 Mixtral 모델이 가장 높은 성능을 기록했다는 것을 발견했습니다. 결론적으로, 이 논문은 허위 정보를 효율적으로 검증할 수 있는 잠재력을 가진 시스템을 제시하며, 향후에는 멀티모달 정보까지 포함하는 방향으로 발전할 필요가 있습니다.