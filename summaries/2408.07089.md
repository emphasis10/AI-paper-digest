# InfinityMATH: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.07089.pdf](https://arxiv.org/pdf/2408.07089.pdf)

### 1. 각 섹션 요약 및 주요 기여와 혁신적인 부분 설명

#### Abstract
이 논문에서는 InfinityMath라는, 프로그래매틱 수학적 추론을 위한 확장 가능한 튜닝 데이터셋을 소개합니다. 현재의 CoT와 PoT 방식의 한계를 극복하고자 데이터셋을 설계했으며, 이를 통해 논리적 일관성을 개선하고 모델의 전반적인 성능을 높입니다.

#### Introduction
수학적 추론은 개념을 이해하고 논리적 추론을 수행하며 복잡한 계산을 처리하는 것이 포함됩니다. 따라서 대형 언어 모델(LLM)의 전반적인 능력을 평가하는 데 필수적입니다. CoT 및 PoT 기법을 활용하면 순차적으로 추론 단계를 전개하거나 실행 가능한 프로그램 문을 통합하여 모델 성능을 크게 향상시킬 수 있습니다. 하지만 높은 품질의 수학적 추론 문제 부족과 데이터 합성의 높은 계산 비용이 대규모 데이터 생산을 제한합니다.

#### Related Work
LLM을 사용하여 수학 문제를 해결하는 것은 복잡한 다단계 및 정량적 추론 작업에서 LLM의 성능을 평가하는 중요한 지표입니다. Chain-of-Thought (CoT) 방식은 문제를 작은 부분으로 분해하여 점진적으로 해결하는 방법을 사용하며, Program-of-Thoughts (PoT) 방식은 계산 단계를 외부 인터프리터에 위임하여 자연어 추론을 유지합니다.

#### Methodology
논리적 일관성 문제를 해결하고 데이터 혹은 스케일링 문제를 다루기 위해, 수학적 문제에서 숫자를 분리하여 수많은 유사한 문제를 생성할 수 있는 간단하면서도 효율적인 파이프라인을 제안합니다. 이 과정에서는 LLM을 사용하여 프로그램을 생성하고, 그 프로그램을 다양한 숫자로 채워 데이터셋 강화를 수행합니다.

#### Experiments
7B 버전의 Llama2, Aquila2 및 CodeLlama와 같은 오픈 소스 모델을 InfinityMath 데이터셋으로 미세 조정하고, 다양한 인도메인 및 외도메인 벤치마크에서 평가했습니다. 그 결과, 대부분의 벤치마크에서 다른 최첨단 모델보다 우수한 성능을 보였습니다. 논리적 일관성 문제를 조사하기 위해 GSM8K+ 및 MATH+ 테스트 세트를 생성하고, 이러한 데이터셋을 사용해 평가한 결과, InfinityMath로 훈련된 모델이 더 높은 정확성과 강건성을 보였습니다.

#### Conclusion
InfinityMath는 무한한 수학적 튜닝 데이터셋을 만들 수 있도록 설계되어, 모델의 논리적 일관성을 크게 개선했습니다. 이 데이터셋은 모델의 수학적 문제 해결 능력을 향상시키는 데 매우 효과적입니다.

### 2. 전체 요약
이 논문에서는, 수학적 추론을 위한 확장 가능한 튜닝 데이터셋인 InfinityMath를 소개합니다. 이 데이터셋은 CoT 및 PoT 방식의 한계를 극복하고자 숫자를 분리하여 유사한 문제를 대량 생성할 수 있는 간단한 파이프라인을 사용합니다. 7B 버전의 Llama2, Aquila2, CodeLlama와 같은 오픈 소스 모델을 InfinityMath로 미세 조정한 결과, 다양한 벤치마크에서 다른 최첨단 모델보다 우수한 성능을 보였습니다. 또한, 논리적 일관성 문제를 해결하기 위해 GSM8K+ 및 MATH+ 테스트 세트를 생성하여, 이 데이터셋으로 훈련된 모델이 더 높은 정확성과 강건성을 보임을 확인했습니다.