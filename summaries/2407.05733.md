# Is GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.05733.pdf](https://arxiv.org/pdf/2407.05733.pdf)

### 요약

#### 1. 각 섹션 요약:

**1. 서론**
- **내용:** 이 연구는 대규모 언어 모델(LLM)과 비교 판단(CJ)을 결합한 자동 에세이 채점 시스템(AES)의 새로운 접근법을 제안합니다.
- **주요 기여:** LLM과 CJ를 결합하여 인간 채점자 수준의 에세이 평가를 모방하려는 제안.
- **혁신성:** 다양한 교육 설정에서 광범위한 특정 작업에 대해 미세 조정이 필요하지 않은 시스템 구축 가능.

**2. 관련 연구**
- **자동 에세이 채점 (AES):** AES의 목표와 LLM의 최근 성과 및 단점.
- **인간 채점자의 인식:** 루브릭 기반 채점의 복잡성과 CJ의 장점.

**3. 연구 질문**
- GPT-4와 GPT-3.5 모델 간의 성능 비교 및 CJ기반 방법의 효율성을 탐구합니다.

**4. 방법론**
- **데이터 세트:** ASAP 데이터 세트 사용.
- **모델:** GPT-3.5와 GPT-4.
- **채점 전략:** 기본 및 자세한 루브릭, CJ기반 채점 전략.

**5. 결과**
- **기본 루브릭으로 GPT-4의 성능이 GPT-3.5보다 우수:** 여기서는 GPT-4의 평균 QWK 점수가 GPT-3.5보다 높았음을 보여줍니다.
- **CJ기반 채점 전략의 효율성:** CJ기반 채점이 기본 루브릭을 사용한 채점보다 성능이 더 뛰어났습니다.
- **세분화된 점수를 활용한 CJ기반 채점 전략:** 세분화된 점수 사용시 GPT 모델의 성능이 더욱 향상되었습니다.

**6. 논의**
- **에세이 세트의 특성이 LLM 성능에 미치는 영향:** 에세이 세트의 특성과 루브릭의 세부 수준에 따른 성능 차이를 강조합니다.
- **CJ기반 채점 전략의 효과**: CJ기반 채점 전략이 인간 채점자 점수를 모방하는 데 더 효과적임을 확인했습니다.
- **세분화된 점수의 활용:** 세분화된 점수를 사용할 때 GPT 모델의 AES 성능이 향상됨을 언급합니다.

**7. 미래 연구**
- 다양한 데이터 세트에 대한 검증 필요성 및 CJ와 인간 채점자의 상호작용을 최적화하는 방법 탐색.

**8. 결론**
- **주요 기여:** 연구 결과는 GPT-4를 AES에 사용하는 것의 가능성과 한계를 보여주며, LLM과 CJ의 결합이 향상된 성능을 달성할 수 있음을 입증합니다.
- **혁신성:** 다양한 채점 요소를 통합한 자세한 루브릭과 세분화된 점수를 사용하여 성능을 향상시키는 전략 제안.

#### 2. 전체 요약:

이 논문은 대규모 언어 모델(GPT-3.5와 GPT-4)을 활용해 자동 에세이 채점 시스템(AES)의 성능을 향상시키기 위한 혁신적인 접근법을 제안합니다. 특히, 비교 판단(CJ) 방법을 사용하여 루브릭 기반의 전통적인 채점 방법보다 더 정교하고 인간의 채점 수준에 가까운 결과를 얻을 수 있음을 보여줍니다. 세분화된 점수를 활용한 CJ기반 채점 전략은 특히 GPT-4 모델에서 높은 성능 개선을 보였으며, 에세이 세트의 특성과 루브릭의 세부 수준에 따라 성능이 달라진다는 것을 강조합니다. 이 연구는 향후 다양한 데이터 세트에 걸친 검증과 더불어 AI와 인간 채점자 간 상호작용 최적화가 필요함을 제안합니다. 

이 논문의 핵심 기여는 AES 시스템에 LLM과 CJ 방법을 결합함으로써, 인간 채점자를 모방한 정교한 점수 산출 방법을 제시한 것입니다. 이 접근법은 교육 환경에서의 적용 가능성을 넓히고, 다양한 채점 기준과 방법을 통합하여 더 실제적이고 신뢰할 수 있는 AES 시스템 개발에 기여할 수 있습니다.

## Similar Papers
- [Learn Your Reference Model for Real Good Alignment](2404.09656.md)
- [TOAD: Task-Oriented Automatic Dialogs with Diverse Response Styles](2402.10137.md)
- [Retrieved In-Context Principles from Previous Mistakes](2407.05682.md)
- [CodecLM: Aligning Language Models with Tailored Synthetic Data](2404.05875.md)
- [Scaling Up Personalized Aesthetic Assessment via Task Vector Customization](2407.07176.md)
- [THOUGHTSCULPT: Reasoning with Intermediate Revision and Search](2404.05966.md)
- [Fine-gained Zero-shot Video Sampling](2407.21475.md)
- [SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales](2405.20974.md)
- [Stylus: Automatic Adapter Selection for Diffusion Models](2404.18928.md)
