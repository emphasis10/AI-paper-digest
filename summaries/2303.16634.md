# G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment
## TL;DR
## Summary
- [https://arxiv.org/pdf/2303.16634.pdf](https://arxiv.org/pdf/2303.16634.pdf)

### 1. 내용 요약:

#### 개요:
이 논문에서는 대형 언어 모델(LLM)을 기반으로 한 평가 프레임워크인 G-EVAL을 제안했습니다. 이는 체인-오브-사고(CoT)와 형식-채우기 패러다임을 사용하여 자연어 생성(NLG) 시스템에 의해 생성된 텍스트의 품질을 평가합니다. 전통적인 자동 평가 지표들이 인간 평가와의 상관관계가 낮아 새로운 작업에 적용하기 어렵다는 점을 고려하면, G-EVAL은 더 일관되게 인간 평가 결과와 높은 상관관계를 나타냅니다.

#### 실험 및 결과:
G-EVAL은 텍스트 요약 및 대화 생성이라는 두 가지 NLG 작업에서 기존의 첨단 평가 도구들을 크게 능가하였습니다. G-EVAL은 특히 대규모 모델인 GPT-4를 활용해 요약 작업에서 인간 평가와 스피어-만 상관관계 0.514를 달성했습니다. 이는 이전 방법들을 큰 차이로 능가하는 결과입니다.

#### 주요 기여와 혁신적인 부분:
- G-EVAL은 LLM을 평가 지표로 사용하여 인간 품질 판단과의 상관관계를 더 높이는 데 성공했습니다. 이는 특히 창의적이고 개방형의 NLG 작업에서 두드러집니다.
- 체인-오브-사고(CoT)를 활용하여 LLM 평가자에게 더 많은 맥락과 안내를 제공함으로써 성능을 향상시켰습니다.
- LLM 기반 평가자들이 LLM이 생성한 텍스트에 대해 편향을 가질 가능성을 강조함으로써, LLM 활용의 잠재적 위험과 도전에 대해 경각심을 일깨웠습니다.

### 2. 전체 요약 (한글):

논문에서는 G-EVAL이라는 새로운 자연어 생성(NLG) 텍스트 평가 프레임워크를 제안하였습니다. G-EVAL은 LLM을 활용하여 평가 작업을 수행하며 기존의 평가 방법보다 인간 평가와의 상관관계가 더 높게 나타났습니다. 이는 특히 GPT-4 모델을 활용한 요약 작업에서 더욱 두드러졌습니다. G-EVAL의 혁신적인 부분은 체인-오브-사고(CoT)를 사용하여 LLM 평가자에게 더 많은 맥락을 제공할 수 있다는 점입니다. 그러나 LLM이 직접 생성한 텍스트에 대한 편향 가능성을 언급하며 기존의 평가 방법에서의 개선점을 제시했습니다. 이 논문은, LLM을 활용한 평가의 잠재적 위험을 강조하며, 더 나은 LLM 평가 방법의 개발을 위한 연구에 영감을 줄 수 있을 것입니다.