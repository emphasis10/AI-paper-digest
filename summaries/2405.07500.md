# PromptLink: Leveraging Large Language Models for Cross-Source Biomedical Concept Linking
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.07500.pdf](https://arxiv.org/pdf/2405.07500.pdf)

### 1. 각 섹션 요약 및 주요 기여 내용

#### 서론 (Introduction)
이 논문은 생물 의학 개념 연결(biomedical concept linking)의 도전 과제를 다루며, 기존의 문자열 매칭 규칙과 머신 러닝 모델은 한계가 있다고 설명합니다. 이에 따라 최신 대형 언어 모델(LLM)을 활용한 생물 의학 개념 연결 프레임워크 'PromptLink'를 제안합니다. 이 프레임워크는 LLM의 풍부한 사전 지식과 예측 능력을 활용하여 다양한 데이터 소스 간 개념을 연결합니다. 주요 기여는 LLM의 비용과 문맥 길이 제한을 고려하여 효율적인 두 단계 프롬프트 기법을 설계한 것입니다.

#### 생물 의학 개념 연결 (Biomedical Concept Linking)
생물 의학 개념 연결은 소스/시스템 간에 생물 의학 개념을 의미론적 의미와 생물 의학 지식을 기반으로 연결하는 작업을 의미합니다. EHR 데이터베이스와 생물 의학 지식 그래프를 정의하고, 이를 통해 개념 연결 작업의 범위를 설명합니다.

#### PromptLink
PromptLink는 사전 학습된 SAPBERT 언어 모델을 사용하여 생물 의학 개념에 대한 개념 임베딩을 생성하고, 코사인 유사도를 기반으로 상위 후보를 반환합니다. 그런 다음 GPT-4 모델에서 두 단계 프롬프트 기법을 사용해 최종 연결 예측을 수행합니다.

#### 실험 및 토론 (Experiments & Discussions)
이 섹션에서는 실험 세부 사항과 데이터를 소개합니다. MIID 및 CISE라는 두 개의 생의학 개념 연결 벤치마크 데이터 셋을 생성하고 다양한 방법들과 비교하였습니다. PromptLink는 기존 방법들보다 훨씬 높은 정확도를 보였습니다. 서술된 두 단계 프롬프트 기법을 통해 효율성과 비용 효율성을 높일 수 있음을 보였습니다. NIL 예측 기능 또한 뛰어나, 상위 모든 후보가 적절하지 않을 때 이를 효과적으로 거부할 수 있다는 점에서 기존 방법보다 우수함을 입증했습니다.

#### 결론 (Conclusion)
PromptLink는 LLM의 강력한 생의학 지식을 활용하여 생의학 개념 연결의 정확성을 향상시켰습니다. 낮은 비용으로 높은 연결 효율성을 유지하고 NIL 예측 문제를 효과적으로 처리하는 특징이 있습니다. 향후 작업은 프롬프트의 효과를 더욱 향상시키고 비용을 절감하며 수동 작업을 최소화하는 방향으로 진행될 예정입니다.

### 2. 전체 요약
이 논문은 생의학 개념 연결 작업의 효율성을 높이기 위한 혁신적인 프레임워크 'PromptLink'를 제안합니다. PromptLink는 대형 언어 모델(LLM)의 강력한 생의학 지식을 활용하여 EHR 데이터베이스와 생의학 지식 그래프 간의 개념을 정확하게 연결합니다. SAPBERT 언어 모델과 GPT-4 기반의 두 단계 프롬프트 기법을 통해 상위 후보를 선별하고 최종 연결을 예측합니다. 실험 결과, PromptLink는 기존 방법들보다 월등한 정확도를 보였고, 특히 NIL 예측 능력이 뛰어났습니다. 본 연구는 생의학 연구 및 다양한 응용 분야에서 강력한 일반화 능력을 갖춘 프레임워크로 평가될 수 있습니다.

.

## Similar Papers
- [Exploring Advanced Large Language Models with LLMsuite](2407.12036.md)
- [BioMamba: A Pre-trained Biomedical Language Representation Model Leveraging Mamba](2408.02600.md)
- [BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine](2405.00465.md)
- [EHRCon: Dataset for Checking Consistency between Unstructured Notes and Structured Tables in Electronic Health Records](2406.16341.md)
- [Towards Building Specialized Generalist AI with System 1 and System 2 Fusion](2407.08642.md)
- [RichRAG: Crafting Rich Responses for Multi-faceted Queries in Retrieval-Augmented Generation](2406.12566.md)
- [Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation](2406.18676.md)
- [From Local to Global: A Graph RAG Approach to Query-Focused Summarization](2404.16130.md)
- [A Survey on Employing Large Language Models for Text-to-SQL Tasks](2407.15186.md)
