# When to Speak, When to Abstain: Contrastive Decoding with Abstention
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.12527.pdf](https://arxiv.org/pdf/2412.12527.pdf)

### 1. 각 섹션 요약

- **서론**
  연구자들은 '대조 디코딩과 기권(Contrastive Decoding with Abstention)'이라는 새로운 방법을 제안했습니다. 이 방법은 대규모 언어 모델(LLMs)이 관련 지식이 있을 때는 자연스럽게 응답을 생성하고, 관련 지식이 없을 때는 응답을 기권할 수 있도록 합니다.

- **관련 연구**
  대조 디코딩(CD)은 서로 다른 출력 분포를 대비시켜 모델을 조정하는 일종의 텍스트 생성 제어 기술입니다. 최근, 문맥을 고려한 대조 디코딩(CCD)이 주목받고 있으며, 이는 매개적 지식과 문맥적 지식을 활용하여 모델의 응답 정확도를 높이는 방법입니다.

- **기술적 방법**
  연구에서는 MRQA 벤치마크의 세 가지 데이터셋인 Natural Questions, HotpotQA, TriviaQA를 사용했습니다. 데이터셋은 특정 문맥 내에서 질문과 답변의 일관성을 평가하며, 적합한 문맥을 선택하여 모델이 지식의 유무를 평가할 수 있도록 설계되었습니다.

- **모멘텀을 이용한 CDA**
  모멘텀은 모델이 디코딩 과정에서 이전의 잘못된 콘텐츠로 인해 오도되지 않도록 도와줍니다. 이전 단계의 가중치가 현재 단계에 영향을 주어 일관성을 유지할 수 있게 합니다.

- **실험 및 결과**
  실험은 세 가지 데이터셋에서 다양한 대규모 언어 모델을 사용하여 수행되었습니다. 평가 기준은 F1 점수와 정확도, 커버리지를 포함하며, 각 실험에서 CDA의 성능을 강조했습니다.

### 2. 전체 요약

이 연구는 대규모 언어 모델들이 기존의 지식을 활용해 다양한 작업에서 우수한 성과를 보이는 것과 달리, 관련 지식이 부족한 상황에서도 정확한 응답과 행동을 보장하는 방법론을 제안합니다. '대조 디코딩과 기권'이라는 새로운 기술은 모델이 적합하지 않은 상황에서는 응답을 기권하는 전략을 통해 신뢰성과 정확성을 강화하며, 특히 실세계에서 사용될 때의 잠재적 위험을 경감할 수 있는 가능성을 보여줍니다.