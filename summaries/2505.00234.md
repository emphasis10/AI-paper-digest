# Self-Generated In-Context Examples Improve LLM Agents for Sequential Decision-Making Tasks
## TL;DR
## Summary
- [https://arxiv.org/pdf/2505.00234.pdf](https://arxiv.org/pdf/2505.00234.pdf)

1. 각 섹션 요약:

- **서론 및 배경**: 본 논문은 LLM(대형 언어 모델) 에이전트의 순차적 의사결정 과제 성능을 향상시키기 위해 자체 생성 예제를 활용하는 방법을 제안합니다. 기존의 지식 공학에 의존하지 않고, 에이전트가 자신의 성공적인 경험을 바탕으로 성능을 향상시킬 수 있는 가능성을 탐구합니다.

- **문제 정의**: ReAct 스타일 에이전트를 활용하여, 순차적 의사결정 과제에서 최대 성능을 낼 수 있도록 경로 데이터베이스를 구축하고 개선하는 방법을 제시합니다. 에이전트가 직면한 과제에 적합한 예제를 어떤 기준으로 선택하는지 연구합니다.

- **관련 연구**: 본 연구는 조정된 호출 설정, in-context 학습, 에이전트 자가 개선과 관련이 있습니다. 특히, in-context 학습 방식의 장점과 강화학습 등과 비교한 장점을 논의합니다.

- **메서드**: Traj-Bootstrap을 통해 에이전트가 성공한 경로를 수집하여 데이터베이스를 구축합니다. 이 메서드는 성공한 예제가 지속적으로 새로운 과제를 해결하는 데 도움을 줄 수 있는 선순환 과정을 생성합니다.

- **결과 및 토의**: 제안된 메서드를 통해 에이전트의 성능이 대폭 개선되며, 데이터 기반 접근 방식의 효과를 확인했습니다. 다섯 가지시도중 성공률은 무엇보다도 트래제토리 데이터베이스의 양과 질의 균형이 중요함을 시사합니다.

2. 종합 요약:

이 논문은 LLM 에이전트의 성능을 향상시키기 위해 자체적으로 생성한 예제를 활용하는 방법론을 제안합니다. 수집된 성공 예제를 통해 에이전트의 성능을 지속적으로 향상시키는 방법을 구체화하며, 기존의 지식 공학을 대체할 수 있는 새로운 방법론을 제시합니다. 관련 실험을 통해 성공 예제의 적절한 수집과 선택이 성능 향상의 핵심임을 입증했습니다. 이 방식을 통해 데이터 기반 접근 방식의 효과와 LLM 에이전트의 자가 개선 가능성을 탐구합니다.