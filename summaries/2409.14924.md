# Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.14924.pdf](https://arxiv.org/pdf/2409.14924.pdf)

### 논문의 주요 내용을 섹션별로 요약

#### 1. 서론
인공지능(AI)과 대형 언어 모델(LLMs)은 다양한 분야에서 뛰어난 성능을 보여주고 있습니다. 하지만 특정 전문 분야에서 효과적으로 활용하기 위해서는 외부 데이터의 통합이 필요한 경우가 많습니다. 외부 데이터를 통합하면 모델의 도메인 전문성과 시의성을 강화하여 잘못된 정보 발생을 줄이고, 결과의 통제 가능성과 설명 가능성을 높일 수 있습니다. 대표적인 기법으로는 Retrieval-Augmented Generation(RAG)와 파인 튜닝(**fine-tuning**)이 있습니다.

#### 2. 문제 정의
데이터 보강 LLM 응용 프로그램은 도메인 특정 데이터에 기반한 질의응답 봇, 복잡한 데이터 파이프라인의 의미론적 처리 운영자 또는 다중 에이전트 시스템에서 특정 단계를 처리하는 에이전트 등 여러 형태로 존재합니다. 이런 응용 프로그램의 개발 과정에서는 외부 데이터의 효과적인 검색 및 사용자가 원하는 정보를 정확히 파악하고, 복잡한 작업을 위한 LLM의 추론 기능을 최대한 활용하는 등의 도전 과제를 포함합니다.

#### 3. 질의의 계층화

##### 명시적 사실 질의 (L1)
이 수준의 질의는 질문에 대해 존재하는 명시적 사실을 기반으로 답변을 생성합니다. 주로 RAG를 사용하여 데이터를 정확히 검색하고, 필요한 정보를 빼내어 답변을 만듭니다. 이 과정에서 데이터 처리의 어려움과 데이터 검색의 어려움을 해결해야 합니다.

##### 암묵적 사실 질의 (L2)
암묵적 사실 질의는 관련된 여러 사실을 종합하여 답변을 생성합니다. 반복적인 RAG와 그래프 또는 트리 구조 상의 RAG 구현을 통해 관련된 여러 데이터를 병행하여 검색하고 연관 짓는 것이 중요합니다. 이 수준의 질의는 다중 단계 추론을 필요로 합니다.

##### 해석 가능한 논리 질의 (L3)
해석 가능한 논리 질의는 명확한 논리를 제공할 수 있는 질의를 말합니다. 프롬프트 튜닝(prompt tuning)을 통하여 LLM이 외부 지시를 준수하여 높은 수준의 논리를 제공하도록 개선할 수 있습니다.

##### 숨겨진 논리 질의 (L4)
숨겨진 논리 질의는 방대한 데이터 세트에서 스스로 문제 해결 접근 방법을 종합해야 하는 질의입니다. 이러한 질의를 처리하기 위해 오프라인 학습, 인컨텍스트 학습(in-context learning) 및 파인 튜닝 등의 방법이 사용됩니다.

#### 4. 결과 및 논의
데이터 보강 LLM 응용 프로그램 개발 시의 주요 도전 과제와 이를 극복하기 위한 방안을 논의합니다. 예를 들어, 적절한 데이터 세분화 및 검색 메커니즘 개발, 성능 평가 기준 마련 등이 포함됩니다. 또한, 단순 RAG를 넘어 파인 튜닝, 작은 모델의 활용 등 다양한 기술적 대안도 소개합니다.

#### 5. 결론
데이터 보강 LLM 응용 프로그램은 다양한 특화된 분야에서 능력을 발휘할 수 있으며, 이를 통해 더 정밀한 답변 제공, 낮은 오류율, 향상된 관리 가능성과 설명 가능성을 제공할 수 있습니다. 특히, 특정 도메인 전문가 데이터를 이용하여 더 전문적이고 시의성 있는 결과를 얻을 수 있습니다.

### 전체 요약
이 논문은 대형 언어 모델(LLM)을 특화된 분야에서 효과적으로 활용하기 위한 데이터 보강 기법을 탐구합니다. 주요 내용은 다음과 같습니다:

1. **서론**: LLM의 활용과 외부 데이터 통합의 필요성.
2. **문제 정의**: 데이터 보강 LLM 응용 프로그램의 다양한 형태와 도전 과제.
3. **질의의 계층화**: 질의를 명시적 사실, 암묵적 사실, 해석 가능한 논리, 숨겨진 논리로 구분하여 다루는 방법.
4. **결과 및 논의**: 데이터 세분화, 검색 메커니즘, 성능 평가 등의 기술적 도전과 해결 방안.
5. **결론**: 데이터 보강을 통한 LLM의 개선 사항과 그 중요성.