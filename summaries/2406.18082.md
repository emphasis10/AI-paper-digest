# Octo-planner: On-device Language Model for Planner-Action Agents
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.18082.pdf](https://arxiv.org/pdf/2406.18082.pdf)

### 1. 섹션별 중요한 내용 요약

#### 1. 도입부
이 논문은 AI 에이전트가 다양한 산업에서 의사 결정을 자율적으로 수행하고 운영 효율성을 향상시키는 방법을 설명합니다. 특히 대형 언어 모델(LLM)인 GPT-4와 Gemini-Pro가 이 분야의 잠재력을 보여주었지만, 복잡한 계획 작업에서는 여전히 인간 수준의 성능을 달성하지 못하고 있습니다. 이 논문에서는 이러한 도전을 극복하기 위해 Octo-planner라는 온디바이스용 계획 에이전트를 소개합니다.

#### 2. 관련 연구
이 섹션에서는 AI 에이전트 시스템에서 계획 에이전트의 중요성과 최근의 연구 동향을 다룹니다. 예를 들어, ReAct 프레임워크는 제한된 행동 공간에서 계획과 실행을 통합하며, Alibaba Group의 연구는 복잡한 작업을 위한 계획 및 실행 모델의 효과를 강조합니다. 또한 LLM을 사용한 로봇 공학 작업 계획의 몇 가지 예도 설명됩니다.

#### 3. 방법론
이 논문은 계획 에이전트와 행동 에이전트를 분리하는 Planner-Action 프레임워크를 제안합니다. 이를 통해 각각의 모델을 최적화하고, 복잡한 작업에서도 효율성과 적응성을 높입니다. 플래닝 모델은 주어진 사용자 쿼리를 여러 하위 단계로 분해하고, 행동 모델은 이 단계를 순차적으로 실행합니다. 이 프레임워크는 특히 제한된 자원 환경에서 효율적으로 작동하도록 설계되었습니다.

#### 4. 실험 설계
실험은 옥토-플래너가 자원 제한이 있는 장치에서 효율적이고 정확한 계획 모델을 배포할 수 있는 최적의 구성을 테스트합니다. 주요 초점은 전체 모델 학습과 LoRA(저-랭크 어댑테이션) 사이의 성능 및 효율성, 다양한 기능 세트를 동시에 처리하는 Multi-LoRA, 다양한 기본 모델 및 크기의 성능 비교, 데이터셋 크기와 정확도의 영향을 평가하는 것입니다.

#### 5. 결과
실험에서는 전체 모델 학습과 LoRA 접근 방식의 성능 차이를 평가합니다. 전체 모델 학습은 98.1%의 정확도를 달성하며, LoRA는 구성에 따라 85.1%에서 72.9% 사이의 정확도를 나타냅니다. Multi-LoRA 기법을 사용하는 경우, 여러 도메인의 기능 세트를 통합할 때 정확도가 점진적으로 감소하지만, 여전히 효율적인 솔루션을 제공합니다.

#### 6. 결론
이 논문은 옥토-플래너를 통해 데이터 프라이버시, 지연 시간, 오프라인 기능 등의 문제를 해결하며, 개인 장치를 위한 실용적이고 정교한 AI 에이전트의 발전을 나타냅니다. 모델 가중치의 오픈소스화를 통해 온디바이스 AI의 혁신을 촉진하는 것을 목표로 합니다. 향후 작업에는 실시간 관찰을 기반으로 계획을 세분화하는 반복 계획 방법론을 탐구하고, 로봇 공학 및 스마트 홈 시스템 등 다양한 응용 분야로 모델의 기능을 확장할 계획입니다.

### 2. 전체 요약
이 논문은 AI 에이전트의 효율성과 적용 가능성을 향상시키기 위해 Octo-planner라는 온디바이스 계획 에이전트를 소개합니다. 이 프레임워크는 계획과 실행을 분리하여 각각의 기능을 최적화하고, 다양한 도메인의 복잡한 작업을 효율적으로 처리합니다. 실험을 통해 전체 모델 학습과 LoRA 접근 방식의 성능을 비교하고, 모델 가중치의 오픈소스화를 통해 온디바이스 AI의 혁신을 촉진합니다. 이 논문은 데이터 프라이버시와 같은 중요한 문제를 해결하며, 실시간 관찰을 기반으로 한 반복 계획 방법론을 통해 AI 에이전트의 적용 가능성을 더욱 확장하고자 합니다.