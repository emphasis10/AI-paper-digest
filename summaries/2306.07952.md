# MOFI: Learning Image Representation from Noisy Entity Annotated Images
## TL;DR
## Summary
- [https://arxiv.org/pdf/2306.07952.pdf](https://arxiv.org/pdf/2306.07952.pdf)

이 논문은 대규모 이미지 데이터셋에서의 잡음이 있는 엔티티 주석을 활용하여 이미지 표현을 학습하는 새로운 시각 기반 모델인 MOFI(Manifold OF Images)를 제시합니다. 이 연구는 기존의 이미지-텍스트 쌍을 활용한 학습 방식과는 달리, 엔티티 인식 모델을 사용하여 텍스트에서 엔티티를 추출하고, 추출된 엔티티를 이미지와 연결하여 새로운 데이터셋인 Image-to-Entities(I2E)를 구축합니다. 이 데이터셋은 약 10억 개의 이미지와 200만 개의 고유 엔티티를 포함하고 있으며, 대규모 이미지 분류와 검색 작업에 활용됩니다.

### 주요 내용 요약

1. **서론 및 배경**:
   - 이미지 표현 학습은 컴퓨터 비전 분야에서 중요한 연구 주제입니다. 특히, 잡음이 있는 이미지-텍스트 쌍에서 학습하는 기존 방법들은 다양한 엔티티 정보를 충분히 활용하지 못하는 한계가 있었습니다.

2. **I2E 데이터셋 구축 방법론**:
   - 웹에서 크롤링한 이미지-텍스트 쌍에서 엔티티를 추출하고, 해당 엔티티가 이미지와 얼마나 관련 있는지를 평가하여 I2E 데이터셋을 구축합니다. 이 과정에서 CLIP 모델을 사용하여 텍스트와 이미지 간의 유사성을 평가하고, 낮은 점수를 가진 쌍은 필터링합니다.

3. **MOFI 모델 학습 방법**:
   - MOFI는 엔티티 기반의 이미지 분류, 엔티티 이름과 설명을 사용한 대조적 학습, 그리고 이 두 방식을 결합한 다중 작업 학습을 포함하여, 다양한 학습 접근 방식을 사용합니다. 이를 통해 더 강력하고 일반화 가능한 이미지 표현을 학습합니다.

4. **실험 결과 및 평가**:
   - 다양한 이미지 검색 및 분류 작업에서 MOFI는 기존의 CLIP 모델보다 우수한 성능을 보여주며, 특히 GPR1200 이미지 검색 데이터셋에서 새로운 최고 성능을 달성합니다. 또한, ImageNet과 VTAB에서의 선형 프로브 및 제로샷 이미지 분류 작업에서도 뛰어난 결과를 보입니다.

### 혁신적인 부분
MOFI의 혁신성은 잡음이 많은 이미지-텍스트 쌍에서 엔티티를 정확하게 추출하고, 이를 기반으로 더 구조화된 지식을 포함하는 새로운 대규모 데이터셋을 구축한 점에 있습니다. 이러한 접근은 이미지 표현 학습을 통한 이미지 검색 및 분류 작업의 성능을 획기적으로 향상시킬 수 있는 기반이 됩니다. 또한, 다중 작업 학습 접근 방식은 엔티티 정보를 활용하여 더욱

 강력한 이미지 표현을 학습하는 데 기여합니다.

이 연구는 잡음이 있는 데이터에서 보다 정교한 이미지 표현 학습 방법을 제시함으로써, 컴퓨터 비전 분야의 발전에 중요한 기여를 하였습니다.

## Similar Papers
- [CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data](2404.15653.md)
- [Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models](2404.07973.md)
- [MoDE: CLIP Data Experts via Clustering](2404.16030.md)
- [Guiding Instruction-based Image Editing via Multimodal Large Language Models](2309.17102.md)
- [MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced Training](2311.17049.md)
- [Diffusion Feedback Helps CLIP See Better](2407.20171.md)
- [Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies](2404.08197.md)
- [Sigmoid Loss for Language Image Pre-Training](2303.15343.md)
- [Knowledge Composition using Task Vectors with Learned Anisotropic Scaling](2407.02880.md)
