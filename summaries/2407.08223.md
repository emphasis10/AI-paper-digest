# Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.08223.pdf](https://arxiv.org/pdf/2407.08223.pdf)

### Section Summaries

#### 1. 도입 (Introduction)
도입부에서는 대형 언어 모델(LLMs)이 질문 응답 과제에서 성공을 거두었음을 설명합니다. LLMs는 방대한 데이터 세트를 학습하여 사용자 쿼리에 그럴듯한 응답을 생성할 수 있습니다. 하지만, 최신 정보나 희귀한 사실을 요구하는 지식 집약적인 질문에 직면할 때는 부정확한 응답이나 허구의 내용을 생성할 수 있습니다. 이를 해결하기 위해, 외부 데이터베이스에서 정보를 검색하여 컨텍스트에 추가하는 방식인 RAG가 도입되었습니다. 이는 지식 집약적인 작업에서 사실 오류를 줄이는 데 효과적입니다.

#### 2. 주요 기여 (Main Contribution)
이 논문은 SPECULATIVE RAG라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 RAG의 성능을 향상시키기 위해 제안된 것입니다. 여기에 사용된 방식은 소규모의 전문 LLM(MDrafter)이 여러 초안을 빠르게 생성하고, 대형의 일반 LLM(MVerifier)이 이를 검증하여 최적의 초안을 선택하는 것입니다. 이를 통해 초안별 입력 토큰 수를 줄이고, 긴 컨텍스트에서 발생할 수 있는 위치 편향을 완화할 수 있습니다. 실험 결과, SPECULATIVE RAG는 TriviaQA, MuSiQue, PubHealth, 그리고 ARC-Challenge와 같은 벤치마크에서 정확도가 최대 12.97% 증가하고, 지연 시간은 51% 감소함을 보여주었습니다.

#### 3. 방법론 (Methodology)
SPECULATIVE RAG 방법론에서는 RAG 작업을 초안 작성 단계와 검증 단계로 나누어 진행합니다. 이 프레임워크는 RAG 시스템의 무거운 작업을 수행하는 소규모 전문 모델과, 이 초안을 검토하고 최적의 답변을 선택하는 대형 일반 모델로 구성됩니다. 이를 통해 데이터 처리 속도는 빠르면서도 정확한 응답을 생성할 수 있습니다. 알고리즘은 K-Means 클러스터링을 사용해 문서를 그룹화한 뒤, MDrafter가 생성한 초안을 MVerifier가 검토하는 절차로 구성됩니다.

#### 4. 실험 결과 및 분석 (Experimental Results and Analysis)
SPECULATIVE RAG의 성능은 다양한 데이터셋에서 측정되었으며, 기존의 RAG 방법론과 비교하여 우수한 성능을 보였습니다. 특히, PubHealth와 ARC-Challenge에서 정확도가 크게 향상되었으며, 지연 시간도 크게 줄어듦을 확인할 수 있었습니다. 이 방법은 문서의 서브셋 크기를 변동하여 실험한 결과, 서브셋에 포함된 문서 수가 큰 경우에도 일관된 성능 향상을 보이지 않음을 발견하였습니다.

#### 5. 결론 및 한계 (Conclusion and Limitations)
논문은 SPECULATIVE RAG가 RAG 작업을 초안 작성과 검증의 두 단계로 나누어 수행함으로써 성능을 향상시킨다는 결론을 내립니다. 이 방법은 다양한 문서 서브셋으로부터 높은 품질의 답변 초안을 생성하고, 이를 검증하여 최종 응답을 생성하는 과정에서 기존 RAG 시스템보다 높은 정확도와 더 빠른 처리 속도를 제공합니다. 그러나 추가적인 초안 작성 모델의 교육이 필요하며, 이는 단순한 RAG 모델에 비해 복잡성을 증가시킬 수 있습니다.

### 전체 요약 (Overall Summary)

이 논문은 대규모 언어 모델(LLMs)이 지식 집약적인 질문에 부정확하거나 허구의 내용을 생성하는 문제를 해결하기 위해 SPECULATIVE RAG라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 소규모의 전문 LLM을 사용하여 여러 초안을 빠르게 생성하고, 대형 일반 LLM이 이를 검증하여 최적의 초안을 선택하는 방식입니다. 이를 통해 RAG 시스템의 정확도와 속도를 크게 향상시킬 수 있음을 실험을 통해 입증했습니다. 하지만 추가 모델의 교육이 필요하다는 한계가 있습니다. SPECULATIVE RAG는 고도의 정확성과 효율성을 목표로 하는 RAG 시스템의 새로운 가능성을 제시합니다.

## Similar Papers
- [Improving Retrieval Augmented Language Model with Self-Reasoning](2407.19813.md)
- [Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought](2404.03414.md)
- [Found in the Middle: Calibrating Positional Attention Bias Improves Long Context Utilization](2406.16008.md)
- [Searching for Best Practices in Retrieval-Augmented Generation](2407.01219.md)
- [Small Language Models Need Strong Verifiers to Self-Correct Reasoning](2404.17140.md)
- [CodecLM: Aligning Language Models with Tailored Synthetic Data](2404.05875.md)
- [RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation](2408.02545.md)
- [A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems](2406.14972.md)
- [Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models](2305.09955.md)
