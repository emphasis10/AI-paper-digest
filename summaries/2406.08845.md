# Rethinking Human Evaluation Protocol for Text-to-Video Models: Enhancing Reliability,Reproducibility, and Practicality
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.08845.pdf](https://arxiv.org/pdf/2406.08845.pdf)

### 1. 섹션별 핵심 내용 요약

---

#### Introduction

- **요약**: 최근 몇 년간 텍스트에서 비디오(Text-to-Video, T2V) 생성 기술이 큰 발전을 이루어왔습니다. 자동 평가 방식의 한계를 극복하기 위해 인적 평가가 중요시되지만, 기존 인적 평가 프로토콜은 재현성, 신뢰성, 실용성에서 문제를 겪고 있습니다. 본 논문은 이를 해결하기 위해 새로운 T2V 인적 평가 프로토콜(T2VHE)을 제안합니다.
- **주요 기여**: T2VHE 프로토콜을 통해 고품질의 주석을 저렴한 비용으로 확보할 수 있으며, 이 프로토콜을 오픈소스로 제공하여 연구 커뮤니티에서 새로운 모델을 평가할 수 있도록 합니다.

---

#### Related Work

- **요약**: T2V 생성 모델의 발전과 관련 연구들을 다룹니다. 생성적 적대 신경망(GAN), 자동 회귀 모델, 확산 모델 등이 비디오 생성에 사용되었습니다. 최근에는 이미지 합성에서 성공한 확산 모델이 비디오 합성으로도 적용되고 있습니다.
- **주요 기여**: 이 논문은 T2V 모델의 평가 방법의 필요성을 강조하며, 기존 모델들의 평가 방식에 대한 리뷰를 제공합니다.

---

#### Evaluation metrics of video generative models

- **요약**: 비디오 생성 모델의 평가 지표에는 자동 평가 지표와 벤치마크 방법이 있습니다. Inception Score(IS), Frechet Inception Distance(FID) 등의 지표가 사용되지만, 인간의 인식과 일치하지 않는 경우가 많습니다.
- **주요 기여**: 높은 품질의 인적 평가가 여전히 중요함을 강조합니다.

---

#### Human evaluation in video generation

- **요약**: 2016년부터 89편의 비디오 생성 모델에 대한 논문을 설문 조사한 결과, 일관성 있는 인적 평가 프로토콜을 사용한 논문은 거의 없음을 발견했습니다. 이는 평가 지표, 평가 방법, 주석자 소스의 차이 때문입니다.
- **주요 기여**: 기존 연구들이 인적 평가에 대한 자세한 정보를 제공하지 않아 재현성이 낮다는 문제를 제기합니다.

---

#### Conclusion

- **요약**: 본 논문은 이전의 인적 평가 프로토콜의 재현성, 신뢰성, 실용성 문제를 해결하려는 T2VHE 프로토콜을 제안합니다. 정해진 평가 지표, 철저한 주석자 교육, 동적 평가 모듈을 통해 고품질의 주석을 저렴한 비용으로 얻을 수 있습니다. 이 프로토콜은 연구 커뮤니티가 새로운 모델을 평가하고 확장 연구를 계속할 수 있는 기반이 됩니다.
- **주요 기여**: T2VHE 프로토콜의 오픈 소싱을 통해 연구자들이 더 복잡한 평가 프로토콜을 구축할 수 있도록 합니다.

### 2. 전체 요약

본 논문은 텍스트-비디오(T2V) 생성 기술의 발전에도 불구하고, 이들 모델에 대한 평가가 어려운 문제를 지적합니다. 자동 평가 방식의 한계를 극복하고 인적 평가의 중요성을 강조하면서도, 기존 인적 평가 프로토콜이 재현성, 신뢰성, 실용성에서 문제를 겪고 있음을 발견했습니다. 이를 해결하기 위해 새로운 T2V 인적 평가 프로토콜(T2VHE)을 제안했습니다.

이 프로토콜은 잘 정의된 평가 지표와 철저한 주석자 교육, 동적 평가 모듈을 통해 고품질의 주석을 매우 낮은 비용으로 얻을 수 있는 점이 특징입니다. 특히, 새로운 평가 모델을 연구 커뮤니티에서 쉽게 적용하고 확장할 수 있는 기반을 마련하여, T2V 모델의 평가와 발전에 기여하고자 합니다. 논문의 주요 기여는 다음과 같습니다:
1. **표준화된 인적 평가 프로토콜 도입**: 높은 품질의 주석을 제공하는 평가 지표 및 주석자 교육 자료 포함.
2. **동적 평가 모듈**: 평가 비용을 절반 수준으로 줄이면서도 주석 품질 유지.
3. **프로토콜 오픈소싱**: 연구자가 새로운 모델을 추가 평가하고 기존 리뷰를 바탕으로 재평가할 수 있게 합니다.

이와 같은 본 논문의 기여는 T2V 평가 프로세스의 신뢰성과 실용성을 높이고, 더 나아가 AI와 머신러닝 기술의 발전에 중요한 역할을 할 것입니다.

## Similar Papers
- [IRASim: Learning Interactive Real-Robot Action Simulators](2406.14540.md)
- [GUI Odyssey: A Comprehensive Dataset for Cross-App GUI Navigation on Mobile Devices](2406.08451.md)
- [VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation](2406.15252.md)
- [MMIU: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models](2408.02718.md)
- [Needle In A Multimodal Haystack](2406.07230.md)
- [Image Conductor: Precision Control for Interactive Video Synthesis](2406.15339.md)
- [VIMI: Grounding Video Generation through Multi-modal Instruction](2407.06304.md)
- [MotionClone: Training-Free Motion Cloning for Controllable Video Generation](2406.05338.md)
- [4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models](2406.07472.md)
