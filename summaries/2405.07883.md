# Zero-Shot Tokenizer Transfer
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.07883.pdf](https://arxiv.org/pdf/2405.07883.pdf)

### 주요 내용 요약

1. **서론 및 배경**:
   - 이 논문은 언어 모델(LM)이 사용되는 토크나이저에 의존하는 문제를 해결하기 위해 제로샷 토크나이저 전이(Zero-Shot Tokenizer Transfer, ZeTT) 문제를 제안합니다. 기존의 언어 모델은 주로 영어에 맞춰져 있어 다른 언어나 프로그래밍 언어에 대해 효율성이 떨어지며, 이 문제를 해결하기 위해 새로운 토크나이저로 전환할 수 있는 방법이 필요합니다.

2. **방법론**:
   - ZeTT의 핵심 과제는 새로운 토크나이저의 어휘에 대한 임베딩을 찾는 것입니다. 이를 위해 하이퍼네트워크를 사용하여 주어진 토크나이저에 대한 임베딩을 예측하는 방법을 제안합니다. 이 하이퍼네트워크는 다양한 토크나이저 분포에 대해 훈련되어 새로운 토크나이저에도 일반화될 수 있습니다.
   - 하이퍼네트워크는 원래 토크나이저로 텍스트를 분해하고, 그 임베딩을 통해 새로운 임베딩을 구성하는 방식으로 작동합니다.

3. **실험**:
   - ZeTT를 구현한 결과, 하이퍼네트워크가 기존 모델의 성능을 거의 유지하면서 새로운 토크나이저로의 전환을 가능하게 한다는 것을 실증적으로 보여주었습니다. 특히 Mistral-7B 모델과 XLM-R 모델에서 좋은 성능을 보였습니다. 일부 작업에서는 약간의 추가 훈련을 통해 성능 격차를 더욱 줄일 수 있음을 확인했습니다.
   - 예를 들어, Mistral-7B 모델의 토크나이저를 코드에 더 적합한 토크나이저로 대체한 결과, 토큰화된 시퀀스 길이가 10% 줄어들었으며, 성능 차이는 약 3% 내외로 유지되었습니다. 또한, 다국어 모델인 XLM-R의 경우, 언어별 토크나이저로 전환하여 약 16%의 속도 향상을 이루었습니다.

### 혁신적인 부분
이 논문의 혁신성은 언어 모델을 특정 토크나이저에 종속시키지 않고, 다양한 토크나이저에 대해 제로샷 전이를 가능하게 하는 하이퍼네트워크를 제안한 데 있습니다. 이 방법은 기존의 휴리스틱 기반 임베딩 초기화 방법보다 더 나은 성능을 제공하며, 최소한의 추가 훈련으로도 높은 성능을 유지할 수 있습니다. 이를 통해 언어 모델의 유연성과 재사용성을 크게 향상시킬 수 있습니다.