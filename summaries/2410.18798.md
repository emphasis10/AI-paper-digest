# Distill Visual Chart Reasoning Ability from LLMs to MLLMs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.18798.pdf](https://arxiv.org/pdf/2410.18798.pdf)

1. 각 섹션의 중요한 내용을 요약하여 제공하겠습니다.

**소개 및 배경**
이 논문은 복잡한 차트 질의응답(Q&A) 작업을 해결하기 위해 멀티모달 대규모 언어 모델(MLLM)의 시각적 추론 능력을 향상시키는 연구에 관한 것입니다. 이러한 능력을 효과적으로 향상시키기 위해, 연구팀은 학습 데이터를 구축하여 키 정보 인식과 합리적 추론에 중점을 둡니다.

**기존 차트 관련 데이터셋의 문제점**
기존 데이터셋은 차트 인식과 추론 능력에 대한 시험에 많은 제약이 있으며, 이는 MLLM 연구의 발전에 미흡함이 있습니다. 연구팀은 이러한 문제를 해결하기 위해 새로운 방식의 데이터셋을 제시합니다.

**ReachQA 데이터셋 구축**
연구팀은 Code-as-Intermediary Translation(CIT)라는 기법을 통해 차트 이미지를 글자 표현으로 번역하고, 이를 기반으로 인식 및 추론을 위한 막대한 Q&A 데이터를 생성합니다. 이로써 시각적 인식과 논리적 추론 능력을 강화하고 비용 효율성을 높였습니다.

**실험 및 결과**
다양한 멀티모달 대규모 언어 모델을 여러 데이터셋을 통해 테스트한 결과, REACHQA와 같은 합성 데이터셋이 인간 주석 데이터에 필적하는 성능을 보였으며, 특히 GPT-4o 모델의 인식 및 추론 점수를 크게 향상시켰습니다.

**논의**
연구팀은 효과적인 시각적 추론을 위해 인식과 추론 능력이 상호 의존적임을 실험을 통해 확인하였으며, 전문적인 추론 능력을 증대시키기 위한 전략을 연구합니다. 또한, 통합 데이터셋의 성능을 균형 있게 유지하기 위한 결과도 다룹니다.

**결론**
논문은 MLLM이 차트와 같은 복잡한 시각적 정보를 효과적으로 처리하도록 하는 방법론을 제시하였으며, 이는 다양한 분야의 추론 작업에서 성능을 향상시키는 결과를 나타냅니다.

2. 전체 요약

이 논문은 멀티모달 대규모 언어 모델이 차트와 같은 복잡한 시각적 요소를 효과적으로 이해하고 응답할 수 있도록 하기 위한 새로운 기법과 데이터셋을 제안합니다. Code-as-Intermediary Translation(CIT)이라는 방법론을 통해 비용 효과적으로 방대한 학습 데이터를 생성하고, 이를 활용하여 모델의 인식 및 추론 능력을 증강시킵니다. 특히, 이 연구는 전문적인 추론 능력을 강화하는 데 중점을 둔 실험 결과와 함께, 기존에 존재하는 데이터셋의 부족함을 보완하는 방안을 제공합니다.