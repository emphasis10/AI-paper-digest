# SURGE: On the Potential of Large Language Models as General-Purpose Surrogate Code Executors
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.11167.pdf](https://arxiv.org/pdf/2502.11167.pdf)

1. **각 섹션 요약**

   - **소개 (Introduction)**
     이 논문은 LLMs(대형 언어 모델)의 일반적인 코드 실행 대리자로서의 가능성을 탐구합니다. 실행되지 않은 코드의 결과를 예측하는 능력은 실행 중에 많은 자원을 소모하거나 위험을 초래할 수 있는 환경에서 특히 유용합니다.

   - **데이터셋 구성 (Dataset Components)**
     다국어 코드, 대회 수준 코드, 저장소 수준 코드, 과학 계산 등을 포함하는 다양한 데이터셋을 사용하여 LLMs의 코드 실행 예측 능력을 평가합니다. 이 데이터셋은 복잡한 알고리즘을 다루며, 각 데이터셋은 구체적인 실행 환경 없이도 정확한 결과를 예측할 수 있는지를 테스트합니다.

   - **실험 및 분석 (Experiments and Analysis)**
     LLMs를 다양한 모델 및 환경 설정하에 테스트하여 각 모델의 성능 및 제한 사항을 조사합니다. 특히 CoT(Chain-of-Thought) 기법을 적용했을 때 성능이 향상된다는 점, 코드 모델이 규칙 기반 모델보다 장점이 있다는 점을 발견했습니다.

   - **결론 (Conclusion)**
     SURGE라는 새로운 벤치마크를 소개하여 LLMs를 일반적인 대리 코드 실행 모델로 평가합니다. LLMs가 실행 결과를 어느 정도 예측할 수 있는 능력이 있지만, 아직 개선의 여지가 많다고 결론 내립니다.

2. **전체 요약**

   이 논문은 LLMs를 일반적인 코드 실행 대리자로 평가하는 새로운 벤치마크인 SURGE를 도입합니다. 다양한 프로그래밍 언어 및 데이터셋을 기반으로, LLMs가 실행되지 않은 코드의 결과를 예측할 수 있는 능력을 평가하며, 특히 CoT 기법이 모델의 성능을 향상시킨다는 결론에 도달합니다. LLMs가 어느 정도의 실행 결과 예측 능력을 지니고 있음에도 불구하고, 아직 많은 부분에서 개선이 필요한 상태라는 점을 강조합니다.