# Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.06703.pdf](https://arxiv.org/pdf/2502.06703.pdf)

1. 각 섹션 요약:

   - **서론**: 이 논문에서는 큰 언어 모델(LLM)의 성능을 향상시키기 위해 시험 시간 확장(TTS)을 사용하는 방법을 탐구합니다. TTS는 모델의 추론 능력을 강화하기 위해 추론하는 동안 추가적인 계산을 할당하는 기법입니다. 특히 다양한 정책 모델, 프로세스 보상 모델(PRM) 및 문제 난이도가 TTS에 미치는 영향을 분석하여 이해를 높이고자 합니다.

   - **실험 및 결과**: 실험에서는 여러 수학적 데이터 세트(MATH-500, AIME24) 상에서 다양한 정책 모델과 PRM을 적용하여 TTS의 성능을 평가합니다. 결과적으로 TTS 전략은 특정 정책 모델 및 문제 난이도에 따라 달라지며, 작은 모델도 잘 최적화된 TTS를 통해 더 큰 모델을 초과할 수 있음을 보여줍니다.

   - **결론 및 토론**: TTS는 다양한 정책 모델 및 PRM에 따라 성능이 달라질 수 있으며, 잘 조정된 TTS를 통해 작은 LLM이 더 큰 모델보다 높은 성능을 발휘할 수 있습니다. 따라서 TTS는 LLM의 추론 능력을 강화하기 위한 유망한 접근 방식임을 시사합니다. 향후 연구에서는 보다 유연하고 보편적인 감독 메커니즘 개발에 중점을 두어야 한다고 언급되었습니다.

2. 전체 요약:

   이 논문은 시험 시간 확장(TTS)이 LLM의 추론 성능을 향상시킬 수 있는 방법에 중점을 두고 있습니다. 조사 결과, 작은 정책 모델도 TTS를 잘 활용할 경우 대형 모델보다 뛰어난 성능을 발휘할 수 있다고 결론지었습니다. TTS는 특히 수학적 문제 해결에서 LLM의 능력을 상당히 개선할 수 있는 가능성을 보여주며, 향후에는 보다 보편적이고 적응성이 뛰어난 감독 메커니즘 개발에 초점을 맞출 필요가 있음을 제안합니다.