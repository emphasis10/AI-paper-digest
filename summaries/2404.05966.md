# THOUGHTSCULPT: Reasoning with Intermediate Revision and Search
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.05966.pdf](https://arxiv.org/pdf/2404.05966.pdf)

**1. 요약**

본 논문에서는 'THOUGHTSCULPT'라는 새로운 일반적인 추론 및 검색 방법을 제시합니다. 이 방법은 Monte Carlo Tree Search(MCTS)를 활용하여 해결책을 한 단계씩 구축하고, 도메인별 휴리스틱을 사용하여 평가하는 검색 트리를 탐색합니다. THOUGHTSCULPT의 주요 특징은 기존 출력의 일부를 수정하는 리비전 작업을 포함한다는 점입니다. 이를 통해 이전 출력을 계속해서 개선할 수 있습니다.

**2. 관련 작업**

이전 연구들은 LLMs의 출력을 개선하기 위해 인간의 피드백을 활용하거나, LLMs가 자가 피드백을 생성하여 출력을 개선하도록 한 방법들을 소개했습니다. 본 연구에서는 휴리스틱 함수를 사용하여 피드백을 생성하고, 여러 후보를 생성한 후 최적의 출력을 선택하는 방식을 제안합니다.

**3. 방법**

THOUGHTSCULPT는 세 가지 주요 모듈로 구성됩니다: 생각 평가기, 생각 생성기, 그리고 결정 시뮬레이터. 생각 평가기는 각 생각 노드의 상태를 평가하고 개선 가능성에 대한 피드백을 제공합니다. 생각 생성기는 초기 지시와 자가 평가 피드백을 바탕으로 가능한 해결책을 생성합니다. 결정 시뮬레이터는 더 깊은 단계의 결정을 시뮬레이션하고 현재 결정의 점수를 업데이트합니다.

**4. 실험**

본 논문에서는 스토리 개요 개선, 미니 크로스워드 해결, 제약 생성 등 세 가지 다양한 작업에서 THOUGHTSCULPT를 평가합니다. 이 실험들은 THOUGHTSCULPT가 다양한 상태의 예술적 추론 전략보다 우수하다는 것을 보여줍니다.

**5. 결론**

THOUGHTSCULPT는 복잡한 작업을 처리하고 깊은 추론 능력을 발휘할 수 있도록 LLMs를 강화하는 프레임워크입니다. MCTS 알고리즘을 활용하여 방대한 검색 공간을 효과적으로 탐색하고 계산 자원 비용을 효율적으로 관리합니다. 이를 통해 LLMs가 지속적으로 생각을 반복하고 개선할 수 있게 도와줍니다.

이러한 내용을 바탕으로 보다 상세한 전반적인 요약을 다음에 제공하겠습니다.

본 논문에서는 'THOUGHTSCULPT'라는 새로운 일반적인 추론 및 검색 방법을 제안합니다. 이 방법은 Monte Carlo Tree Search(MCTS)를 사용하여 가능한 해결책의 검색 트리를 탐색하며, 특정 도메인의 휴리스틱을 사용하여 각 단계에서 솔루션을 평가합니다. THOUGHTSCULPT의 주요 혁신은 수정 작업을 포함하여 이전의 출력을 지속적으로 개선할 수 있다는 점입니다.

이 방법은 스토리 개요 개선, 미니 크로스워드 해결, 그리고 제약된 생성과 같은 세 가지 복잡한 작업에서 테스트되었습니다. THOUGHTSCULPT는 다양한 상태의 예술 추론 전략을 베이스라인으로 하여 실험되었으며, 이들 작업에서 기존 방법들을 능가하는 성능을 보였습니다. 결과적으로, THOUGHTSCULPT는 복잡한 문제를 해결하고 지속적인 개선을 통해 더 나은 결과를 도출할 수 있는 LLMs의 능력을 향상시키는 유망한 방법임을 입증하였습니다.

## Similar Papers
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](2305.10601.md)
- [AlphaMath Almost Zero: process Supervision without process](2405.03553.md)
- [Improve Mathematical Reasoning in Language Models by Automated Process Supervision](2406.06592.md)
- [LiteSearch: Efficacious Tree Search for LLM](2407.00320.md)
- [Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages](2407.03321.md)
- [Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B](2406.07394.md)
- [Is Programming by Example solved by LLMs?](2406.08316.md)
- [Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing](2404.12253.md)
- [Efficient World Models with Context-Aware Tokenization](2406.19320.md)
