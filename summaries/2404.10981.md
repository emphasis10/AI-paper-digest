# A Survey on Retrieval-Augmented Text Generation for Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.10981.pdf](https://arxiv.org/pdf/2404.10981.pdf)

### 논문 요약

#### 1. 서론
이 논문은 대형 언어 모델(LLMs)의 한계를 극복하기 위해 검색 보강 생성(RAG)을 소개합니다. RAG는 최신 외부 정보를 동적으로 통합하여 LLM의 정확도와 신뢰성을 향상시키는 방법을 제공합니다. 이는 주로 텍스트 도메인에 초점을 맞추어 플라우저 대응이 가능하도록 하며, 가장 비용 효율적인 솔루션을 제공합니다.

#### 2. RAG 프레임워크
RAG는 크게 네 가지 단계로 구성됩니다: 사전 검색(pre-retrieval), 검색(retrieval), 사후 검색(post-retrieval), 그리고 생성(generation). 이 단계들을 통해 관련 정보를 효과적으로 검색하고 정확한 응답을 생성하는 방법을 설명합니다.

#### 3. 기술적 접근
- **사전 검색**: 데이터 정규화, 색인 생성, 쿼리 조정과 같은 초기 데이터 준비 작업을 포함합니다.
- **검색**: 향상된 검색 알고리즘과 LLM을 사용하여 쿼리의 의미를 더 잘 파악하고 관련 문서를 검색합니다.
- **사후 검색**: 검색된 문서를 재정렬하고 필터링하여 최종 생성 작업에 사용할 최적의 문서를 선택합니다.
- **생성**: 검색된 정보를 바탕으로 사용자의 쿼리에 대한 관련성 높은 텍스트를 생성합니다.

#### 4. 평가 및 미래 연구 방향
논문은 RAG의 평가 방법을 소개하고, 텍스트 기반 연구를 넘어 이미지 및 다중 모달 데이터를 고려한 미래 연구 방향을 제시합니다. 평가는 RAG 시스템의 효과를 면밀히 측정하여 더 나은 성능을 이끌어내는 데 중점을 둡니다.

### 종합적인 요약
이 논문은 검색 보강 생성(RAG)을 통해 대형 언어 모델(LLMs)의 정확성과 신뢰성을 향상시키는 방법론을 제공합니다. RAG는 최신 정보를 통합하여 모델의 반응을 개선하고, 네 가지 주요 단계를 통해 이를 구현합니다. 또한, RAG의 평가 방법과 미래 연구 방향을 제시하여 이 분야의 발전 가능성을 탐색합니다. 이 연구는 RAG의 기술적 기반을 명확히 하고, 다양한 LLMs의 적응성과 응용 가능성을 넓히는 데 기여할 것입니다.

## Similar Papers
- [RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing](2404.19543.md)
- [A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models](2405.06211.md)
- [Privacy Preserving Prompt Engineering: A Survey](2404.06001.md)
- [MindSearch: Mimicking Human Minds Elicits Deep AI Searcher](2407.20183.md)
- [A Systematic Survey of Text Summarization: From Statistical Methods to Large Language Models](2406.11289.md)
- [Exploring Advanced Large Language Models with LLMsuite](2407.12036.md)
- [When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively](2404.19705.md)
- [A Survey on Mixture of Experts](2407.06204.md)
- [RAFT: Adapting Language Model to Domain Specific RAG](2403.10131.md)
