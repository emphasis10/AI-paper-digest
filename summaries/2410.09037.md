# Mentor-KD: Making Small Language Models Better Multi-step Reasoners
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.09037.pdf](https://arxiv.org/pdf/2410.09037.pdf)

### 1. 각 섹션의 요약 및 주요 기여와 혁신적인 부분

이 논문은 소형 언어 모델(Small Language Model)이 멀티스텝 사고(Reasoning) 능력을 갖추도록 하는 Mentor-KD라는 새로운 지식 증류 프레임워크를 제안합니다. 주요 내용은 다음과 같습니다:

- **서론(Introduction):** 
  대형 언어 모델(LLM)은 복잡한 작업에서 뛰어난 능력을 보여주고 있으며, 이는 주로 Chain-of-Thought(CoT) 프롬프트를 통해 이루어집니다. 그러나 기존의 큰 모델들은 막대한 컴퓨팅 자원이 필요하여 자원이 제한된 환경에서는 사용이 어렵습니다. 이를 해결하기 위해, 기존 연구들은 LLM의 멀티스텝 사고 능력을 소형 모델로 전달하는 지식 증류(KD) 방식을 사용했습니다.
  
- **관련 연구(Related Works):** 
  CoT 프롬프트는 LLM이 복잡한 문제를 단계별로 해결하는 데 도움을 주며, 이론상 모델이 작아도 이러한 능력을 갖추게 하려는 연구가 진행되었습니다. KD 기법은 일반적으로 LLM 교사 모델의 출력을 증류 세트로 활용하여 학생 모델을 미세조정합니다.
  
- **Mentor-KD 방법론(Methodology):** 
  Mentor-KD는 중간 크기의 작업 별 미세조정된 모델을 멘토 역할로 활용하여 추가적인 CoT 주석과 소프트 레이블을 생성합니다. 이를 통해 기존 LLM 교사 모델의 제한된 증류 세트 문제를 보완하여 학생 모델의 멀티스텝 사고 능력을 개선합니다.

- **실험 결과(Results):** 
  다양한 복잡한 사고 과제에서 Mentor-KD는 기존 기법보다 학생 모델의 성능을 향상시킴을 확인하였습니다. 특히, 저자원 시나리오에서 비용 효율성도 입증했습니다.

### 2. 전체적인 요약

Mentor-KD는 복잡한 사고 능력을 갖춘 LLM의 장점을 소형 언어 모델에 효과적으로 전이할 수 있는 혁신적인 지식 증류 프레임워크입니다. 이 방법은 기존의 CoT 프롬프트를 강화하고, LLM으로부터의 한정된 증류 세트를 보완하여, 소형 모델도 고급 사고 능력을 가질 수 있게 합니다. 특히 다양한 지식 집약적인 과제에서 성능을 크게 향상시킬 수 있으며, 저자원 환경에서도 효율적으로 사용할 수 있습니다.