# MiniCPM-V: A GPT-4V Level MLLM on Your Phone
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.01800.pdf](https://arxiv.org/pdf/2408.01800.pdf)

### 요약: MiniCPM-V Series 모델

#### 1. 도입
- **다중모달 대형 언어 모델(MiniCPM-V) 시리즈**: 이 연구는 여러 장치에서 실행 가능한 효율적인 다중모달 대형 언어 모델(MLLM)을 설계하는 데 중점을 둡니다. 현재 대부분의 MLLM은 대규모 파라미터로 인해 높은 에너지 소비와 탄소 배출을 유발해 클라우드 서버에서만 실행이 가능합니다. 이로 인해 모바일 기기, 에너지 민감한 시나리오, 오프라인 사용 및 개인 정보 보호에 한계가 있습니다.

#### 2. MiniCPM-V Series 모델 특징
- **MiniCPM-Llama3-V 2.5**: 최신 모델로, 주목할 만한 성능과 효율성을 자랑하며, GPT-4V-1106, Gemini Pro, Claude 3를 능가하는 성능을 보입니다.

#### 3. 주요 기술적 특징
- **선두 성능**: OpenCompass 평가에서 GPT-4V-1106, Gemini Pro, Claude 3를 능가.
- **강력한 OCR 기능**: 텍스트 인식 및 변환 기능을 지원, 높은 해상도를 통해 고품질 이미지 인식.
- **신뢰할 수 있는 동작**: AI/인간 피드백을 통한 행동 정렬(RLAIF-V, RLHF-V) 기술로 신뢰성 높은 동작 구현.
- **다국어 지원**: 30개 이상의 언어를 지원하며, 다국어 교육을 통한 멀티모달 역량 확대.
- **효율적인 엔드사이드 배포**: 최적화 기술을 활용한 메모리 및 컴파일 최적화, NPU 가속을 통해 모바일 기기에서도 효율적인 실행 가능.

#### 4. 전체 요약
- **총괄 요약**: 본 연구는 휴대폰 등 다양한 장치에서 실행 가능한 효율적인 다중모달 대형 언어 모델(MLLM) 시리즈인 MiniCPM-V를 소개합니다. MiniCPM-Llama3-V 2.5는 GPT-4V 수준의 성능을 구현하며, 텍스트 인식, 다국어 지원 및 신뢰성 있는 동작을 특징으로 합니다. 이러한 모델은 클라우드 서버에서 실행해야 하는 기존 MLLM의 한계를 극복하고, 모바일 및 에너지 민감한 시나리오에서도 활용할 수 있는 가능성을 열어줍니다. 향후에는 멀티모달 역량을 더욱 확장하고, 다양한 장치에서의 실시간 상호작용을 가능하게 하기 위한 연구가 필요합니다.