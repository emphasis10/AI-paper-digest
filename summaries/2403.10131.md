# RAFT: Adapting Language Model to Domain Specific RAG
## TL;DR
## Summary
- [https://arxiv.org/pdf/2403.10131.pdf](https://arxiv.org/pdf/2403.10131.pdf)

### 1. 섹션별 요약

#### 1. Introduction (소개)
이 논문은 'Retrieval-Augmented Fine-Tuning' (RAFT)라는 새로운 학습 방법을 제안하고 있습니다. 이는 문서 검색을 통해 질문에 답을 제공하는 기존 방법들의 단점을 해결하고자 합니다. RAFT는 대형 언어 모델(LLM)이 특정 도메인 내에서 더 나은 성능을 발휘하도록 도와줍니다.

#### 2. LLMs for Open-Book Exam (개방형 책 시험을 위한 LLM)
기존의 'in-context retrieval'(문맥 내 검색) 방법이나 'supervised fine-tuning'(감독된 미세 조정) 방법은 개방형 책 시험과 비유될 수 있습니다. RAFT는 점진적으로 더 나은 문서 이해와 답변 생성을 위해 설계되었습니다.

#### 3. RAFT
RAFT는 Q(질문), D*(관련 문서), Dk(산만한 문서) 조합으로 학습 데이터를 구성합니다. 이를 통해 모델이 관련 문서를 더 잘 식별하고 불필요한 정보를 무시할 수 있도록 돕습니다. 또한 Chain-of-Thought 접근 방식을 사용하여 일련의 논리적 단계를 거쳐 답을 생성합니다. 이 방법론은 다양한 데이터세트에서 우수한 성능을 보였습니다.

#### 4. Evaluation (평가)
다양한 데이터세트를 사용해 RAFT와 기존 방법들을 비교한 결과, RAFT는 일관되게 우수한 성능을 보여주었습니다. 특히 HotpotQA와 HuggingFace 데이터세트에서 큰 성능 향상을 보였습니다.

#### 5. RAFT Generalizes to Top-K RAG (Top-K RAG에 대한 RAFT 일반화)
TRAIN과 TEST 시점에서의 문서 수의 변화에 대한 모델의 성능을 연구한 결과, RAFT는 혼합된 문서 구성으로 인해 다양한 상황에서도 견고한 성능을 유지할 수 있었습니다.

#### 6. Related Works (관련 연구)
기존의 RAG와 학습 방법론들의 한계를 보완하며, 더 나은 성능을 위해 RAFT가 제안되었습니다. 이는 특히 특정 도메인 내의 질문에 답변하는 시나리오에서 유용합니다.

#### 7. Conclusion (결론)
RAFT는 모델이 특정 도메인 내에서 질문에 대해 더 나은 성능을 발휘하도록 도와주는 학습 전략입니다. 이는 특히 실무적이고 학문적인 영역에서 인기를 끌 것으로 기대됩니다.

### 2. 논문의 전체 요약

이 논문에서는 Retrieval-Augmented Fine-Tuning (RAFT)라는 새로운 학습 방법을 제안합니다. RAFT는 대형 언어 모델(LLM)을 특정 도메인 내에서 질문에 대해 더 잘 응답할 수 있도록 돕습니다. 이를 위해 모델은 문맥 내에서 관련 문서를 식별하고, 쓸모없는 정보를 걸러내는 능력을 키웁니다. 다양한 데이터셋에서의 성능 평가 결과, RAFT는 기존 방법들보다 우수한 성능을 보였으며 특히 특정 도메인 내에서 일관된 우수한 성능을 유지했습니다. 이런 특성 덕분에 RAFT는 향후 특정 도메인 내에서의 질문 답변 태스크에 유용하게 사용될 수 있을 것입니다.