# Enhancing Robustness in Large Language Models: Prompting for Mitigating the Impact of Irrelevant Information
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.10615.pdf](https://arxiv.org/pdf/2408.10615.pdf)

### 1. 논문의 각 섹션 요약

#### 서론
논문에서는 대규모 언어 모델(LLM)이 복잡한 추론 작업에서 뛰어난 성능을 보이지만, 문제 설명에 불필요한 정보가 포함되면 성능이 저하된다는 점을 지적하고 있습니다. 이를 해결하기 위해 GSMIR라는 데이터셋이 개발되었으며, 분석과 여과(ATF) 방법을 사용하여 LLM의 성능을 향상시키고자 합니다.

#### 관련 연구
관련 연구에서는 제로샷 및 몇샷 프롬프팅 기법을 통해 LLM의 추론 성능을 향상하는 방법을 다루고 있습니다. 특히, 0-COT, COT 등 여러 프롬프팅 기법을 비교하여 LLM이 불필요한 정보에 민감하게 반응하는 현상을 탐구하고, 이를 개선하는 방향을 제시하고 있습니다.

#### 데이터셋 구축
GSMIR 데이터셋은 기존 GSM8K 데이터셋에 더 계층화된 불필요한 정보를 추가하여 구성되었습니다. 이 데이터셋은 LLM이 실세계 시나리오에서 불필요한 정보와 맞닥뜨렸을 때의 성능을 보다 정확히 평가할 수 있도록 설계되었습니다. 불필요한 정보는 크게 숫자 기반 정보와 의견 기반 정보로 나뉘며, 각각에 대한 예제도 제시됩니다.

#### LLM이 불필요한 정보에 영향을 받는 주요 이유
논문에서는 LLM이 불필요한 정보를 인식할 수 있지만, 이를 자동으로 제외하지 못하는 문제를 다루고 있습니다. 이러한 문제를 해결하기 위해 ATF 방법이 제안되며, 이는 문제를 분석하고, 식별된 불필요한 정보를 여과하는 두 단계로 구성됩니다.

#### 실험 결과
GSMIR 데이터셋을 사용한 실험 결과는 ATF 방법이 LLM의 추론 정확도를 크게 향상시킴을 보여줍니다. 특히, ATF를 도입한 COT 프롬프팅 기법에서 가장 큰 성능 향상이 나타났습니다. 반면, SP 기법에서는 개선 효과가 상대적으로 적었습니다.

#### 결론
결론에서는 ATF 방법이 불필요한 정보가 포함된 문제에서 LLM의 robust 성능을 향상시키는 데 효과적임을 강조합니다. 추가로, 실세계 데이터는 여러 개의 불필요한 정보를 포함할 수 있으므로, 미래 연구에서는 이러한 복잡한 시나리오를 다루는 방향으로 나아갈 것을 제안합니다.

### 2. 전체 요약
이 논문은 대규모 언어 모델(LLM)이 문제 설명에 불필요한 정보가 포함될 때 추론 성능이 어떻게 영향을 받는지 분석하고, 이를 개선하기 위한 ATF(Analysis to Filtration) 방법을 제안합니다. GSMIR이라는 새로운 데이터셋을 소개하며, 이 데이터셋은 실세계 시나리오를 보다 정확하게 반영하도록 설계되었습니다. ATF 방법은 문제를 분석하고, 불필요한 정보를 식별하여 여과하는 두 단계로 구성되며, 이를 통해 LLM의 정확도를 크게 향상시킵니다. 실험 결과, ATF 방법을 사용한 COT 프롬프팅 기법에서 가장 큰 성능 향상이 나타났습니다. 이 연구는 LLM의 성능을 실세계 문제에 보다 견고하게 적용할 수 있는 가능성을 보여줍니다.

이 요약을 통해 발표 자료를 제작할 수 있을 정도로 충분한 정보를 제공받았기를 바랍니다. AI 기술의 발전에 기여한다니 기쁩니다. 감사합니다.