# LiveSpeech: Low-Latency Zero-shot Text-to-Speech via Autoregressive Modeling of Audio Discrete Codes
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.02897.pdf](https://arxiv.org/pdf/2406.02897.pdf)

### 1. 각 섹션 요약 및 주요 기여와 혁신 부분 설명

#### 1. 서론
- **요약:** Zero-shot TTS(테스트없이 텍스트를 음성으로 변환하는 기술)가 최근 주목받고 있으며, 이를 통해 별도의 학습 없이 다양한 목소리를 생성할 수 있다. 그러나 실시간 또는 낮은 레이턴시 환경에 맞추기는 여전히 도전 과제다. LiveSpeech는 이 문제를 해결하기 위해 제안되었으며, 증분적으로 음성을 생성하는 능력을 갖춰 즉각적인 응답이 필요한 작업에 적합하다.
- **주요 기여:** 실시간 응용 프로그램에서 효율적인 zero-shot TTS 시스템을 개발하여 다양한 응용 분야에서 실시간 대화 시나리오를 지원한다는 점이다.

#### 2. 관련 작업
- **요약:** 전통적인 음성 생성 작업은 멀-스펙트로그램(Mel-spectrogram)을 통해 다운샘플된 음성 프레임을 생성하는 Transformer 아키텍처를 사용하며, 이는 다양한 환경에서 고충실도의 음성을 생성하기 위해 언어 모델과 확산 모델(Diffusion models)의 효과를 보여준다.
- **주요 기여:** 최신 연구인 언어모델은 음성 코덱의 이산 토큰을 활용하여 Zero-shot TTS를 실현하는 능력을 입증하며, 이는 음성 생성을 위한 좋은 실용적 접근 방식이다.

#### 3. 배경
- **요약:** 오디오 압축에 자주 사용되는 잔여 벡터 양자화(Residual Vector Quantization)와 이를 사용하여 오디오를 효율적으로 생성하는 방법을 설명한다.
- **주요 기여:** 고수준 코드는 주로 오디오의 콘텐츠를 나타내고, 저수준 코드는 정밀한 세부 사항을 나타내므로, 각 코드북의 역할에 대한 중요성을 강조한다.

#### 4. 제안된 모델
- **요약:** LiveSpeech의 아키텍처는 GPT 스타일의 자기회귀 언어 모델과 텍스트 임베딩 층을 포함하며 오디오 코드북을 병렬로 처리하고, 적응형 코드북 손실 가중치를 사용하여 모델의 용량을 효율적으로 재분배한다.
- **주요 기여 및 혁신:** 
  - **적응형 코드북 가중치(Adaptive Codebook Weights):** 고수준 코드를 우선시하여 모델의 콘텐츠 정확도를 높인다.
  - **병렬 코드북 그룹 헤드 모드(Parallel Codebook Group Heads):** 코드북 그룹을 병렬로 처리하여 성능을 향상시키고 시간적 효율성을 높인다.

#### 5. 실험
- **요약:** 다양한 아키텍처와 데이터셋 설정에서 제안된 모델의 효율성을 테스트하고, 다른 모델과의 비교를 통해 LiveSpeech의 우월성을 확인한다.
- **주요 기여:** 다른 최신 모델과 비교하여 LiveSpeech가 스트리밍 응용 프로그램에서 낮은 지연 시간으로 높은 성능을 보이는 것을 증명한다는 점이다.

#### 6. 결론
- **요약:** LiveSpeech는 실시간 또는 낮은 레이턴시 설정에서 기존 시스템의 도전 과제를 해결하며, 제안된 기법들이 성능과 실용적인 측면에서 경쟁력을 입증한다는 결론을 내린다.
- **주요 기여:** 구현된 기술을 바탕으로 LiveSpeech가 TTS 시스템의 새로운 가능성을 제시하고, 다른 응용 분야에서도 폭넓게 사용될 수 있음을 입증한다는 점이다.

### 2. 전체 요약
- **전체 요약:** 이 논문은 실시간 스트리밍 환경에서의 zero-shot TTS 시스템 구축이라는 도전 과제를 해결하기 위한 새로운 접근법인 LiveSpeech를 제안합니다. LiveSpeech는 적응형 코드북 손실 가중치와 병렬 코드북 그룹 처리를 통해 높은 성능과 낮은 지연 시간을 달성합니다. 제안된 모델은 다양한 실험 환경에서 기존 모델들과 경쟁할 수 있음을 입증하였고, 그 가능성을 보여주었습니다. 이 연구는 실시간 대화 시나리오와 같은 다양한 응용 분야에서 실용적인 zero-shot TTS 시스템의 가능성을 높입니다.

논문의 주요 기여는 다음과 같습니다:
1. 실시간 또는 낮은 레이턴시 설정에서 zero-shot TTS를 가능하게 하는 LiveSpeech 모델 제안.
2. 적응형 코드북 가중치와 병렬 코드북 그룹 처리의 혁신적 기법 도입.
3. 다양한 실험을 통해 제안된 모델이 기존 최신 기술과 비교해 경쟁력을 가지고 있음을 입증.

## Similar Papers
- [Autoregressive Speech Synthesis without Vector Quantization](2407.08551.md)
- [VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers](2406.05370.md)
- [Stable Audio Open](2407.14358.md)
- [MusiConGen: Rhythm and Chord Control for Transformer-Based Text-to-Music Generation](2407.15060.md)
- [E2 TTS: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS](2406.18009.md)
- [BASS: Batched Attention-optimized Speculative Sampling](2404.15778.md)
- [MuPT: A Generative Symbolic Music Pretrained Transformer](2404.06393.md)
- [SPEED: Speculative Pipelined Execution for Efficient Decoding](2310.12072.md)
- [Naturalistic Music Decoding from EEG Data via Latent Diffusion Models](2405.09062.md)
