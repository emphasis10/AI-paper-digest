# OlympicArena: Benchmarking Multi-discipline Cognitive Reasoning for Superintelligent AI
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.12753.pdf](https://arxiv.org/pdf/2406.12753.pdf)

### 섹션 요약

#### 1. 소개
이 논문은 AI 모델의 인지적 추론 능력을 평가하기 위해 "OlympicArena"라는 새로운 벤치마크를 소개합니다. 이 벤치마크는 7개 분야의 62개의 올림픽 수준의 경쟁 문제를 포함한 총 11,163개의 문제로 구성되며, 영어와 중국어로 제공됩니다. 텍스트와 이미지가 혼합된 문제들을 포함하여 다양한 형식의 평가를 진행합니다   .

#### 2. 관련 연구
AI 지능을 벤치마킹 하는 방법은 오랜 연구 과제였습니다. 초기에는 튜링 테스트를 통해 AI의 지능을 평가했지만, 이후에는 컴퓨터 비전, 자연어 처리 등의 특화된 도메인에서 벤치마크가 개발되었습니다. 최근에는 다중 언어 및 다분야 문제를 평가하는 다양한 벤치마크가 생성되었습니다  .

#### 3. 데이터 수집 및 주석
데이터는 다양한 공개 테스트 문서에서 수집되며, 수집된 문제는 과학 및 공학 배경을 가진 약 30명의 학생들이 주석을 달았습니다. 모든 문제는 중복 제거 및 난이도 분류 과정을 거칩니다 .

#### 4. 평가 및 실험 결과
OlympicArena 벤치마크에서 다양한 LMM 및 LLM 모델을 평가한 결과, 현존하는 최첨단 모델인 GPT-4o도 39.97%의 정확도를 기록했습니다. 이는 현재의 AI 모델들이 복잡한 문제를 해결하는 데 제한이 있음을 시사합니다 . 또한, 모델들은 특히 복잡한 분해 추론 문제와 공간적, 기하학적 인식 능력이 약한 것으로 나타났습니다  .

### 논문의 주요 기여 및 혁신적인 부분
OlympicArena는 AI 모델의 인지적 추론 능력을 평가하기 위한 포괄적이고 세밀한 평가 메커니즘을 포함하고 있습니다. 특히, 기존 벤치마크들이 주로 지식 집약적이고 텍스트 중심인 반면, OlympicArena는 다분야 및 다형식 문제들을 포함하여 모델의 범용성과 복잡한 추론 능력을 평가하는 데 중점을 둡니다.

### 전체 요약
OlympicArena 벤치마크는 AI의 인지적 추론 능력을 평가하기 위한 총 11,163개의 문제로 구성된 포괄적이고 도전적인 평가 도구입니다. 이 벤치마크는 영어와 중국어로 제공되며, 텍스트와 이미지가 혼합된 다양한 형식의 문제를 포함합니다. 오랜 기간 동안 AI 지능을 평가하기 위한 다양한 벤치마크가 개발되어 왔지만, OlympicArena는 특히 복잡한 추론 능력을 세밀하게 평가할 수 있는 점에서 혁신적입니다.

현존하는 최고 성능의 모델인 GPT-4o도 이 벤치마크에서 39.97%의 정확도만을 기록하였으며, 이는 현재의 AI 모델들이 복잡한 문제를 해결하는 데 여전히 한계가 있음을 보여줍니다. OlympicArena는 AI 연구를 위한 종합적인 리소스와 도구를 제공하며, AI가 더 복잡한 과학적 도전 과제를 해결할 수 있도록 기여할 것입니다.

        