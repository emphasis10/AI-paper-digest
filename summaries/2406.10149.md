# BABILong: Testing the Limits of LLMs with Long Context Reasoning-in-a-Haystack
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.10149.pdf](https://arxiv.org/pdf/2406.10149.pdf)

### 주요 내용 요약

#### 섹션 1: 소개
대형 언어 모델(LLM)의 입력 컨텍스트 크기가 급격히 증가하고 있습니다. 그러나 기존 평가 방법은 이에 따라가고 있지 못하며, 모델의 효율성을 종합적으로 평가하지 못하고 있습니다. 이 격차를 해소하기 위해, 우리는 매우 긴 문서에서 사실을 이유하여 추론하는 능력을 테스트하기 위한 BABILong 벤치마크를 제안합니다.

#### 섹션 2: BABILong 벤치마크
BABILong은 여러 사실이 분산된 매우 긴 문서에서 언어 모델의 추론 능력을 테스트하기 위해 설계된 20개의 추론 작업을 포함합니다. 이 작업에는 사실 연결, 단순 유추, 연역, 계산, 목록/집합 처리 등이 포함됩니다. BABILong은 최대 1백만 토큰까지의 미리 정의된 길이를 제공하며, 최대 1100만 토큰까지 평가할 수 있습니다.

#### 주요 기여 및 혁신
1. LLM의 성능을 평가하기 위한 새로운 확장 가능한 생성 멀티태스크 벤치마크인 BABILong을 도입하였습니다.
2. 다양한 크기, 아키텍처, 컨텍스트 확장 방법을 가진 20개 이상의 최신 장문 입력 언어 모델을 BABILong에서 평가하였습니다.
3. BABILong을 사용하여 대중적인 LLM이 컨텍스트의 10-20%만 효과적으로 활용하며, 추론 복잡도가 증가함에 따라 성능이 급격히 감소함을 발견하였습니다.
4. Recurrent Memory Transformer(RMT)를 사용하여 최대 1100만 토큰에 이르는 텍스트에서 성공적인 단일 사실 질문 응답을 시연하였습니다.

#### 섹션 3: 평가 결과
BABILong 벤치마크의 첫 번째 작업(QA1)부터 다섯 번째 작업(QA5)까지의 평균 정확도를 보고합니다. 평가 결과, 모델의 성능이 입력 크기와 관계없이 일관되게 높은 성능을 유지해야 한다고 기대됩니다. 일부 모델은 제한된 길이에서만 좋은 성능을 보였으며, 특히 RAG 방법은 도움이 되지 않았습니다. 그러나 작은 규모의 모델을 위해 훈련한 경우, 과제는 해결 가능하였습니다.

### 전체 요약
이 논문은 대형 언어 모델(LLM)의 매우 긴 문맥 처리 능력을 평가하기 위한 새로운 벤치마크, BABILong을 제안합니다. BABILong은 사실 연결, 유추, 연역 등의 20가지 다양한 추론 작업을 포함하며, 최대 1100만 토큰까지 컨텍스트를 확장합니다. 이를 통해 LLM의 성능을 종합적으로 평가하며, 대중적인 LLM이 컨텍스트의 10-20%만 효과적으로 활용함을 밝혔습니다. 또한, Recurrent Memory Transformer(RMT)를 사용하여 매우 긴 텍스트에서 성공적인 단일 사실 질문 응답을 시연하여 이 모델의 가능성을 입증했습니다.