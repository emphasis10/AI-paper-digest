# LLaVaOLMoBitnet1B: Ternary LLM goes Multimodal!
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.13402.pdf](https://arxiv.org/pdf/2408.13402.pdf)

### 1. 각 섹션 요약

#### I. 서론
이 논문은 LLaVa, NousResearch의 작업을 기반으로, 최초의 텍스트 및 이미지를 모두 처리할 수 있는 삼진 다중모달 대형언어모델(LLM)을 구축했습니다. 주된 기여는 모델과 함께 가중치 및 훈련 스크립트를 오픈소스로 제공하고, 삼진 모델의 주류화를 위한 도전과 기회를 강조하는 것입니다.

#### II. 관련 연구
Flamingo는 다중모달 모델의 급속한 발전의 시작점을 마련했으며, 그 후 여러 파생 모델들이 개발되었습니다. LLaVa는 텍스트 전용 GPT를 활용하여 다중모달 데이터세트를 확장하는 방법을 제안하며 오픈소스 프레임워크를 도입했습니다. 삼진 모델은 매우 낮은 정밀도로 가중치를 양자화하는 BitNetb1.58의 방법을 따랐으며, 성능 저하는 최소화하면서 지연 시간을 최대 4배 줄였습니다. 그러나 이 방법은 아직까지 많은 데이터와 계산 자원이 필요합니다.

#### III. 모델 세부사항
LLaVaOLMoBitNet1B 모델은 CLIP 비전 인코더, MLP 연결기, 삼진 LLM으로 구성됩니다. 이미지는 비전 인코더를 통해 처리되고 이후 MLP를 통해 LLM 임베딩 공간으로 다시 투영됩니다. 최종적으로, 텍스트 쿼리가 삼진 LLM을 통해 처리되어 응답이 생성됩니다.

#### III.B 훈련 세부사항
훈련은 두 단계로 나뉩니다: (1) 특성 정렬을 위한 사전 훈련 단계, (2) 종단 간의 명령 미세 조정 단계. 각 단계에서는 LLaVa1.5 논문에 제시된 방법론을 따랐으며, DeepSpeed 라이브러리를 사용해 다중 GPU 훈련을 수행했습니다.

#### IV. 결과
최종 모델 LLaVaOLMoBitNet1B의 성능을 질적 및 양적으로 평가했습니다. 질적 평가에서는 주로 올바른 응답을 생성하였으나, 일부 오차를 보였습니다. 양적 평가에서는 벤치마크 테스트에서 비슷한 크기의 모델들에 비해 낮은 점수를 기록했습니다. 이는 모델이 다른 삼진 또는 완전 정밀 모델들에 비해 상대적으로 적은 데이터를 사용해 훈련되었기 때문입니다.

#### V. 미래 작업
향후 연구에서는 공개 가중치 사전 훈련 모델을 삼진 도메인으로 양자화하는 효과적인 방법을 찾는 것이 중요할 것입니다. 또한, 삼진 모델은 기존 대형 언어 모델의 문제인 편향성, 불확실성, 환각 등의 문제를 여전히 가지고 있습니다. 하드웨어 측면에서도 삼진 연산을 효율적으로 매핑하는 것이 중요한 과제입니다.

#### VI. 감사의 글
이 논문은 LLaVa 프레임워크, BitNetb1.58, NousResearch의 지원을 받아 작성되었습니다.

### 2. 총괄 요약

이 논문은 최초의 텍스트 및 이미지를 모두 처리할 수 있는 삼진 다중모달 대형언어모델(LLM)인 LLaVaOLMoBitNet1B를 제안하며, 이를 오픈소스로 제공하여 연구자들이 활용할 수 있도록 합니다. LLaVa 프레임워크를 기반으로 구축되었으며, 모델은 CLIP 이미지 인코더, MLP 연결기, 삼진 LLM으로 구성됩니다. 훈련은 두 단계로 진행되며, 최종 모델은 주로 올바른 응답을 생성하지만, 일부 오차를 보였습니다. 벤치마크 평가에서는 다른 모델들에 비해 낮은 성능을 기록했지만, 이는 훈련된 데이터 양이 상대적으로 적기 때문입니다. 미래 연구에서는 삼진 도메인으로의 양자화를 통한 성능 개선, 편향성 문제 해결, 하드웨어 효율성 향상이 필요합니다.