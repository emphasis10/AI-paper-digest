# CodeSteer: Symbolic-Augmented Language Models via Code/Text Guidance
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.04350.pdf](https://arxiv.org/pdf/2502.04350.pdf)

1. **각 섹션 요약**:

   **서론**:
   이 논문에서는 대형 언어 모델(LLM)이 텍스트 추론과 코드 생성을 효과적으로 구분하지 못하고, 따라서 기호 계산 능력이 충분히 활용되지 못하고 있음을 지적한다. 새로운 방법인 CodeSteer를 통해 LLM의 코드/텍스트 생성을 안내할 수 있는 방법을 제시한다. 기존의 문제점들을 해결하기 위해서 37개의 상징적 작업을 포함하는 포괄적인 벤치마크인 SymBench를 구축하였다.

   **기여**:
   - SymBench의 개발 및 발표
   - 데이터셋 구축 및 모델 세밀 조정 (SFT 및 DPO에 대한 새로운 방법)
   - 기호 검사기 및 자기 답변 검사기의 도입
   - CodeSteer가 아홉 가지 기준라인을 초과하여 성능 향상.

   **방법론**:
   CodeSteer는 Llama-3-8B 모델을 세밀하게 조정하여 코드 생성을 위해 필요한 다양한 단계를 포함하는 여러 단계의 안내를 제공하도록 설계되었다. 이 과정에서 더 나은 성능을 위해 데이터 합성 및 훈련 프로세스의 새로운 요소가 도입되었다.

   **실험 및 결과**:
   SymBench의 수행 결과, CodeSteer는 GPT-4o 모델의 평균 성능 점수를 53.3에서 86.4로 높였다. 이는 CodeSteer가 상징적 계산을 효과적으로 활용하여 복잡한 작업에서도 뛰어난 성능을 발휘할 수 있음을 보여준다.

   **결론**:
   CodeSteer의 개발로 LLM의 추론 및 계획 능력 향상을 위한 상징적 계산의 중요성이 강조되었으며, 이 방법이 보다 안전하고 인간의 선호도에 맞는 결과물 생성을 가능하게 할 것으로 기대된다.

2. **전체 요약**:
   이 논문은 LLM의 텍스트 및 코드 생성을 안내할 새로운 방법인 CodeSteer를 소개하며, 이 방법이 LLM의 상징적 계산 능력을 최대한 활용하는 방식으로 설계되었음을 강조한다. SymBench 벤치마크를 통해 CodeSteer는 기존 모델보다 월등히 향상된 성능을 보이며, 이는 특히 고도한 복잡성을 요구하는 작업에서도 두드러진다. 이 연구는 LLM의 기능적 향상을 통해 AI 기술이 인간의 기대에 부응하는 결과를 생성하는 데 기여할 것으로 전망된다.