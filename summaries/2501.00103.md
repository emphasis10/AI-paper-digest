# LTX-Video: Realtime Video Latent Diffusion
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.00103.pdf](https://arxiv.org/pdf/2501.00103.pdf)

1. **각 섹션 요약**

   - **소개**
     LTX-Video는 비디오 생성의 효율성과 품질을 향상시키기 위해 비디오-VAE와 디노이징 변환기의 상호작용을 최적화하는 신경망 모델입니다. 이 모델은 고압축 비율로 작동하며, 텍스트에서 비디오로 변환 및 이미지에서 비디오로 변환 기능을 동시에 지원합니다. 이 모델은 실시간보다 빠르게 비디오를 생성할 수 있습니다.

   - **메소드**
     LTX-Video는 Video-VAE의 입력으로 패치화 작업을 이동시키고, 필셀 공간에서 최종 디노이징 단계를 수행하는 VAE 디코더를 사용하여 고품질 비디오를 생성합니다. 이는 별도의 업샘플링 모듈 없이도 세부사항을 생성할 수 있게 해 줍니다. 이 모델은 또한 다양한 크기와 지속시간의 비디오 생성을 가능하게 합니다.

   - **비디오 VAE**
     본 문헌에서는 32×32×8의 공간적-시간적 압축을 통해 VAE가 높은 압축 비율을 달성합니다. 학습을 통해 채널의 중복성을 줄이고 효율적이고 통합된 잠재 공간으로 비디오와 영상을 매핑하는 여러 VAE 설계를 비교하며 검증합니다.

   - **디퓨전 변환기**
     LTX-Video는 RoPE(Positional Embedding)를 채택하여, 비디오 데이터에서의 위치 정보를 보다 동적이고 컨텍스트적으로 해석할 수 있게 하여 정확도를 향상시킵니다. 또한 이디 구현에서는 RMSNorm을 사용하여 성능을 극대화했습니다.

2. **전체 요약**

   LTX-Video는 텍스트 및 이미지에서 비디오로 변환할 수 있는 최신의 변환기 기반의 잠재 디퓨전 모델로, Video-VAE와 디노이징 변환기를 보다 긴밀하게 통합하여 효율성과 품질을 향상시키고 있습니다. 이 모델은 고압축 비율을 통해 시간적 일관성을 유지하면서도 높은 해상도의 비디오를 생성할 수 있으며, 실시간보다 빠른 비디오 생성을 실현합니다. LTX-Video는 다양한 응용 분야에서 사용될 수 있으며, 오픈 소스로의 기여를 통해 AI 커뮤니티 내에서 협업과 혁신을 촉진하는 것을 목표로 합니다.