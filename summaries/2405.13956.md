# Attention as an RNN
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.13956.pdf](https://arxiv.org/pdf/2405.13956.pdf)


#### 서론
이 논문에서는 AI 및 머신러닝에 관한 주제를 다룬 논문으로, 주로 시퀀스 모델링에서 트랜스포머(Transformer) 모델의 역할과 이에 대한 한계를 해결하고자 하는 새로운 접근 방식을 제시합니다. 트랜스포머는 시퀀스 모델링에서 우수한 성능을 보이지만, 높은 메모리 사용량과 계산 복잡도로 인해 저자원 환경에서는 사용이 제한됩니다. 이 문제를 해결하기 위해 저자들은 새로운 접근 방식인 Aaren을 제안합니다.

#### 배경지식
- **순환 신경망(RNN)**: 시퀀스 데이터를 처리하기 위해 각 단계에서 은닉 상태를 반복적으로 계산하는 모델입니다.
- **어텐션(attention)**: 주어진 쿼리 토큰 세트에 대해 컨텍스트 토큰 세트에서 정보를 검색하는 방법입니다. 트랜스포머는 셀프-어텐션 메커니즘을 사용하여 계산 효율성을 높입니다.

#### 방법론
1. **기존의 어텐션을 RNN으로 보기**: 어텐션 메커니즘을 RNN으로 재해석하여 시퀀스 데이터를 효과적으로 업데이트 할 수 있는 구조를 제안합니다.
2. **병렬 프리픽스 스캔 알고리즘**: 어텐션을 다대다 RNN으로 효율적으로 계산하기 위한 병렬 프리픽스 스캔 알고리즘을 소개합니다.
3. **Aaren 제안**: 기존 트랜스포머 모델과 달리 병렬 학습이 가능하면서도 새로운 토큰을 효율적으로 업데이트할 수 있는 Aaren 모델을 제안합니다.

#### 실험
- **강화 학습**: Aaren이 트랜스포머와 비교하여 경쟁력 있는 성능을 보여주며 환경과의 상호작용 시 서열 데이터를 효율적으로 처리할 수 있음을 입증했습니다.
- **이벤트 예측**: 다양한 실세계 데이터셋을 사용하여 Aaren이 트랜스포머에 비해 더 효율적임을 보여줍니다.
- **시계열 Forecasting 및 분류**: Aaren이 시간과 메모리 사용 측면에서 트랜스포머보다 효율적임을 보이며, 여러 시계열 데이터셋에서 경쟁력 있는 성능을 보입니다.

#### 결론
이 논문은 트랜스포머의 어텐션 메커니즘을 RNN으로 재해석하여 새로운 모델인 Aaren을 제안했습니다. Aaren은 병렬 학습이 가능하면서도 시퀀스 데이터의 실시간 업데이트를 효율적으로 처리할 수 있어 강력한 성능을 보입니다. 이로써 트랜스포머의 한계를 극복하고 더 많은 실제 응용 환경에서의 사용 가능성을 높였습니다.

#### 종합 요약
이 논문은 트랜스포머 모델의 한계를 극복하기 위해 어텐션 메커니즘을 순환 신경망(RNN)으로 재해석한 새로운 접근법을 제시합니다. 이를 통해 병렬 학습과 실시간 데이터 업데이트가 모두 가능한 새로운 모델인 Aaren을 제안하고, 다양한 실험을 통해 그 효용성을 입증했습니다. Aaren은 기존 트랜스포머 모델에 비해 시간과 메모리 효율성을 높이면서도 경쟁력 있는 성능을 보여 다양한 시퀀스 데이터 처리 환경에서의 활용 가능성을 제시합니다.