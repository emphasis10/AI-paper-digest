# Photorealistic Object Insertion with Diffusion-Guided Inverse Rendering
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.09702.pdf](https://arxiv.org/pdf/2408.09702.pdf)

### 1. 섹션 요약

#### 서론

이 논문은 실제 세계의 장면에 가상의 물체를 삽입하는 방법에 대해 논의합니다. 기존의 큰 규모의 확산 모델(diffusion model)들이 생성 및 인페인팅(inpainting) 능력을 일부 가지고 있지만, 이 작업에 완벽히 적합하지 않습니다. 이 논문에서는 물리 기반 역 렌더링(physically-based inverse rendering) 프로세스를 안내하는 확산 모델을 사용하여 장면의 조명과 톤 매핑 파라미터를 복구하여 단일 프레임 또는 비디오의 실내 및 실외 장면에 임의의 가상 물체를 사실적으로 합성하는 방법을 제안합니다.

#### 관련 연구

역 렌더링의 주요 과제는 현장의 물질, 형상, 조명 등의 내재적 특성을 단일 또는 복수의 이미지로부터 복구하는 것입니다. 초기 방법은 최적화 문제로 설정했지만, 현실 세계 조명을 손으로 설정하는 것은 복잡합니다. 데이터 기반의 사전 지식이 필요하며, 이를 위한 대규모 실제 데이터 수집은 도전 과제입니다.

#### 주요 기여

논문은 DiPIR(Diffusion Prior for Inverse Rendering)라는 모델을 제안합니다. 이는 다음 세 가지 주요 기여점이 있습니다:
1. 물리적 기반 렌더러를 사용하여 빛과 3D 자산 간의 상호 작용을 정확히 시뮬레이션.
2. 경량화된 사전 학습된 확산 모델의 개인화 스킴 제안.
3. 새로운 SDS(sliced denoising score) 손실 변형을 설계하여 훈련 안정성을 개선.

#### 모델 설명

DiPIR은 사람이 편집한 이미지에 피드백을 제공하는 것처럼 작동하여 물리 기반 장면 속성을 최적화합니다. 이를 통해 실내 및 실외 데이터셋에서 기존 최첨단 조명 추정 방법보다 뛰어난 성능을 보여줍니다. 특히, 작은 용량의 사전 학습 모델을 사용하여 개인화된 사전 지식과 함께 새로운 손실 설계를 통해 안정적이고 고품질의 결과를 제공합니다.

#### 평가 및 결과

논문은 Waymo와 PolyHaven 데이터셋을 활용해 제안된 방법의 성능을 평가하며, 기존 방법들에 비해 높은 선호도를 나타냅니다. 이 방법은 도시 계획 및 증강 현실 내비게이션 등의 응용 프로그램에서 유망한 접근 방식으로 평가됩니다.

### 2. 전체 요약

이 논문은 DiPIR이라는 모델을 통해 물리 기반 역 렌더링 프로세스를 안내하는 확산 모델을 사용하여 단일 이미지에서 장면 조명 및 톤 매핑 파라미터를 복구하는 방법을 제안합니다. 논문은 이 새로운 접근 방식이 기존의 최첨단 조명 추정 방법보다 우수한 성능을 제공하며, 가상 물체 삽입 응용 프로그램에서 유망한 도구로서의 가능성을 보여줍니다. DiPIR은 실내 및 실외 데이터셋을 통한 실험에서 높은 정확도와 안정성을 입증하며, 다양한 디지털 콘텐츠 제작 응용 프로그램에서 활용될 수 있습니다.