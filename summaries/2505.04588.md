# ZeroSearch: Incentivize the Search Capability of LLMs without Searching
## TL;DR
## Summary
- [https://arxiv.org/pdf/2505.04588.pdf](https://arxiv.org/pdf/2505.04588.pdf)

1. 각 섹션의 주요 내용 요약:

- **소개:** 대형 언어 모델(LLMs)이 다양한 작업에서 탁월한 성능을 보여주지만, 지식이 선훈련 데이터에만 제한되어 있어 현실 적용에는 제약이 있습니다. Retrieval-Augmented Generation(RAG)을 사용하여 외부 지식을 생성 과정에 통합하려는 연구가 이루어지고 있으나, 이는 모델의 추론 능력에 많은 부담을 주고 복잡한 프롬프트 공학이 필요합니다.

- **관련 연구:** 최근 강화 학습(RL)이 LLM의 추론 능력을 강화하는 유망한 전략으로 부상했습니다. OpenAI-o1, DeepSeek-R1 등 여러 RL 기반 모델들은 보상 신호를 통해 논리적 추론 능력을 향상시켰습니다.

- **방법론 - ZEROSEARCH:** 이 프레임워크는 실제 검색 엔진과의 상호작용 없이 LLM의 검색 능력을 향상시킵니다. 경량화된 감독 세부 튜닝을 통해 LLM을 검색 모듈로 변환하고, 커리큘럼 롤아웃 메커니즘을 도입하여 모델이 점점 더 어려운 검색 시나리오에 적응하도록 합니다.

- **실험 결과:** ZEROSEARCH는 실제 검색 기반 모델보다 우수하며, 다양한 LLM 크기에서 일반화가 잘되고 광범위한 RL 알고리즘을 지원합니다. 시뮬레이션 검색 엔진은 다양한 LLM 설정에서 구글 검색과 유사하거나 뛰어난 성능을 보입니다.

2. 전체 요약:

이 논문은 대형 언어 모델의 효율적인 검색 능력을 촉진하기 위해 실제 검색 엔진에 의존하지 않고 LLM을 활용하는 혁신적인 강화 학습 프레임워크인 ZEROSEARCH를 제안합니다. ZEROSEARCH는 경량화된 감독 세부 튜닝과 커리큘럼 롤아웃 메커니즘을 활용하여 모델의 검색 및 추론 능력을 크게 향상시킵니다. 실험 결과, ZEROSEARCH는 실제 검색 엔진을 사용하는 모델보다 성능이 뛰어나며, 다양한 LLM 크기와 강화 학습 알고리즘과도 높은 호환성을 보여주었습니다. 이는 학습의 인프라 비용을 낮추고, 데이터 품질을 능동적으로 제어할 수 있다는 장점이 있습니다.