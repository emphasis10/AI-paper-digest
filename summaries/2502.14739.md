# SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.14739.pdf](https://arxiv.org/pdf/2502.14739.pdf)

1. 논문의 각 섹션 요약:

- **서론**:
  인공지능과 대형 언어 모델(LLM)의 발전이 인간의 삶을 크게 변화시켰으며, 이들은 다양한 분야에서 인간의 성과를 능가하고 있습니다. 하지만, LLM의 현실 세계에서의 전문성을 측정하는 일은 해결되지 않은 문제로 남아있습니다. 기존 벤치마크들은 너무 일반적인 분야에 치중되어 있어 실제 다양한 전문 영역에서는 실질적인 의미를 가지지 못하고 있습니다. 이를 해결하기 위해, 285개의 대학원 수준의 분야를 포괄하는 "SuperGPQA"를 도입하여 현실 세계의 다양한 전문성을 평가할 수 있도록 하였습니다.

- **주요 결과**:
  LLM 중에서 "DeepSeek-R1"과 "o1-2024-12-17"이 가장 성과가 좋은 것으로 나타났으며, 대형 언어 모델들이 어려운 질문들에서 오히려 더 강점을 보이는 것으로 분석되었습니다. 이는 LLM의 강력한 논리적 처리 능력을 잘 보여주는 부분입니다.

- **연구의 혁신적인 부분 및 공헌**:
  SuperGPQA는 285개 분야의 다양한 학문들을 대상으로 하고 있어, LLM의 다양하고 고도화된 능력을 평가할 수 있는 변화를 제시하고 있습니다. 특히, 인간-LLM 협력 시스템을 통해 정확하고 신뢰성 있는 데이터를 제공하며, 이는 LLM의 개발과 적용에 있어 중요한 지표가 됩니다.

2. 전체적인 요약:

SuperGPQA는 기존의 평가 체계가 일반적인 학문에 국한된 한계를 넘어서서, STEM 외의 다양한 학문 분야에 걸친 고급 지식을 평가하기 위한 최첨단의 벤치마크입니다. 이는 LLM의 포괄적이며 세밀한 분석을 가능하게 하여, LLM의 혁신적인 성과를 더욱 구체적으로 평가할 수 있도록 지원합니다. 논문은 이러한 평가 체계를 통해 LLM 연구와 개발의 새로운 방향을 제시하고 있습니다.