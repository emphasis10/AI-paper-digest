# BLINK: Multimodal Large Language Models Can See but Not Perceive
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.12390.pdf](https://arxiv.org/pdf/2404.12390.pdf)

이 문서는 인공지능(AI)과 기계학습에 관한 논문으로, 다중모달 대규모 언어 모델(LLMs)이 시각적 인식을 어떻게 처리하는지에 대한 새로운 벤치마크인 Blink에 초점을 맞추고 있습니다. 해석을 요구하는 시각적 작업들이 현재의 다양한 모달 LLMs에 의해 어떻게 처리되는지, 그리고 이러한 모델들이 인간 수준의 시각적 인식을 달성하기 위해 어떻게 개선될 수 있는지를 탐구합니다. 이제 섹션별 요약을 한국어로 제공하겠습니다.

### 1. Blink 벤치마크 소개
Blink는 고전 컴퓨터 비전 문제를 현대적인 다중선택형 질문 형태로 재구성하여, 이미지 하나 또는 여러 이미지와 함께 제시되는 3,807개의 다중선택형 질문으로 구성된 새로운 벤치마크입니다. 이 벤치마크는 사람들이 '눈 깜짝할 사이'에 해결할 수 있는 14개의 시각적 인식 작업을 포함하며, 현재의 멀티모달 LLMs에게 상당한 도전을 제시합니다. 논문의 실험 결과에 따르면 인간은 평균적으로 95.70%의 정확도를 보인 반면 최고 성능의 GPT-4V와 Gemini 모델은 각각 51.26%와 45.72%의 정확도를 달성에 그쳤습니다.

### 2. 컴퓨터 비전과 LLMs의 차이점
초기 컴퓨터 비전 연구는 2D 이미지가 아닌 3D 장면의 투사를 해석하려 했고, 이 과정에서 다양한 중간 과업(반사율 이해, 다시점 추론, 지오메트릭 추론 등)을 개발했습니다. 현대의 대규모 언어 모델은 자연 언어를 통해 표현된 새로운 작업에 초점을 맞추며, 전통적인 컴퓨터 비전 작업이 자연 언어를 통한 중재에 저항한다는 사실을 간과하고 있습니다.

### 3. Blink의 기여
Blink는 다른 평가 매트릭스에서 찾을 수 없는 핵심 시각적 인식 능력에 초점을 맞춘 벤치마크로, 다양한 시각적 프롬프트(원, 박스, 이미지 마스크 등)를 포함하여 더 포괄적인 시각적 인식 능력을 평가합니다. 이것은 인간이 몇 초 안에 답할 수 있는 '시각적' 상식 문제들을 포함하여, 솔루션 찾기에 있어 언어 모델이 가지는 한계를 넘어서려 시도합니다.

### 전체 요약
Blink는 현재 멀티모달 LLMs가 아직 인간 수준의 시각적 인식 능력을 달성하지 못한 새로운 도전을 제시하며, 이를 통해 커뮤니티가 멀티모달 LLMs를 인간 수준의 시각적 인식으로 발전시키는 데 도움이 될 것으로 기대합니다. 이 벤치마크는 고전 컴퓨터 비전 문제를 다양한 모달 LLM 평가에 적용 가능한 현대적 질문-답변 형태로 재구성하였으며, 이를 통해 각 모델의 시각적 인식 능력을 깊이 있게 분석하고 잠재적인 개선 방안을 모색합니다. Blink를 통해 얻은 통찰력은 멀티모달 LLMs가 전통적인 컴퓨터 비전 모델이 해결하는 시각적 작업을 어떻게 처리하는지에 대한 이해를 심화시키는 데 중요한 역할을 합니다.