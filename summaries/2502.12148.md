# HermesFlow: Seamlessly Closing the Gap in Multimodal Understanding and Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.12148.pdf](https://arxiv.org/pdf/2502.12148.pdf)

**1. 섹션별 요약:**

**서론**  
이 논문은 멀티모달 대형 언어 모델(MLLMs)에서 이해와 생성 능력 간의 격차를 발견한 후 이를 해결하기 위해 HermesFlow라는 프레임워크를 제안합니다. 이 방법은 이해가 생성을 능가한다는 현상에서 시작하여, 이해와 생성 간의 차이를 연결하기 위해 Pair-DPO와 self-play iterative optimization을 사용합니다.

**관련 연구**  
최근 연구들이 멀티모달 이해와 생성을 통합하려는 시도를 하고 있으며, 이 모델들은 이미지 생성까지 포함해 다양한 성능을 보여주고 있습니다. 그러나 기존 연구들은 이해와 생성 능력 간의 균형을 맞추는 데 실패하고 있습니다.

**방법론: HermesFlow**  
HermesFlow는 이해와 생성 데이터의 쌍을 사용하여 Move Attention Mechanism을 활용해 멀티모달 데이터를 효율적으로 처리합니다. 이 시스템은 Self-Play와 Pair-DPO를 통해 두 능력을 균등하게 발전시키며, 반복적 최적화를 통해 모델의 전반적인 성능을 향상시킵니다.

**실험 결과**  
실험에서는 HermesFlow가 기존 모델보다 우수한 성능을 보여주었으며, 특히 설계한 Pair-DPO 방식이 이해와 생성 간의 격차를 효과적으로 줄이는 데 기여하였습니다. 더불어 HermesFlow는 다양한 이해와 생성 벤치마크에서 강력한 성과를 나타냈습니다.

**결론**  
이 연구는 HermesFlow라는 새로운 패러다임을 소개하여 데이터 간의 간격을 줄이고, 전체적인 멀티모달 모델의 성능을 강화합니다. 하지만 오픈 소스 MLLMs의 적은 수 때문에, 더 넓은 범위의 모델에 최적화되지 못한 점이 한계로 지적됩니다.

**2. 전체 요약:**

이 논문은 HermesFlow라는 혁신적 프레임워크를 기반으로 멀티모달 대형 언어 모델의 이해 및 생성 능력 간의 격차를 효과적으로 줄인 연구를 소개합니다. HermesFlow는 반복적인 자기 최적화 및 Pair-DPO 방법론을 활용하여, 이해가 생성을 일관되게 능가하는 상황을 해결하고, 다양한 실험에서 그 효과를 입증하였습니다. 이 접근 방식은 미래의 멀티모달 기초 모델의 일반적 정렬 프레임워크로서 가능성을 갖고 있습니다.