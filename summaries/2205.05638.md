# Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2205.05638.pdf](https://arxiv.org/pdf/2205.05638.pdf)

### 1. 섹션 요약

#### Introduction
논문은 few-shot in-context learning(ICL)와 parameter-efficient fine-tuning(PEFT)을 비교합니다. 새로운 PEFT 방법인 (IA)³를 소개하고, 이를 통해 학습된 T-Few 레시피를 제안합니다. T-Few는 새로운 작업에 대해 높은 정확도를 유지하면서도 낮은 계산 비용을 자랑합니다.

#### Background
- **Few-shot In-Context Learning (ICL)**: ICL은 미리 학습된 언어 모델에 몇 가지 예제와 질의를 입력으로 주어 작업을 수행하게 합니다. 이 방법은 별도의 경사 하강 학습이 필요 없지만 계산 비용이 높고 예제 순서에 민감합니다.
- **Parameter-Efficient Fine-Tuning (PEFT)**: PEFT는 소수의 파라미터만 업데이트하여 모델을 미세 조정합니다. 이는 메모리와 저장 공간을 절약하며, 다양한 작업을 혼합하여 배치 처리할 수 있습니다.

#### Designing the T-Few Recipe
- **Model and Datasets**: T0 모델을 기반으로 하여 PEFT 방법을 적용했습니다. T-Few는 unlikelihood loss(LUL)와 length-normalized loss(LLN)를 사용하여 학습했습니다.
- **Parameter-Efficient Fine-Tuning with (IA)³**: (IA)³는 중간 활성화를 학습된 벡터로 스케일링하여 성능을 향상시킵니다. 이는 전체 모델을 미세 조정하는 것보다 적은 파라미터를 업데이트하면서도 더 나은 성능을 보입니다.
- **Combining the Ingredients**: T0 모델을 백본으로 하고, (IA)³를 추가하여 다운스트림 작업에 적응시킵니다. 학습 시 Adafactor optimizer를 사용하며, 모든 다운스트림 데이터셋에 동일한 레시피를 적용합니다.

#### Experiments
- **Performance on T0 Tasks**: T-Few는 기존의 ICL 방법보다 월등한 성능을 보였습니다. 특히, GPT-3 175B보다 6% 더 높은 정확도를 달성했습니다.
- **Comparing Computational Costs**: T-Few는 ICL보다 계산 비용이 훨씬 낮습니다. 예를 들어, GPT-3 175B의 ICL은 1.4e15 FLOPs를 필요로 하는 반면, T-Few는 1.1e12 FLOPs만 필요합니다.
- **Performance on Real-world Few-shot Tasks (RAFT)**: T-Few는 RAFT 벤치마크에서 인간 기준을 초과하는 성능을 최초로 달성했습니다.
- **Ablation Experiments**: (IA)³ 사전 학습, unlikelihood loss, length normalization을 제거하면 성능이 각각 1.6%, 4.1%, 2.5% 감소했습니다.

#### Conclusion
T-Few는 few-shot ICL보다 더 높은 정확도를 낮은 계산 비용으로 달성합니다. (IA)³를 사용하여 파라미터를 효율적으로 미세 조정하고, RAFT 벤치마크에서 최고 성능을 달성했습니다. 앞으로 생성 작업에 T-Few를 적용하는 연구를 계획하고 있습니다.

### 2. 전체 요약
이 논문은 few-shot in-context learning(ICL)과 parameter-efficient fine-tuning(PEFT)을 비교하고, 새로운 PEFT 방법인 (IA)³를 소개합니다. 이를 통해 개발된 T-Few 레시피는 높은 정확도를 유지하면서도 낮은 계산 비용을 자랑합니다. T-Few는 특히 GPT-3 175B보다 6% 높은 정확도를 달성하고, RAFT 벤치마크에서 인간 기준을 초과하는 성능을 최초로 기록했습니다. 이 방법은 앞으로 다양한 생성 작업에도 적용될 가능성이 큽니다.