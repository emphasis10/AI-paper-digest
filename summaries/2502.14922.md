# SIFT: Grounding LLM Reasoning in Contexts via Stickers
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.14922.pdf](https://arxiv.org/pdf/2502.14922.pdf)

### 1. 논문의 각 섹션 요약

#### 서론
이 논문은 최근 자연어 처리 분야에서의 큰 언어 모델(LLM)의 발전을 다루며, 특히 Chain-of-Thought (CoT) 프롬프트와 자기 일관성 같은 기법들이 문제 해결을 위한 다단계 추론에 얼마나 기여했는지를 설명합니다. 그러나 다양한 크기의 LLM들이 질의 문맥을 잘못 해석하거나 핵심 정보를 간과하는 '사실 드리프트'라는 문제를 식별하고 있습니다.

#### 관련 연구
기존의 연구들은 주로 지도형 미세조정(SFT)나 강화 학습(RL) 등을 통한 추론 향상에 초점을 맞추고 있으며, 이 논문은 이러한 방법들이 모델의 추론 경로를 정렬하거나 추론을 강화하는데 어떻게 기여했는지 설명합니다.

#### 방법론
SIFT(Sick to the Facts)라 불리는 새로운 방법론을 제안하여, 마치 사람들이 복잡한 문제를 해결할 때 스티커 노트를 사용하듯이 모델 자체가 생성한 '스티커'를 사용해 LLM의 추론을 문맥에 기반해 확고히 하도록 합니다. 스티커는 질의에서 핵심적인 조건과 본질적인 질문을 포함해 요약되는 구조화된 정보입니다.

#### 실험
SIFT는 다양한 LLM 및 벤치마크에서 성능 향상을 일관되게 보여주며, 특히 DeepSeek-R1 모델에서는 AIME2024에서 7.34%의 정확도 향상을 이끌어냈습니다. 이는 SIFT가 기존 기법들을 뛰어넘는 새로운 사실 기반 추론 성과를 증명합니다.

#### 결론
SIFT는 훈련 데이터나 추가적인 훈련 없이도 사실 기반의 추론을 강화하는 실질적인 솔루션을 제공합니다. 이는 소형화된 LLM에서 내부적으로 적용되어 더 효율적인 기기 내 추론을 가능하게 할 수 있습니다.

### 2. 전체 요약
이 논문은 복잡한 문제 해결을 위한 대규모 언어 모델(LLM)의 다단계 추론을 개선하는 새로운 방식인 SIFT를 소개합니다. SIFT는 모델 자체가 생성한 '스티커'를 사용하여 문맥 기반으로 추론의 정확성을 높이며, 이를 통해 LLM이 질의의 핵심 정보를 보다 명확히 이해하고 처리하도록 돕습니다. 여러 실험에서는 SIFT가 다양한 모델 및 데이터세트에 대한 성능 향상을 일관되게 보여주며, 무훈련 상태에서도 사실 기반의 신뢰성 있는 추론을 가능하게 합니다. 이것은 LLM 연구와 활용에 있어 중요한 진전을 의미합니다.