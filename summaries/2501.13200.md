# SRMT: Shared Memory for Multi-agent Lifelong Pathfinding
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.13200.pdf](https://arxiv.org/pdf/2501.13200.pdf)

### 1. 각 섹션의 중요한 내용을 요약

#### 초록
이 논문은 다중 에이전트 강화 학습(MARL)의 협력 문제와 경쟁 문제를 다루며, 에이전트 간 협력을 위한 행동 예측의 필요성을 강조합니다. 이를 해결하기 위해 개별 작업 메모리를 풀링하고 전송하는 방식으로 정보 교환을 가능케 하는 공유 반복 메모리 트랜스포머(SRMT)를 제안합니다. 이 방법은 복잡한 환경에서의 협력과 의사 결정 과정을 크게 향상시키며, 비통신적 환경에서도 높은 성능을 나타냅니다.

#### 도입
다중 에이전트 시스템은 복잡한 문제를 해결할 수 있는 잠재력이 있지만, 에이전트 간의 상호작용을 조율하는 것은 여전히 어려운 문제입니다. 본 연구는 브레인의 글로벌 워크스페이스 이론에 영감을 받아, 에이전트들이 공유 메모리 환경에서 협력할 수 있는 방안을 제시합니다. SRMT는 작업 메모리를 공유하여 죽음의 고리를 피하고 협력을 촉진할 수 있습니다.

#### 관련 작업
본 연구는 네트워크화된 에이전트들 간의 비통신적 지식 공유 방법론을 소개하며, 반복적으로 업데이트되는 메모리를 통해 개별 에이전트가 정보를 읽고 작성할 수 있도록 합니다. 이는 행동이 중앙 집중적이지 않고 분산적으로 유지될 수 있도록 합니다.

#### 모델 및 방법론
이 논문에서는 SRMT를 제안하며, 여러 에이전트가 글로벌 메모리 공간에서 정보를 교환하고 조정할 수 있는 구조를 제공합니다. SRMT는 개별 에이전트의 메모리를 풀링하고 전송함으로써 공유 액세스를 가능케 하며, 팀 내의 공동 의사 결정을 촉진합니다.

#### 실험 결과
SRMT는 혼잡한 환경에서도 효과적으로 작동하며, Follower 계획과 통합되었을 때 더 나은 혼잡 관리 성능을 보여주었습니다. 다양한 고수준 메트릭에 대한 경쟁력 있는 성능은 SRMT의 확장성과 견고성을 입증합니다.

#### 결론
본 연구는 다중 에이전트 시스템의 향상된 협력을 위해 새롭게 제안된 SRMT 아키텍처를 소개합니다. SRMT는 공유 메모리 메커니즘을 통해 환경의 확장성과 견고성을 보장합니다.

### 2. 전체 요약
이 연구는 다중 에이전트 시스템에서 공유 반복 메모리를 통해 정보 교환을 가능하게 하는 새로운 방법론인 SRMT를 제안합니다. SRMT는 중앙 집중적이지 않은 환경에서 에이전트가 정보를 교환하며 협력을 향상시킬 수 있도록 하며, 혼잡한 환경 및 보상 구조에서도 높은 성능을 보입니다. SRMT는 다양한 계획 기반 알고리즘 및 강화 학습 기준보다 성과가 뛰어나며, 이는 다중 에이전트 강화 학습에서 메모리 구조의 잠재적 가치를 강조합니다.