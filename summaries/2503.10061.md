# Compute Optimal Scaling of Skills: Knowledge vs Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2503.10061.pdf](https://arxiv.org/pdf/2503.10061.pdf)

1. 각 섹션 요약:

- **서론 (Introduction)**
  이 논문은 대형 언어 모델(LLM)의 중요한 발전 요소인 스케일링 법칙에 대해 탐구합니다. 특히, 특정 기술에 따라 컴퓨트 최적 스케일링 행동이 달라질 수 있는지를 확인하고자 합니다. 저자들은 지식 기반 질문 응답(Knowledge-based QA)와 코드 생성 같은 기술들에 대해 연구하여, 기술의 스케일링 법칙이 다른 행동을 보임을 확인했습니다.

- **배경 (Background)**
  스케일링 법칙은 트레이닝과 검증 셋에서 손실을 예측하기 위해 사용됩니다. 이 법칙은 파라미터 수와 데이터 셋 크기 간의 트레이드오프를 보여주는 IsoFLOP 곡선을 활용합니다. 본 논문에서는 이러한 스케일링 법칙을 기술 의존적으로 고려하며, 이에 대한 배경을 제공합니다.

- **연구의 주요 질문 (Research Questions)**
  세 가지 연구 질문을 제시했습니다: 
  1. 컴퓨트 최적점(COs)이 기술 의존적인가?
  2. 지식과 코드 기술의 스케일링 차이가 전체 데이터 믹스의 결과물인가, 아니면 본질적인 차이인가?
  3. 기술 의존 컴퓨트 최적점의 존재가 LLM 트레이닝에 미치는 영향은 무엇인가?.

- **실험과 결과 (Experiments and Results)**
  다양한 컴퓨트 스케일과 두 가지 기술(지식 QA와 코드)에 대해서 총 19개의 데이터셋을 사용한 실험 결과, 지식 QA는 보다 많은 파라미터를 필요로 하며, 코드는 데이터에 더 민감한 것으로 나타났습니다. 이는 곧 기술에 따라 최적의 파라미터와 데이터 토큰 크기가 달라짐을 의미합니다.

- **결론 (Conclusion)**
  논문은 기술별 스케일링 법칙의 존재를 확인했습니다. 특히 지식 기반 QA는 리소스가 많이 소모되는 반면, 코드는 추가적인 데이터가 더 필요한 것으로 나타났습니다. 또한, 검증 세트를 어떻게 구성하느냐에 따라 최적 파라미터 수의 편차가 최대 50%까지 변할 수 있음을 보여주었습니다.

- **관련 연구 (Related Works)**
  스케일링 법칙과 데이터 선택에 관한 기존 연구들과의 차별성을 설명하며, 데이터 믹스 최적화를 위한 최신 연구 동향을 다루었습니다.

2. 전체 요약:
이 논문은 AI 및 머신 러닝 연구에 있어 중요한 스케일링 법칙을 기술의 차이에 따라 다르게 적용할 수 있음을 밝혔습니다. 지식 기반 질문 응답과 코드 생성의 예를 들어, 특정 기술이 얼마나 데이터나 파라미터에 민감한지를 알아내어, 효율적인 LLM 훈련을 위한 방향성을 제시했습니다. 이 연구 결과는 LLM 개발에서 기술별 최적 파라미터 및 데이터 설정을 위한 중요한 통찰을 제공합니다.