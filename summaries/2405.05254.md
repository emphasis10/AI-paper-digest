# You Only Cache Once: Decoder-Decoder Architectures for Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.05254.pdf](https://arxiv.org/pdf/2405.05254.pdf)

### 주요 내용 요약

1. **서론 및 배경**:
   - 기존 언어 모델은 문맥 기반의 양방향 인코더 모델과 출력 생성을 위한 단방향 디코더를 사용하는 인코더-디코더 모델로 구분됩니다. 이 연구에서는 'You Only Cache Once (YOCO)'라는 새로운 디코더-디코더 구조를 도입하여 큰 언어 모델의 성능을 향상시키기 위해 제안합니다.

2. **YOCO의 구조 및 기능**:
   - YOCO는 자기 디코더와 교차 디코더의 두 부분으로 구성됩니다. 자기 디코더는 글로벌 키-값 캐시를 효율적으로 인코딩하고, 이 캐시는 교차 디코더가 교차 주의 메커니즘을 통해 재사용합니다. 이 구조는 디코더만 있는 트랜스포머와 유사하게 작동하지만, YOCO는 키-값 쌍을 단 한 번만 캐싱합니다.

3. **성능 평가 및 응용**:
   - YOCO는 다양한 규모의 모델 크기와 훈련 토큰 수, 문맥 길이에서 확장 가능성을 입증하였습니다. 특히, 1백만 토큰의 문맥 길이로 확장할 때 거의 완벽한 니들 검색 정확도를 달성합니다. YOCO는 인퍼런스 메모리, 사전 채우기(latency) 지연, 처리량을 대폭 개선하며, 특히 긴 시퀀스 모델링에 효과적입니다.

### 혁신적인 부분
YOCO의 혁신성은 큰 언어 모델에서 필요로 하는 메모리 요구를 대폭 줄이면서 글로벌 주의 기능을 유지한다는 점에 있습니다. 또한, 계산 흐름은 사전 채우기 단계를 대폭 가속화하여 사용자 경험을 향상시킵니다. 이러한 특성은 특히 긴 문맥의 언어 모델을 효과적으로 지원하면서, 시스템 설계의 효율성을 높이는 데 기여합니다.

이 논문은 대규모 언어 모델의 성능과 효율성을 혁신적으로 향상시키며, 향후 큰 스케일의 실시간 언어 처리 응용에서 중요한 역할을 할 것으로 기대됩니다.