# Beyond the Next Token: Towards Prompt-Robust Zero-Shot Classification via Efficient Multi-Token Prediction
## TL;DR
## Summary
- [https://arxiv.org/pdf/2504.03159.pdf](https://arxiv.org/pdf/2504.03159.pdf)

1. 논문의 각 섹션 요약:

- **소개 (Introduction):** 논문은 Prompt Brittleness(프롬프트 취약성) 문제를 다루고 있으며, 이는 자연어 모델이 프롬프트의 미세한 변화에도 민감하게 반응하여 예측 결과가 크게 달라질 수 있음을 말합니다. 이 문제를 해결하기 위해 P3라는 새로운 방법을 제안하여 프롬프트 없이도 지속적으로 우수한 성능을 보여주려고 합니다.

- **관련 연구 (Related Work):** Prompt Brittleness와 제로샷 텍스트 분류에 대한 기존 연구들을 검토합니다. 특히, 기존의 방법들이 얼마나 프롬프트에 의존적인지를 설명합니다.

- **방법론 (Methodology):** P3 방법론은 후속 토큰 예측을 통해 여러 토큰 예측을 단일 모델 실행 안에서 수행합니다. 이는 프롬프트 취약성을 줄이고, 성능을 크게 개선시킬 수 있어 제로샷 텍스트 분류에서 효율적인 대안으로 제시됩니다.

- **실험 결과 (Results):** P3는 여러 데이터셋에서 프롬프트 없이도 안정적으로 높은 정확도를 유지하며, 기존의 상태-주도-의-예술 (SoTA)보다 좋은 성능을 보여주었습니다.

- **결론 (Conclusion):** P3는 자원 절약적이고 안정적으로 프롬프트 취약성을 크게 줄이며, 제로샷 분류에서의 신뢰성을 높입니다.

- **한계 (Limitation):** 논문에서는 P3의 한계로 자동회귀 언어모델에서의 활용 및 다양한 언어와 모델 타입에 대해 추가 연구가 필요하다고 논의합니다.

2. 전반적인 요약:

논문에서는 자연어 처리(NLP)에서의 프롬프트 의존성과 그에 따른 취약성을 해결하기 위해 P3 방법을 제안합니다. P3는 다음 토큰 예측만으로 분류의 정확성과 안정성을 높이며, 특히 프롬프트 엔지니어링에 대한 의존도를 크게 줄입니다. 이를 통해 자연어 모델이 프롬프트 없이도 일관된 성능을 보여줄 수 있음을 실험적 증거로 제시하였고, 이를 통해 제로샷 분류에서의 효과적인 활용 가능성을 보여줍니다.