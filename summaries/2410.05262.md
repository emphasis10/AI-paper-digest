# TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.05262.pdf](https://arxiv.org/pdf/2410.05262.pdf)

### 1. 각 섹션의 주요 내용 요약:

#### 소개
이 연구는 Large Language Models(LLMs)의 점점 더 복잡하고 다양한 실제 시나리오에서 그들의 언어 이해 및 추론 능력을 평가하는 데 직면한 문제를 탐색합니다. 기존의 LLM 평가 기준은 과대평가로 인해 신뢰성이 저하될 수 있으며, 이는 모델의 실제 성능과 거리가 멀게 평가될 수 있습니다.

#### TurtleBench 소개
TurtleBench는 실제 사용자 상호 작용에 기반한 평가 벤치마크로, 사용자로부터 수집된 예측을 실시간으로 업데이트하여 보다 신뢰할 수 있는 평가 결과를 제공합니다. 이는 모델 간의 지식 기반 차이에 의해 발생할 수 있는 불공정한 평가를 피하고, 모델의 추론 능력 자체에 집중할 수 있게끔 설계되었습니다.

#### 자료 수집
TurtleBench 데이터셋은 온라인 터틀 수프 퍼즐 게임을 통해 실제 사용자 추측 데이터로 구성됩니다. 이 게임은 표면 이야기와 바닥 이야기를 제공하여 모델이 사용자의 추측이 맞는지 여부를 판단하도록 설계되었습니다. 이러한 데이터는 모델의 따뜻하지 않은 코호트 토큰(network of reasoning nodes) 과정을 평가하는 데 사용됩니다.

#### 실험 결과
실험은 공개 및 폐쇄 소스 모델 모두를 포함하여 9가지 LLMs에 대해 수행되었습니다. Claude-3.5-Sonnet와 GPT-4o는 전체 정확도가 87% 이상으로 다른 모델들보다 우월한 성능을 보여주었습니다. OpenAI의 최신 o1 시리즈 모델은 상대적으로 낮은 성능을 보였습니다.

#### 결론
TurtleBench는 LLMs의 추론 능력을 평가하는 안정적이고 실용적인 프레임워크를 제안합니다. 이 연구는 LLMs 평가의 신뢰성을 향상시키기 위한 미래의 방향성을 제시하며, LLMs가 실제 세계에 적용되는 데 있어 더 실질적인 평가 결과를 지원하고자 합니다.

### 2. 전체 요약:
이 논문은 실제 사용자 상호 작용을 기반으로 AI 모델을 보다 신뢰성 있게 평가할 수 있는 새로운 벤치마크인 TurtleBench를 소개합니다. TurtleBench는 사용자가 주어진 문제에 대해 예상할 수 있는 추측을 통해 AI 모델의 추론 능력을 평가합니다. 특히, 이 시스템은 동적 데이터 수집을 통해 고정된 데이터셋에 의한 과대평가를 방지하고 실질적인 신뢰성을 제공합니다. 결론적으로, 이 연구는 LLMs 평가 방법의 개선을 통해 실제 적용 가능한 실질적 평가를 목표로 하고 있으며, 이러한 시스템의 실용성을 더욱 향상시키기 위한 잠재적 경로를 제안합니다.