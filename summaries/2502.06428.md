# CoS: Chain-of-Shot Prompting for Long Video Understanding
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.06428.pdf](https://arxiv.org/pdf/2502.06428.pdf)

1. 각 섹션 요약:
   
   - **서론**: 이 논문은 대형 언어 모델(LLM)을 기반으로 한 멀티모달 모델이 긴 비디오 이해에 어려움을 겪는 문제를 해결하기 위해 개발된 '체인-오브-샷 프롬프팅(CoS)'이라는 새로운 방법론을 소개합니다. CoS는 시각적 데이터를 테스트 시간에 최적화하여 긴 비디오에서도 효과적으로 정보를 추출하도록 도와주며, 실험을 통해 이 방법의 효율성을 입증했습니다.

   - **관련 연구**: 최신 다중모달 대형 언어 모델(MLLM)들이 긴 비디오를 이해하는데 필요한 문제를 다룹니다. 기존 방법들은 대개 텍스트 입력 최적화에 집중해 시각적 입력의 중요성이 간과되었으며, 긴 비디오의 경우 관련 정보가 드문드문 분포되어 있어 이 문제를 해결하는 데 집중합니다.

   - **방법론**: CoS는 이진 비디오 요약과 비디오 공동추론 모듈로 구성되어 있으며, 각 비디오 인스턴스마다 작업에 필요한 포지티브 샷과 네거티브 샷을 생성, 중요한 정보에 집중하고 불필요한 노이즈를 필터링합니다. 이는 훈련이 필요 없는 동적 최적화 전략으로, 테스트 시 비디오 입력을 최적으로 전환합니다.

   - **실험**: 다양한 데이터셋에서 CoS의 효능을 검증하기 위해 LongVA, VideoXL, LLaVA-Video와 같은 기준모델에 통합하여 실험하였습니다. 결과는 CoS가 모든 기준모델과 시간적 축척에서 유의미한 성능 개선을 가져왔음을 보여줍니다.

   - **결론**: CoS는 비디오 이해 능력을 향상시키기 위한 강력한 도구로, 긴 비디오에서 중요한 정보를 캡처하고 불필요한 정보를 최소화하는 데 효과적임을 시사합니다.

2. 전체 요약:

   이 논문은 긴 비디오에서 중요한 정보를 효과적으로 추출하기 위한 체인-오브-샷 프롬프팅(CoS) 방법론을 제안합니다. CoS는 비디오의 시각적 데이터를 동적으로 최적화하여 테스트 시간에 최적의 비디오 입력을 구성하며, 그 결과 긴 비디오 이해 능력을 개선했습니다. 다양한 데이터셋과 기준모델 실험을 통해 CoS의 효율성을 입증했습니다. 이 방법론은 대형 언어 모델의 비디오 이해 능력을 강화하여 AI의 발전에 기여할 수 있을 것입니다.