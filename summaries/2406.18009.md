# E2 TTS: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.18009.pdf](https://arxiv.org/pdf/2406.18009.pdf)

### 1. 각 섹션 별 요약

#### Introduction
이 섹션에서는 텍스트-투-스피치(이하 TTS) 시스템의 최근 발전을 설명합니다. 텍스트에서 자연스러운 음성을 생성하는 능력이 크게 향상되었으며, 특히 소량의 음성 샘플로부터 다양한 화자의 자연스러운 음성을 생성해내는 제로샷 TTS가 주목받고 있습니다. 전통적인 제로샷 TTS 모델은 화자 임베딩을 사용하여 화자의 특성을 반영했으며, 최근에는 VALL-E와 같은 모델이 신경 코덱 도메인에서 언어 모델링으로 접근하여 성능을 더욱 향상시켰습니다.

#### Main Contribution
논문의 주요 기여는 E2 TTS라는 매우 간단한 구조의 완전 비자기회귀(Non-Autoregressive, 이하 NAR) 제로샷 TTS 시스템을 제안한 것입니다. E2 TTS는 텍스트 입력을 문자 시퀀스로 변환한 후, 이 시퀀스를 멜 스펙트로그램으로 변환하는 과정을 단순화했습니다. 덕분에 복잡한 구성 요소나 추가적인 기술 없이도 최첨단 성능을 달성했습니다.

#### Innovative Part
E2 TTS는 매우 단순한 아키텍처를 사용하여 다양한 입력 표현을 유연하게 처리할 수 있는 장점을 지녔습니다. 이 모델은 멜 스펙트로그램 생성기와 보코더로 구성되며, Vanilla Transformer와 U-Net 스타일의 스킵 연결을 사용하여 훈련됩니다. 또한 E2 TTS는 자연스러운 제로샷 TTS를 구현하는 데 있어서 불필요한 복잡성을 제거하고도 각광받는 성능을 달성합니다.

#### E2 TTS System - Training
훈련 과정에서는 Flow-matching 기반의 멜 스펙트로그램 생성기를 사용하며, 음성 채워넣기(infilling) 작업으로 학습됩니다. 모델은 약 800,000 미니 배치 업데이트를 통해 훈련되었으며 뛰어난 성능을 보였습니다.

#### E2 TTS System - Inference
추론 과정에서는 주어진 음성 샘플로부터 화자 특성을 모방하며, 텍스트 입력과 일치하는 멜 스펙트로그램을 생성합니다. 모델은 학습된 분포를 기반으로 멜 스펙트로그램을 생성하고 이를 보코더를 통해 음성 신호로 변환합니다.

#### Experiments
실험에서는 E2 TTS 모델을 다양한 데이터셋에서 Voicebox, VALL-E, NaturalSpeech 3와 비교 평가했습니다. 평가 결과 E2 TTS는 단순한 구조임에도 불구하고 다른 선도적인 모델들과 대등하거나 뛰어난 성능을 보였으며, 특히 학습 스케일링에서도 강점을 보였습니다.

#### Conclusion
결론적으로, E2 TTS는 단순하면서도 뛰어난 성능을 자랑하는 제로샷 TTS 모델로, 복잡한 추가 구성 요소 없이 유연하고 효율적인 음성 생성을 가능하게 합니다. 이는 향후 TTS 시스템의 개발에 있어 중요한 기여가 될 것입니다.

### 2. 전체 요약

이 논문은 텍스트-투-스피치(TTS) 시스템의 종단간 무자기회귀(Non-Autoregressive) 제로샷 모델인 E2 TTS를 소개합니다. E2 TTS는 복잡한 추가 구성 없이도 자연스러운 음성을 생성할 수 있는 단순한 아키텍처를 채택했습니다. 멜 스펙트로그램 생성기와 보코더로 구성된 E2 TTS는 텍스트 입력을 문자 시퀀스로 변환한 후 이를 멜 스펙트로그램으로 바꿔주는 역할을 하며, 학습 과정에서는 Flow-matching 기반의 기법을 활용했습니다. 다양한 데이터셋 실험에서, E2 TTS는 다른 최신 모델들보다 우수하거나 동등한 성능을 보이며 특히 학습 스케일링에서 강점을 보였습니다. 이로써 E2 TTS는 차세대 TTS 시스템 개발에 중요한 기여를 할 것으로 기대됩니다.