# Hierarchical Patch Diffusion Models for High-Resolution Video Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.07792.pdf](https://arxiv.org/pdf/2406.07792.pdf)

### 주요 내용 요약

#### 1. 서론
이 논문에서는 고해상도 비디오 생성을 위한 계층적 패치 확산 모델(Hierarchical Patch Diffusion Models, HPDM)을 소개합니다. 기존의 확산 모델이 고해상도로 확장되기 어려운 점을 감안하여, 패치를 독립적으로 모델링하는 새로운 접근 방식을 제안합니다. 이 방법은 학습 효율성을 높이며, 고해상도 비디오의 종단 간 최적화를 가능하게 합니다. 주목할 만한 개선 사항으로는 딥 컨텍스트 융합(Deep Context Fusion)과 적응적 계산(Adaptive Computation)을 도입한 점이 있으며, 이는 고해상도 비디오 생성을 위한 새로운 해결책을 제공합니다.

#### 2. 관련 연구
본 연구는 패치 확산 모델과 기존의 계단형 확산 모델(Cascaded Diffusion Models, CDM), 잠재 확산 모델(Latent Diffusion Models, LDM)과의 비교를 통해, 패치 단위로 모델을 학습하는 방법이 고해상도 비디오 생성을 효율적으로 할 수 있음을 증명합니다. 특히, 기존의 많은 연구들이 전체 해상도로 설정된 데이터에 의존하는 반면, 본 연구는 패치의 작은 부분 만으로 높은 일관성을 유지할 수 있는 기술을 개발했습니다.

#### 3. 배경: 확산 모델
확산 모델은 주어진 데이터셋의 분포를 추정하는 데 사용됩니다. 이 논문에서는 주로 패치 기반 훈련을 통해 고해상도 비디오 생성을 목표로 하고 있으며, 패치별로 독립적으로 노이즈가 추가된 데이터를 복원하는 방식으로 동작합니다.

#### 4. 방법론
**패치 확산 (Patch Diffusion):** 패치 확산은 전체 해상도의 데이터를 사용하는 대신, 무작위로 추출한 패치를 통해 모델을 학습합니다. 패치 크기는 계층적으로 설정되며, 이전 단계에서 생성된 저해상도 패치를 기반으로 고해상도 패치를 생성합니다. 이는 전체 해상도의 데이터를 학습에 사용하는 것보다 훨씬 효율적입니다.

**깊은 컨텍스트 융합 (Deep Context Fusion):** 딥 컨텍스트 융합은 저해상도 단계에서 고해상도 단계로 컨텍스트 정보를 전달하여 패치 간의 일관성을 유지하는 기술입니다. 이를 통해 보다 정밀하고 일관성 있는 결과를 얻을 수 있습니다.

**적응형 계산 (Adaptive Computation):** 적응형 계산은 모든 층에서 동일하게 작동하는 대신, 일부 층은 높은 해상도의 패치에서만 작동하도록 하여 계산 자원을 효율적으로 사용할 수 있게 합니다.

#### 5. 실험 및 결과
UC101 데이터셋에 대한 실험 결과, 제안된 HPDM 모델이 클래스 조건부 비디오 생성에서 최신 기술 대비 두 배 이상의 성능 향상을 이루었음을 보여줍니다. 특히, 끝단-종단 학습으로 고해상도 64x288x512 텍스트-비디오 생성을 빠르게 미세 조정할 수 있음을 증명했습니다.

#### 6. 결론
본 연구는 패치 단위로 데이터의 일부만을 사용하여도 고해상도 비디오 생성을 효율적으로 할 수 있음을 입증했습니다. 딥 컨텍스트 융합과 적응형 계산을 도입함으로써, 기존의 모델들보다 훨씬 향상된 성능을 보여줬고, 이는 고해상도 비디오 생성을 위한 새로운 기준을 제시합니다.

### 전체 요약

이 논문은 고해상도 비디오 생성을 위한 새로운 패러다임인 계층적 패치 확산 모델(HPDM)을 제안합니다. 기존의 확산 모델이 고해상도로 확장하기 어려운 문제를 해결하기 위해, 패치 단위로 데이터를 처리하는 방법을 사용하여 학습 효율성을 크게 높였습니다. 또한, 딥 컨텍스트 융합과 적응형 계산 같은 혁신적인 기술을 도입하여, 패치 간 일관성을 유지하면서도 높은 성능을 달성했습니다. UC101 데이터셋을 통해 HPDM의 우수성을 실험으로 입증하였고, 이는 고해상도 비디오 생성 분야에서 새로운 기준을 제시합니다.