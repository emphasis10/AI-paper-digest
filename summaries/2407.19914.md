# Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.19914.pdf](https://arxiv.org/pdf/2407.19914.pdf)

### 논문의 중요 내용 요약

#### 1. 서론
이 논문은 리투아니아어 특정 감성 분석을 다룹니다. 현대 사회에서는 소셜 미디어가 중요한 역할을 하며, 이를 통해 많은 데이터가 생성됩니다. 그러나 리투아니아어 관련 연구는 부족한 실정입니다. 이 논문은 리투아니아어 온라인 리뷰의 감성 분석을 위해 대형 언어 모델(LLM)과 변형 모델(BERT, T5)을 처음으로 적용하고 그 성능을 평가합니다.

#### 2. 감성 분석 과제와 도전 과제
감성 분석은 의견, 감정, 견해 등을 자동으로 분석하는 작업입니다. 특히 리투아니아어와 같은 덜 연구된 언어의 경우 데이터의 복잡성과 언어의 특수성 때문에 추가적인 도전 과제가 있습니다.

#### 3. 관련 연구
- **텍스트 전처리 및 표현**:
  - 토큰화(tokenization): 텍스트를 작은 단위로 분할하여 관리하기 쉽도록 함.
  - 단어 임베딩(word embeddings): 단어를 벡터로 변환하여 모델이 이해할 수 있도록 함.

- **텍스트 분류를 위한 LLMs**:
  - BERT: 양방향 문맥을 이용하여 높은 정확성을 보임.
  - T5: 모든 텍스트 문제를 텍스트 생성 문제로 변환하여 다양한 NLP 작업에 적용 가능.

- **리투아니아어 관련 연구**:
  - 현재 리투아니아어를 대상으로 한 단일언어 LLM 모델은 존재하지 않음. 다만, 다중언어 모델에서 리투아니아어 데이터로 훈련된 모델은 있음.

#### 4. 데이터와 방법론
- **데이터셋**:
  - 다양한 리투아니아어 온라인 리뷰에서 수집됨.
  - 리뷰의 5성 평가 체계를 기준으로 감성을 분류.

- **모델 사용 방법**:
  - DistilBERT 모델: 더 작고 빠르지만 BERT의 성능을 대부분 유지.
  - ByT5 모델: 리투아니아어 텍스트로 추가 훈련된 T5 모델.

- **평가 지표**:
  - 정확도(Accuracy)
  - F1-스코어: 정밀도와 재현율의 조화 평균.

#### 5. 실험 결과
- DistilBERT와 ByT5 모델 모두 데이터셋의 불균형이 성능에 큰 영향을 미침.
- DistilBERT 모델은 대부분 긍정적인 감성을 예측하는 경향이 있음.
- ByT5 모델은 빠르게 과적합되는 경향이 있음.

#### 6. 토론
- 리투아니아어를 위한 단일언어 LLM 모델이 없기 때문에 연구가 제한적임.
- 더 많은 데이터와 개선된 모델 파라미터를 통해 성능 향상 가능성 있음.

#### 7. 결론
이 논문은 리투아니아어 온라인 리뷰를 위한 새로운 데이터셋을 수집하고 두 가지 LLM 모델을 실험하여 비교했습니다. DistilBERT 모델이 GPT-4 모델보다 더 나은 성능을 보여줌으로써 맞춤형 모델의 중요성을 강조했습니다.

#### 주요 기여와 혁신
- 리투아니아어 감성 분석을 위한 새로운 데이터셋 수집.
- 대형 언어 모델을 처음으로 적용하여 성능 평가.
- 다중 언어 모델의 리투아니아어 데이터셋에 대한 성능 비교.

### 전체 요약
이 논문은 리투아니아어 온라인 리뷰의 감성 분석을 위해 변형 모델을 적용하고 이를 평가한 연구입니다. 본 연구는 새로운 데이터셋을 수집하여 DistilBERT 및 ByT5 모델을 통해 성능을 비교합니다. 실험 결과, 맞춤형 모델이 상용 모델인 GPT-4보다 높은 정확성을 보여주었으며, 더 많은 데이터와 개선된 파라미터를 통해 성능 향상이 가능함을 시사합니다. 이러한 연구는 감성 분석 분야에서 리투아니아어와 같은 덜 연구된 언어의 분석에 기여할 수 있습니다.