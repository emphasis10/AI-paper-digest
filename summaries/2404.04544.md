# BeyondScene: Higher-Resolution Human-Centric Scene Generation With Pretrained Diffusion
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.04544.pdf](https://arxiv.org/pdf/2404.04544.pdf)

이 논문은 고해상도 인간 중심 장면 생성을 위한 새로운 프레임워크인 BeyondScene에 대해 소개합니다. 기존의 텍스트-이미지 확산 모델들이 제한된 훈련 이미지 크기, 텍스트 인코더 용량, 그리고 복잡한 장면을 생성하는 데 있어서의 어려움으로 인해 고해상도 인간 중심 장면을 상세하게 제어하며 생성하는 데 한계가 있었습니다. 이러한 문제들을 해결하기 위해, BeyondScene은 기존에 사전 훈련된 확산 모델을 사용하여 뛰어난 텍스트-이미지 일치도와 자연스러움을 갖춘 8K 이상의 고해상도 인간 중심 장면을 생성합니다. 이 프레임워크는 단계적이고 계층적인 접근 방식을 채택하여, 먼저 중요한 요소에 초점을 맞춘 상세한 기본 이미지를 생성한 다음, 이를 고해상도 출력으로 원활하게 변환하여 텍스트와 인스턴스를 고려한 상세 정보를 추가합니다.

### 1. 소개
고해상도 인간 중심 장면 생성은 애니메이션, 게임 제작을 넘어 다양한 분야에서 중요한 연구 영역으로 부상했습니다. 텍스트-이미지(T2I) 확산 모델의 최근 발전에도 불구하고, 여러 인간이 등장하는 더 크고 복잡한 장면을 처리하는 것은 여전히 중요한 도전 과제입니다. BeyondScene은 이러한 제약을 극복하고 고해상도에서 인간 중심 장면을 자연스럽게 생성할 수 있는 새로운 프레임워크를 제안합니다.

### 2. 관련 작업
인간 생성과 대규모 장면 생성에 관한 기존 연구들은 특정 시나리오 내에서 성공을 거두었으나, 다양한 장면과 임의의 포즈에서는 한계를 보였습니다. BeyondScene은 이러한 한계를 넘어서고자 합니다.

### 3. BeyondScene
BeyondScene은 두 단계로 이루어진 프레임워크입니다. 첫 번째 단계에서는 핵심 요소에 초점을 맞춘 상세한 기본 이미지를 생성합니다. 이후 인스턴스를 고려한 계층적 확대 과정을 통해 이 기본 이미지를 고해상도 출력으로 변환하여, 텍스트와 인스턴스를 고려한 추가 상세 정보를 포함시킵니다.

### 4. 실험
BeyondScene은 기존 방법들과 비교하여 더 자연스러우며, 텍스트와의 일치도가 높은 고해상도 인간 중심 장면을 생성할 수 있음을 실험을 통해 입증했습니다.

### 결론
BeyondScene은 고해상도에서 인간 중심 장면을 생성하는 새로운 접근 방식을 제시합니다. 이는 텍스트에 기반한 자세한 제어를 가능하게 하며, 사전 훈련된 확산 모델의 한계를 넘어서는 결과를 달성했습니다.

---
이 논문의 핵심 내용을 바탕으로, 다음과 같은 요약을 제공할 수 있습니다:

BeyondScene 프레임워크는 고해상도 인간 중심 장면 생성의 한계를 극복하기 위해 개발되었습니다. 이는 복잡한 장면을 자연스럽게 생성하며, 상세한 텍스트-이미지 일치를 달성하는 것을 목표로 합니다. 기존 확산 모델을 활용하되, 단계적이고 계층적인 접근 방식을 통해 고해상도 이미지를 성공적으로 생성함으로써, 이 분야의 새로운 방향을 제시합니다.

## Similar Papers
- [Click-Gaussian: Interactive Segmentation to Any 3D Gaussians](2407.11793.md)
- [MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation](2404.05674.md)
- [Improved Distribution Matching Distillation for Fast Image Synthesis](2405.14867.md)
- [Collaborative Video Diffusion: Consistent Multi-video Generation with Camera Control](2405.17414.md)
- [Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding](2405.08748.md)
- [Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention](2408.00760.md)
- [Editable Image Elements for Controllable Synthesis](2404.16029.md)
- [BitsFusion: 1.99 bits Weight Quantization of Diffusion Model](2406.04333.md)
- [EMMA: Your Text-to-Image Diffusion Model Can Secretly Accept Multi-Modal Prompts](2406.09162.md)
