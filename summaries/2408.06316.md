# Body Transformer: Leveraging Robot Embodiment for Policy Learning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.06316.pdf](https://arxiv.org/pdf/2408.06316.pdf)

### 주요 섹션 요약

#### 도입부
이 논문에서는 기존 트랜스포머 아키텍처를 활용한 로봇 학습 문제를 다룹니다. 트랜스포머는 자연어 처리와 컴퓨터 비전에서 성공적으로 사용되었지만, 로봇의 신체 구조를 충분히 활용하지 못했습니다. 이를 개선하기 위해 Body Transformer(BoT)를 제안하며, 로봇의 센서와 엑추에이터를 그래프로 표현하고, 이를 통해 학습을 유도합니다.

#### 배경
- **주의 메커니즘**: 트랜스포머에서 사용하는 자기-주의 메커니즘은 쿼리, 키, 값 매트릭스를 사용해 시퀀스 엘리먼트 간의 관련 쌍을 식별합니다.
- **트랜스포머 기반 GNN**: 로봇의 신체는 노드(센서와 엑추에이터)와 엣지(연결관계)로 그래프 형태로 모델링 됩니다. 그러나 메시지 전달 방식은 과도한 스무딩과 스쿼싱 문제를 야기할 수 있습니다.
- **마스킹된 주의**: 이 메커니즘은 바이너리 마스크를 사용해 주의 메커니즘에서 특정 쌍의 기여를 제거합니다.

#### Body Transformer (BoT)
BoT는 로봇 신체 구조를 반영한 마스킹된 주의 메커니즘을 사용합니다. 각 레이어에서 노드는 자신과 인접한 노드의 정보만 참조하며, 이를 통해 정보가 그래프 구조를 따라 흐르도록 합니다. BoT의 주요 구성요소는 다음과 같습니다:
- **토크나이저**: 관측 벡터를 로컬 상태 벡터로 변환합니다.
- **BoT 인코더**: 스탠다드 트랜스포머 인코더를 사용합니다.
- **디토크나이저**: 트랜스포머 인코더의 출력 피쳐를 액션으로 변환합니다.

#### 실험
- **모방 학습 실험**: BoT는 MoCapAct 데이터셋에서 다른 아키텍처들 보다 우수한 성능을 보입니다. 마스킹된 주의 메커니즘으로 인해 학습 데이터에 과적합되지 않으며, 검증 클립에서도 뛰어난 일반화 능력을 보였습니다.
- **강화 학습 실험**: BoT는 여러 로봇 제어 태스크에서 PPO 알고리즘을 사용하여 검증되었습니다. Embodiment bias는 성능 향상에 기여했습니다.

#### 결론
BoT는 로봇의 신체 구조를 반영한 새로운 트랜스포머 아키텍처로, 마스킹된 주의 메커니즘을 통해 모방 학습 및 강화 학습 성능을 크게 향상시킵니다. 또한, BoT는 높은 차원의 시스템에 적합한 스케일링 및 계산 특성을 가지고 있습니다.

### 전체 요약
이 논문에서는 트랜스포머 아키텍처를 기반으로 한 로봇 학습 프레임워크인 Body Transformer(BoT)를 제안합니다. BoT는 로봇의 센서와 엑추에이터를 그래프로 모델링하여, 마스킹된 주의 메커니즘을 통해 학습을 향상시킵니다. 이 메커니즘은 각 노드가 자신과 인접한 노드의 정보만 참조하게 하여 정보가 그래프 구조를 따라 흐르도록 합니다. BoT는 모방 학습과 강화 학습에서 기존의 트랜스포머와 다층 퍼셉트론을 능가하는 성능을 보이며, 로봇의 신체 구조를 반영한 특성을 통해 일반화 능력과 계산 효율성을 높였습니다. 이를 통해 BoT는 고차원 시스템에 적합한 아키텍처로 자리매김합니다. 

이 답변은 AI 연구를 발전시키는 데 도움을 줄 수 있을 것입니다. 감사합니다.