# MotionGS: Exploring Explicit Motion Guidance for Deformable 3D Gaussian Splatting
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.07707.pdf](https://arxiv.org/pdf/2410.07707.pdf)

### 1. 논문의 주요 내용 요약

#### 서론
논문은 3D 가우시안 스플래팅(3D Gaussian Splatting)을 활용한 동적 장면 복원에 대한 새로운 방법인 MotionGS를 제안합니다. 이 방법은 개체의 움직임에 대한 명시적인 가이드를 제공하여 3D 가우시안의 변형을 유도합니다. 주된 아이디어는 광학 흐름을 분리하여 카메라 움직임과 객체 움직임을 나누고, 이를 통해 동적 객체의 운동을 시뮬레이션하는 것입니다.

#### 관련 연구
NeRF(신경 방사장 필드)를 기반으로 한 기존 연구들과 달리, 3D 가우시안 스플래팅은 실시간으로 높은 품질의 이미지를 렌더링 할 수 있습니다. 그러나 기존의 방법들은 물체의 움직임에 대한 명시적인 제약이 없다는 점에서 한계가 있었습니다.

#### 방법론
MotionGS는 두 가지 주요 모듈을 포함합니다. 첫 번째는 광학 흐름 분리 모듈로, 카메라의 움직임과 물체의 움직임을 분리합니다. 두 번째는 카메라 위치 보정 모듈로, 3D 가우시안과 카메라 위치를 번갈아 최적화하여 렌더링 품질을 향상시킵니다.

#### 실험 결과
NeRF-DS와 HyperNeRF 데이터셋을 통해 실험을 수행했으며, MotionGS는 동적 장면 복원에서 최첨단의 성능을 발휘함을 입증했습니다. 실험은 MotionGS가 다른 전통적인 방법들에 비해 높은 품질의 렌더링을 가능하게 함을 보여줍니다.

#### 결론
논문은 동적 장면 복원에서 개체의 움직임을 명확히 모델링하고 제약하는 MotionGS를 제안합니다. 모듈의 개선 사항은 특정 네트워크 설계에 구애받지 않으며, 다른 3D 가우시안 스플래팅 방법에도 응용될 수 있습니다. 추후 연구에서는 카메라 위치 정보에 의존하지 않는 3DGS 방법을 개발하는 것을 목표로 하고 있습니다.

### 2. 전체 요약
이 논문은 동적 장면 복원을 향상시키기 위해 3D 가우시안 스플래팅을 활용하는 MotionGS라는 새로운 프레임워크를 소개합니다. MotionGS는 물체의 움직임을 분리하여 보다 명시적인 제약을 제공하고, 카메라 위치를 보정하여 동적 환경에서의 렌더링 품질을 향상시킵니다. 이러한 접근 방식은 실험을 통해 다른 기존 방법에 비해 우월한 성능을 입증했으며, 높은 품질의 실시간 렌더링을 가능하게 합니다. 추후에는 카메라 위치에 의존하지 않고도 성능을 발휘할 수 있는 방법으로의 발전을 목표로 하고 있습니다.