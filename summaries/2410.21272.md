# Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.21272.pdf](https://arxiv.org/pdf/2410.21272.pdf)

### 1. 섹션별 요약 및 주요 기여 및 혁신적인 부분

**도입 및 배경**  
이 논문은 대형 언어 모델(LLM)이 산술적 추론 문제를 해결할 때 얼마나 일반화 가능한 알고리즘을 학습하는지 아니면 단순히 데이터를 암기하는지를 조사합니다. 이를 위해, 저자들은 인과 분석을 사용하여 산술 논리를 설명하는 서브셋(회로)을 식별하고, 이 회로 내에서 중요한 뉴런들을 분석합니다. 이 모델의 주된 메커니즘은 서로 다른 뉴런들이 다양한 수학적 휴리스틱을 사용하여 올바른 산술 답변을 증진시키는 것입니다.

**주요 내용과 기여**  
- LLM은 강력한 알고리즘이 아닌 "휴리스틱의 집합"을 사용하여 산술적 문제를 해결하는 것으로 나타났습니다. 
- 이 논문은 특히 개별 뉴런이 구현하는 간단한 휴리스틱을 밝히고, 휴리스틱 뉴런의 결합이 정확한 산술 답변을 산출하는 과정을 설명하고자 합니다.
- 이러한 메커니즘은 LLM의 전반적인 산술능력의 주요 원천으로 작용하며, 훈련 초기에 등장한다는 점을 입증합니다.

**결론 섹션**  
LLM의 산술 능력의 사용 방식은 기억과 알고리즘적 이해의 중간에 위치하며, 여러 휴리스틱 규칙의 조합을 통해 산술적 추론을 수행한다는 결론을 도출합니다. 이 메커니즘은 점진적으로 진화하며, 단순한 휴리스틱 기능만을 강하게 사용하는 경향이 있습니다. 따라서 LLM의 수학적 능력을 향상시키기 위해서는 학습과 구조에 근본적인 변화가 필요할 수 있음을 시사합니다.

### 2. 전반적인 요약

이 논문은 대형 언어 모델이 산술적 문제 해결을 위해 어떠한 메커니즘을 사용하는지에 관한 연구입니다. LLM은 미리 학습된 휴리스틱의 집합을 사용하여 산술 문제를 해결하며, 이는 훈련 초기부터 메커니즘으로 자리잡습니다. 이 연구는 LLM의 산술적 추론 방식이 메모리 의존 보다는 휴리스틱 조합을 통해 이루어진다는 것을 밝혀냈으며 이는 향후 LLM의 수학적 문제 해결 능력을 개선하는 데 기본적인 이해를 제공합니다.