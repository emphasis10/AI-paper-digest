# To Code, or Not To Code? Exploring Impact of Code in Pre-training
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.10914.pdf](https://arxiv.org/pdf/2408.10914.pdf)

### 1. 섹션별 중요한 내용 요약 및 논문의 주요 기여 및 혁신적인 부분 요약
#### Abstract (초록)
이 연구는 코드 데이터를 포함한 사전 학습이 비코드 작업에도 중요한 영향을 미친다는 점을 체계적으로 조사하였다. 다양한 자연어 추론 및 세계 지식 작업에서 코드 데이터를 포함한 모델이 더 높은 성능을 나타냈다. 코드를 포함한 사전 학습은 자연어 추론에서 8.2%, 세계 지식에서 4.2%, 생성적 승률에서 6.6%, 코드 성능에서는 12배의 상대적 향상을 나타냈다.

#### Introduction (소개)
최근 AI 모델의 성능은 데이터의 다양성과 양, 그리고 계산 능력에 크게 의존한다. 특히 사전 학습 데이터에 코드 데이터를 포함하는 것이 비코드 작업에도 긍정적인 영향을 미친다는 것을 발견했다. 많은 최신 모델들이 코드 데이터를 포함하고 있으며, 이는 자연어 처리 및 다른 비코드 작업에서 높은 성능을 보이는 주요 요인 중 하나로 간주된다.

#### Experiments (실험)
다양한 실험을 통해 코드 데이터를 포함한 사전 학습이 다양한 작업에서 어떻게 영향을 미치는지 조사했다. 특히, 코드 데이터를 포함한 모델은 자연어 추론, 세계 지식, 코드 생성 등에서 높은 성능을 보인다. 최적의 성능을 위해서는 코드의 비율과 품질이 중요하며, 모든 단계의 사전 학습에서 코드 데이터를 활용하는 것이 권장된다.

#### Conclusion (결론)
코드 데이터를 사전 학습에 포함하는 것은 비코드 작업에서도 큰 성능 향상을 제공한다는 점을 증명했다. 코드 품질 향상, 코드 데이터 비율 조정, 코드 데이터를 포함한 식히기 단계 등의 다양한 요소가 모델 성능에 중요한 영향을 미친다. 이 연구는 코드가 단지 코드를 생성하는 작업뿐만 아니라 광범위한 일반화 작업에서도 중요한 구성 요소임을 시사한다.

### 2. 전체 요약
이 논문은 코드 데이터를 포함한 사전 학습이 비코드 작업에도 큰 영향을 미친다는 점을 종합적으로 연구했다. 연구 결과, 코드 데이터를 포함한 모델이 자연어 추론, 세계 지식, 생성적 작업에서 높은 성능을 보였으며, 코드 품질과 비율이 중요한 요인임을 발견했다. 특히, 코드 데이터를 포함한 식히기 단계가 모델 성능을 크게 향상시키는 것으로 나타났다. 이 연구는 코드가 광범위한 작업에서 중요한 구성 요소임을 제시하며, 이는 AI 기술 발전에 중요한 기여를 한다.