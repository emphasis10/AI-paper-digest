# Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.19385.pdf](https://arxiv.org/pdf/2410.19385.pdf)

**1. 섹션별 요약**

- **서론 (Introduction):**

  본 논문은 대형 언어 모델(LLM)의 중요성과 일반적 사용 사례를 설명하며, 이러한 모델에서 발생할 수 있는 고유한 문제점인 '환상(hallucinations)'에 대해 논의합니다. LLM은 다양한 언어 처리 작업을 수행할 수 있지만, 그 특유의 무작위성으로 인해 현실과 맞지 않는 부정확한 정보를 생성할 수 있습니다.

- **배경 (Background):**

  LLM에 대한 배경 지식이 제공됩니다. 여기에는 LLM 작동 방식, '환상'의 유형, 그리고 효과적인 예측을 위해 LLM을 어떻게 설계해야 하는지가 포함됩니다.

- **방법론과 실험 설계 (Methodology and Experimental Design):**

  다양한 효과적인 프로팅 전략을 설계하고 이를 평가하기 위한 실험적 접근 방식을 다루고 있습니다. 여기에는 체인 오브 사유(CoT), 자기일관성(SC) 등 다양한 프롬프트 전략의 구현과 LLM 요원(agent) 기반 구조의 연구가 포함됩니다.

- **결과 (Results):**

  프롬프팅 기술 및 외부 도구 활용이 LLM의 환상 발생 빈도에 미치는 영향을 분석하고, 특정 문제 유형에 따라 가장 효과적인 프롬프팅 기술이 달라진다는 것을 보여줍니다. 보다 간단한 방법이 종종 복잡한 방법보다 낫다는 것을 발견했습니다.

- **결론 (Conclusion):**

  본 논문은 여러 프로팅 기법과 프레임워크의 성능과 환상 발생률을 평가했으며, 이러한 기법 및 프레임워크를 어떻게 결합하여 더 강력한 LLM을 만들 수 있는지 논의합니다.

**2. 전체 요약:**

이 논문은 대형 언어 모델(LLM)의 환상(hallucinations)을 감소시키기 위한 다양한 프롬프팅 전략과 외부 도구의 사용에 대한 종합적인 평가를 제공합니다. LLM은 강력한 언어 처리 능력을 지니고 있지만, 비판적인 사회적 영역에서 검증되지 않은 잘못된 정보를 생성할 위험이 있습니다. 본 연구는 다양한 프롬프팅 전략과 LLM 요원(agent) 설계가 이러한 문제점을 어떻게 완화할 수 있는지를 밝히며, 보다 단순한 기법이 자주 더 복잡한 방식보다 효과적일 수 있음을 시사합니다. 향후 연구는 이러한 전략을 결합하여 더 효과적인 모델을 만들고 환상 발생률을 줄이는 방향으로 나아가야 할 것입니다.