# BenTo: Benchmark Task Reduction with In-Context Transferability
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.13804.pdf](https://arxiv.org/pdf/2410.13804.pdf)

### 섹션별 요약:

1. **서론**:
   - 최근 대형 언어 모델(LLM)의 평가가 중요하며 여러 작업을 포함한 벤치마크의 필요성이 강조됩니다. 벤치마크의 크기를 줄이면서도 정확한 평가가 가능하도록 하는 연구 방향을 제시하고 있습니다.

2. **관련 연구**:
   - 과거의 작업 전이성 추정 방식은 주로 모델의 파인튜닝이나 피셔 정보에 의존하지만, 이번 연구에서는 이러한 복잡성을 해결하기 위해 인컨텍스트 학습을 활용하는 방안을 제안합니다.

3. **인컨텍스트 학습을 통한 작업 전이성 분석**:
   - 서로 다른 두 작업 간의 전이성을 측정하는 방법으로, 훈련 없는 전이성 평가를 위한 비용 효율적인 해결책을 제안합니다.

4. **벤치마크 작업 감소(BENTO) 방법**:
   - 유사 시설 위치 문제로 작업 선택을 공식화하여, 최대 작업 유사성을 유지하는 작업 감소 방법을 제안합니다. 실험적으로 5%의 작업만으로도 95%의 평가 정확도를 유지할 수 있음을 보였습니다.

5. **실험**:
   - 다양한 데이터셋을 바탕으로 제안된 방법의 유효성을 평가하며, 성능 차이를 최소화하면서 평가 비용을 대폭 절감할 수 있음을 확인합니다.

6. **결론**:
   - 대형 언어 모델의 평가에서 벤치마크의 수를 줄여도 정확한 평가가 가능하다는 것을 입증하며, 이 방법이 다른 모델과 작업에 확장될 가능성을 제시합니다.

### 전체 요약:

이 논문은 대형 언어 모델의 평가 비용을 줄이면서도 정확한 결과를 제공할 수 있는 새로운 방법을 제안합니다. '인컨텍스트 전이성(ICL)'을 통해 훈련 없이도 다양한 작업 간의 전이성을 측정하여 벤치마크 작업을 효과적으로 축소할 수 있습니다. 특히, 이 방법은 5%의 축소된 작업으로 원래의 95% 평가 정확도를 유지하면서도, 벤치마크 감소의 효율성을 증대시킵니다. 이 연구는 모범적인 평가 효율성과 비용 절감을 제공함으로써, AI 및 머신러닝 분야의 발전에 기여하고자 합니다.