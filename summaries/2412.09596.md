# InternLM-XComposer2.5-OmniLive: A Comprehensive Multimodal System for Long-term Streaming Video and Audio Interactions
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.09596.pdf](https://arxiv.org/pdf/2412.09596.pdf)

## 1. 각 섹션 요약

### 서론 (Introduction)

연구의 목표는 인간의 인지와 비슷하게 환경과 장기간 상호작용할 수 있는 AI 시스템을 개발하는 것입니다. 최근에는 대형 언어 모델의 발전으로 자유형 멀티모달 질문 응답 기술이 크게 발전해 왔습니다. 그러나 현재의 멀티모달 언어 모델(MMLM)은 입력과 출력을 동시에 처리하지 못하며, 지속적인 상호작용이 어렵습니다. 기존 아키텍처의 한계를 극복하기 위해, 저자들은 스페셜라이즈드 제너럴리스트 AI의 개념에 영감을 받아, 인지, 추론, 그리고 메모리를 분리해 실시간으로 스트리밍 비디오와 오디오 입력을 처리하는 새로운 시스템을 개발했습니다.

### 관련 연구 (Related Works)

텍스트-이미지 대화를 위한 대형 언어 모델(LLM)과 비디오 이해를 위해 발전해온 멀티모달 언어 모델에 대해 다룹니다. 기존 솔루션은 인지, 메모리, 추론을 동시에 수행할 수 없어 일관된 장기적인 인간-AI 상호작용에 한계가 있습니다.

### 방법론 (Methodology)

이 시스템은 스트리밍 인식 모듈, 멀티모달 장기 기억 모듈, 추론 모듈로 구성되며, 모든 모듈이 동시에 작동합니다. 
- 스트리밍 인식 모듈은 오디오 인식 및 비디오 인식을 위해 설계되어 있으며, Whisper 모델과 Qwen2-1.8B 모델을 사용합니다.
- 멀티모달 장기 기억 모듈은 단기 기억을 장기 기억으로 압축함으로써 효율적인 검색과 정확성을 개선합니다.
- 추론 모듈은 인식 모듈에 의해 활성화되며, 쿼리를 처리하고 추론 작업을 수행합니다.

### 결과 및 논의 (Results and Discussion)

제안된 IXC2.5-OL 시스템은 실시간 비디오 상호작용과 같은 다양한 기준점에서 우수한 성능을 보였습니다. 특히, 10B 미만의 파라미터로도 최고 수준의 비디오 및 오디오 이해 성능을 달성했습니다. 또한 AI와의 지속적인 상호작용을 가능하게 하는 실용적인 시스템으로의 발전 가능성을 보여줬습니다.

## 2. 전체 요약

이 논문에서는 인간의 인지 능력을 모방하여 장기적으로 환경과 상호작용할 수 있는 AI 시스템을 소개합니다. 이를 위해 다양한 모듈로 구성된 IXC2.5-OL 시스템을 제안하여 지속적인 스트리밍 인식과 추론, 메모리를 가능하게 했습니다. 이러한 접근 방식은 대형 언어 모델의 한계를 극복하고 AI의 장기적이고 중단 없는 서비스를 가능하게 하여, 보다 동적인 AI 애플리케이션 개발에 기여할 수 있는 가능성을 제공합니다.