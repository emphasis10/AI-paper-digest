# SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.09413.pdf](https://arxiv.org/pdf/2407.09413.pdf)

### 논문의 주요 내용 요약

#### 1. 서론

이 연구는 과학 연구 논문 내에서 질문에 대한 답변을 찾는 문제를 다루고 있으며, 그런 데이터셋의 부족을 해결하기 위해 SPIQA(Scientific Paper Image Question Answering)라는 새로운 대규모 데이터셋을 소개합니다. 기존의 데이터를 극복하기 위해 학습 모델이 표와 그림을 이해할 수 있도록 설계되었습니다.

#### 2. 관련 연구

기존의 과학 논문 QA 데이터셋은 주로 텍스트에 집중하고 있지만, SPIQA는 그림과 표를 통해 질문에 응답하는 능력을 평가합니다. 기존 데이터셋의 한계는 복잡한 시각적 정보와 텍스트를 동시에 이해하지 못하는 점입니다.

#### 3. SPIQA 데이터셋 및 과제

SPIQA 데이터셋은 컴퓨터 과학의 다양한 도메인에서 출판된 25,859개의 논문을 포함하며, 그림과 표 및 전체 텍스트를 기반으로 질문을 생성합니다. QA 과제는 3가지로 나뉘며, 그림과 표로 직접 질문에 답하는 것과 전체 논문을 통해 질문에 답하는 것, 그리고 유용한 그림과 표를 먼저 식별하고 그 후 답변을 생성하는 Chain-of-Thought (CoT) QA가 포함됩니다.

#### 4. LLMLogScore: Free-form QA를 위한 향상된 지표

LLMLogScore (L3Score)는 자유형 QA의 평가 메트릭으로, 후보 답변의 품질을 평가하기 위해 LLM의 성능을 사용합니다. 이 메트릭은 기존의 평가 메트릭보다 더욱 정교한 평가를 제공하며, 다양한 QA 시스템을 비교하는 데 효과적입니다.

#### 5. 실험 결과

다양한 QA 시스템을 SPIQA 데이터셋으로 평가한 결과, 일부 모델은 특정 종류의 그림이나 표를 처리하는 데 어려움을 겪었습니다. 그러나 CoT QA 설정을 사용함으로써 모델의 성능이 눈에 띄게 향상되었습니다. 특히 LLMLogScore를 통한 평가에서 높은 정확도를 보였습니다.

#### 6. 결론

SPIQA와 LLMLogScore의 도입은 과학 논문을 이해하고 분석하는 QA 시스템을 발전시키는 데 중요한 기초를 제공합니다. 또한, SPIQA 데이터셋은 다양한 도메인에서 QA 시스템의 성능 평가를 향상시키며, 향후 연구의 중요한 자료가 될 것입니다.

### 전체 요약

SPIQA는 과학 논문의 복잡한 그림과 표를 분석하여 질문에 답하는 대규모 QA 데이터셋으로, 컴퓨터 과학 전반에 걸친 다양한 도메인을 포함합니다. LLMLogScore는 자유형 질문에 대한 평가를 위해 개발된 메트릭으로, 기존보다 정밀한 평가를 제공합니다. 실험 결과, CoT QA 접근 방식으로 모델 성능이 크게 향상되었으며, 이러한 새로운 데이터셋과 평가 메트릭은 과학 논문 이해를 위한 QA 시스템의 발전에 큰 기여를 할 것입니다. 

이 요약은 발표 자료를 제작하고 AI 연구를 발전시키는 데 있어 중요한 기초 자료로 사용될 수 있을 것입니다.