# Heterogeneous LoRA for Federated Fine-tuning of On-Device Foundation Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2401.06432.pdf](https://arxiv.org/pdf/2401.06432.pdf)

### 논문의 주요 내용 요약

#### 1. 요약
이 논문은 **기기상에서 실행 가능한 기초 모델**(On-Device Foundation Models, ODFMs)을 **연합 학습(Federated Learning, FL)**을 이용해 **효율적으로 미세 조정(finetuning)**하는 방법인 **Heterogeneous LoRA (HETLORA)**를 제안합니다. HETLORA는 **랭크 자가 가지치기(self-pruning)**와 **스패시티 가중 합산(sparsity-weighted aggregation)**을 사용하여 다양한 랭크의 LoRA 모듈을 효율적으로 통합하고 분배합니다.

#### 2. 도입부
기초 모델(FMs)은 다양한 작업에 적응할 수 있도록 미세 조정되며, 연합 학습(FL)은 개인 데이터를 보호하면서도 FMs를 미세 조정할 수 있는 잠재력을 가지고 있습니다. 그러나 전통적인 PEFT(매개변수 효율적 미세 조정) 방법은 모든 클라이언트 장치에 동일한 랭크를 사용하여 느린 학습 속도와 과적합 사이의 균형 문제를 가지고 있습니다.

#### 3. 연합 학습의 기본
연합 학습에서는 각 클라이언트가 자신의 데이터로 글로벌 모델을 지역적으로 학습한 후 서버에 업데이트를 보내면, 서버는 모든 클라이언트의 업데이트를 통합하여 글로벌 모델을 갱신합니다. 이 과정은 여러 통신 라운드를 거쳐 반복됩니다.

#### 4. 기존 Homogeneous LoRA의 문제점
동일한 랭크를 사용하는 Homogeneous LoRA는 낮은 랭크에서는 과적합 없이 성능이 안정적이지만, 높은 랭크에서는 빠르게 과적합하는 문제를 가지고 있습니다. 따라서 클라이언트 장치의 시스템 자원에 맞추어 다양한 랭크를 사용하는 것이 더욱 효과적임을 보여줍니다.

#### 5. HETLORA 제안
HETLORA는 다음과 같은 세 단계를 포함합니다:
 
 1. **분배(Distribution via Truncation)**: 서버는 글로벌 LoRA 모듈을 각 클라이언트의 랭크에 맞게 잘라서 보냅니다.
 2. **지역 학습(Local Training)과 랭크 자가 가지치기(rank self-pruning)**: 클라이언트는 자신의 랭크에 맞게 LoRA 모듈을 학습하며, 랭크 자체를 자가 가지치기 합니다.
 3. **스패시티 가중 합산(Sparsity-Weighted Aggregation)**: 서버는 각 클라이언트의 업데이트를 통합할 때, 업데이트의 중요도를 반영하여 가중치를 부여합니다.

#### 6. 실험 결과
HETLORA는 Homogeneous LoRA에 비해 학습 속도가 빠르고 최종 성능이 뛰어납니다. 특히, 낮은 랭크의 LoRA 모듈이 과적합을 방지하는 데 기여하며, 최종 성능에서 훨씬 높은 점수를 기록합니다. 또한, HETLORA의 랭크 자가 가지치기와 스패시티 가중 합산이 성능을 극적으로 향상시키는 것을 실험적으로 확인하였습니다.

#### 7. 결론
HETLORA는 연합 학습 환경에서 클라이언트 장치의 이질적인 시스템 능력에 맞추어 효율적으로 미세 조정할 수 있는 방법을 제안합니다. 이는 기존 방법에 비해 높은 최종 성능과 효율성을 입증합니다.

### 전체 요약
이 논문은 **연합 학습 환경**에서 **기기에서 실행 가능한 기초 모델**을 효과적으로 미세 조정하기 위한 새로운 방법인 **HETLORA**를 제안합니다. 기존 방법의 문제점을 해결하기 위해 **랭크 자가 가지치기**와 **스패시티 가중 합산** 기법을 도입하였습니다. 이러한 접근 방식은 학습 속도를 높이고 과적합을 방지하며 최종 성능을 향상시키는 데 기여합니다. 이 방법의 유효성은 다양한 실험을 통해 입증되었습니다. HETLORA는 이질적인 클라이언트 시스템 능력에 맞추어 연합 학습 환경에서 기초 모델의 효율적인 미세 조정을 가능케 합니다. 

이를 통해 연합 학습과 기기상에서의 모델 실행을 위한 중요한 발전을 이룰 수 있습니다.