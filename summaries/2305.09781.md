# SpecInfer: Accelerating Generative Large Language Model Serving with Tree-based Speculative Inference and Verification
## TL;DR
## Summary
- [https://arxiv.org/pdf/2305.09781.pdf](https://arxiv.org/pdf/2305.09781.pdf)

### 요약 및 분석: SpecInfer 논문

#### 1. 서론
SpecInfer는 대형 언어 모델(LLM)의 서비스 속도를 높이기 위해 제안된 시스템으로, 트리 기반 추측 추론 및 검증을 사용합니다. 기존의 순차적 디코딩 및 단일 후보 추론 방식 대신, SpecInfer는 다양한 추측 후보를 동시에 고려하여 성능을 극대화합니다.

#### 2. SpecInfer의 개요
SpecInfer는 입력 토큰 시퀀스를 받아 추측된 토큰 트리를 생성하는 학습 기반 추측기를 포함합니다. 이 시스템은 추측된 토큰 트리의 모든 후보 토큰 시퀀스의 정확성을 병렬로 검증하여 LLM 디코딩 단계에서 생성되는 토큰 수를 크게 증가시킵니다. SpecInfer는 트리 기반 병렬 디코딩 메커니즘을 통해 모든 토큰을 한 번의 LLM 디코딩 단계에서 검증합니다.

#### 3. 학습 기반 추측기
기존의 추측 디코딩 방법은 단일 시퀀스 기반 추측을 수행하지만, SpecInfer는 다양한 후보를 동시에 추측하여 성공률을 높입니다. 이를 통해, SpecInfer는 LLM과의 정렬 성공률을 크게 향상시킵니다. 또한, SpecInfer는 다양한 SSM을 사용하여 추측 성능을 최적화합니다.

#### 4. 트리 기반 병렬 디코딩
SpecInfer는 트리 구조를 사용하여 모든 토큰의 병렬 검증을 수행합니다. 이는 GPU 메모리 접근 횟수를 줄이고, CPU와 GPU 메모리 간의 데이터 전송을 최소화하여 에너지 소비를 줄입니다. 또한, SpecInfer는 키-값 캐시를 트리 구조에 맞게 업데이트하여 중복 계산을 줄입니다.

#### 5. 다단계 추측 샘플링
SpecInfer는 다단계 추측 샘플링을 통해 LLM의 생성 성능을 유지하면서 검증할 수 있는 토큰 수를 최대화합니다. 이를 통해, SpecInfer는 스토캐스틱 디코딩 시 기존 방법보다 1.2~1.3배 더 많은 토큰을 검증할 수 있습니다.

#### 6. 평가
SpecInfer는 분산 LLM 추론과 오프로드 기반 LLM 추론에서 기존 시스템보다 최대 3.5배 더 나은 성능을 보입니다. 이는 추측 트리 구조를 통해 디코딩 단계를 줄이고, 병렬 검증을 통해 전체적인 추론 지연 시간을 단축시킨 결과입니다.

### 전체 요약
SpecInfer는 트리 기반 추측 추론 및 검증을 사용하여 대형 언어 모델의 서비스 속도를 크게 향상시키는 시스템입니다. 다양한 추측 후보를 동시에 고려하여 성능을 극대화하고, 병렬 디코딩 메커니즘을 통해 메모리 접근 및 데이터 전송을 최소화하여 에너지 소비를 줄입니다. 이를 통해 SpecInfer는 분산 및 오프로드 기반 LLM 추론에서 뛰어난 성능을 발휘하며, 기존 시스템보다 최대 3.5배 더 빠른 추론 속도를 제공합니다. SpecInfer의 혁신적인 다단계 추측 샘플링 및 트리 기반 구조는 LLM의 효율적인 서비스 제공에 큰 기여를 합니다.