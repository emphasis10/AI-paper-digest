# Generation Constraint Scaling Can Mitigate Hallucination
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.16908.pdf](https://arxiv.org/pdf/2407.16908.pdf)

### 주요 내용 요약: "Generation Constraint Scaling Can Mitigate Hallucination"

#### 개요 (Abstract)
이 논문에서는 대형 언어 모델(LLM)에서 발생하는 환각 문제를 해결하기 위한 새로운 방법을 제시합니다. 메모리를 증강하여 LLM에서 환각을 줄이는 방법을 탐구하며, 메모리 읽기 벡터의 스케일링을 통해 훈련 없이도 효과적으로 환각을 줄일 수 있음을 실험적으로 증명했습니다. 이는 최신 LLM 편집 방법보다 뛰어남을 보여줍니다.

#### 소개 및 배경 (Introduction and Background)
대형 언어 모델은 언어 생성과 번역에서 뛰어난 성능을 보이지만 환각 문제를 안고 있습니다. 환각을 줄이기 위한 방법으로 모델 편집 기법과 문맥 기반 접근법이 있지만, 이 논문에서는 메모리 기반 접근법을 탐구하여 그 효과를 검증하였습니다. 메모리 증강 LLM이 환각을 줄이는 데 도움이 된다는 이전의 연구 결과를 기반으로 했습니다.

#### Larimar
Larimar는 외부 에피소드 메모리 컨트롤러를 갖춘 LLM의 한 종류입니다. Larimar의 기본 구조는 인코더, 연관 메모리 모듈, 디코더로 이루어져 있습니다. 이 구조는 텍스트 입력(에피소드)과 쿼리의 잠재 표현을 계산하여 메모리를 업데이트하고 쿼리하여 읽기 인코딩을 반환하는 역할을 합니다. 디코더는 읽기 벡터로 제한된 프롬프트에서 출력 텍스트를 생성합니다.

#### GRACE
GRACE는 LLM의 파라미터를 변경하지 않고도 편집을 수행할 수 있는 방법입니다. 이는 동적으로 확장되는 키-값 코드북을 레이어에 설치하여 작동합니다. 코드북 값은 특정 태스크 손실 함수를 최소화하여 학습됩니다.

#### 실험 (Experiments)
- 데이터: 위키백과 같은 전기(biography) 데이터셋인 WikiBio를 사용하여 238명의 인물에 대해 환각을 포함한 문장을 GPT-3로 생성하고, 이를 실제 위키백과 문장과 비교하여 사실 여부를 평가했습니다. 
- 모델: Larimar-1.3B와 GRACE를 비교 실험에 사용했습니다.

#### 결과 및 논의 (Results and Discussion)
- Larimar는 메모리에서 얻은 zreadout 벡터의 길이를 스케일링하여 환각을 효과적으로 줄일 수 있음을 발견했습니다. 최적의 스케일링 팩터는 3에서 4 사이였으며, 이는 GRACE보다 높은 성능을 보였습니다.
- Larimar는 WikiBio 항목을 합성하는 데 있어 GRACE보다 1-2배 빠르며, 최대 0.72의 RougeL 점수를 기록했습니다.

### 전체 요약
이 연구는 메모리를 증강한 Larimar 모델을 사용하여 대형 언어 모델의 환각 문제를 해결하는 혁신적인 방법을 제시했습니다. 메모리 읽기 벡터의 스케일링을 통해 훈련 없이도 환각을 줄일 수 있음을 실험적으로 증명했으며, 이는 기존 편집 방법보다 뛰어난 성능을 보였습니다. 이러한 방법은 메모리 기반 접근법이 효과적일 수 있음을 시사하며, Larimar 모델은 더 빠르고 정확한 텍스트 생성을 가능하게 합니다. 이 연구 결과는 AI의 언어 모델 개발에 중요한 기여를 할 수 있습니다.

## Similar Papers
- [Large Language Model Confidence Estimation via Black-Box Access](2406.04370.md)
- [Meltemi: The first open Large Language Model for Greek](2407.20743.md)
- [Discrete Flow Matching](2407.15595.md)
- [Video-to-Audio Generation with Hidden Alignment](2407.07464.md)
- [Eliminating Position Bias of Language Models: A Mechanistic Approach](2407.01100.md)
- [Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses](2408.00584.md)
- [Searching for Best Practices in Retrieval-Augmented Generation](2407.01219.md)
- [CoverBench: A Challenging Benchmark for Complex Claim Verification](2408.03325.md)
- [Style-NeRF2NeRF: 3D Style Transfer From Style-Aligned Multi-View Images](2406.13393.md)
