# Large Language Models as Analogical Reasoners
## TL;DR
## Summary
- [https://arxiv.org/pdf/2310.01714.pdf](https://arxiv.org/pdf/2310.01714.pdf)

### Section Summaries with Main Contributions and Innovations

#### 1. Introduction
이 논문은 대형 언어 모델(LLM)들이 복잡한 문제를 해결하는 과정을 지도하는 새로운 방법인 "아날로지 프로밍(Analogical Prompting)"을 도입합니다. 아날로지 프로밍은 과거의 관련 경험을 사용하여 새로운 문제를 해결하는 인간의 인지 과정을 모방하여, 언어 모델에 스스로 관련된 예제들을 생성하고 이를 사용해 문제를 해결하도록 유도합니다. 주요 기여는 수작업으로 레이블링된 예제를 필요로 하지 않으며, 문제별로 맞춤형 예제를 생성할 수 있다는 점입니다.

#### 2. 관련 연구
이 섹션에서는 대형 언어 모델과 프로밍 기법, 체인 오브 생각(CoT) 프로밍 방법, 그리고 아날로지 프로밍의 연관 연구들에 대해 다룹니다. 체인 오브 생각(CoT) 프로밍은 중간 추론 단계를 생성하게 하여 문제 해결 능력을 향상시키는 전략입니다. 아날로지 프로밍은 자가 예제 생성을 통해 이 문제를 해결하고 있습니다.

#### 3. 배경지식
문제 해결 과제를 중심으로 한 예제 문제 소개와 기초 프로밍 방법을 설명합니다. 0-shot 프로밍, 0-shot CoT, few-shot CoT와 같은 기존 프로밍 방법들을 예로 들며, 새로운 프로밍 방법을 설계하는 목표를 제시합니다.

#### 4. 접근법
아날로지 프로밍의 구체적인 메커니즘을 설명합니다. 새로운 문제를 해결할 때 LLM이 문맥에서 관련 예제를 스스로 생성하고, 초기 문제를 해결하도록 유도합니다. 이를 통해 복잡한 문제를 효과적으로 풀 수 있도록 돕습니다.

#### 5. 실험
여러 가지 실험을 통해 제안된 접근법이 기존의 0-shot CoT와 few-shot CoT를 능가하는 성능을 보임을 입증합니다. 다양한 종류의 LLM을 사용해 모형의 강도를 분석하고, 문제 해결 성능 향상을 확인합니다. 특히, 수학 문제 해결(GSM8K, MATH), 코드 생성(Codeforces), 논리적/시간적 추론 문제에서 우수한 결과를 얻었습니다.

#### 6. 분석
자가 예제 생성과 기존의 예제 검색 기반 방법을 비교분석합니다. 자가 예제 생성은 외부 레이블 데이터를 필요로 하지 않으며, 더 적절한 예제를 특정 문제에 맞게 생성할 수 있다는 장점이 있습니다. 반면, 검색 기반 예제는 신뢰성 측면에서 장점이 있습니다.

#### 7. 결론
논문은 아날로지 프로밍이 레이블 된 데이터 없이 세부적이고 맞춤형 예제를 각 문제에 대해 제공할 수 있음을 강조하며, 다양한 추론 작업에서 기존 방법들보다 뛰어난 성능을 보였음을 결론 짓습니다. 연구의 한계점들도 언급하여 향후 연구 방향을 제시합니다.

### 전체 요약
이 논문은 대형 언어 모델(LLM)이 복잡한 문제를 해결하는 과정에서 인간의 아날로지 적 추론을 모방하는 새로운 프로밍 방법, 아날로지 프로밍을 제안합니다. 이 방법은 LLM이 스스로 관련 예제를 생성하여 문제 해결에 활용하도록 유도하며, 이를 통해 기존의 0-shot CoT와 few-shot CoT보다 뛰어난 성능을 보입니다. 주요 기여는 수작업으로 레이블 된 데이터가 필요하지 않다는 점과 문제별로 맞춤형 예제를 생성할 수 있다는 점입니다. 실험 결과, 다양한 추론 작업에서 우수한 성능이 입증되었고, 자가 예제 생성이 검색 기반 예제보다 효율적임이 확인되었습니다. 하지만 이 방법은 더 많은 계산 자원을 필요로 하고, 모델의 강도에 크게 의존하는 등의 한계점이 있습니다.

## Similar Papers
- [Active Prompting with Chain-of-Thought for Large Language Models](2302.12246.md)
- [NATURAL PLAN: Benchmarking LLMs on Natural Language Planning](2406.04520.md)
- [Weak-to-Strong Reasoning](2407.13647.md)
- [Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning](2407.18248.md)
- [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](2404.02575.md)
- [Can LLMs Learn by Teaching? A Preliminary Study](2406.14629.md)
- [Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought](2404.03414.md)
- [NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?](2407.11963.md)
- [THOUGHTSCULPT: Reasoning with Intermediate Revision and Search](2404.05966.md)
