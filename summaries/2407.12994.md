# A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.12994.pdf](https://arxiv.org/pdf/2407.12994.pdf)

### 1. 섹션별 중요한 내용 요약

#### 섹션 1: 서론
인공지능, 특히 대형 언어 모델(LLM)의 발전으로 NLP 작업의 성능이 크게 향상되었습니다. LLM은 거대한 텍스트 데이터에 대한 학습을 기반으로 하며, 그 성능은 모델 파라미터 수가 증가함에 따라 향상됩니다. LLM의 주요 연구 방향은 단순히 다음 토큰을 예측하는 것에서 벗어나 프롬프트를 통한 추론 능력에 집중하고 있습니다.

#### 섹션 2: 프롬프트 엔지니어링 기술
프롬프트 엔지니어링은 LLM의 내재된 지식을 구조화된 방식으로 추출하기 위해 자연어 지시문, 즉 프롬프트를 작성하는 과정입니다. 이 기술은 모델의 재학습이나 미세 조정 없이 LLM의 지식을 활용합니다. 주요 프롬프트 엔지니어링 기법으로는 Chain-of-Thought(CoT), Self-Consistency, Ensemble Refinement(ER), Automatic CoT 등이 있습니다.

1. 기본 프롬프트: 단순한 지시문을 사용하여 답변을 유도합니다.
2. Chain-of-Thought(CoT): 복잡한 문제를 해결하기 위해 중간 추론 과정을 단계별로 나누어 해결합니다.
3. Self-Consistency: 다양한 추론 경로를 생성하고 가장 일관된 답변을 선택합니다.
4. Ensemble Refinement(ER): 여러 세대의 답변을 생성하고 결합하여 최종 답변을 도출합니다.

#### 섹션 3: NLP 작업
다양한 NLP 작업별로 적용된 프롬프트 전략과 해당 성과를 설명합니다. 여기에는 Commonsense Reasoning, Mathematical Problem Solving, Multi-Hop Reasoning 등이 포함됩니다. 각 작업에 대한 프롬프트 기술의 효과를 검토하고, 이를 통해 최고 성능을 달성한 단일 기법을 제시합니다.

#### 섹션 4: 결론
프롬프트 엔지니어링은 LLM의 잠재력을 극대화하는 중요한 역할을 하며, 이를 통해 많은 NLP 작업에서 뛰어난 성과를 달성할 수 있습니다. 논문에서는 44개의 연구 논문을 검토하여 39개의 프롬프트 기술과 29개의 NLP 작업에 대해 분석하였습니다.

### 2. 전체 요약
이 논문은 대형 언어 모델(LLM)의 성능을 향상시키기 위한 프롬프트 엔지니어링 기법을 체계적으로 조사한 연구입니다. 프롬프트 엔지니어링을 통해 모델의 파라미터 재학습이나 미세 조정 없이도 다양한 NLP 작업에서 뛰어난 성능을 달성할 수 있음을 보여줍니다. 주요 기술로는 Chain-of-Thought(CoT), Self-Consistency, Ensemble Refinement(ER), Automatic CoT 등이 있으며, 각 기법은 특정 NLP 작업에서 최고 성능을 달성하는 데 효과적입니다. 이 연구는 44개의 논문을 분석하여 39개의 프롬프트 기술과 29개의 NLP 작업을 다루고 있으며, 이를 통해 프롬프트 엔지니어링의 중요성과 잠재력을 강조합니다.

논문의 주요 기여는 프롬프트 엔지니어링 기술을 다양한 NLP 작업에 적용하여 성과를 효과적으로 요약하고, 최고 성능을 달성할 수 있는 방법을 제시한 것입니다. 이를 통해 프롬프트 엔지니어링의 중요성과 활용 가능성을 입증합니다.

## Similar Papers
- [MindSearch: Mimicking Human Minds Elicits Deep AI Searcher](2407.20183.md)
- [Privacy Preserving Prompt Engineering: A Survey](2404.06001.md)
- [Synthesizing Text-to-SQL Data from Weak and Strong LLMs](2408.03256.md)
- [GLiNER multi-task: Generalist Lightweight Model for Various Information Extraction Tasks](2406.12925.md)
- [MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases](2402.14905.md)
- [Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs](2406.18629.md)
- [Piccolo2: General Text Embedding with Multi-task Hybrid Loss Training](2405.06932.md)
- [A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models](2405.06211.md)
- [Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing](2404.12253.md)
