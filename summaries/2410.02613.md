# NL-Eye: Abductive NLI for Images
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.02613.pdf](https://arxiv.org/pdf/2410.02613.pdf)

### 1. 각 섹션의 중요 내용 요약

#### 1) 서론
이 논문은 VLM(비전 언어 모델)의 시각적 귀납적 추론 능력을 평가하기 위한 새로운 벤치마크인 NL-EYE를 소개합니다. NL-EYE는 다양한 추론 범주(물리적, 기능적, 논리적, 감정적, 문화적, 사회적)와 같은 실제 시나리오에 적용할 수 있도록 설계되었습니다. 이러한 태스크는 VLM이 사고 예방 봇 및 기타 실제 응용 프로그램에서 활용될 수 있도록 합니다.

#### 2) 관련 연구
최근 멀티모달 학습의 발전으로 텍스트와 시각 데이터를 통합하는 모델들이 다양하게 등장하고 있으며, VLM들이 여러 작업을 수행할 수 있게 되었습니다. 이러한 연구들은 기존의 상식적 추론을 토대로 VLM의 기능을 확장하고자 합니다.

#### 3) 연구 방법론
NL-EYE는 텍스트를 기반으로 했던 기존의 자연어 추론(NLI)을 시각적 영역으로 확장하여 사진 간의 귀납적 추론을 수행할 수 있는 프레임워크를 제공합니다. 이를 통해 모델들은 선택한 사항을 설명할 수 있어 더 깊이 있는 추론 능력을 평가할 수 있습니다.

#### 4) 데이터 및 실험 설정
NL-EYE 벤치마크는 텍스트-이미지 모델을 사용하여 생성된 1,050개의 이미지가 포함된 350개의 트리플렛 예제를 담고 있습니다. 이는 VLM의 추론 능력을 시험하고자 하며, 사람들이 효율적으로 수행할 수 있지만 VLM은 랜덤 수준에서 반응하는 결과를 보였습니다.

#### 5) 결과
VLM은 인간에 비해 상당히 낮은 성능을 보였습니다. 이 연구는 모델들이 인간처럼 복잡한 시각적 논리 추론을 할 수 없는 현 상황의 한계를 보여주며, 이를 극복하기 위한 미래의 연구 및 기술 발전 방향을 제시합니다.

#### 6) 결론
NL-EYE 벤치마크는 VLM의 시각적 귀납적 추론 한계를 탐구하고 개선함으로써 더 견고한 멀티모달 추론 모델 개발을 위한 방향성을 제공합니다.

### 2. 전체 요약
NL-EYE는 VLM의 시각적 추론 능력을 시험하려는 새로운 벤치마크로, 특히 사고 예방과 같은 실제 적용 사례에서의 활용 가능성을 염두에 두고 설계되었습니다. 연구 결과에 따르면 인간이 쉽게 수행할 수 있는 시각적 추론에 VLM이 어려움을 겪고 있다는 것이 드러났습니다. 이를 극복하기 위해, 향후 연구는 인간의 인지 과정을 모방하여 VLM의 추론 능력을 개선하는 데 초점을 맞출 것입니다. 이 논문은 VLM의 시각적 해석 및 논리적 추론의 통합 부족을 강조하며, 보강된 VLM 아키텍처 개발을 위한 기초 연구를 제시합니다.