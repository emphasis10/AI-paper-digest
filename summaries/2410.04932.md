# OmniBooth: Learning Latent Control for Image Synthesis with Multi-modal Instruction
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.04932.pdf](https://arxiv.org/pdf/2410.04932.pdf)

### 1. 섹션별 주요 내용 요약

#### Introduction
이 논문에서는 인스턴스 수준의 다면적 사용자 정의를 통해 공간 제어가 가능한 "OmniBooth" 프레임워크를 소개합니다. 이 프레임워크는 텍스트 프롬프트와 이미지 참조를 통해 사용자 정의된 마스크에 기반해 객체들을 지정된 위치에 배치하고, 각 객체의 속성을 정확히 맞추는 것을 목표로 합니다.

#### Related Work
기존의 컨트롤러블 이미지 생성 방법에는 많은 제약이 있었습니다. 특히, 주로 단일 모달리티 또는 제한적인 제어 방법으로만 가능합니다.

#### Method
- **멀티모달 임베딩 추출:** 텍스트 임베딩 및 이미지 임베딩을 통해 다중 모달 입력을 통합합니다.
- **통일된 다중 모달 지침:** "Latent Control Signal"을 사용하여 공간적, 텍스트적, 이미지적 조건을 통합하여 이미지 생성을 제어합니다.

#### Experiment
- **데이터셋 및 메트릭:** MS COCO 및 DreamBooth 데이터셋을 사용하여 텍스트 및 이미지 정렬 정확도를 평가합니다.
- **정량적 결과:** 본 연구에서 제안한 방법은 APmask에서 더 나은 성과를 보여주었고, 적층 점수는 InstanceDiffusion보다 높은 성능을 나타냈습니다.

#### Conclusion
이 프레임워크는 다면적 사용자 정의가 가능하며, 사용자가 필요에 따라 텍스트 또는 이미지 조건을 선택할 수 있도록 합니다. 실험 결과 이 방법이 높은 품질의 이미지 생성과 다양한 설정 및 작업에서 정확한 정렬을 달성함을 보여주었습니다.

### 2. 논문의 전체 요약

이 논문은 OmniBooth라는 새로우면서도 강력한 이미지 생성 프레임워크를 제안합니다. 이 프레임워크는 다중 모달 입력을 활용하여 사용자 정의 마스크와 텍스트 또는 이미지 지침에 따라 객체를 생성함으로써, 공간 제어 및 인스턴스 수준의 사용자 정의 기능을 제공합니다. 이는 텍스트 기반의 단순한 설명을 넘어, 복잡한 레이아웃과 형상을 정확하게 표현할 수 있는 보다 실용적이고 유연한 방안을 제시합니다. 실험 결과, 제안된 방법이 인스턴스 수준의 커스터마이징을 포함한 다양한 과제에서 우수한 성능을 발휘함이 확인되었습니다.