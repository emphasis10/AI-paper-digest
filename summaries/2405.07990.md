# Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.07990.pdf](https://arxiv.org/pdf/2405.07990.pdf)

### 주요 내용 요약

1. **서론 및 배경**:
   - 이 논문은 과학 플롯에서 실행 가능한 코드를 생성하는 멀티모달 대규모 언어 모델(MLLMs)의 능력을 평가하기 위해 **Plot2Code**라는 포괄적인 벤치마크를 소개합니다. 기존의 MLLMs가 시각적 문맥에서 우수한 성능을 보였으나, 시각적 이미지를 실행 가능한 코드로 변환하는 능력은 충분히 평가되지 않았습니다. 이를 해결하기 위해 6가지 유형의 플롯에 걸쳐 총 132개의 고품질 matplotlib 플롯과 해당 소스 코드를 포함하는 데이터셋을 구축했습니다.

2. **방법론**:
   - Plot2Code는 다양한 입력 모달리티에서 MLLMs의 코드 생성 능력을 평가하기 위해 세 가지 자동 평가 지표(코드 통과율, 텍스트 매치 비율, GPT-4V 종합 평가)를 제안합니다. 시각적 요소를 기반으로 코드의 유효성을 판단하며, GPT-4V 모델을 사용하여 생성된 이미지와 참조 이미지의 유사성을 평가합니다. 이를 통해 인간 평가와 일치하는 높은 평가 정확도를 달성합니다.
   - 데이터셋 구축 과정에서 matplotlib 갤러리에서 841개의 코드 블록을 수집하고, 이를 필터링하여 최종적으로 132개의 테스트 예제를 선택했습니다. 각 플롯에는 GPT-4가 요약한 설명이 포함되어 있습니다.

3. **실험**:
   - Plot2Code 벤치마크를 사용하여 GPT-4V, Gemini-Pro, Claude-3 등의 14개 MLLMs를 평가한 결과, 대부분의 모델이 텍스트가 많은 플롯에서 어려움을 겪으며, 텍스트 지시에 크게 의존하는 것으로 나타났습니다. GPT-4V 모델은 종합 평가에서 7.68/10의 점수를 받았으며, 이는 시각적 코딩 작업에서 상당한 개선의 여지가 있음을 시사합니다.
   - 평가 결과는 Plot2Code가 제시하는 도전 과제가 상당함을 보여주며, 특히 텍스트와 이미지의 조합을 입력으로 사용한 경우 모델의 성능이 낮아지는 경향이 있습니다. 이는 시각적 요소와 텍스트 지시를 동시에 처리하는 능력의 중요성을 강조합니다.

### 혁신적인 부분
Plot2Code의 혁신성은 멀티모달 입력을 통해 MLLMs의 시각적 코딩 능력을 종합적으로 평가할 수 있는 새로운 벤치마크를 제공하는 데 있습니다. 이는 시각적 문맥을 코드로 변환하는 능력을 정량적으로 평가할 수 있는 도구를 제공하여, 멀티모달 언어 모델의 발전을 위한 중요한 기준점을 제시합니다. 또한, 다양한 평가 지표를 도입하여 모델의 성능을 세밀하게 분석하고, 시각적 유사성 평가에 GPT-4V를 활용하여 인간 평가와 일치하는 결과를 도출합니다.