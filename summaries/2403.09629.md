# Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking
## TL;DR
## Summary
- [https://arxiv.org/pdf/2403.09629.pdf](https://arxiv.org/pdf/2403.09629.pdf)

### 요약: Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking

#### 1. 서론
- **요약**: Quiet-STaR는 언어 모델이 '잠시 생각' 후 말을 하도록 훈련시킵니다. 이는 예측을 위해 각 토큰에서 내적 추론(rationale)을 생성하여 언어 모델의 성능을 향상시키는 방법입니다.
  
#### 2. 주요 기여 내용
- **요약**:
  - 기존 STaR(자기 학습 추론자) 모델의 일반화.
  - 평형 샘플링 알고리즘을 통해 대규모 데이터셋에서 추론 학습.
  - 내적 추론의 시작과 끝을 지정하는 메타 토큰 도입.
  - 예측 정확도를 높이기 위한 혼합 헤드(mixing head) 적용.
  - 논생물적(non-myopic) 손실 함수를 사용해 효과적인 추론 도출.
  
#### 3. 관련 연구
- **요약**: 언어 모델의 추론 학습과 관련된 기존 연구들을 종합하여 설명하고, Quiet-STaR의 혁신점을 강조합니다.

#### 4. Quiet-STaR 작동 방식
- **요약**:
  - **병렬 생성**: 여러 토큰에서 병렬로 추론을 생성.
  - **혼합 알고리즘**: 추론과 예측을 혼합하여 더 나은 결과 도출.
  - **최적화**: 추론 생성 파라미터를 최적화해 향후 텍스트 예측 확률 증가.

#### 5. 실험 결과
- **요약**:
  - Quiet-STaR 모델은 CommonsenseQA와 GSM8K 데이터셋에서 기본 모델 대비 각각 10.9%, 5.0%의 성능 향상을 보였습니다.
  - 긴 추론을 사용할수록 더 나은 성능을 보였습니다.
  
#### 6. 결론
- **요약**: Quiet-STaR는 다양한 웹 텍스트에서 추론을 학습함으로써 언어 모델의 전반적인 추론 능력을 향상시킵니다.
  
---

### 전체 요약
Quiet-STaR는 언어 모델이 텍스트를 예측하기 전에 내부적으로 생각을 하도록 유도하는 방식으로, 기존 언어 모델의 성능을 획기적으로 향상시키는 혁신적인 방법론입니다. 병렬 추론 생성과 혼합 알고리즘을 사용함으로써 대규모 데이터셋에서 모델의 추론 능력을 효과적으로 발전시킵니다. 이를 통해 CommonsenseQA와 GSM8K 등 다양한 테스트 데이터셋에서 성능이 크게 개선되었습니다. Quiet-STaR의 이러한 접근법은 언어 모델이 인류의 언어 이해와 비슷한 수준의 추론 능력을 갖출 수 있도록 합니다.

## Similar Papers
- [Stream of Search (SoS): Learning to Search in Language](2404.03683.md)
- [Cognitively Inspired Energy-Based World Models](2406.08862.md)
- [Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought](2404.03414.md)
- [Prompt Sketching for Large Language Models](2311.04954.md)
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](2305.10601.md)
- [Prover-Verifier Games improve legibility of LLM outputs](2407.13692.md)
- [Sibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning](2407.10718.md)
- [From RAGs to rich parameters: Probing how language models utilize external knowledge over parametric information for factual queries](2406.12824.md)
- [Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models](2407.19914.md)
