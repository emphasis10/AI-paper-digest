# Hyper-Connections
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.19606.pdf](https://arxiv.org/pdf/2409.19606.pdf)

### 1. 섹션 요약 및 주요 기여
#### 1.1. Introduction
이 논문에서는 현재 신경망 아키텍처의 주요 요소인 잔여 연결을 대체할 수 있는 하이퍼 연결(hyper-connections)을 제안합니다. 하이퍼 연결은 깊이와 너비 연결을 통해 네트워크의 성능을 최적화하고, 거의 계산 및 매개변수 증가 없이 성능을 크게 향상시킵니다. 이 방법은 큰 언어 모델(LLM) 학습 과정에서 주로 실험되었으며, Vision 태스크에서도 효율성 향상을 입증했습니다.

#### 1.2. Method
하이퍼 연결은 정적(static)과 동적(dynamic) 하이퍼 연결로 나뉩니다.
- **정적 하이퍼 연결**(Static Hyper-Connections): 각 층의 입력 벡터를 복사하여 여러 층에 전달하는 방식입니다. 이로 인해 층 간의 정보 교환이 촉진되어 성능이 향상됩니다.
- **동적 하이퍼 연결**(Dynamic Hyper-Connections): 입력에 따라 연결 가중치를 동적으로 조정할 수 있습니다. 이는 네트워크가 입력에 따른 최적의 연결 강도를 학습할 수 있게 합니다.

#### 1.3. Why Hyper-Connections
잔여 연결의 주요 변형인 Pre-Norm과 Post-Norm을 비학습형 하이퍼 연결로 설명하며, 하이퍼 연결이 네트워크 층의 순차적, 병렬적 배치를 동적으로 최적화할 수 있게 해줍니다. 이로 인해 전통적인 잔여 연결의 한계를 극복할 수 있습니다.

#### 1.4. Results
실험 결과, 하이퍼 연결을 사용한 네트워크가 잔여 연결을 사용한 네트워크보다 더 빠르게 수렴하고 더 나은 성능을 보였습니다. 특히, 하이퍼 연결을 사용한 모델이 1B와 7B 매개변수를 가진 모델에서 상당한 성능 향상을 보였으며, 시각화 결과에서도 더 낮은 유사성을 보이며 각 층의 영향을 강화했습니다.

#### 1.5. Conclusion
하이퍼 연결은 잔여 연결의 한계를 넘어서는 효과적인 대안으로 입증되었습니다. 이 방법은 AI 문제 해결에 널리 적용될 수 있는 가능성을 보여줍니다.

### 2. 전체 요약
이 논문은 잔여 연결의 한계를 극복하고 신경망의 성능을 크게 향상시킬 수 있는 하이퍼 연결이라는 혁신적인 방법을 제안합니다. 하이퍼 연결은 정적 및 동적 방법으로 구현되며, 입력에 따라 네트워크의 연결 강도를 최적화할 수 있습니다. 실험 결과, 하이퍼 연결을 사용한 모델이 기존의 잔여 연결 모델에 비해 더 빠르고 효율적으로 학습하며, 여러 AI 문제에서 탁월한 성능을 보였습니다. 이로써 하이퍼 연결은 다양한 도메인에서 널리 적용될 수 있는 강력한 방법임을 입증했습니다.