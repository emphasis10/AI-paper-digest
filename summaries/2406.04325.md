# ShareGPT4Video: Improving Video Understanding and Generation with Better Captions
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.04325.pdf](https://arxiv.org/pdf/2406.04325.pdf)

### 섹션별 요약:

1. **소개**:
    최근 멀티모달 학습 분야에서 대형 언어 모델이 주도하는 발전이 이루어졌습니다. 특히, 이미지-텍스트 대화와 텍스트-이미지 생성 작업에서 큰 진전이 있었는데요, 이는 비디오 이해와 생성을 위한 중요한 기초를 마련했습니다. 그러나 현재 비디오와 짝지어 제공되는 캡션은 매우 간단하여 세밀한 비디오 이해 및 생성에 제한이 있습니다. 이런 문제를 해결하기 위해 고품질의 비디오 캡션 제작 방안이 필수적이며, 이 논문에서는 그러한 방안을 제안하고 있습니다.

2. **ShareGPT4Video 데이터셋**:
    고품질의 비디오-캡션 쌍 40,000개를 포함하는 데이터셋 ShareGPT4Video를 소개합니다. 이 데이터셋은 다양한 출처에서 비디오를 수집하고, 의미 기반 데이터 필터링 및 의미 인식 키프레임 추출 전략을 사용하여 비디오의 중복성을 줄였습니다. 이를 통해 고품질의 캡션을 생성하게 되었습니다.

3. **영상 처리**:
    DiffSW(차분 슬라이딩 윈도우 캡션 전략)를 소개합니다. 이 전략은 비디오 전체 프레임을 차분 설명 작업으로 변환하여 첫 프레임에 대한 상세 캡션을 생성하고, 시차를 두고 후속 프레임을 처리하여 프레임 간 변화를 중심으로 캡션을 작성합니다. 이를 통해 시간 순서의 정확성과 입력 프레임 수에 관계없는 일관된 캡션 품질을 유지할 수 있습니다.

4. **캡션 파이프라인**:
    DiffSW를 기반으로 한 ShareCaptionor-Video라는 고성능 비디오 캡션 툴을 개발했습니다. 이 툴은 고해상도 비디오에 대해 세밀하고 정밀한 캡션을 효율적으로 생성합니다. 이를 통해 4.8백만 개의 비디오 캡션 쌍을 생성하여 고품질 비디오 데이터셋을 확장할 수 있었습니다.

5. **실험**:
    비디오 이해와 생성 작업에서 우리의 데이터셋과 캡션 툴의 가치를 증명하기 위해 광범위한 실험을 수행했습니다. 우리의 모델은 현재의 최신 모델들보다 우수한 성능을 보였습니다. 특히, ShareGPT4Video-8B 모델은 여러 벤치마크에서 최고 성능을 기록했으며, 이는 고품질의 시간 정보 덕분입니다.

6. **제한 사항 및 사회적 영향**:
    고품질 비디오 캡션 생성의 한계와 현재 활용 가능한 오픈소스 LVLM의 부족함을 지적했습니다. 이러한 문제들은 고품질 캡션 데이터의 중요성을 강조하며, 이를 통해 더 나은 비디오 이해와 생성 모델을 개발할 수 있습니다.

### 전체 요약:

이 논문은 멀티모달 학습 분야의 최신 발전을 기반으로 하여 고품질의 비디오 캡션을 생성하기 위한 전략을 제안합니다. DiffSW라 불리는 차분 슬라이딩 윈도우 캡션 전략을 통해 시간적인 변화를 중심으로 안정적이고 효율적으로 비디오 캡션을 생성할 수 있습니다. 이 전략을 이용하여 ShareGPT4Video 데이터셋과 고성능 캡션 툴인 ShareCaptionor-Video를 개발하였으며, 이를 통해 다수의 비디오 이해 및 생성 작업에서 우수한 성과를 얻었습니다. 논문은 고품질 비디오 캡션의 중요성과 이를 활용한 더 나은 모델 개발의 가능성을 강조합니다.

논문에서 제안한 기술과 데이터셋은 비디오 이해 및 생성 기술의 발전에 중요한 자원이 될 것으로 기대됩니다. 이를 통해 더 나은 AI 시스템을 구축하고, 멀티모달 학습 분야의 새로운 가능성을 열어가는 데 기여할 수 있을 것입니다.