# LLMs Get Lost In Multi-Turn Conversation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2505.06120.pdf](https://arxiv.org/pdf/2505.06120.pdf)

### 1. 각 섹션의 중요 내용을 요약

#### 서론
현대의 대형 언어 모델(LLM)은 대화형 인터페이스로서 사용자와의 다중 회전을 통한 상호작용을 허용합니다. 하지만 많은 연구에서 대화를 에피소드처럼 평가하여 실제 인간 대화의 일반적인 모호함을 반영하지 못하는 경우가 많습니다. 이 논문은 다중 회전 대화 시뮬레이션 환경을 구축하여 이러한 간극을 메우고자 합니다.

#### 메트릭 선택
LLM은 텍스트 생성을 위한 확률적 과정을 사용하는데, 이는 대화 상태가 고정되었을 때 다양한 반응을 생성할 가능성을 제공합니다. 본 연구에서는 LLM이 여러 번의 시뮬레이션을 통해 상이한 점수를 획득하는데, 여기서 평균 성능(P), 지능(Aptitude, A90), unreliability(U90)라는 세 가지 메트릭을 정의하고자 합니다.

#### 다중 회전 상호작용에서의 성과 저하
다중 회전 대화에서는 성능 저하가 발생하는데, 이는 주로 모델의 비신뢰성(Unreliability)이 증가했기 때문입니다. Single-Turn 설정에서는 지능이 높은 모델이 더 신뢰할 수 있는 반면, Multi-Turn 설정에서는 모든 모델에서 비신뢰성이 높게 나타납니다.

#### 실험 결과
다중 회전 설정에서 모든 LLM은 높은 비신뢰성을 보이며 이는 LLM이 대화에서 길을 잃는 현상으로 이어집니다. 구체적인 요인은 모델이 너무 긴 응답을 생성하여 문제가 초기 단계에서 발생한다는 점입니다.

### 2. 전체 요약
이 논문은 다중 회전 대화에서의 LLM 성능 저하 문제를 연구하고, 언더스펙된 상호작용 시나리오에서 모델의 비신뢰성이 어떻게 증가하는지를 보여줍니다. 연구는 시뮬레이션 환경을 통해 상호작용 성능을 시험하고, 모델들의 응답이 영향 요인을 파악함으로써 대화 중에 길을 잃는 현상을 밝힙니다. 결과적으로, LLM 개발자들은 모델의 성능뿐 아니라 비신뢰성을 줄이는 데도 더욱 집중해야 함을 강조합니다.