# InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.15027.pdf](https://arxiv.org/pdf/2502.15027.pdf)

**1. 각 섹션 요약**

- **서론**  
  이 논문은 대형 멀티모달 모델(LMM)들이 인간의 피드백과 상호작용하여 어떻게 수행하는지를 탐구합니다. 기본적으로 LMM은 뛰어난 문제 해결 능력과 피드백을 통해 스스로 개선하는 능력이 필요하며, 이 논문은 후자에 중점을 둡니다.

- **관련 연구**  
  LMM의 상호작용 지능을 검증하기 위한 기존 기준들이 부족한 상황에서, 다양한 멀티모달 능력을 평가하는 최신 벤치마크의 필요성과 최신 연구들을 제시합니다.

- **InterFeedback 프레임워크 소개**  
  InterFeedback은 인간과 AI의 상호작용을 평가하기 위한 포괄적인 프레임워크로, 이를 통해 LMM이 피드백을 해석하고 문제를 해결하는 능력을 평가할 수 있습니다. 이를 통해 LMM의 성능을 향상시키기 위한 새로운 벤치마크, InterFeedback-Bench를 제안합니다.

- **실험 결과**  
  실험 결과를 통해 상호작용 프로세스가 대부분의 LMM의 성능을 향상시킬 수 있음을 발견했지만, 기존의 LMM은 피드백을 해석하고 통합하는 데 있어 다소 비효율적입니다. 고품질의 피드백이 필수적이며, 부적절한 피드백은 성능을 악화시킬 수 있습니다.

- **결론**  
  InterFeedback-Bench는 현재 LMM의 상호작용 지능을 평가하기 위한 최초의 해결책이며, LMM이 피드백을 통해 스스로 개선하는 방법을 탐구하는 중요한 첫 걸음을 내딛었습니다.

**2. 전체 요약**

논문은 대형 멀티모달 모델(LMM)의 상호작용 지능을 통해 문제 해결 능력을 개선하기 위한 새로운 프레임워크와 벤치마크를 소개합니다. InterFeedback 프레임워크는 다양한 멀티모달 데이터셋을 사용하여 LMM의 상호작용 성능을 측정하고 분석합니다. 실험 결과, 상호작용이 LMM의 성능을 향상시킬 수 있으나, 피드백 해석에 있어서 한계가 있음을 발견하였습니다. 이는 AI의 피드백 해석 능력을 개선하기 위한 향후 연구의 필요성을 시사합니다.