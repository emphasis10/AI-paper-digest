# RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.02545.pdf](https://arxiv.org/pdf/2408.02545.pdf)

### 섹션별 요약

#### 1. 소개 (Introduction)
대형 언어 모델(LLMs)은 AI 분야에서 다양한 작업을 수행할 수 있는 뛰어난 능력을 보여주고 있지만, 사실성 부족, 최신 정보에 접근할 수 없음 등 여러 한계를 가지고 있습니다. 이 논문은 이러한 한계를 극복하기 위해 검색 강화 생성(Retrieval-Augmented Generation, RAG)을 도입하는 RAG FOUNDRY 프레임워크를 소개합니다.

#### 2. 관련 작업 (Related Work)
RAG와 관련된 다양한 오픈 소스 도구와 연구를 검토합니다. 기존의 라이브러리(LlamaIndex, LangChain 등) 및 프레임워크(Hoshi 등)는 그리드 기반 접근법 등을 도입했지만, 종합적인 평가를 지원하지 않거나 훈련 기능이 미비한 경우가 많습니다. 이를 개선하기 위해 다양한 RAG 기술을 평가하고 실험할 수 있는 프레임워크가 필요합니다.

#### 3. 데이터 생성 및 처리 (Data Creation and Processing)
이 섹션에서는 RAG 지향의 데이터셋을 생성하고 이를 처리하는 모듈을 설명합니다. 데이터셋 로딩, 열(normalization), 정보 검색, 프롬프트 생성 등 여러 단계로 구성되며, 이를 통해 모델에 독립적인 형식으로 데이터를 저장할 수 있습니다. 이 모듈은 다양한 데이터셋을 동시에 처리하고, 단계별 캐싱을 통해 계산 효율성을 높입니다.

#### 4. 모델 및 평가 (Models and Evaluation)
Llama-35와 Phi-36 모델을 사용해 다양한 RAG 기술을 실험합니다. 평가 지표로는 정확한 일치(Exact Match), F1 점수, 신뢰성(Faithfulness), 관련성(Relevancy) 등이 포함됩니다. 평가 결과는 검색을 통해 문맥을 가져오면 성능이 향상됨을 보여주며, 여러 베이스라인 모델과의 비교를 통해 RAG 기술의 유용성을 증명합니다.

#### 5. 결론 (Conclusion)
RAG FOUNDRY는 RAG 적용을 위해 LLM을 향상시키는 오픈 소스 라이브러리입니다. 이 논문은 세 가지 지식 집약적 Q&A 데이터셋에 대해 다양한 모델과 RAG 설정을 통해 RAG 기술의 유용성을 입증하며, 여러 평가 지표를 사용해 평가의 필요성을 강조합니다.

### 전체 요약
이 논문은 LLM의 한계를 극복하기 위해 검색 강화 생성(RAG) 기술을 도입하고, 이를 실험하고 평가하기 위한 RAG FOUNDRY 프레임워크를 소개합니다. RAG FOUNDRY는 데이터 생성 및 처리, 모델 훈련, 추론, 평가의 네 가지 주요 모듈로 구성되어 있으며, 다양한 RAG 기술을 좀 더 체계적이고 종합적으로 실험할 수 있습니다. 이 프레임워크를 통해 여러 대형 언어 모델을 실험하여 RAG 기술의 효과를 보여주고, 앞으로의 연구와 실무에 중요한 토대를 제공합니다.

## Similar Papers
- [Exploring Advanced Large Language Models with LLMsuite](2407.12036.md)
- [Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts](2405.19893.md)
- [LLoCO: Learning Long Contexts Offline](2404.07979.md)
- [Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting](2407.08223.md)
- [Finch: Prompt-guided Key-Value Cache Compression](2408.00167.md)
- [Time Sensitive Knowledge Editing through Efficient Finetuning](2406.04496.md)
- [Luna: An Evaluation Foundation Model to Catch Language Model Hallucinations with High Accuracy and Low Cost](2406.00975.md)
- [Searching for Best Practices in Retrieval-Augmented Generation](2407.01219.md)
- [Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost](2407.19825.md)
