# The Prompt Report: A Systematic Survey of Prompting Techniques
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.06608.pdf](https://arxiv.org/pdf/2406.06608.pdf)

### 1. 섹션별 요약 및 주 기여점

#### 1. 서론 (Introduction)
이 논문은 프롬프트 엔지니어링 및 다양한 프롬프트 기법들의 메타 분석을 통해, AI와 머신러닝 분야에서의 프롬프트의 발전과 활용을 체계적으로 이해하려는 시도를 다루고 있습니다. 프롬프트란 무엇인지, 관련 용어의 정의, 그리고 프롬프트의 역사에 대해 설명합니다.

#### 2. 메타 분석 (Meta-Analysis of Prompting)
이 섹션에서는 프롬프트 기법들의 체계적인 리뷰 과정을 설명하고, 텍스트 기반 프롬프트 기법들, 그리고 프롬프트 엔지니어링 관련 내용을 다룹니다. 주요 기법으로는 인-컨텍스트 학습(In-Context Learning), 제로샷 학습(Zero-Shot Learning), 생각 생성(Thought Generation), 분해(Decomposition), 앙상블(Ensembling), 자기 비판(Self-Criticism) 등이 있습니다. 

#### 3. 프롬프트 엔지니어링 (Prompt Engineering)
프롬프트 엔지니어링은 프롬프트를 지속적으로 수정하고 개발해 성능을 향상시키는 과정을 말합니다. 이는 디스크리트 프롬프트와 클로즈 프롬프트의 차이, 하드 프롬프트와 소프트 프롬프트의 구분 등을 포함합니다. 또한, 다양한 프롬프트 엔지니어링 기법과 답변 엔지니어링(Answer Engineering)에 대해서도 설명합니다.

#### 4. 다양한 유형의 에이전트 (Agents)
여기서는 도구 사용 에이전트, 코드 생성 에이전트, 관찰 기반 에이전트, 평생 학습 에이전트 등 다양한 에이전트 유형들에 대해 다룹니다. 대표적인 예로는 CRITIC, MRKL 시스템, PAL, ToRA, ReAct 등이 있습니다.

#### 5. 얼라인먼트 (Alignment)
모델의 출력이 사용자의 필요에 맞도록 조절하는 것이 중요하며, 이를 위해 다양한 프롬프트 기반 얼라인먼트 문제와 해결 방안을 제시합니다. 프롬프트 민감도, 바이어스, 질문 명확화, 시너지 등을 설명합니다.

#### 6. 평가 및 결론 (Evaluation and Conclusions)
논문의 결론 부분에서는 프롬프트 기반 기법들의 현재 상태 및 미래 방향성을 논의합니다. 이 연구는 프롬프트의 다양한 정의와 기법들을 체계적으로 정리하여 새로운 기법들이 등장할 때 쉽게 포함될 수 있는 기반을 제공합니다.

### 주요 기여점 및 혁신요소
1. **프롬프트의 체계적 이해**: 프롬프트의 정의와 관련 용어들을 체계적으로 정리하여, 혼란을 줄이고 이해를 돕습니다.
2. **메타 분석**: 다양한 프롬프트 기법들을 메타 분석하여, 이들의 장단점과 활용 사례들을 체계적으로 분류합니다.
3. **프롬프트 엔지니어링**: 다양한 프롬프트 엔지니어링 기법들을 제시하고, 이를 개선하는 방법을 설명합니다.
4. **에이전트의 다양성**: 도구 사용, 코드 생성, 관찰 기반, 평생 학습 등 다양한 에이전트 유형들을 소개하고, 각 유형의 예와 특징을 설명합니다.
5. **얼라인먼트 문제 해결**: 모델의 출력이 사용자 필요에 맞도록 조정하는 다양한 방법론을 제시하며, 민감도와 바이어스 등의 문제를 다룹니다.

### 2. 종합 요약
이 논문은 AI와 머신러닝 분야에서 프롬프트 엔지니어링 및 다양한 프롬프트 기법들을 체계적으로 정리하고 분석한 연구입니다. 프롬프트의 정의와 역사, 텍스트 기반 프롬프트 기법들, 프롬프트 엔지니어링 방법론, 다양한 에이전트 유형, 모델 얼라인먼트 문제 및 해결 방안 등을 포괄적으로 다룹니다. 프롬프트와 관련된 용어들을 체계적으로 정리하고, 다양한 프롬프트 기법들을 메타 분석하여 프롬프트 엔지니어링의 현재 상태와 미래 방향성을 제시합니다. 이 연구는 프롬프트 기법들의 발전을 돕기 위한 중요한 기초 자료를 제공합니다.

## Similar Papers
- [Gemini vs GPT-4V: A Preliminary Comparison and Combination of Vision-Language Models Through Qualitative Cases](2312.15011.md)
- [A Survey on Efficient Inference for Large Language Models](2404.14294.md)
- [Leveraging Large Language Models for Multimodal Search](2404.15790.md)
- [Privacy Preserving Prompt Engineering: A Survey](2404.06001.md)
- [A Primer on the Inner Workings of Transformer-based Language Models](2405.00208.md)
- [Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost](2407.19825.md)
- [LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model](2404.01331.md)
- [GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models](2407.02936.md)
- [$\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient Finetuning](2405.17258.md)
