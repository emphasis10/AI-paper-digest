# RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.03204.pdf](https://arxiv.org/pdf/2404.03204.pdf)

#### 1. 소개
RALL-E는 대형 언어 모델(LLM)을 활용한 텍스트-음성 합성(TTS)에서 발생하는 안정성 문제를 해결하기 위한 새로운 방법입니다. 기존 LLM 기반 TTS는 발음 오류, 단어 누락, 반복 등의 문제를 자주 겪는데, 이는 예측의 자기회귀적 스타일 때문입니다. RALL-E는 이러한 문제를 해결하기 위해 체인-오브-생각(CoT) 프롬프트를 도입하여 작업을 여러 단계로 나누어 안정성을 향상시킵니다.

#### 2. 관련 연구
LLM 기반 TTS는 최근 몇 년간 많은 발전을 이루었습니다. 특히, VALL-E와 같은 모델은 수많은 음성 데이터를 활용해 뛰어난 성능을 보였지만, 여전히 높은 단어 오류율(WER)과 불안정한 음조 문제를 가지고 있습니다. 기존 연구들은 주로 LLM의 학습 능력을 활용해 이 문제를 해결하려 했습니다.

#### 3. RALL-E
RALL-E의 핵심 아이디어는 CoT 프롬프트를 통해 중간 결과를 생성하여 음성 토큰 생성을 안정화하고, 이를 통해 LLM 기반 TTS의 강건성을 높이는 것입니다. 이를 위해, RALL-E는 먼저 입력 텍스트의 음소 수준에서 음조(pitch)와 지속 시간(duration)을 예측하고, 이를 중간 조건으로 사용하여 음성 토큰을 예측합니다.

- **VALL-E 소개**: VALL-E는 두 개의 트랜스포머를 사용하여 텍스트로부터 음성 토큰을 예측하는 LLM 기반 TTS 시스템입니다.
- **음조 및 지속 시간 예측**: RALL-E는 음조와 지속 시간을 CoT 프롬프트로 사용하여 음성 토큰을 예측합니다.
- **지속 시간 기반 마스킹**: 지속 시간 정보를 사용하여 현재 예측 중인 음성 토큰과 관련 없는 음소 및 음조 토큰을 마스킹하여 모델이 올바른 음소와 음조에 집중하도록 합니다.

#### 4. 실험 결과
RALL-E는 다양한 객관적 및 주관적 평가를 통해 VALL-E보다 우수한 성능을 보였습니다.

- **객관적 평가**: WER(단어 오류율)에서 RALL-E는 VALL-E 대비 55% 상대적 개선을 보였으며, 재랭크된 WER(WER-R)에서도 41% 개선되었습니다.
- **주관적 평가**: CMOS(비교 평균 의견 점수)와 SMOS(유사성 평균 의견 점수)에서 RALL-E는 VALL-E보다 더 높은 점수를 기록했습니다.
- **어려운 문장 평가**: RALL-E는 VALL-E보다 어려운 문장에서 오류율을 68%에서 4%로 대폭 감소시켰습니다.

#### 5. 결론
RALL-E는 CoT 프롬프트와 지속 시간 기반 마스킹을 활용하여 LLM 기반 TTS의 강건성을 크게 향상시킵니다. 이를 통해 발음 오류, 단어 누락, 반복 등의 문제를 효과적으로 해결할 수 있습니다.

### 전체 요약
RALL-E는 텍스트-음성 합성(TTS)에서 발생하는 안정성 문제를 해결하기 위해 체인-오브-생각(CoT) 프롬프트와 지속 시간 기반 마스킹을 도입한 혁신적인 방법입니다. 이를 통해 발음 오류, 단어 누락, 반복 등의 문제를 크게 개선할 수 있습니다. 종합적인 평가 결과, RALL-E는 기존의 VALL-E 대비 우수한 성능을 보였으며, 특히 어려운 문장에서의 오류율을 크게 감소시켰습니다. RALL-E의 이러한 접근 방식은 LLM 기반 TTS의 새로운 가능성을 열어줄 것으로 기대됩니다.