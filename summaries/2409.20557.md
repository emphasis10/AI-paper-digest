# Propose, Assess, Search: Harnessing LLMs for Goal-Oriented Planning in Instructional Videos
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.20557.pdf](https://arxiv.org/pdf/2409.20557.pdf)

1. 각 섹션의 중요한 내용 요약:

- **소개 (Introduction)**: 논문은 목표 지향적 계획을 다루며 이는 주어진 목표를 달성하기 위한 행동 계획을 예측하는 것을 의미합니다. 비디오 데이터로부터 이러한 정책을 학습하는 것은 상당한 도전 과제를 제시합니다. 이전 연구에서는 강력한 지도학습으로부터 파생된 절차적 지식이 훈련 데이터에 대한 큰 편향을 보이는 공통의 제한점을 가지고 있습니다.

- **VidAssist 소개 (Introduction of VidAssist)**: VidAssist는 이전 비디오의 시각 학습과 목표에 대한 언어적 기술을 소크라테스 방식으로 처리하여 시각 관찰과 목표를 평가하고 예측하는 통합 프레임워크입니다. 이는 계획의 각 단계에서 최적의 행동 계획을 생성하기 위한 검색 기반 전략을 제공합니다.

- **알고리즘 (Algorithm)**: VidAssist는 제안, 평가 및 검색의 세 가지 주요 과정을 포함합니다. 먼저, LLM을 통해 예상 가능한 다음 행동을 제안(프로포즈)하고, 이를 다양한 가치 함수로 평가하며, 최종적으로 검색 알고리즘을 통해 최적의 행동 계획을 검색합니다.

- **결과 (Results)**: VidAssist는 COIN 및 CrossTask 데이터셋에서 이전의 지도학습 방법을 초월하는 성능을 보여주었습니다. 제안한 LLM은 다른 기법들과 비교하여 장기 계획에서 뛰어난 성과를 올렸습니다.

- **결론 (Conclusion)**: VidAssist는 속도 기반 탐색(public 시그니쳐 인식) 및 검색 기반 기술을 통합하여 장기 계획에서 뛰어난 결과를 달성했습니다. 향후 연구는 더 복잡한 작업과 장시간 비디오 입력에 프레임워크를 확장할 예정입니다.

2. 전체 요약:

이 논문은 AI와 머신러닝에서 목표 지향적 계획을 다루고 있으며, 종합적인 전략으로 VidAssist라는 프레임워크를 제시합니다. VidAssist는 대량의 데이터를 요구하지 않으면서도 다양한 절차적 과제를 해결하기 위해 대형 언어 모델(LLM)을 활용하여 목표 지향적 행동 계획을 수행합니다. 제안된 모델은 영상을 텍스트로 변환하여 계획 단계를 예측한 후 평가하고, 검색 기반 알고리즘을 사용해 최적의 행동 시퀀스를 산출합니다. VidAssist는 제로/소숏 학습 환경에서도 강력한 성능을 보여주며, 이는 현존하는 지도학습 방법들을 능가합니다. 이러한 기술적 혁신은 사람을 돕는 지능형 시스템의 발전에 기여할 것입니다.