# rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.04519.pdf](https://arxiv.org/pdf/2501.04519.pdf)

1. 논문의 각 섹션 요약:

- **서론(Introduction):** rStar-Math는 작은 언어 모델(SLM)들이 OpenAI의 o1을 능가해 수학적 추론을 수행할 수 있음을 보여줍니다. 이는 MCTS(Monte Carlo Tree Search)라는 탐색 방법을 사용하여 깊은 사고를 통해 가능해집니다.

- **관련 연구(Related Works):** 수학 데이터 합성의 발전은 고품질의 Chain-of-Thought(CoT) 데이터 수집에 크게 의존합니다. 대부분의 선두적인 접근법은 GPT와 같은 프론티어 모델을 사용해 합성된 것이며, 이는 선생 LLM의 능력에 한정될 수밖에 없습니다.

- **방법론(Methodology):** rStar-Math는 MCTS를 통해 정책 모델 및 보상 모델을 통합하여 System 2 스타일의 깊은 사고를 구현합니다. 이 방법은 복잡한 수학 문제를 간단한 단일 단계 생성으로 나누어 정책 모델에 주어지는 부담을 줄입니다.

- **결과(Experiments):** rStar-Math는 다양한 수학 benchmark에서 경쟁력을 입증하였습니다. 특히 Olympiad 수준의 과제를 해결하며 OpenAI o1 모델을 초과하였습니다.

- **결론(Conclusion):** rStar-Math는 자기 진화형 System 2 스타일의 깊은 사고 방법으로, 작은 LLM의 수학적 추론 능력을 크게 향상시킵니다. 미래 연구에서는 더 도전적인 수학 문제를 추가하여 개선을 추구할 예정입니다.

2. 논문의 전체 요약:

rStar-Math는 작은 언어 모델을 사용하여 수학 추론을 수행하는 혁신적인 접근법입니다. 기존의 큰 모델 의존을 벗어나, MCTS를 활용하여 자체적으로 데이터를 생성하고 이를 통해 더욱 향상된 성능을 보여줍니다. 특히 Olympiad 수준의 어려운 수학 문제에서는 OpenAI o1 모델을 초과하는 능력을 발휘하였습니다. 이 연구는 작은 모델도 충분한 깊은 사고 절차와 고품질 데이터 생성 방법을 통해 뛰어난 성능을 낼 수 있음을 증명합니다. 이는 수학적 추론 분야에 있어서 중요한 공헌이며, 앞으로 이러한 방법론의 발전은 다양한 응용 분야에서 강화 학습 모델의 가능성을 확장시킬 것으로 기대됩니다.