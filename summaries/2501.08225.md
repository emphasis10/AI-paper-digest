# FramePainter: Endowing Interactive Image Editing with Video Diffusion Priors
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.08225.pdf](https://arxiv.org/pdf/2501.08225.pdf)

**1. 섹션별 요약**

**서론**  
이 논문에서는 상호작용 이미지 편집을 이미지-비디오 생성 문제로 재구성하고, FramePainter라는 새로운 접근법을 제안합니다. 기존의 텍스트-이미지 확산 모델에 비해 트레이닝 코스트가 낮고, 이미지 간 일관성을 유지하는 것이 장점입니다.

**기술적 배경**  
기존 방법들은 이미지-이미지 생성 작업으로 접근해 대규모 데이터와 추가 참조 인코더가 필요했습니다. 본 연구는 이미지가 첫 프레임 역할을 하며, 편집 신호가 비디오 생성에 영향을 미치는 새로운 방식을 도입했습니다.

**제안 방법: FramePainter**  
FramePainter는 비디오 확산 모델인 Stable Video Diffusion을 활용해 트레이닝 코스트를 낮추고, 강력한 확산 모델의 사전 정보를 사용합니다. 주목할 점은 ‘Matching Attention’ 기술을 사용하여 소스 및 편집된 이미지 간 밀집된 대응을 촉진한 것입니다. 이로써 현재 방법들보다 덜 복잡한 모델 구조를 갖게 되었습니다.

**실험 및 결과**  
정성적 및 정량적 결과에 따르면, FramePainter는 더 적은 트레이닝 데이터로도 높은 편집 신뢰성과 시각적 일관성을 제공합니다. 사용자 연구 결과에서도 강력한 편집 기술과 고품질 이미지 생성 능력을 입증했습니다.

**결론**  
매칭 어텐션을 통해 편집 결과의 시각적 일관성을 크게 개선하고, 숙련된 비디오 생성 모델의 사전 정보를 활용하여 더 저렴한 비용으로 고품질 편집을 달성합니다.

**주요 기여 및 혁신적인 부분**  
- 인터랙티브 이미지 편집을 위해 비디오 생성 모델을 사용한 새로운 아키텍처.
- 매칭 어텐션을 통한 매우 디테일한 시각적 표현 향상.
- 실제 비디오에서 발견되지 않는 시나리오에서도 뛰어난 일반화 성능.

**2. 전체 요약**

이 논문은 상호작용 이미지 편집의 새로운 패러다임을 제시하며, FramePainter라는 모델로 대화형 편집의 복잡성을 감소시키고 정확성을 높였습니다. 이미지에서 영상을 생성하는 프로세스를 통해 이미지 편집의 효과를 더 자연스럽고 정밀하게 만들었으며, 비디오 확산 모델의 강력한 프라이어를 활용하여 더 적은 데이터로도 고품질의 결과를 얻었습니다. 또한 제안된 매칭 어텐션 기술은 소스와 편집된 이미지 사이의 일관성을 크게 향상시켜 복잡한 편집 작업에서도 높은 품질의 이미지를 생성했습니다.