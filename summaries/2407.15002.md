# GET-Zero: Graph Embodiment Transformer for Zero-shot Embodiment Generalization
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.15002.pdf](https://arxiv.org/pdf/2407.15002.pdf)

### 1. 각 섹션의 중요한 내용 요약 

#### Introduction (소개)
본 논문은 GET-Zero라 불리는 새로운 인공지능 모델을 소개합니다. 이 모델은 로봇의 하드웨어 변경에 대해 재훈련 없이 즉시 적응할 수 있는 능력을 가집니다. 이를 위해 Graph Embodiment Transformer(GET)라는 트랜스포머 모델을 사용합니다. 이 모델은 로봇의 그래프 연결성을 학습된 구조적 편향으로 활용하여 새로운 하드웨어 구성에 즉각 적응할 수 있습니다.

#### Related Work (관련 연구)
최근 연구들은 로봇의 하드웨어 구성에 따라 로봇 제어 정책을 조정하는 다양한 방법들을 탐구해왔습니다. 그러나 기존 모델들은 그래프 구조의 변화에 잘 적응하지 못하는 단점이 있었습니다. 본 논문의 GET-Zero는 이러한 한계를 극복하기 위해 설계되었습니다.

#### Method: Graph Embodiment Transformer (방법: 그래프 임베디먼트 트랜스포머)
GET 알아 내기 위해 3가지 주요 구성 요소를 도입했습니다.
- **Graph Embodiment Transformer (GET):** 로봇의 각 관절을 별도 토큰으로 인코딩하고, 그래프 연결성을 트랜스포머 주의 메커니즘에 구조적 편향으로 사용합니다.
- **Embodiment-Aware Distillation (EA):** 각 구성에 특화된 전문가의 시범 데이터를 수집하고 이를 기반으로 GET 모델을 훈련합니다.
- **Self Modeling Loss (SML):** 모델의 각 관절 위치를 예측하는 추가적인 자기모델링 손실을 도입하여 그래프의 구조를 더 잘 이해하고, 이에 따라 올바른 행동을 추론하도록 합니다.

#### Case Study: In-hand Object Rotation (사례 연구: 손안의 물체 회전)
손안에서 물체를 회전시키는 작업을 통해 GET-Zero의 성능을 평가했습니다. 여기에는 여러 구성의 로봇 손을 사용하여 다양한 하드웨어 변경 사항에 대해 모델이 어떻게 일반화되는지 분석했습니다. 총 44개의 하드웨어 구성을 만들고, 각 구성에 대해 심층 강화학습을 통해 전문가 정책을 훈련한 후, 이를 GET-Zero 모델에 통합하였습니다.

#### Experiments (실험)
실험 결과, GET-Zero는 다양한 하드웨어 구성에 대해 기존 방법보다 뛰어난 성능을 보였습니다. 특히 훈련에 사용되지 않은 새로운 구성에 대해서도 높은 정확도로 작업을 수행할 수 있었습니다. 또한 그래프 인코딩과 자기모델링 손실이 성능 향상에 크게 기여했습니다.

#### Real-world Evaluation (실세계 평가)
실험실 환경 외 실제 환경에서도 GET-Zero의 성능을 평가했습니다. 실세계 평가에서도 여전히 높은 성능을 보여주었으며, 일부 구성에서는 시뮬레이션보다 더 나은 결과를 얻었습니다.

#### Limitations (한계)
그러나 GET-Zero는 특정 로봇 손 구성에 맞춰 진화된 모델이기 때문에 다른 구성의 로봇 손에는 성능이 저하될 가능성이 높습니다. 또한 손가락의 형태나 마찰 특성 등 다양한 요소를 명시적으로 인코딩하지 않았기 때문에, 이러한 요소가 중요한 작업에서는 추가 연구가 필요합니다.

### 2. 전반적인 요약

이 논문은 GET-Zero라는 새로운 모델을 소개하며, 이는 로봇의 하드웨어 변경에 대해 재훈련 없이도 즉시 적응할 수 있는 능력을 가집니다. GET-Zero는 트랜스포머 아키텍처를 기반으로 하며, 로봇의 그래프 구조를 학습된 편향으로 활용하여 다양한 하드웨어 구성에 대해 효율적으로 제어할 수 있습니다. 본 연구는 손안의 물체 회전 작업을 통해 다양한 로봇 손 구성에 대해 모델의 성능을 검증했으며, 기존 방법들보다 뛰어난 성능을 보여주었습니다. 다만, 특정 구성에 맞춰진 모델이기 때문에 다른 로봇 손 구성에 적용하려면 추가 연구가 필요합니다.

## Similar Papers
- [Learning to Manipulate Anywhere: A Visual Generalizable Framework For Reinforcement Learning](2407.15815.md)
- [Lessons from Learning to Spin "Pens"](2407.18902.md)
- [Make-An-Agent: A Generalizable Policy Network Generator with Behavior-Prompted Diffusion](2407.10973.md)
- [Octo: An Open-Source Generalist Robot Policy](2405.12213.md)
- [Ag2Manip: Learning Novel Manipulation Skills with Agent-Agnostic Visual and Action Representations](2404.17521.md)
- [Grasping Diverse Objects with Simulated Humanoids](2407.11385.md)
- [MotionBooth: Motion-Aware Customized Text-to-Video Generation](2406.17758.md)
- [Controlling Space and Time with Diffusion Models](2407.07860.md)
- [Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics](2408.04631.md)
