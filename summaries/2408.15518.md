# Dolphin: Long Context as a New Modality for Energy-Efficient On-Device Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.15518.pdf](https://arxiv.org/pdf/2408.15518.pdf)

### 1. 섹션별 요약과 설명

#### Introduction (소개)
AI 및 머신 러닝 모델이 점점 더 많이 사용되면서, 특히 모바일 디바이스에서 큰 언어 모델(LLM)의 에너지를 효율적으로 처리하는 것이 중요해졌습니다. "Dolphin" 모델은 이러한 긴 문맥을 효율적으로 처리하기 위해 고안된 디코더-디코더 아키텍처를 소개합니다. 이 모델은 작은 0.5B 파라미터 디코더를 사용해 긴 문맥 정보를 메모리 임베딩으로 증류하고, 더 큰 7B 파라미터 디코더를 통해 주 질의를 처리합니다. 이는 에너지 효율성을 10배 향상하고, 지연 시간을 5배 줄이는 성과를 나타냅니다.

#### Related Works (관련 작업)
이 섹션에서는 문맥 길이 문제를 해결하기 위한 기존의 연구와 방법들을 다룹니다. 주요 방법으로는 프롬프트 압축, 멀티모달 모델, 온 디바이스 모델 배포 등의 기술이 포함됩니다. 다양한 연구를 통해 문맥 길이를 줄이고 계산 비용을 절감하려는 시도가 이루어졌습니다.

#### Methodology (방법론)
새로운 디코더-디코더 아키텍처를 상세히 설명합니다. Dolphin 모델은 긴 문맥을 새로운 모달리티로 간주하며, 두 개의 디코더를 사용합니다. 작은 디코더(0.5B 파라미터)는 긴 문맥 정보를 처리하고, 큰 디코더(7B 파라미터)는 주 질의를 처리합니다. 이 과정에서 프로젝트를 이용해 임베딩 정보를 변환합니다.

#### Long Context as a Novel Modality (긴 문맥을 새 모달리티로)
Dolphin 모델의 핵심 기술 중 하나는 긴 문맥을 새로운 모달리티로 간주하는 것입니다. 이를 통해 효율적으로 긴 문맥을 처리할 수 있습니다. 이 섹션에서는 모델의 아키텍처를 상세히 설명합니다.

#### Conclusion (결론)
Dolphin 모델의 주요 성과와 그 중요성을 요약합니다. 이 모델은 에너지 효율성을 크게 향상시키고, 긴 문맥을 처리하면서도 정확도를 높게 유지합니다. 이는 모바일 컴퓨팅, IoT, 웨어러블 기술 등의 다양한 응용 분야에 중요한 영향을 미칠 것입니다.

### 2. 전체 요약

"Dolphin" 모델은 긴 문맥을 효율적으로 처리하기 위해 고안된 새로운 디코더-디코더 아키텍처입니다. 작은 0.5B 파라미터 디코더를 통해 문맥 정보를 축소하고, 7B 파라미터 디코더를 통해 주 질의를 처리하는 방법을 사용합니다. 이 혁신적인 접근법은 에너지 효율성을 10배 향상시키고 지연 시간을 5배 줄입니다. 다양한 실험 결과, 이 모델은 문맥 길이를 줄이더라도 높은 정확도를 유지하며, 모바일 컴퓨팅, IoT, 웨어러블 기술 등 다양한 응용 분야에서 활용될 수 있습니다력하고 지적이며, 다양한 연구를 통해 문맥 길이를 줄이려는 시도가 적극적으로 이루어지고 있습니다. Dolphin 모델은 이러한 접근법들의 한계를 극복하며, 긴 문맥을 새로운 모달리티로 처리함으로써 에너지 효율성과 성능을 크게 향상시킵니다. 이런 점에서 Dolphin 모델은 AI 기술 발전에 중요한 기여를 하고 있습니다.