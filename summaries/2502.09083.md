# Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.09083.pdf](https://arxiv.org/pdf/2502.09083.pdf)

1. 각 섹션의 요약 및 논문의 주요 기여와 혁신적인 부분:

- 도입부: 논문은 최근 온라인 미디어의 대중화와 생성 AI의 발달로 팩트 체킹의 필요성이 대두되고 있다고 설명합니다. 팩트 체킹 조직들은 늘어나는 허위정보를 검증하기 위해 AI 기반 도구 개발이 필요하며, 이러한 도구가 어떻게 팩트 체커의 작업 흐름에 통합될 수 있는지를 조사합니다.

- 연구 방법론: 반구조화된 인터뷰를 통해 팩트체킹 전문가들의 작업 방식, 자동화된 도구 사용 방식, 설명 필요성 등을 파악하였습니다. 주어진 데이터를 통해 팩트체크의 각 단계에서 AI 도구가 어떻게 사용되며, 설명력이 어떻게 요구되는지 분석합니다.

- 자동화된 팩트체킹의 현황: AI 시스템이 인간의 논리와 완전히 일치하지 않음을 지적하며, 이러한 간극을 메우기 위한 인간 중심 접근의 필요성을 강조합니다.

- 설명 가능한 AI의 필요성: 팩트체크의 자동화에서 설명의 중요성에 대해 다루며, 시스템이 결과를 추론한 과정에 대한 설명을 요구하는 팩트체커들의 요구사항을 강조합니다.

- 연구 결과: 자동화된 팩트체킹 시스템이 팩트체커의 작업 과정과 충분히 연결되지 않음을 밝혔고, AI 도구의 설명력이 불충분하다고 판단됩니다. 이에 대응하여, 인간의 맥락에 맞춘 설명력 있는 도구 개발의 필요성을 제안합니다.

2. 전체 요약:

이 논문은 허위정보 문제의 심각성과 이를 해결하기 위한 자동화된 팩트체킹 시스템의 필요성을 강조합니다. 이를 위해 인간 중심의 접근법을 강조하며, AI 시스템이 어떻게 설명력을 갖춰야 팩트체커의 작업방식에 통합될 수 있는지 분석합니다. 팩트체커들이 필요로 하는 설명력의 기준을 조사하고, 현재의 자동화 시스템이 이러한 필요성에 부합하지 못함을 지적하며, 설명 가능한 AI 시스템의 개발 방향을 제안합니다.