# Introducing v0.5 of the AI Safety Benchmark from MLCommons
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.12241.pdf](https://arxiv.org/pdf/2404.12241.pdf)

종합적인 요약:
이 논문은 MLCommons AI 안전성 워킹 그룹(v0.5)이 개발한 AI 안전성 벤치마크를 소개하고 있습니다. 이 벤치마크는 특히 챗봇 언어 모델의 안전성 리스크를 평가하기 위해 설계되었습니다. 벤치마크는 하나의 사용 사례(영어로 일반 목적의 어시스턴트와 대화하는 성인)와 한정된 사용자 유형(일반 사용자, 악의적 사용자, 취약 사용자)을 다루며, 13개의 위험 범주 중 7개를 테스트 합니다. 최종 목표는 2024년 말까지 AI 안전성 벤치마크 v1.0을 출시하는 것입니다.

주요 내용 요약:
1. 도입부: AI 안전성 워킹 그룹은 챗봇 언어 모델의 안전성을 평가하기 위해 벤치마크를 만들었으며, 이를 통해 AI 시스템의 안전성을 개선하고자 합니다.

2. 벤치마크의 범위 및 사양: 테스트 대상 시스템(SUT)은 일반 목적의 AI 챗 시스템이며, 사용 사례, 유형, 언어, 사용자 유형 및 테스트 아이템을 포함합니다.

3. 위험 범주의 분류: 13개의 위험 범주가 정의되어 있으며, 그 중 7개 범주에 대해 테스트가 수행됩니다. 이 범주들은 개인 및 사회적 리스크가 높은 활동들을 포함합니다.

4. 테스트 아이템: 각 위험 범주에 대해 고유한 테스트 세트가 있으며, 총 43,090개의 테스트 아이템이 포함되어 있습니다.

5. 평가 시스템: 벤치마크에 따라 AI 시스템을 평가하는 시스템이 개발되었으며, 이는 오픈 소스 플랫폼과 다운로드 가능한 도구를 통해 사용할 수 있습니다.

6. 예시 평가 보고서: 여러 개의 공개된 챗봇 언어 모델을 벤치마크하여 평가하고 모든 모델이 익명화되어 있습니다.

이 논문은 AI 안전성을 평가하고 개선하기 위한 새로운 방법론을 제시하며, 이는 향후 AI 시스템의 신뢰성과 효율성을 높이는 데 기여할 것입니다.