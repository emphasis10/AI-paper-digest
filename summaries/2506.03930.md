# VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2506.03930.pdf](https://arxiv.org/pdf/2506.03930.pdf)

1. **섹션 요약**

   - **서론:** 대규모 언어 모델(LLM)이 일반적인 코드 생성에 대해 발전해 왔지만, 데이터 분석에서 유효하고 의미 있는 시각화 코드 생성을 잘 수행하지 못하고 있습니다. 이는 시각화를 위한 코드 생성이 자연어, 데이터 구조, 시각 출력이라는 세 가지 양식에 걸쳐 매핑을 요구하기 때문입니다.

   - **데이터셋 구성:** VisCode-200K는 파이썬 기반의 시각화와 피드백 중심의 코드 수정에 대한 명령 조정 데이터셋으로, 다양한 플롯 라이브러리를 지원하고 반복적인 수정이 가능하도록 설계되었습니다.

   - **모델 분석:** VisCoder 모델은 자체 디버그 프로토콜을 통해 실행과 시각 점수 측면에서 강력한 성능을 보이며, 특히 복잡한 시각화 구조가 포함된 Plotly 및 복잡한 해결 과정을 거치는 환경에서 두드러진 성과를 나타냅니다.

   - **주요 기여:** VisCoder는 도메인에 특화된 명령 조정이 시각화 코드 생성 모델의 성능을 향상시킴을 보여주며, 향후 확장 가능성이 크다는 점에서 강력한 기반이 됩니다.

2. **전체 요약**

   이 논문은 시각화 작업에서 대규모 언어 모델의 성능 개선을 목표로 하는 연구로, VisCoder라는 새로운 모델을 제안합니다. 이 모델은 파이썬 기반 시각화 코드 생성을 돕는 대규모 데이터셋 VisCode-200K로 훈련되어, 복잡한 시각화 구조에서도 높은 실행 성공률과 시각적 정합성을 자랑합니다. 또한, 오류 발생 시 자체 디버깅을 통해 문제를 해결하는 능력을 보유하고 있어, 도메인 특화 조정이 이러한 모델의 성능을 극대화할 수 있음을 시사합니다.