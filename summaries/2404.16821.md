# How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.16821.pdf](https://arxiv.org/pdf/2404.16821.pdf)

이 논문에서는 새로운 개방형 다중 모달 대규모 언어 모델인 InternVL 1.5를 소개합니다. 이 모델은 기존의 개방형 소스 모델과 상업용 모델 간의 성능 격차를 줄이는 데 중점을 두고 있습니다. 다음은 각 섹션의 주요 내용 요약입니다.

1. **서론**:
   - 다중 모달 대규모 언어 모델은 시각적 및 언어적 정보 간의 간격을 메우는 데 중요한 역할을 하며, 상업적 모델들은 주로 영어 데이터에 중점을 두고 훈련됩니다.
   - 이에 반해 InternVL 1.5는 상업적 모델들이 다루지 않는 중국어를 포함한 다양한 언어로도 효과적인 성능을 발휘할 수 있도록 설계되었습니다.

2. **InternVL 1.5의 주요 개선 사항**:
   - **강력한 시각 인코더**: InternViT-6B 모델을 통한 지속적인 학습을 통해 시각적 이해 능력을 향상시킵니다.
   - **동적 고해상도 전략**: 입력 이미지의 종횡비와 해상도에 따라 이미지를 448x448 픽셀의 타일로 분할하여 최대 4K 해상도까지 지원합니다.
   - **고품질 이중 언어 데이터셋**: 영어와 중국어로 주석이 달린 고품질 데이터셋을 구축하여 OCR 및 중국 관련 작업에서의 성능을 향상시킵니다.

3. **벤치마크 및 비교 연구를 통한 평가**:
   - InternVL 1.5는 개방형 소스 및 상업용 모델과 비교하여 18개 벤치마크 중 8개에서 최고의 성능을 달성했습니다.
   - 특히 OCR 관련 데이터셋에서 뛰어난 성능을 보여 주었습니다.

이 논문은 다양한 언어와 고해상도 이미지를 효과적으로 처리할 수 있는 새로운 다중 모달 대규모 언어 모델을 제시함으로써, 개방형 소스 모델의 발전에 기여할 수 있을 것으로 기대됩니다.