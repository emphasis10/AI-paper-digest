# Parrot: Multilingual Visual Instruction Tuning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.02539.pdf](https://arxiv.org/pdf/2406.02539.pdf)

### 1. 섹션별 요약

#### Introduction
현재의 다중모달 대형 언어 모델(MLLM)은 시각적 특징을 텍스트 임베딩 토큰과 맞추는 것이 핵심입니다. 대부분의 연구는 영어 중심의 데이터 셋을 사용하여 학습되었기 때문에 다중언어 반응 능력이 떨어지는 문제를 보입니다. 이를 해결하고자 PARROT는 언어 수준에서 시각적 토큰 정렬을 위한 텍스트 가이던스를 사용하여 다중언어 시각적 토큰을 생성합니다.

#### Methods
PARROT의 핵심 방법론은 두 가지 단계로 나뉩니다. 첫 번째 단계는 모달리티 정렬입니다. 이 단계에서는 시각적 특징을 사전 학습된 언어 모델의 단어 임베딩과 맞추는 것을 목표로 합니다. 두 번째 단계는 다중언어 정렬을 위한 명령어 튜닝입니다. 이 과정을 통해 PARROT는 소량의 다중언어 이미지-텍스트 데이터를 사용하여 시각적 표현을 다양한 언어로 빠르게 맞출 수 있습니다.

#### 데이터 및 평가
LLaVA와 CC12M 등의 데이터를 사용하여 다중언어 정렬을 위한 훈련을 진행했습니다. 평가 벤치마크로는 MMBench와 새롭게 개발된 MMMB가 사용되었으며, 다양한 다중모달 과제를 포함한 다양한 벤치마크에서도 탁월한 성능을 보였습니다.

#### Main Results
PARROT는 MMBench와 MMMB에서 모든 언어에서 우수한 성과를 기록했으며, 특히 터키어와 아랍어에서 큰 개선을 보였습니다. 또한, 다양한 다중모달 벤치마크에서도 경쟁력 있는 성과를 보여주었습니다.

#### Conclusion
PARROT는 다중언어 및 다중모달 모델의 새로운 프론티어를 열었으며, 다국적 및 문화적 다양성에 따른 기술 혜택 접근성을 강조했습니다.

### 2. 전체 요약

이 논문은 다중모달 대형 언어 모델(MLLM)의 다중언어 능력을 향상시키기 위한 PARROT라는 새로운 방법을 제안합니다. 기존 모델이 영어 중심의 데이터로 인해 다중언어 처리 능력이 떨어지는 문제를 해결하기 위해, PARROT는 텍스트 가이던스를 활용해 시각적 토큰을 언어별로 정렬합니다. 이를 통해 소량의 다중언어 데이터를 사용하여 시각적 표현을 다양한 언어로 빠르게 맞출 수 있으며, 주요 벤치마크에서 뛰어난 성능을 보였습니다. 이러한 접근 방식은 다국적 및 문화적 다양성에 따른 기술 접근성을 크게 향상시킬 수 있습니다.