# Active Prompting with Chain-of-Thought for Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2302.12246.pdf](https://arxiv.org/pdf/2302.12246.pdf)

#### 1. 섹션별 요약

1. **서론**
   - **내용 요약**: 대규모 언어 모델(LLM)의 성장이 여러 복잡한 작업 수행 능력을 향상시키고 있음. 특히, 체인 오브 사고(Chain-of-Thought, CoT) 방식의 예시 기반 프롬프트가 복잡한 질문-응답 작업에서의 성과를 크게 개선시키는 것으로 나타남. 하지만 기존의 CoT 방식은 고정된 인간 주석 예시에 의존하여 다양한 작업에 적합하지 않을 수 있음.
   - **주요 기여 및 혁신 점**: Active-Prompt 방법을 도입하여 작업 관련 예제 프롬프트를 통해 LLM을 적응시키는 방법을 제안함. 이 방법은 학습을 위해 가장 중요한 질문을 선택하도록 돕는 불확실성 기반의 능동 선택 전략을 도입함.
  
2. **관련 연구**
   - 여러 연구들이 CoT 방식의 단점을 개선하기 위해 다양한 방법론(자기 일관성, 부트스트래핑, 자가 학습 등)을 도입함. Active-Prompt 방식은 이러한 기존 연구들에 비해 특정 작업에 최적화된 질문을 선택할 수 있는 방법을 제안함.

3. **Active-Prompt 방법론**
   - **내용 요약**: 주석이 필요한 질문을 선택하고 효과적인 예제를 구성하는 과정을 설명함. 불확실성 추정 기법으로 불일치, 엔트로피, 분산, 자기 신뢰도 등의 다양한 측정 방법을 도입함.
   - **주요 기여 및 혁신 점**: 다양한 불확실성 추정 방법을 활용하여 주석이 필요한 가장 중요한 질문을 선택할 수 있는 전략을 제안함.

4. **실험 결과**
   - **내용 요약**: 8개의 다양한 데이터셋에 대해 Active-Prompt 방법의 성과를 평가함. Active-Prompt 방식이 기존의 CoT 및 자기 일관성 방식에 비해 뛰어난 성과를 보임.
   - **주요 기여 및 혁신 점**: 실험 결과 Active-Prompt 방식이 대규모 언어 모델의 성능을 효과적으로 향상시킴을 입증함.

5. **분석**
   - **내용 요약**: 추가 실험을 통해 다양한 불확실성 측정 방법 및 데이터셋 크기 등에 따른 성능 변화를 분석함. 예시 없이 시작하는 방법(Zero-Shot-CoT)도 효과적으로 작동함을 확인함.
   - **주요 기여 및 혁신 점**: 불확실성을 줄임으로써 예측 정확도가 높아지는 경향을 파악함.

6. **결론**
   - **내용 요약**: 본 연구에서는 Active-Prompt 방식을 통해 LLM의 추론 능력을 효과적으로 끌어내는 방법을 제안함. 여러 데이터셋에서 뛰어난 성과를 거두었으며, 불확실성 기반의 질문 선택 전략이 모델 성능을 크게 향상시킴을 입증함.
   - **한계 및 향후 연구 방향**: 더 강력한 모델들(GPT-4 등)을 대상으로 한 추가 실험 필요성과 연구 결과 재현의 어려움 등 몇 가지 한계가 존재함.

#### 2. 전체 요약

본 논문은 대규모 언어 모델(LLM)의 복잡한 문제 해결 능력을 향상시키기 위한 새로운 방법론, Active-Prompt를 제안합니다. 기존의 체인 오브 사고(CoT) 방식이 고정된 인간 주석 예시들에 의존하는 것과 달리, Active-Prompt는 특정 작업에 최적화된 예제를 선택할 수 있도록 불확실성 기반의 능동 선택 전략을 도입했습니다. 실험 결과, 이 방법은 여러 데이터셋에서 기존의 CoT 및 자기 일관성 방식보다 뛰어난 성과를 보였습니다. 앞으로는 더 강력한 모델들에 대한 추가 실험과 연구 결과 재현 가능성을 높이기 위한 노력이 필요합니다. Active-Prompt 방식은 대규모 언어 모델의 다양한 복잡한 작업 수행 능력을 크게 향상시키는 혁신적인 접근법입니다.

## Similar Papers
- [TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts](2407.03203.md)
- [DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](2405.04434.md)
- [Large Language Models Are Reasoning Teachers](2212.10071.md)
- [Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought](2404.03414.md)
- [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](2404.02575.md)
- [Large Language Models as Analogical Reasoners](2310.01714.md)
- [SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales](2405.20974.md)
- [Aligning Teacher with Student Preferences for Tailored Training Data Generation](2406.19227.md)
- [Time Sensitive Knowledge Editing through Efficient Finetuning](2406.04496.md)
