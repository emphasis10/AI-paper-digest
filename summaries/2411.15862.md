# LLMs Do Not Think Step-by-step In Implicit Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.15862.pdf](https://arxiv.org/pdf/2411.15862.pdf)

### 각 섹션의 요약과 주요 기여 및 혁신적인 부분

1. **서론**
   - 이 연구는 대형 언어 모델(LLM)이 암시적 Chain-of-Thought(COT) 추론을 수행할 때 중간 단계를 실제로 생각하지 않는다는 것을 실험적으로 밝히려 합니다. 암시적 COT는 LLM이 경험에 의존해 최종 답을 직관적으로 제공할 수 있지만, 이 방식이 명시적 COT의 체계적인 단계별 추론과 동등하지 않다는 의문을 제기합니다.

2. **접근 방법**
   - 연구진은 공개 소스 모델 Qwen2.5-72B-Instruct를 사용하여 단순한 산술 문제를 통해 암시적 추론 과정을 분석합니다. 이 모델을 활용해 명시적 중간 단계 없이 답을 도출하도록 실험했습니다.

3. **실험 설계**
   - 실험은 단계별 산술 문제를 통해 진행되며, 문제의 중간 결과들을 기록하여 모델이 암시적 추론에서 실제로 계산을 수행하는지 검사합니다. 이를 통해 모델의 은닉 상태를 조사하여 중간 결과를 매핑할 수 있는지 확인합니다.

4. **중간 단계 추론 결과**
   - 모델은 초기 및 최종 단계 결과는 기억하지만 중간 단계의 정확한 결과는 잘 처리하지 못합니다. 이로 인해 모델이 암시적 추론에서 단계적 계산을 건너뛰고 최종 결과를 직접 도출한다고 결론지었습니다.

5. **약간의 문제 변칙 결과**
   - 문제를 약간 수정했을 때 암시적 추론의 정확도가 크게 떨어지는 것을 발견했습니다. 이는 암시적 추론이 경험과 직관에 의존하며, 단계별 추론이 아니라는 것을 깨닫게 합니다.

6. **결론**
   - 암시적 추론은 LLM의 강력한 기억력과 경험에서 비롯된 직관적인 방식으로, 기존의 명시적 COT에 비해 신뢰성이 떨어집니다. 이 연구는 복잡한 작업에서 LLM의 능력을 향상시키기 위해 명시적 COT 방법론이 여전히 필요하다는 점을 강조합니다.

---

### 전체 요약

이 논문은 대형 언어 모델의 암시적 추론 과정에서, 단계별 추론 대신 모델이 경험에 의존해 최종 해답을 직관적으로 제공한다는 점을 실험적으로 증명합니다. 모델의 은닉 상태를 분석해 보았을 때, 암시적 추론이 중간 단계를 건너뛰면서 최종 답변으로 바로 도달한다는 것을 발견했습니다. 이는 암시적 추론이 명시적 추론과 같은 방식으로 동작하지 않으며, 복잡한 작업을 효과적으로 수행하기 위해서는 여전히 명시적 COT 방법이 중요하다는 결론을 내렸습니다. 이 연구는 AI의 추론 메커니즘에 대한 심층적 이해를 제공하고, 추후 연구 및 기술 발전 방향에 큰 기여를 할 수 있는 내용을 포함하고 있습니다.