# Promptriever: Instruction-Trained Retrievers Can Be Prompted Like Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.11136.pdf](https://arxiv.org/pdf/2409.11136.pdf)

### 요약 - Section 별 주요 내용

#### Abstract & Introduction
이 논문은 명령 조정을 거친 언어 모델(LM)이 명령어를 이해하고 자연스러운 사용자 인터페이스를 제공할 수 있다는 점을 강조합니다. Promptriever는 이러한 접근 방식을 정보 검색(IR) 모델에 적용한 최초의 모델로, 사용자가 제공하는 자연어 명령어를 통해 검색 기능을 조정할 수 있도록 합니다. 이를 위해 MS MARCO 데이터셋을 기반으로 한 새로운 명령 기반 검색 데이터셋을 만들어 Promptriever를 훈련했습니다. Promptriever는 표준 검색 작업뿐만 아니라 명령어에 따라 더 효과적으로 적응할 수 있는 성능을 보여주었습니다.

#### Promptriever Data Generation (데이터 생성)
- **Instruction Generation**: Llama 3과 같은 대형 언어 모델을 사용해 기존 쿼리를 기반으로 다양한 길이와 스타일의 명령어를 생성했습니다. 이와 함께 쿼리와 관련된 양성 패세지와 명령어를 조합하여 새로운 데이터셋을 구축했습니다.
- **Instruction Negatives (명령 네거티브)**: 명령 네거티브는 쿼리와 패시지가 개별적으로는 관련이 있지만, 특정 명령어 추가 시 해당 관련성이 크게 감소하는 사례를 만들어 훈련에 사용했습니다.

#### Methodology
Promptriever의 훈련 과정 및 방법론은 RepLLaMA의 MS MARCO 데이터와 새로운 명령어 데이터를 결합해 수행되었습니다. 기존 IR 모델과 같은 하이퍼파라미터를 사용하여 공정한 비교를 목표로 했습니다. MS MARCO, BEIR와 같은 인도메인 및 아웃도메인 데이터셋에서 평가했으며 InstructIR 및 FollowIR과 같은 명령어 추종 데이터셋에서도 평가했습니다.

#### Results
Promptriever는 RepLLaMA보다 훨씬 뛰어납니다. 구체적으로:
- **명령어 추종 능력**: FollowIR 및 InstructIR 데이터셋에서의 주요 성과로, p-MRR 기준으로 RepLLaMA보다 +14.3점 증가했습니다.
- **표준 검색 성능**: MS MARCO 및 BEIR에서 기존 모델과 유사한 성능을 유지하면서도 인도메인 및 아웃도메인에서 매우 견고한 성능을 보여주었습니다.
- **Zero-shot Prompting**: 명령어를 바로 적용하는 zero-shot 능력도 매우 뛰어나, 이를 통해 검색 성능이 향상되었습니다.

### 논문의 주요 기여 및 혁신 점
Promptriever는 명령 조정을 통해 교육된 검색 모델 중 최초로 사용자가 제공한 자연어 명령어를 활용하여 검색 성능을 조정할 수 있는 모델이며, 이는 기존 IR 모델과의 큰 차별점입니다. MS MARCO 데이터셋을 기반으로 한 명령어 교육 데이터셋 생성 및 명령 네거티브의 도입은 이러한 성능 향상의 핵심 요소입니다. 향후 더 많은 대규모 언어 모델 연계 연구와 함께 대응력이 뛰어난 검색 모델 개발을 촉진할 것입니다.

### 전체 요약
Promptriever는 언어 모델의 명령어 추종 능력을 정보 검색 모델에 성공적으로 적용한 최초의 사례로, MS MARCO를 기반으로 한 새로운 명령어 교육 데이터셋을 통해 훈련되었습니다. 이는 정보 검색 성능을 크게 향상시키며, zero-shot prompting과 같은 최신 기술을 효과적으로 활용할 수 있도록 합니다. Promptriever는 기존 모델보다 더 나은 명령어 추종 능력을 보여주며, 향후 더 많은 연구와 혁신을 촉진할 수 있는 기반을 마련하였습니다.