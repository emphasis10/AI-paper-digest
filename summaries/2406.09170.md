# Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.09170.pdf](https://arxiv.org/pdf/2406.09170.pdf)

### 논문의 주요 내용 요약

#### 1. **서론**
이 논문은 대형 언어 모델(LLM)의 시간적 추론 능력을 평가하기 위해 새로운 벤치마크인 ToT(Test of Time)를 소개합니다. 현재 LLM 연구는 다양한 데이터셋과 벤치마크를 통해 성능을 입증했으나, 시간적 추론 능력에 대해서는 한계가 있었습니다. ToT는 이러한 한계를 극복하기 위해 설계되었으며, 시간 논리와 시간 산술을 독립적으로 평가할 수 있습니다.

#### 2. **관련 연구**
기존 연구에서는 LLM의 다양한 추론 능력을 탐구했지만, 대부분 지식 그래프에 의존하여 시간적 사실을 다루었습니다. 이는 모델의 실제 시간적 추론 능력을 평가하기에 한계가 있습니다. ToT는 다양한 그래프 구조와 문제의 복잡성을 포함하여 독립적인 평가를 가능하게 합니다.

#### 3. **ToT 벤치마크 소개**
ToT는 두 가지 주요 과제를 통해 LLM을 평가합니다.
- **ToT-Semantic**: 시간적 의미와 논리를 다루는 합성 데이터셋.
- **ToT-Arithmetic**: 시간 포인트와 기간을 계산하는 능력을 평가하는 크라우드소싱 데이터셋.

이 두 과제는 각 축에서 모델의 성능을 독립적으로 평가할 수 있도록 도와줍니다.

#### 4. **실험결과**
각각의 그래프 구조와 시간적 오더, 문제 크기 및 질문 유형이 LLM의 성능에 미치는 영향을 체계적으로 조사했습니다. 실험 결과, 그래프 구조와 문제 크기가 LLM 성능에 크게 영향을 미친다는 것을 발견했습니다. 특히, 특정 그래프 구조에서 GPT-4의 정확도가 크게 차이나는 것을 확인했습니다.

#### 5. **결론**
ToT 벤치마크는 LLM의 시간적 추론 능력을 더 종합적이고 체계적으로 평가할 수 있는 도구를 제공합니다. 이 논문은 ToT를 통해 현재 LLM의 강점과 약점을 밝히고, 더 나아가 시간적 추론 연구를 촉진하고자 합니다. 이를 통해 LLM의 복잡한 추론 작업에 대한 연구와 개발이 가속화될 수 있기를 바랍니다.

### 전체 요약

이 논문은 대형 언어 모델(LLM)의 시간적 추론 능력을 평가하고 향상시키기 위해 ToT(Test of Time)라는 새로운 종합 벤치마크를 제안합니다. ToT는 시간적 의미와 논리를 평가하는 ToT-Semantic과 시간 산술 능력을 평가하는 ToT-Arithmetic 두 가지 주요 과제를 통해 더 정밀한 평가를 가능하게 합니다. 실험 결과, 그래프 구조와 문제 크기 등의 요소가 LLM의 시간적 추론 성능에 큰 영향을 미친다는 점을 밝혔습니다. 이 연구를 통해 LLM의 시간적 추론 능력에 대한 이해를 심화하고, 향후 연구와 개발 방향을 제시하는 중요한 기여를 하고자 합니다.

## Similar Papers
- [LongVideoBench: A Benchmark for Long-context Interleaved Video-Language Understanding](2407.15754.md)
- [GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models](2407.02936.md)
- [SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers](2407.09413.md)
- [MINT-1T: Scaling Open-Source Multimodal Data by 10x: A Multimodal Dataset with One Trillion Tokens](2406.11271.md)
- [Long Code Arena: a Set of Benchmarks for Long-Context Code Models](2406.11612.md)
- [DialSim: A Real-Time Simulator for Evaluating Long-Term Dialogue Understanding of Conversational Agents](2406.13144.md)
- [Large Scale Transfer Learning for Tabular Data via Language Modeling](2406.12031.md)
- [Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning](2406.06469.md)
- [ChuXin: 1.6B Technical Report](2405.04828.md)
