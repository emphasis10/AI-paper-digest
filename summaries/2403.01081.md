# LAB: Large-Scale Alignment for ChatBots
## TL;DR
## Summary
- [https://arxiv.org/pdf/2403.01081.pdf](https://arxiv.org/pdf/2403.01081.pdf)

#### 1. 소개 (Introduction)
이 논문은 챗봇의 대규모 정렬(LAB)을 위한 새로운 방법론을 소개합니다. 이 방법은 대규모 언어 모델(LLM) 훈련의 지침 조정 단계에서 발생하는 확장성 문제를 해결하는 것을 목표로 합니다. 이를 위해 분류 체계에 따른 합성 데이터 생성 과정과 다단계 조정 프레임워크를 활용합니다. 이를 통해 비싼 인간 주석과 GPT-4와 같은 독점 모델에 대한 의존성을 크게 줄이고, 경쟁력 있는 성능을 달성합니다.

#### 2. 관련 연구 (Related Work)
기존의 지침 조정 방법은 주로 인간 주석자에 의존하거나 큰 교사 모델을 사용하여 합성 데이터를 생성합니다. OpenAI의 연구는 인간 데이터에서 모델 정렬을 설정하는 표준을 제시했으며, 이는 수천 명의 주석자가 필요합니다. Meta의 LLaMA 2 모델 시리즈도 유사한 접근 방식을 사용하지만, 이러한 접근 방식은 비용이 많이 들고 시간이 많이 소요됩니다. 이에 대한 대안으로 합성 데이터 생성 접근법이 제안되고 있습니다.

#### 3. 방법론 (Methodology)
LAB 방법은 두 가지 주요 구성 요소로 이루어집니다:
1. **분류 체계에 따른 합성 데이터 생성**: 데이터의 다양성과 품질을 보장하기 위해 분류 체계를 사용하여 합성 데이터를 생성합니다.
2. **다단계 지침 조정 방법**: 재학습 버퍼를 사용하여 대규모 정렬 조정을 가능하게 합니다. 이 방법은 훈련의 안정성을 보장하고, "catastrophic forgetting"을 방지합니다.

#### 4. 실험 및 결과 (Experiments and Results)
LAB 방법을 LLAMA-2-13B와 MISTRAL-7B 모델에 적용하여 두 가지 LAB 정렬 모델을 개발했습니다: LABRADORITE-13B와 MERLINITE-7B. 이 모델들은 다양한 벤치마크에서 기존의 인간 주석이나 GPT-4에서 생성된 합성 데이터를 사용한 모델과 경쟁력 있는 성능을 보여주었습니다. 특히 MT-Bench에서 LABRADORITE-13B와 MERLINITE-7B는 각각의 기본 모델을 미세 조정한 다른 모델들보다 우수한 성능을 보였습니다.

### 주요 기여 및 혁신 부분 요약

이 논문의 주요 기여는 다음과 같습니다:
1. **분류 체계에 따른 합성 데이터 생성**: 다양한 고품질의 지침 데이터셋을 생성하여 인간 주석이나 GPT-4와 같은 독점 모델에 대한 의존성을 줄였습니다.
2. **다단계 지침 조정 방법**: 재학습 버퍼를 사용하여 새로운 지식과 지침 따르기 능력을 추가하면서도 "catastrophic forgetting"을 방지했습니다.
3. **LAB 정렬 모델**: LABRADORITE-13B와 MERLINITE-7B 모델은 다양한 벤치마크에서 경쟁력 있는 성능을 보였으며, 특히 MT-Bench에서 뛰어난 성능을 입증했습니다.

### 전체 요약

이 논문은 챗봇의 대규모 정렬(LAB)을 위한 새로운 방법론을 제안합니다. LAB 방법은 분류 체계에 따른 합성 데이터 생성과 다단계 지침 조정 방법을 통해 기존의 인간 주석이나 GPT-4와 같은 독점 모델에 대한 의존성을 줄이고, 높은 성능을 달성합니다. 실험 결과, LABRADORITE-13B와 MERLINITE-7B 모델은 다양한 벤치마크에서 우수한 성능을 보여줬으며, 이는 LAB 방법이 확장 가능하고 비용 효율적인 LLM 정렬 및 지침 따르기 행동 강화에 효과적임을 입증합니다.