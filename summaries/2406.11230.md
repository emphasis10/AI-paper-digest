# Multimodal Needle in a Haystack: Benchmarking Long-Context Capability of Multimodal Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.11230.pdf](https://arxiv.org/pdf/2406.11230.pdf)

### 1. 각 섹션 요약

#### Introduction
논문은 멀티모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)의 긴 맥락 이해 능력을 평가하기 위해 설계된 "MultiModal Needle-in-a-haystack (MMNeedle)" 벤치마크를 제안합니다. 주로, 텍스트 설명과 이미지 콘텐츠를 결합하여 여러 이미지에서 목표 이미지를 찾는 능력을 평가합니다.

#### Related Work
기존 연구는 MLLMs의 한계점을 평가하기 위한 다양한 벤치마크를 제안했지만, 긴 맥락을 포함하는 평가에는 부족합니다. MMNeedle은 4만 개의 이미지, 56만 개의 캡션, 28만 개의 needle-haystack 쌍으로 구성된 대규모 데이터셋을 포함하며, 기존 벤치마크와 차별화됩니다.

#### Methodology
MMNeedle 벤치마크는 여러 이미지와 이미지 스티칭(stitching)을 활용하여 입력 컨텍스트 길이를 확장하며, 서브 이미지 수준의 검색을 위한 레이블링 프로토콜을 개발합니다. 주로, MLLMs가 긴 맥락 이미지 입력 내에서 목표 서브 이미지를 얼마나 효과적으로 찾는지 평가합니다.

#### Experiments
다양한 MLLMs를 MMNeedle 데이터셋으로 평가하였고, GPT-4o가 긴 맥락 상황에서 다른 모델들을 꾸준히 뛰어넘는 성과를 보였으나, 부정적 샘플에서 환각(hallucination) 문제를 겪었습니다. 이 실험은 API 기반 모델과 오픈 소스 모델 간의 상당한 성능 격차를 강조했습니다.

#### Results
결과는 MLLMs의 긴 맥락 처리 능력에서 GPT-4o가 우세하지만, 이미지 개수가 증가할수록 정확도가 떨어진다는 것을 보여줍니다. 또한, 오픈 소스 모델은 더 복잡한 컨텍스트에서는 성능이 떨어지며, API 기반 모델과 큰 차이를 보입니다.

#### Discussion
결과를 바탕으로, MMNeedle은 MLLMs의 긴 맥락 시나리오에서의 처리 능력을 전반적으로 평가하며, API 기반 모델이 여전히 더 뛰어나지만 환각 문제를 해결해야 한다고 결론지었습니다. 또한, 대규모 데이터셋을 통해 신뢰할 수 있는 평가가 가능함을 증명했습니다.

#### Conclusion
MMNeedle 벤치마크는 MLLMs의 긴 맥락 처리 능력을 종합적으로 평가할 수 있도록 설계되었으며, 실험 결과는 API 기반 모델이 더 뛰어나지만 여전히 개선의 여지가 있음을 나타냅니다. 이를 통해 향후 MLLMs 개발 방향을 제시합니다.

### 2. 전체 요약
이 논문은 MLLMs의 긴 맥락 처리 능력을 평가하기 위해 MMNeedle 벤치마크를 제안합니다. MMNeedle은 대규모 이미지와 캡션 데이터셋을 활용하여, 여러 이미지에서 목표 서브 이미지를 찾는 능력을 평가합니다. 결과적으로, GPT-4o가 긴 맥락 상황에서 뛰어난 성능을 보였지만, 여전히 환각 문제를 해결해야 합니다. 또한, API 기반 모델이 오픈 소스 모델 대비 우수하지만, 더 큰 컨텍스트에서는 성능 저하가 발생함을 보여줍니다. 이 연구는 MLLMs 평가에 중요한 기준을 제공하며, 향후 개선 방향을 제시합니다.