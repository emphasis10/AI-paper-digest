# VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.01957.pdf](https://arxiv.org/pdf/2501.01957.pdf)

### 1. 주요 섹션 요약

#### 소개
- 이 논문에서는 멀티모달 대형 언어 모델인 VITA-1.5를 소개하며, 비전, 언어, 음성을 통합하여 강력한 멀티모달 상호작용을 실현하려는 목표를 설명합니다. 이를 위해 세 가지 단계로 나뉜 교육 전략을 사용하여 점진적으로 다양한 데이터를 통합합니다.

#### 관련 연구
- 최근 멀티모달 연구의 발전과 주요 경쟁 모델들을 소개하고, 비전과 텍스트에 중점을 두어 왔던 기존 모델들과는 달리 VITA-1.5가 음성까지 다루는 점을 강조합니다.

#### VITA-1.5 모델 아키텍처
- VITA-1.5는 비전과 오디오 인코더를 통해 데이터를 수집하고 이를 학습된 LLM에 통합시키는 멀티모달 접속 시스템을 채택합니다. 특히, 기존의 TTS 모듈을 사용하는 대신 독자적인 음성 생성을 가능하게 하는 점이 혁신적입니다.

#### 교육 데이터
- 다양한 데이터 세트를 활용해 학습을 진행하며, 영상 설명, 이미지 QA, OCR 및 다이어그램 이해, 비디오 데이터 처리, 순수 텍스트 데이터 이해 등을 목표로 합니다.

#### 세 가지 단계의 교육 전략
- 1단계: 비전-언어 훈련. 비전과 언어 간 간극을 줄이고, 멀티모달 데이터 이해도를 향상시킵니다.
- 2단계: 오디오 입력 조정. 음성 데이터를 통해 QA 기능을 향상시킵니다.
- 3단계: 오디오 출력 조정. 음성 생성을 개선하여 자연스러운 대화가 가능하게 합니다.

#### 평가
- 비전-언어 평가: VITA-1.5는 이미지 이해와 비디오 이해 평가에서 탁월한 성능을 보이며 다른 오픈 소스 및 일부 폐쇄 소스 모델을 초과하는 성능을 발휘합니다.
- 음성 평가: 영어와 만다린의 ASR 과제에서 우수한 정확성을 달성하여 멀티모달 상호작용을 효과적으로 지원합니다.

#### 결론
- VITA-1.5는 기존의 모달 충돌을 해소하고, 비전과 음성 이해 능력을 향상시킴으로써 실시간 상호작용을 가능하게 합니다. 이를 통해 VITA-1.0의 계승자로서 오픈 소스 모델의 발전을 촉진하고자 합니다.

### 2. 전체 요약
VITA-1.5는 비전, 언어, 음성을 통합하여 강력한 멀티모달 대화 시스템을 개발하는 것이 목표입니다. 이 모델은 점진적인 데이터 통합 및 세 단계의 교육 전략을 통해 비전과 언어, 음성을 자연스럽게 연결하여 더욱 효과적인 대화 인터페이스를 제공하고자 합니다. 평가 결과, VITA-1.5는 다양한 멀티모달 과제에서 뛰어난 성능을 보이며, 사용자 경험 향상에 기여할 수 있을 것으로 보입니다.