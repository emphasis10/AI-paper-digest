# MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.05237.pdf](https://arxiv.org/pdf/2412.05237.pdf)

1. **섹션 요약**

   - **서론**: 논문은 다중 모달 대형 언어 모델(MLLM) 분야에서의 최신 기술을 다루고 있다. 주요 문제점은 고품질의 지시 조정 데이터세트 부족으로, 이는 기존의 학문적 데이터세트를 변형한 것이 대부분이라 복잡한 이유 설명을 제공하지 못하는 문제점이 있다.

   - **방법론**: 본 연구는 개방형 모델만을 사용하여 1200만 개의 지시-응답 쌍을 포함하는 데이터세트를 생성하는 방법을 제안한다. 이 방법은 다양한, 추론 집약적인 작업을 포괄하며 중간 이유 설명을 포함한다.

   - **모델 훈련**: MAmmoTH-VL-8B 모델은 다양한 데이터세트를 기반으로 단계적으로 훈련되며, 이는 싱글 이미지, 다수 이미지 및 비디오 작업을 다루는 능력을 확장한다.

   - **실험 결과**: MAmmoTH-VL-8B는 여러 벤치마크에서 다른 개방형 소스 모델 대비 우수한 성과를 보여주며, 특히 수학적 추론 분야에서 높은 성과를 달성한다.

   - **결론**: 연구는 고급 AI 개발 접근을 민주화하여 다양한 연구자와 조직이 접근 가능하도록 만든다. 향후 연구를 위한 새로운 경로를 열며, 이 방법론을 다른 모달리티와 데이터세트로 확장할 가능성을 제시한다.

2. **논문의 주요 기여와 혁신**:

   - 이 논문은 다중 모달 대형 언어 모델 분야에서의 학문적 데이터세트 한계를 극복하기 위한 새로운 데이터세트 생성 방법론을 제안하며, 이를 통해 모델의 추론 능력을 향상시킨다. 특히, 개방형 소스 모델만을 사용하여 다양한 이유를 설명할 수 있는 대규모 데이터세트를 구축하여, 복잡한 시나리오를 처리할 수 있는 실질적 능력을 개선한다는 점에서 혁신적이다.

3. **전체 요약**:

   본 논문은 다중 모달 대형 언어 모델의 성능을 개선하기 위한 새로운 방법론을 제안한다. 개방형 소스 모델만을 사용하여 1200만 개의 지시-응답 쌍을 포함하는 데이터세트를 생성함으로써, 복잡한 작업에 대한 추론 능력을 크게 향상시켰다. 이 모델은 다양한 벤치마크에서 두각을 나타내며, 기본적인 AI 기술에 대한 접근성을 확장함으로써 연구와 개발의 민주화를 이루고자 한다. 이러한 연구는 AI 발전을 가속화할 뿐만 아니라, 다른 모달리티와 데이터세트로의 확장 가능성이 높아 향후 연구의 기반을 마련한다.