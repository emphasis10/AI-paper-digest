# Explanatory Instructions: Towards Unified Vision Tasks Understanding and Zero-shot Generalization
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.18525.pdf](https://arxiv.org/pdf/2412.18525.pdf)

1. 각 섹션의 중요한 내용 요약:
   - **서론**: 자연어 처리(NLP)에서는 대규모 학습과 자동 회귀 모델을 통해 제로샷 태스크 일반화를 달성하는 데 성공했지만, 컴퓨터 비전(CV)에서는 여전히 이러한 성과를 이루지 못했습니다. 본 논문에서는 CV에서 사용되는 구체적이고 용어적인 태스크 정의가 제로샷 일반화를 방해한다고 가정하였습니다.
   
   - **실험 방법 및 결과**: AI 모델의 제로샷 일반화 능력을 높이기 위해 대규모 데이터셋과 설명적 지시를 사용하여 실험을 진행했습니다. 이 데이터셋은 1,200만 개의 "이미지 입력 → 설명적 지시 → 출력" 삼중항을 포함합니다.
   
   - **주요 기여 및 혁신 부분**: 설명적 지시는 기존의 고정된 설명 대신 직관적이고 자세한 언어적 변환을 제공하여 CV 태스크의 목적을 정의합니다. 이를 통해 모델은 이전에 본 태스크와 보지 못한 새로운 CV 태스크에서도 제로샷 능력을 보입니다.
   
   - **제한 사항**: 제로샷 능력이 생성 태스크와 저수준 비전 태스크에 국한되어 있으며, 일부 과제에서는 이러한 능력이 부족합니다.

2. 전체 요약:
   이 논문은 컴퓨터 비전 분야에서 제로샷 일반화의 저해 요인으로 작용하는 기존의 용어적 정의 방식을 극복하기 위해 설명적 지시를 도입했습니다. 이러한 지시를 사용하여, AI 모델은 이전에 본 태스크뿐만 아니라 새로운 비전 태스크에서도 놀라운 제로샷 일반화 능력을 보여줍니다. 이 방법은 기존의 제한적인 비전 태스크 정의를 뛰어넘어 보다 유연하고 보편적으로 적용 가능한 생성 모델 개발의 발판을 마련합니다.