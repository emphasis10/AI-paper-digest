# SWE-Fixer: Training Open-Source LLMs for Effective and Efficient GitHub Issue Resolution
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.05040.pdf](https://arxiv.org/pdf/2501.05040.pdf)

1. 각 섹션의 요약

- 소개: 대형 언어 모델(LLM)은 GitHub의 실제 문제 해결에 있어 중요한 진전을 보였습니다. 하지만 주로 출처가 공개되지 않은 모델에 의존하기 때문에 재현성과 접근성이 제한됩니다. 이를 해결하기 위해 SWE-Fixer라는 오픈 소스 LLM을 개발했습니다. SWE-Fixer는 코드 파일 검색과 코드 편집의 두 가지 핵심 모듈로 구성되어 있습니다.

- 체인 오브 사고 데이터 생성: 복잡한 작업에서도 높은 정확도를 얻기 위해 체인 오브 사고(CoT) 데이터가 필요합니다. 이는 GOLD 패치를 입력의 일부로 사용하여 SQL에서 합리적인 과정을 생성하는 방식을 채택하여 해결했습니다.

- 실험: 실험 환경은 SWE-Fixer의 성능을 시험하기 위해 마련되었습니다. SWE-Fixer는 SWE-Bench Lite 및 Verified라는 두 가지 데이터셋에서 테스트되었으며, 이는 GitHub 문제 해결 성능을 평가합니다.

- 성과: SWE-Fixer는 오픈 소스 모델 중에서 최고의 성능을 보였습니다. SWE-Bench Lite에서 23.3%, SWE-Bench Verified에서 30.2%의 성과를 기록하며, 대부분의 폐쇄형 모델을 뛰어넘었습니다.

2. 전체 요약

이 논문은 GitHub의 문제를 해결하기 위한 SWE-Fixer라는 오픈 소스 LLM을 소개합니다. 이 도구는 코드 파일 검색과 코드 편집의 두 가지 주요 작업을 수행합니다. SWE-Fixer는 데이터셋을 기반으로 해 문제를 효율적으로 풀어내며, 실험에서 뛰어난 성과를 보였습니다. 폐쇄형 모델과 비교하여 비용 효율적인 대안으로 주목받고 있으며, 이는 AI 소프트웨어 개발의 새로운 가능성을 열어줍니다.