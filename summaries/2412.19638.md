# Xmodel-2 Technical Report
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.19638.pdf](https://arxiv.org/pdf/2412.19638.pdf)

### 1. 섹션별 요약

- **인트로덕션**
  Xmodel-2는 1.2억 파라미터로 구성된 대형 언어 모델로, 복잡한 추론 작업을 효율적으로 수행하도록 설계되었습니다. 이 모델은 다양한 모형 규모에서 동일한 하이퍼파라미터를 공유할 수 있게 해주는 텐서 프로그램 구조를 채택하였으며, 이는 작은 모델에서 최적의 하이퍼파라미터를 찾아 큰 모델에 적용하는 것을 가능하게 합니다. 또한 효율성을 위해 WSD 학습률 스케줄러를 적용하여 낮은 비용으로 훈련을 최적화했습니다.

- **사전 훈련**
  Xmodel-2의 사전 훈련 과정에는 모델의 구조와 안정적 훈련 및 감쇠 단계에서의 데이터 분배 설명이 포함되었습니다. 이 모델은 LLama 2와 유사한 아키텍처를 사용합니다. 중요한 점은 대형 모델에서 사용되는 BPE 토크나이저 대신 유니그램 토크나이저를 사용하고, 내장 공유와 얇고 깊은 구조를 도입하여 모델의 매개변수를 줄였습니다.

- **결과**
  Xmodel-2는 일반 상식 추론 및 복합 추론 벤치마크에서 강력한 성능을 보였으며, FEVER와 HotpotQA 같은 다양한 에이전트 퀘리에서 테스트되었는데, 이는 복잡한 추론이 요구되는 실제 환경에서의 성능을 고도화한 것입니다.

- **사례 연구**
  사례 연구에서는 Xmodel-2가 보정된 모델로 예상 확률과 실제 결과 간 일치성이 확인되었습니다. 위키텍스트-2 데이터셋을 통한 후 훈련 스케일링 법칙 분석에서 더 많은 문맥 길이가 보다 정확한 토큰 예측으로 이어짐이 밝혀졌습니다.

- **결론**
  Xmodel-2는 최대 업데이트 매개변수화(µP), WSD 학습률 스케줄러, 그리고 감쇠 단계에서의 데이터 비율 최적화를 통하여 복잡한 추론 능력을 강화하고, 1-2억 파라미터 범위 내의 타 에이전트 기반 평가에서 최상의 성능을 기록했습니다. 이는 전자 상거래 고객 서비스나 작업 자동화 같은 실제 응용 프로그램에서 큰 잠재력을 나타냅니다.

### 2. 전체 요약

Xmodel-2는 효율적인 훈련을 통해 복잡한 추론 작업을 강화할 수 있도록 설계된 1.2억 파라미터 대형 언어 모델입니다. 다양한 데이터 소스를 기반으로 사전 훈련된 이 모델은, 특히 텐서 프로그램 기반의 아키텍처를 통해 모델 확장이 용이하며, 다양한 응용 시나리오에서 뛰어난 성능을 발휘합니다. 교육 데이터에서 최적의 하이퍼파라미터를 찾기 쉬운 구조로 설계되었으며, 에이전트 기반의 실제 환경에서 강력한 성능을 보임으로써 AI 혁신에 기여할 수 있는 잠재력을 가지고 있습니다.