# RAGTruth: A Hallucination Corpus for Developing Trustworthy Retrieval-Augmented Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2401.00396.pdf](https://arxiv.org/pdf/2401.00396.pdf)

### 논문 요약 (2401.00396v2-2.pdf)

#### 1. 소개
이 논문은 RAGTruth라는 대규모 단어 수준의 환각 탐지 데이터셋을 소개합니다. 이 데이터셋은 RAG 응용 프로그램의 환각을 평가하기 위해 설계되었으며, 이를 통해 주요 LLM들이 환각을 생성하는 경향을 평가하고, 현재의 환각 탐지 방법을 비교 분석합니다. 주요 기여는 다음과 같습니다:
- RAGTruth 데이터셋 제안: 18,000개 이상의 완전 주석된 자연 응답 데이터 포함
- 다양한 환각 탐지 방법의 종합적인 비교 수행
- RAGTruth 데이터로 미세 조정된 Llama-2-13B 모델이 기존 방법보다 뛰어난 성능을 보임
- 미세 조정된 환각 탐지기를 사용하여 LLM의 환각 발생률을 크게 줄일 수 있음을 입증

#### 2. 관련 연구
- 기존 연구는 LLM의 환각 문제를 이해하고 해결하는 데 중점을 두고 있습니다.
- RAG(정보 검색 강화 생성) 접근법이 실제 LLM 응용 프로그램에서 널리 사용되고 있으며, 이를 통해 환각을 줄일 수 있음이 증명되었습니다.

#### 3. RAGTruth의 구성 과정
- 환각 분류: 명백한 충돌, 미묘한 충돌, 명백한 근거 없는 정보 도입, 미묘한 근거 없는 정보 도입 등 4가지 유형으로 분류
- 응답 생성: 질문 응답, 데이터 텍스트 작성, 뉴스 요약의 세 가지 주요 작업을 선정하여 데이터를 생성

#### 4. 실험 결과
- 응답 수준 탐지: GPT-4-turbo가 평균 F1 점수 63.4%로 가장 높은 성능을 보였으나 여전히 많은 환각이 포함됨
- 스팬 수준 탐지: 미세 조정된 Llama-2-13B 모델이 평균 52.7%의 F1 점수로 가장 높은 성능을 보였으나 완벽하지 않음

#### 5. 환각 억제
- 두 가지 전략을 통해 환각 발생률을 크게 줄일 수 있음: 예측된 환각 스팬이 적은 응답 선택, 검출된 환각 스팬이 없는 응답 선택
- 미세 조정된 환각 탐지기를 사용하여 환각률을 최대 63.2%까지 줄일 수 있음

#### 6. 결론
RAGTruth는 고품질의 데이터셋으로, 이를 통해 RAG 상황에서의 환각 탐지 방법을 개선할 수 있음을 보였습니다. 그러나 여전히 환각 탐지의 어려움이 존재하며, 추가 연구가 필요합니다.

### 전체 요약
이 논문은 대규모 단어 수준의 환각 탐지 데이터셋인 RAGTruth를 소개하고, 이를 통해 주요 LLM들의 환각 생성 경향을 평가하고 환각 탐지 방법을 비교 분석합니다. RAGTruth 데이터셋은 18,000개 이상의 완전 주석된 자연 응답 데이터를 포함하고 있으며, 이를 사용해 미세 조정된 Llama-2-13B 모델이 기존 방법보다 뛰어난 성능을 보였습니다. 환각 억제 전략을 통해 LLM의 환각 발생률을 크게 줄일 수 있음을 입증했습니다. 이 연구는 RAG 상황에서의 환각 탐지 방법을 개선하기 위한 중요한 데이터셋과 방법을 제시하고 있으며, 여전히 해결해야 할 과제가 많음을 강조합니다.

## Similar Papers
- [Luna: An Evaluation Foundation Model to Catch Language Model Hallucinations with High Accuracy and Low Cost](2406.00975.md)
- [AgentInstruct: Toward Generative Teaching with Agentic Flows](2407.03502.md)
- [Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction](2405.12656.md)
- [Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps](2407.07071.md)
- [Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval](2405.06545.md)
- [A Survey on Retrieval-Augmented Text Generation for Large Language Models](2404.10981.md)
- [LLM In-Context Recall is Prompt Dependent](2404.08865.md)
- [Estimating the Hallucination Rate of Generative AI](2406.07457.md)
- [Many-Shot In-Context Learning](2404.11018.md)
