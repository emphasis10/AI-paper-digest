# Mixture of Nested Experts: Adaptive Processing of Visual Tokens
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.19985.pdf](https://arxiv.org/pdf/2407.19985.pdf)

### 1. 각 섹션 요약

#### Introduction
이 논문은 이미지 및 비디오에서의 정보 중복성을 활용한 효율적인 처리 방법을 제안한다. Vision Transformer(ViT) 기반 모델은 큰 데이터 셋을 처리하는 능력이 있지만, 정보 중복성을 충분히 활용하지 못해 계산 비용이 높아진다. MoE(Mixture of Experts) 네트워크는 같은 추론 시간 비용으로 확장 가능성을 보장하지만, 더 많은 파라미터가 필요하다. 이 문제를 해결하기 위해 Mixture of Nested Experts(MoNE) 프레임워크가 제안되었다. MoNE는 중첩된 구조의 전문가를 활용하여 계산 예산 내에서 동적으로 토큰을 처리한다. 이를 통해 추론 시간 계산을 절반 이상 줄이면서 성능을 유지할 수 있다.

#### Related Work
Transformers는 언어, 이미지, 비디오 등 다양한 데이터 처리에서 표준 아키텍처가 되었고, 이를 더욱 효율적으로 만들기 위한 많은 연구가 진행되고 있다. 관련 연구는 토큰 수를 줄이거나, 주의 메커니즘을 효율적으로 변경하는 등의 방법을 포함한다. MoE 트랜스포머는 여러 전문가 MLP에 토큰을 라우팅하는 방법을 배운다. 기존의 MoE는 모든 전문가가 동일한 파라미터와 계산량을 가지기 때문에 모든 입력에 대해 고정된 계산 비용이 필요하다. 이에 반해 MoNE는 중첩된 네트워크 구조를 사용하여 적응적으로 토큰을 처리함으로써 계산 효율성을 높인다.

#### Methodology
MoNE 프레임워크는 효율적인 추론을 위해 시각적 토큰을 처리하는 동적 라우팅 메커니즘을 사용한다. 이 방법론은 주어진 계산 예산 내에서 중첩된 모델을 선택하여 토큰을 처리함으로써 전체 계산량을 줄인다. 구체적으로 MoNE는 각 레이어에서 서로 다른 파라미터 크기를 가진 중첩된 블록을 사용하고, 라우터 네트워크를 통해 적절한 중첩된 블록에 토큰을 할당한다. 또한, 각 토큰의 중요도를 학습하여 큰 모델에서 처리할 필요가 있는 중요한 토큰을 식별한다.

#### Results
MoNE 프레임워크는 이미지와 비디오 데이터셋에 대한 실험에서 기존 모델 대비 성능을 유지하면서도 추론 시간 계산을 두 배 이상 줄일 수 있음을 보여준다. 특히, ImageNet-21k와 같은 이미지 분류 작업과 Something-Something-v2와 같은 비디오 분류 작업에서 유의미한 성능 개선이 있었다. 이는 MoNE의 동적 라우팅 메커니즘과 중첩 구조의 효율성 덕분이다.

#### Discussion
논문에서는 MoNE의 효율성을 더욱 향상시키기 위한 다양한 디자인 선택지를 탐구하였다. 라우터 네트워크의 설계 및 배치가 모델 성능에 미치는 영향도 분석하였다. 특히, 중요한 토큰을 시각화하여 모델이 어떤 기준으로 토큰을 선택하는지 확인할 수 있었다. 이를 통해 MoNE의 적응적 토큰 처리 메커니즘이 효과적으로 동작함을 확인할 수 있었다.

#### Conclusion
MoNE는 비전 트랜스포머 기반 모델의 효율성을 극대화하기 위한 프레임워크로, 정보 중복성을 활용하여 추론 시간 동안의 계산 비용을 크게 줄일 수 있다. 이로 인해 에너지 사용량과 탄소 배출량을 줄이는 데 기여할 수 있으며, AI 모델에 대한 접근성을 높일 수 있다. 그러나 이 모델은 주로 인코더 아키텍처에 맞춰 설계되었기 때문에, 향후 연구에서는 오토리그레시브 디코딩에 대한 확장이 필요하다.

### 2. 전체 요약
이 논문에서는 Vision Transformer 기반 모델의 계산 효율성을 극대화하기 위해 Mixture of Nested Experts(MoNE) 프레임워크를 제안한다. MoNE는 중첩된 구조를 사용하여 토큰을 동적으로 처리함으로써 추론 시간 계산량을 절반 이상 줄일 수 있다. 이 프레임워크는 이미지와 비디오 데이터셋에서 기존 모델과 동일한 성능을 유지하면서도 계산 비용을 크게 줄인다. 이를 통해 AI 모델의 에너지 사용량을 줄이고 접근성을 높이며, 향후 더 복잡한 작업에 대한 확장 가능성을 가진다. 특히, 라우터 네트워크를 통한 동적 토큰 처리가 효율적으로 동작함을 다양한 실험을 통해 입증하였다.


## Similar Papers
- [DenseFormer: Enhancing Information Flow in Transformers via Depth Weighted Averaging](2402.02622.md)
- [A Primer on the Inner Workings of Transformer-based Language Models](2405.00208.md)
- [Mixture-of-Depths: Dynamically allocating compute in transformer-based language models](2404.02258.md)
- [Not All Prompts Are Made Equal: Prompt-based Pruning of Text-to-Image Diffusion Models](2406.12042.md)
- [No Time to Waste: Squeeze Time into Channel for Mobile Video Understanding](2405.08344.md)
- [FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning](2307.08691.md)
- [Knowledge Composition using Task Vectors with Learned Anisotropic Scaling](2407.02880.md)
- [Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models](2404.04478.md)
- [RouteLLM: Learning to Route LLMs with Preference Data](2406.18665.md)
