# SciCode: A Research Coding Benchmark Curated by Scientists
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.13168.pdf](https://arxiv.org/pdf/2407.13168.pdf)

### 1. 각 섹션 요약 및 주요 기여와 혁신 부분 설명

#### 서론 (Introduction)
- 언어 모델(LM)의 성능 향상으로 대부분의 인간, 특히 도메인 전문가를 제외한 사람들을 능가하고 있습니다. 이를 평가하기 위한 새로운 벤치마크가 필요합니다.
- 책에선 실제 과학 연구 문제를 해결하기 위해 코드 생성 능력을 평가하는 새로운 과학자 큐레이트 코딩 벤치마크인 SciCode를 소개합니다.
- SciCode는 수학, 물리학, 화학, 생물학 등 16개 자연 과학 하위 분야의 문제를 다루며 총 338개의 하위 문제로 구성되어 있습니다.
- 현재 가장 성능이 좋은 모델인 Claude3.5-Sonnet은 실제 환경에서 4.6%의 문제만 해결할 수 있습니다.
- SciCode는 LM의 발전을 실질적이고 도전적인 과제를 통해 평가할 수 있는 중요한 프레임워크를 제공합니다.

#### 언어 모델과 과학 (Language models for science)
- 과학적 태스크는 복잡한 이유와 지식을 요구합니다.
- Galactica 같은 모델은 인용 예측, 과학적 추론, 문서 생성, 몰 분자 특성 예측 등 다양한 과학적 태스크를 수행합니다.
- 많은 모델이 특정 도메인과 태스크에 집중하고 있으며, 수학, 단백질 구조 예측, 의학적 추론 등에서 활용됩니다.

#### SciCode 디자인 (SciCode design)
- SciCode는 자연 과학 여러 분야에서 연구 수준 코딩 문제를 다룹니다.
- 문제들은 실제로 과학자가 사용하는 스크립트로 구성되어 있으며, 출판된 논문에서도 사용된 것들이 포함되어 있습니다.
- SciCode는 총 80개의 주요 문제와 338개의 하위 문제로 구성되어, 자연 과학의 다양한 측면을 포괄합니다.

#### 평가 (Evaluation)
- SciCode는 다양한 평가 설정을 통해 모델 능력을 측정할 수 있습니다.
- 예를 들어, 이전 하위 문제의 솔루션 제공 여부, 과학적 배경 정보 제공 여부 등을 조절할 수 있습니다.
- 모델들은 배경 지식 제공 시 성능이 향상되지만, 여전히 많은 문제를 해결하지 못합니다.
- 하위 문제 평가에서 가장 성능이 좋은 모델은 Claude3.5-Sonnet으로, 실제 문제 해결 비율이 4.6%입니다.

#### 실험 (Experiments)
- GPT-4o, GPT-4-Turbo, Claude3.5-Sonnet 등의 모델을 평가했습니다.
- 모든 모델이 하위 문제 솔루션을 많이 활용했을 때 성능이 향상되지만, 전체 문제 해결 능력은 여전히 부족합니다.
- 배경 지식 제공 시 GPT-4o, Claude3.5-Sonnet 등의 모델이 가장 성능이 좋습니다.

#### 결론 (Conclusion)
- SciCode는 전문 과학자들이 큐레이트한 연구 벤치마크로, 향후 다양한 과학적 응용을 위한 코드 언어 모델 개발에 중요한 지침 역할을 할 것으로 기대됩니다.
- SciCode는 현대 언어 모델이 과학적 조수로 발전하는 경로를 명확히 해줍니다.

### 2. 전체 요약

이 논문은 언어 모델(LM)의 성능을 평가하기 위해 'SciCode'라는 새로운 과학자 큐레이트 코딩 벤치마크를 제안합니다. SciCode는 수학, 물리학, 화학 등 16개 다양한 자연 과학 분야에서 얻은 실제 연구 문제를 해결하는 능력을 테스트합니다. 주요한 혁신은 이 벤치마크가 실제 문제를 해결하기 위한 코드를 작성하는 능력을 평가한다는 점입니다. SciCode는 현재 가장 성능이 좋은 모델인 Claude3.5-Sonnet도 4.6%의 문제만 해결할 수 있을 정도로 도전적입니다. 이는 언어 모델이 과학적 조수로서 실질적인 발전을 이루기 위한 평가를 가능하게 합니다. 이 논문은 향후 과학적 응용을 위한 코드 언어 모델 개발에 중요한 프레임워크를 제공합니다.