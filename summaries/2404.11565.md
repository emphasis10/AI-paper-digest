# MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.11565.pdf](https://arxiv.org/pdf/2404.11565.pdf)

**1. 서론**
- 최근 인공지능을 이용한 시각 콘텐츠 생성 분야는 눈부신 발전을 이루었습니다. 기존의 모델들은 사용자로부터 간단한 텍스트 명령을 받아 질 높은 이미지를 생성할 수 있는 능력을 가지고 있었습니다. 그 중에서도 개인화(personalization)는 중요한 연구 분야 중 하나로 꼽히며, 사용자 맞춤형 대상을 고품질로 통합하여 개인적으로 의미 있는 결과물을 생성하는 것을 목표로 합니다.
- 현재 개인화 기술에도 불구하고, 원본 모델의 다양성을 유지하는 데에는 한계가 있었습니다. 특히 여러 대상의 구성과 상호작용 생성에 어려움이 있었습니다.
- 이에 본 연구는 'Mixture-of-Attention (MoA)'라는 새로운 아키텍처를 소개하며, 개인화된 attention 분기와 비개인화된 prior 분기 사이의 생성 작업을 분배함으로써 이러한 문제를 해결하고자 합니다.

**2. 관련 연구**
- 기존의 이미지 생성 모델과 개인화 생성에 대한 연구들은 고정된 이미지 합성 모델의 강력한 생성 능력을 유지하면서도 제한된 입력 이미지를 사용하여 원하는 대상을 적용하는 방식에 초점을 맞추었습니다. 'Textual Inversion' 같은 기술은 특정 대상을 인코딩하는 특수 텍스트 토큰을 학습하여 개인화를 달성합니다.

**혁신적인 부분 요약**
- MoA는 개인화된 분기와 비개인화된 분기 간의 균형을 최적화하기 위해 픽셀 단위로 작동하는 새로운 라우팅 메커니즘을 도입했습니다. 이를 통해 사용자 지정 대상을 원본 모델이 생성한 레이아웃과 컨텍스트에 최소한의 개입으로 통합합니다.
- 해당 메커니즘은 모델의 기존 기능과 새롭게 추가된 개인화된 개입을 분리함으로써, 이전에는 달성하기 어려웠던 주제-컨텍스트 분리(혼돈) 제어 수준을 제공합니다. 이를 통해 대상 교체, 대상 변형, 스타일 전송 등과 같은 다양한 애플리케이션을 생성할 수 있습니다.

### 전체 요약

Mixture-of-Attention (MoA)은 텍스트 투 이미지 생성 모델의 개인화를 위한 새로운 아키텍처로, 개인화된 attention 경로와 비개인화된 prior 경로 간의 분리와 조화를 통해 개인화된 이미지 생성을 극대화합니다. 기존 모델의 다양성을 보존하면서 사용자 맞춤형 대상의 고품질 통합을 목표로 하며, 이를 위해 새로운 라우팅 메커니즘을 도입하여 개인화된 분기만을 대상 픽셀에 적용합니다. MoA는 주제-컨텍스트 분리 제어의 새로운 수준을 제공하며, 이는 모델의 핵심 기능과 개인적인 개입이 명확히 구분되는 결과물을 생성함으로써 다양한 애플리케이션 개발을 가능하게 합니다.

## Similar Papers
- [VIMI: Grounding Video Generation through Multi-modal Instruction](2407.06304.md)
- [RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance](2405.14677.md)
- [pOps: Photo-Inspired Diffusion Operators](2406.01300.md)
- [EMMA: Your Text-to-Image Diffusion Model Can Secretly Accept Multi-Modal Prompts](2406.09162.md)
- [Compositional Text-to-Image Generation with Dense Blob Representations](2405.08246.md)
- [MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation](2404.05674.md)
- [StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation](2405.01434.md)
- [4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models](2406.07472.md)
- [PuLID: Pure and Lightning ID Customization via Contrastive Alignment](2404.16022.md)
