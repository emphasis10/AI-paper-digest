# LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via Hybrid Architecture
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.02889.pdf](https://arxiv.org/pdf/2409.02889.pdf)

### 논문의 섹션별 요약 및 분석

---

#### 1. 서론 (Introduction)

#### 요약:
멀티모달 대형 언어 모델(MLLM) 기술의 급진적인 발전에도 불구하고, 다중 이미지 시나리오는 아직 충분히 탐구되지 않았습니다. 특히, MLLM의 문맥을 확장하여 더 긴 비디오 이해, 고해상도 이미지 이해, 그리고 더 많은 역사적 메시지 기반 결정을 내리는 것은 사용자 경험을 향상시키는 데 중요합니다. 이러한 맥락 확장을 통해 성능 저하와 높은 계산 비용에 대한 도전 과제가 발생합니다. 이를 해결하기 위해 LongLLaVA라는 하이브리드 아키텍처 기반 모델을 소개하였으며, 이는 성능과 효율성을 균형 있게 유지합니다.

#### 주요 기여점 및 혁신:
- LongLLaVA는 다중 이미지 시나리오에서의 성능 저하와 높은 계산 비용 문제를 해결하기 위해 설계되었습니다.
- 이 모델은 멀티모달 아키텍처, 데이터 구축 및 훈련 전략 전반에 걸쳐 최적화를 도입하였습니다.
- 성능을 유지하면서 계산 비용을 줄이기 위해 2D 풀링을 적용한 효율적인 이미지 표현 방법을 제안합니다.

---

#### 2. MLLM에서 이미지 수 확대를 향하여 (Towards Scaling up the Image Number in MLLMs)

#### 요약:
이미지 수가 증가함에 따라 모델의 입력 길이가 급격히 길어지면서 성능 저하와 높은 추론 비용 문제가 발생합니다. 많은 기존 오픈 소스 MLLM들은 단일 이미지 작업에서 뛰어난 성능을 보이지만, 다중 이미지 작업에서는 성능이 크게 저하됩니다. 이러한 문제를 해결하기 위해서 이미지 수를 늘리는 방향으로 나아가는 것이 필요합니다.

#### 주요 기여점 및 혁신:
- 다중 이미지 처리의 필요성 및 이와 관련된 성능 저하 문제를 논의합니다.
- 시간적 및 공간적 확장을 통해 다양한 응용 시나리오에서 MLLM의 활용도를 넓히는 방안을 제시합니다.

---

#### 3. LongLLaVA: LLaVA의 확장 (LongLLaVA: Scaling LLaVA to Longer Context)

#### 요약:
이 섹션에서는 LongLLaVA 모델의 세부 아키텍처, 데이터 처리 프로토콜, 훈련 전략 등을 설명합니다. 모델은 LLaVA를 기반으로 구축되었으며, 하이브리드(LLaVA와 Mamba) 아키텍처, 2D 풀링을 통한 이미지 토큰 압축, 그리고 Mixture of Experts 접근 방식을 채택하여 성능과 효율성을 모두 극대화하였습니다.

#### 주요 기여점 및 혁신:
- CLIP를 비전 인코더로 사용하고, Mamba와 Transformer 레이어를 결합한 하이브리드 아키텍처로 성능을 최적화합니다.
- 다양한 작업에 적합하도록 이미지 간의 시간적 및 공간적 종속성을 구분하는 특별 문자를 사용한 데이터 처리 프로토콜을 개발하였습니다.

---

#### 4. 실험 및 결과 (Experiments)

#### 요약:
이 섹션에서는 LongLLaVA 모델의 훈련 세부 사항, 평가 설정, 주요 결과 및 진단 평가를 다룹니다. LongLLaVA는 다양한 기준에서 뛰어난 성능을 보이며 특히 동영상 벤치마크에서 탁월한 결과를 보여주었습니다. 또한, 사용된 계산 자원 대비 높은 효율성을 증명하였습니다.

#### 주요 기여점 및 혁신:
- LongLLaVA가 기존의 오픈 소스 모델을 능가하는 높은 효율성과 성능을 입증하였습니다.
- 모델이 다양한 작업에서 뛰어난 성능을 발휘하며 자원 관리 측면에서 최적화된 것을 확인하였습니다.

---

#### 5. 추가 분석 (More Analysis)

#### 요약:
이 섹션에서는 LongLLaVA의 내부 동작 및 멀티모달 장문 이해 능력을 추가로 분석하였습니다. 하이브리드 아키텍처의 동기 및 이미지 수 확대에 따른 성능 스케일링 법칙을 탐구하였습니다.

#### 주요 기여점 및 혁신:
- 하이브리드 아키텍처의 장점을 분석하고, 다양한 이미지 수 처리에서의 모델 성능을 이해하기 위한 진단 평가를 수행하였습니다.

---

### 전체 요약

LongLLaVA는 멀티모달 대형 언어 모델의 장문 문맥 이해 및 효율성 문제를 해결하기 위해 개발된 모델입니다. 이 모델은 하이브리드 아키텍처, 2D 이미지 토큰 압축, Mixture of Experts 접근 방식을 채택하여 성능과 효율성을 최적화합니다. 실험 결과, LongLLaVA는 다양한 벤치마크에서 뛰어난 성능을 보이며 특히 계산 자원의 효율적인 사용을 통해 높은 성능을 유지합니다. 이러한 혁신적인 접근 방식은 멀티모달 대형 언어 모델의 실용성 및 적용 범위를 한층 넓히는 데 기여할 것입니다.

---

이 요약을 바탕으로 발표 자료를 작성할 경우, 주요 섹션별 주요 기여점과 혁신을 중심으로 설명하고, LongLLaVA 모델의 전체적인 성능과 효율성을 강조하는 것이 좋습니다.