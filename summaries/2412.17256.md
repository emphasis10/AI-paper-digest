# B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.17256.pdf](https://arxiv.org/pdf/2412.17256.pdf)

### 1. 보고서 요약

#### 도입 및 배경
AI와 머신러닝 분야에서, 큰 언어 모델은 복잡한 문제 해결 능력을 보유하고 있지만, 고품질의 사람 제작 데이터세트에 대한 의존은 점점 지속 가능하지 않게 되었습니다. 이를 해결하기 위해, 복잡한 문제 해결 작업에서 '자기 개선' 방법이 중요한 해결책으로 등장했습니다. 이러한 방법은 모델이 자체 출력을 바탕으로 훈련을 진행해 성능을 향상시키는 체계입니다.

#### 핵심 요소: 탐색과 활용
자기 개선 과정의 핵심은 모델이 다양한 응답을 생성하는 탐색 능력과 외부 보상을 통해 고품질 솔루션을 선택하는 활용 능력입니다. 기존 방법들이 몇 회 반복 후 성장이 정체되는 문제를 해결하기 위해 이 두 요소의 동적 균형을 모니터링하는 새로운 접근법이 필요합니다.

#### 주요 기여: B-STAR
B-STAR라는 새롭고 균형잡힌 자기 학습 추론기를 개발하여 모델의 탐색과 활용을 동적으로 조절합니다. 이 방법은 평균 균형 점수를 높이기 위해 설정값을 조정하여 성능을 최대화하는 것을 목표로 합니다. 이 방법은 다양한 설정을 자동으로 조정하여 좋은 성능을 유지함과 동시에 모델의 발전을 돕습니다.

#### 실험 결과
수학 문제 해결, 코딩 도전 및 상식 추론에서 B-STAR는 다른 자기 개선 방법을 능가하는 성능을 보여줍니다. 또한, Pass@1 및 Pass@32와 같은 탐색 관련 메트릭 역시 개선되었다는 점에서 B-STAR의 우수성을 드러냅니다.

### 2. 총괄 요약
이 논문은 인공지능 모델의 자기 개선에서 탐색과 활용의 중요성을 강조하고, 이를 동적으로 조절하여 모델의 성능을 극대화하는 방법을 제안합니다. B-STAR는 학습 과정 동안 탐색과 활용의 균형을 맞추는 데 중점을 두며, 이를 통해 복잡한 문제 해결 능력을 향상시키는 데 주력합니다. 전체적으로 B-STAR는 기존 방법들에 비해 더 나은 성과를 보이며 인공지능의 자기 개선에 대한 새로운 지평을 열었다고 할 수 있습니다.