# Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.13863.pdf](https://arxiv.org/pdf/2410.13863.pdf)

파일에서 AI와 머신러닝 관련 논문에 대한 각 섹션을 요약하였습니다. 여기서는 중요한 기여와 혁신적 부분을 중심으로 설명하겠습니다.

1. **머리말:**
   이 논문은 대규모 언어 모델의 성공적인 스케일링이 비전 모델, 특히 텍스트에서 이미지로의 생성 모델에 어떻게 적용될 수 있는지를 탐구합니다. 비전 모델들의 경우, 전통적으로 사용되던 벡터 양자화(VQ) 방식은 정보 손실을 발생시켜 모델의 성능을 제한할 수 있습니다. 이러한 문제를 해결하기 위해, 랜덤 순서의 연속 토큰을 사용하는 새로운 방법을 제안하여 이미지 생성의 품질과 성능을 향상시킵니다.

2. **배경:**
   AR 모델은 텍스트에서 이미지로의 변환에서 현재 널리 사용되고 있는 diffusion 모델에 비해 뒤쳐져 왔습니다. 이를 해결하기 위해, 이 논문에서는 AR 모델을 벡터 양자화 없이 연속 토큰과 함께 사용하여 성능을 최적화하는 방법을 탐구합니다.

3. **모델 및 방법:**
   두 가지 주된 설계 요소는 토큰의 표현(이산 또는 연속)과 생성 순서입니다. 연속 토큰을 사용하는 모델이 시각적 품질 면에서 더 우수하다는 결과를 발견했습니다. 이를 통해 Fluid라는 새로운 모델을 만들었으며, 이 모델은 텍스트에서 이미지로의 변환 시탁도에서 최신 성과를 거두고 있습니다.

4. **결과:**
   Fluid 모델은 타이밍과 파라미터 크기에 따라 FID(Sample Quality Metric) 및 GenEval 점수에서 탁월한 성과를 보였습니다. 랜덤 순서로 연속 토큰을 사용하는 모델은 이러한 지표에서 최상의 성능을 보여 주었으며, 이는 비전을 위한 확장 가능성 있는 모델링 방법의 새로운 경로를 제공합니다.

5. **논의:**
   이 논문은 텍스트에서 이미지로의 생성에 있어 AR 모델이 확장성과 성능 면에서 가진 가능성을 강조합니다. 이러한 결과는 비전 모델에서도 성공적인 스케일링 법칙을 적용할 수 있는 가능성을 제시하며, 향후 연구에 유용한 통찰력을 제공할 것입니다.

**전체 요약:**
이 논문은 저명한 대규모 언어 모델의 스케일링 성공을 비전 AR 모델로 전환하고자 하는 연구입니다. 연구의 주된 기여는 연속 토큰을 사용함으로써 기존의 벡터 양자화 방식을 제거하고 성능을 크게 향상시킨 것입니다. Fluid 모델은 연속 토큰과 랜덤 순서 생성 방식의 장점을 활용하여 텍스트에서 이미지로의 변환 성능을 크게 향상시키며, 이는 비전과 언어 모델 간의 격차를 줄이는 새로운 벤치마크로 작용할 것입니다.