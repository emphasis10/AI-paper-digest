# IllumiNeRF: 3D Relighting without Inverse Rendering
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.06527.pdf](https://arxiv.org/pdf/2406.06527.pdf)

### 요약

#### 1. 논문 섹션별 요약 및 주요 내용

**Abstract**:
기존의 재조명 가능한 뷰 합성 방법들은 물체의 지오메트리(형상), 재료, 조명을 분리하여 역 렌더링을 통해 이미지를 생성하는 데 초점을 맞췄습니다. 그러나 이 방법은 취약하고 계산 비용이 많이 듭니다. 이 연구에서는 단순하게 이미지를 재조명한 후, Neural Radiance Field(NeRF)를 재구축하여 목표 조명 하에서 새로운 뷰를 생성하는 방식을 제안합니다. 이 방법은 여러 벤치마크에서 최첨단 결과를 달성하는 것으로 나타났습니다.

**Introduction**:
3D 객체의 재조명 가능한 뷰 합성은 AR, VR, 촬영, 영화 제작 등에 매우 중요한 문제입니다. 기존의 방법은 특정 조명 하에서만 작동하며, 새로운 조명 입력을 받으면 실패하는 경우가 많습니다. 이 연구는 간단한 2D Diffusion Model을 사용하여 먼저 이미지를 재조명한 후, 이를 바탕으로 3D NeRF를 재구축하는 새로운 패러다임을 제안합니다. 이 방법은 TensoIR과 Stanford-ORB 벤치마크에서 기존 방법들을 능가하는 성능을 보였습니다.

**Related Work**:
본 연구는 조명 조건을 고려한 diffusion 모델을 사용하여 단일 이미지 재조명과 3D 재구축을 수행합니다. 이전 연구에서는 inverse rendering과 가역적인 렌더링 방법을 주로 사용했습니다. 그러나 이러한 방법들은 계산 비용이 많이 들고 모호성이 존재합니다.

**Method**:
다양한 조명 조건 하에서 객체의 이미지를 재조명하려면, 물리 기반 모델 대신 잠재 변수를 도입하여 재조명된 데이터를 생성합니다. 이러한 잠재 변수를 통해 각 이미지를 독립적으로 재조명하고, latent NeRF 모델을 사용해 최종 3D 표현을 구축합니다. 이 모델은 여러 샘플을 생성하여 일관된 3D 표현을 만들어 냅니다.

**Experiments and Results**:
연구는 TensoIR 및 Stanford-ORB 벤치마크에서 기존 최첨단 방법들과 비교하여 우위를 보였습니다. 특히 향상된 성능은 모델이 specular highlights(반사적 하이라이트)를 더 잘 재현하는 데 있으며, 이는 기존 방법들이 재현하기 어려운 부분입니다.

**Limitations**:
모델의 한계는 고품질의 지오메트리 추정에 의존하므로, 누락된 구조나 부정확한 지오메트리는 결과 품질에 악영향을 미칠 수 있습니다. 또한, 실시간 재조명에는 적합하지 않습니다.

**Conclusion**:
이 연구는 재조명 가능한 3D 재구축을 위한 새로운 패러다임을 제안합니다. Diffusion Model을 사용해 다양한 재조명 이미지를 생성하고, 이를 Latent NeRF로 통합하여 3D 표현을 구축하는 것입니다. 이 패러다임은 기존의 inverse rendering 방법들을 능가하는 성능을 보였습니다.

#### 2. 전체 요약:

이 논문은 현재 연구되고 있는 재조명 가능한 3D 재구축 방법들의 한계를 극복하기 위해 제안된 새로운 접근 방식을 다룹니다. 기존 방법들은 복잡하고 계산 비용이 높은 반면, 이 연구에서는 보다 간단한 방법인 2D Diffusion Model을 사용하여 이미지들을 재조명한 후, 이를 NeRF로 통합하여 최종적으로 3D 표현을 구축하는 방식을 채택했습니다.

핵심 기여는 다음과 같습니다:
1. **새로운 패러다임 제안**: 역 렌더링 대신 2D 이미지 재조명을 통해 다수의 샘플을 생성하고, 이를 Latent NeRF로 통합하여 일관된 3D 표현을 생성.
2. **성능 우수**: TensoIR 및 Stanford-ORB 벤치마크에서 기존 역 렌더링 방법들보다 우수한 성능을 보였으며, 특히 반사적 특성을 더 잘 재현.

이 연구는 향후 데이터 캡처, 재료 및 조명 추정 등의 분야에서 실질적인 발전을 이룰 가능성을 보여줍니다. 이를 통해 AR, VR, 촬영, 영화 제작 등의 다양한 응용 분야에서 3D 콘텐츠 생성이 더욱 용이해질 것입니다.