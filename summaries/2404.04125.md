# No “Zero-Shot” Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.04125.pdf](https://arxiv.org/pdf/2404.04125.pdf)

이 논문은 웹에서 수집된 사전 훈련 데이터셋이 멀티모달 모델, 예를 들어 분류/검색을 위한 CLIP과 이미지 생성을 위한 Stable-Diffusion 같은 모델들의 인상적인 “제로샷(zero-shot)” 평가 성능의 기반이 되고 있지만, 이러한 멀티모달 모델들이 사전 훈련 데이터셋 내에서 하류(hard-downstream) 개념들의 빈도에 어떻게 영향을 받는지에 대해 명확하지 않다고 지적합니다. 본 연구에서는 멀티모달 모델들이 사전 훈련 데이터셋 내의 개념들의 빈도에 따라 어떻게 성능이 달라지는지에 대해 질문합니다. 연구진은 34개의 모델과 5개의 표준 사전 훈련 데이터셋(CC-3M, CC-12M, YFCC-15M, LAION-400M, LAION-Aesthetics)을 통해 이 질문을 종합적으로 조사하고, 300GB 이상의 데이터 아티팩트를 생성합니다.

연구 결과, 멀티모달 모델들이 사전 훈련 데이터에서 하류 개념의 성능 향상을 위해 필요한 데이터 양이 지수적으로 증가해야 한다는 것을 발견했습니다. 이는 선형적인 성능 향상을 위해 필요한 데이터 양이 로그-리니어(log-linear) 추세를 따른다는 것을 의미합니다. 이러한 추세는 사전 훈련과 하류 데이터셋 간의 샘플 수준 유사성을 제어하거나 순수하게 합성된 데이터 분포에 대한 실험에서도 지속됩니다.

이 연구는 멀티모달 모델들이 제로샷 일반화 능력을 가지고 있다고 보고된 실제 성능 대부분이 사전 훈련 데이터셋 내의 하류 개념들의 존재로 인한 것이라는 점을 밝혀냈습니다. 이는 모델들이 해당 개념에 대한 데이터를 지수적으로 더 많이 필요로 하며, 이는 극단적인 샘플 비효율성을 강조합니다.

또한, 이 연구는 다양한 사전 훈련 데이터셋에서 개념 분포가 긴 꼬리를 가지고 있음을 문서화하고, 사전 훈련 데이터셋 간에 개념 분포가 강하게 상관되어 있음을 발견했습니다. 이는 인터넷이 이러한 데이터셋의 공통 소스로서 자연스럽게 긴 꼬리 분포를 보이며, 이로 인해 파생된 모든 데이터셋도 유사한 긴 꼬리 행동을 보일 것임을 시사합니다.

연구진은 "Let It Wag!"라는 새로운 긴 꼬리 테스트 데이터셋을 소개하고, 현재 모델들이 공개된 데이터셋(LAION-2B, DataComp-1B 등)과 폐쇄된 데이터셋(OpenAI-WIT, WebLI 등) 모두에서 이 데이터셋에서의 성능이 크게 떨어짐을 증명함으로써, 이러한 관찰이 폐쇄된 데이터셋에도 전이될 수 있음을 제시합니다. 연구진은 300GB 이상의 데이터 아티팩트를 공개하며, 멀티모달 기반 모델의 사전 훈련 데이터셋 분석 비용을 절감하고, 향후 멀티모달 모델의 데이터 중심 이해를 위한 연구를 촉진합니다.

---
이 요약은 해당 논문의 핵심 내용과 발견을 소개합니다. 멀티모달 모델의 제로샷 일반화 능력에 대한 현재의 이해를 재평가하고, 이 분야에서의 진전을 위한 새로운 방향을 제시합니다.