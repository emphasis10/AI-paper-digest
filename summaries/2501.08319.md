# Enhancing Automated Interpretability with Output-Centric Feature Descriptions
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.08319.pdf](https://arxiv.org/pdf/2501.08319.pdf)

1. 각 섹션의 요약:

- **서론**: 이 논문은 대규모 언어 모델(LLM)에서 자동 해석성을 개선하기 위한 새로운 방법을 제안합니다. 기존의 자동화 해석 파이프라인은 입력 활성화에 기반한 설명을 생성하지만, 이는 출력에 대한 인과적 영향을 포착하지 못한다는 한계가 있습니다. 이를 해결하기 위해 출력 중심의 방법론인 VocabProj와 TokenChange를 소개합니다.

- **문제 설정**: 본 연구는 LLM의 계산 단위를 '특징'으로 자동으로 설명하는 방법을 제시합니다. 특징은 LLM의 은닉 벡터를 다양한 특징 공간으로 변환하는 방법을 사용하여 표현됩니다. 이 방법론은 인간이 이해할 수 있는 특징 설명을 자동으로 생성하여 대규모 파이프라인에 통합할 수 있는 기능을 목표로 합니다.

- **방법론**: VocabProj는 특징을 모델의 어휘 공간으로 변환하여 중요한 토큰을 사용하는 방법이며, TokenChange는 모델 출력에서 특징을 증폭할 때 토큰 확률 변화가 가장 큰 토큰을 고려하는 방법입니다. 이 두 가지 방법은 계산 효율성이 높아, 활성화 입력에 의존하지 않고도 설명을 생성할 수 있습니다.

- **결과와 분석**: 실험 결과, 특징 설명에서 입력 중심 및 출력 중심 방법을 결합하면 더 나은 설명을 제공할 수 있으며, 이는 특히 '죽은' 특징을 활성화하는 데 효과적입니다. 이는 출력 중심 방법이 기존의 입력 중심 방법보다 효율적일 수 있음을 시사합니다.

- **결론**: 연구는 두 가지 상보적 평가 프레임워크를 제안하며, 기존의 MaxAct 방법론의 단점을 보완할 수 있는 출력 중심 방법을 제안합니다. 이를 통해 더 충실한 특징 설명을 가능하게 하고 지금까지의 파이프라인을 개선할 수 있음을 입증했습니다.

2. 전체 요약:

이 논문은 기존의 언어 모델 해석 파이프라인의 한계를 극복하기 위한 방법론을 제안합니다. 핵심 기여는 VocabProj와 TokenChange와 같은 효율적인 출력 중심 방법을 통해 자동 생성된 특징 설명의 인과적 정확성을 개선한 것입니다. 이는 특히 입력 기반 설명의 경제성과 정확성 측면에서 두드러진 성과를 보입니다. 이러한 방법론은 언어 모델의 해석 가능성을 전반적으로 높이고, 대규모 특징 해석 파이프라인의 성능을 향상시킬 수 있습니다.