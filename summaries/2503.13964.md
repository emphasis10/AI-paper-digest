# MDocAgent: A Multi-Modal Multi-Agent Framework for Document Understanding
## TL;DR
## Summary
- [https://arxiv.org/pdf/2503.13964.pdf](https://arxiv.org/pdf/2503.13964.pdf)

1. 각 섹션 요약:

- **서론**: 이 논문은 RAG(검색 보강 생성) 기법이 텍스트나 이미지 중 하나에만 초점을 맞추기 때문에, 복잡한 다중 모드 문서 이해(DocQA) 작업에 적합하지 않다는 문제를 제기합니다. 이를 해결하기 위해, 본 논문은 MDocAgent라는 새로운 프레임워크를 소개합니다. 이 프레임워크는 여러 에이전트가 협력하여 문서의 텍스트와 이미지를 통합하고 이해하는 방식으로, 정보의 과부하를 효과적으로 다룹니다.

- **다중 모드 다중 에이전트 프레임워크**: MDocAgent는 5단계로 문서 처리 과정을 설명합니다. 첫 단계에서는 문서를 OCR을 통해 텍스트와 이미지로 변환하고, 다중 모드 컨텍스트 검색을 통해 관련 텍스트와 이미지를 수집합니다. 그런 다음, 일반 에이전트가 초기 응답을 생성하고, 중요한 정보를 추출하여 특화된 에이전트들에 제공하며 최종적으로 요약 에이전트가 통합된 답변을 생성합니다.

- **결론 및 기여**: 본 논문의 주요 기여는 다중 모드, 다중 에이전트 시스템을 통해 DocQA 성능을 크게 개선하는 것입니다. 실험 결과, 다섯 가지 벤치마크에서 SOTA(최신 기술) 대비 12.1%의 성능 향상을 보였습니다. 또한, 에이전트 각각의 기여도를 입증하는 연구도 진행되었습니다.

2. 전체 요약:

본 논문은 복잡한 문서 질문 답변(DocQA) 문제를 해결하기 위해 MDocAgent라는 다중 모드, 다중 에이전트 시스템을 제안합니다. 이 시스템은 텍스트 및 이미지에 대한 전문 에이전트들이 협력하여 문서의 내용을 통합적으로 이해하고 처리합니다. MDocAgent는 기존의 RAG 기반 방식들이 가지고 있는 한계를 극복하고, 문서의 모든 모드를 포함하는 보다 정확하고 포괄적인 응답을 생성할 수 있도록 지원합니다. 실험에서는 LVLMs, 다중 모드 RAG 방법을 포함한 여러 최신 기술들과 비교하여 우수성을 입증하였으며, 향후에는 에이전트 간의 보다 발전된 통신 및 외부 지식 소스의 통합을 모색할 계획입니다.