# Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer Selection in Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.12939.pdf](https://arxiv.org/pdf/2405.12939.pdf)

### 섹션별 요약

#### 1. Introduction
이 섹션에서는 대형 언어 모델(LLMs)이 복잡한 추론 작업에서 성과를 내고 있지만 여전히 인간 수준의 추론 능력에 미치지 못한다고 설명합니다. 이를 해결하기 위해, "Chain-of-Thought (CoT)" 기법이 도입되었으며, 이는 LLM이 중간 단계를 거쳐 최종 답에 도달하게 합니다. 기존의 방법들은 단일 추론 체인의 무작위성을 문제로 지적하며, 다양한 추론 체인을 샘플링하고 일관된 답을 선택하는 방법을 제안합니다.

#### 2. Related Work
기존 연구들은 주로 LLM의 추론 능력 향상에 중점을 둡니다. CoT 기법은 일관된 풀이 과정을 만들어 LLM의 성능을 높이며, 여러 추론 체인을 결합해 보다 정확한 답을 도출하는 방법들이 연구되었습니다. 그러나 이러한 방법들은 여전히 잘못된 답이 다수일 때는 실패할 가능성이 높습니다.

#### 3. Proposed Method
AoR (Aggregation of Reasoning)이라는 새로운 계층적 추론 집계 프레임워크를 제안합니다. 이 방법은 답의 빈도수를 기반으로 하지 않으며, 추론 과정을 평가해 답을 선택합니다. 또한, 추론 체인의 수를 동적으로 조정하여 과제의 복잡성에 따라 샘플링합니다. 이를 통해 LLM의 추론 성능을 최적화하면서도 효율성을 유지합니다.

#### 4. Experiments
실험 결과는 다양한 복잡한 추론 작업에서 AoR이 기존의 방법들을 능가함을 보여줍니다. 추가 샘플링을 통해 추론 오버헤드를 줄이면서도 성능을 최적화합니다. 전반적인 실험은 AoR의 효과성과 비용 효율성을 입증합니다.

#### 5. Conclusion
논문에서는 기존의 답 빈도수에 기반한 방법의 한계를 지적하고, 추론 과정을 고려한 AoR의 필요성을 강조합니다. AoR은 동적 샘플링을 통해 성능과 비용 효율성을 동시에 달성하였습니다. 이를 통해 LLM의 복잡한 추론 작업에서의 성능을 크게 향상시킬 수 있음을 확인하였습니다.

### 종합 요약
이 논문은 대형 언어 모델의 복잡한 추론 작업에서 성능을 향상시키기 위해 새로운 계층적 추론 집계 프레임워크인 AoR을 제안합니다. 기존의 방법들이 올바르지 않은 답이 다수일 때 실패하는 문제를 해결하기 위해, AoR은 추론 과정을 평가해 더 정확한 답을 선택합니다. 실험 결과, AoR은 다양한 복잡한 추론 작업에서 기존 방법들보다 뛰어난 성능을 보였으며, 추가 샘플링으로 효율성을 극대화하였습니다. 이 연구는 LLM의 추론 능력을 한층 더 향상시키는 중요한 기여를 하였습니다.