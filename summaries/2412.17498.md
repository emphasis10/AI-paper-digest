# DRT-o1: Optimized Deep Reasoning Translation via Long Chain-of-Thought
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.17498.pdf](https://arxiv.org/pdf/2412.17498.pdf)

### 1. 논문 각 섹션 요약

**서론:**
최근 O1 모델과 비슷한 모델들이 수학 및 코딩과 같은 추론 작업에서 큰 성과를 보이고 있습니다. 논문에서 소개하는 DRT-o1은 이러한 긴 사고 과정을 기계 번역에 적용한 사례로, 은유 및 직유가 포함된 문장 번역 시 긴 사고 과정이 어떻게 도움이 되는지를 다룹니다.

**DRT-o1 데이터:**
DRT-o1 출력을 위한 데이터 수집은 문학작품에서 은유나 직유가 있는 문장을 찾아내는 과정으로 시작됩니다. 수집된 문장은 최종적으로 길게 사고해야 하는 번역의 예시로 저장되고, 이에 맞춘 구조로 번역 데이터가 생성됩니다.

**문학 작품 채굴:**
구텐베르크 프로젝트 등의 공공 도메인에서 문학 작품을 채집하여 은유나 직유가 포함된 문장을 탐색합니다. 이들 중 비유적 표현이 제대로 번역되지 못한 문장은 긴 사고 과정을 통해 번역하여 DRT-o1 모델을 훈련했습니다.

**다중 에이전트 프레임워크:**
이 프레임워크에서는 번역기, 조언자, 평론가라는 세 에이전트가 협력하여 번역을 개선합니다. 번역자는 초안을 제공하고, 조언자는 피드백을 주며, 평론가는 평가하여 필요한 경우 수정 단계를 반복하여 최적화된 번역을 제공합니다.

**긴 사고의 재구성:**
다중 에이전트 협업 과정 후에 긴 사고 과정을 통해 최종 번역 샘플을 얻습니다. 이렇게 변환된 번역은 GPT-4o 등을 사용해 가독성을 높이고 최종 데이터로서 사용됩니다.

**실험과 결과:**
DRT-o1 모델인 DRT-o1-7B와 DRT-o1-14B는 이전 모델보다 BLEU 및 CometScore에서 뛰어난 성능을 보여 번역의 효과를 입증했습니다.

### 2. 전체 요약

이 논문은 새로운 DRT-o1 모델을 통해 긴 사고 과정을 기계 번역에 적용하여 번역 품질을 향상시키려는 시도를 소개합니다. 이 모델은 은유 및 직유가 있는 문장을 번역하는 데 초점을 맞추며, 문학 문장 채굴과 다중 에이전트 협력 방식을 사용하여 데이터 샘플을 수집하고 개선된 번역을 제공합니다. 실험 결과, DRT-o1은 기존 번역 모델에 비해 향상된 성능을 보여주며, 특히 복잡한 의미의 텍스트 번역에 있어서 효과적임을 보였습니다.