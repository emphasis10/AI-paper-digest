# DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.16657.pdf](https://arxiv.org/pdf/2411.16657.pdf)

1. **논문의 세부 내용 요약**

   **서론**
   이 논문은 이야기 비디오 생성(SVG, Storytelling Video Generation) 모델의 필요성을 강조하고 있으며, 기존 비디오 생성의 한계를 지적했습니다. SVG 모델은 복잡한 장면 전환과 자연스러운 객체 움직임을 생성하여 이야기를 더 몰입감 있게 전개할 수 있게끔 돕습니다.

   **관련 연구**
   비디오 생성 접근 방식의 진화와 함께 이야기 생성의 발전을 논하고 있으며, 대규모 언어 모델(LLM)과 참조 및 검색이 포함된 동영상 생성의 필요성을 강조합니다.

   **방법론**
   - **계획 생성**: 사용자에게 제공된 이야기를 바탕으로 하이레벨 및 세부 계획을 생성합니다. 이를 통해 각 장면의 서사적 일관성을 보장합니다.
   - **동작 및 주제 학습**: 시나리오와 맞는 동작 비디오를 자동으로 검색하여, 이를 기반으로 동작 및 주제 선행 학습을 진행합니다.
   - **SR3AI**: 객체와 동작의 결합을 위한 공간-시간 기반 3D 주의 메커니즘을 도입하여 비디오 생성을 미세 조정합니다.

   **실험**
   DREAMRUNNER는 기존의 스토리-비디오 생성과 텍스트-비디오 생성 작업에서 우수한 성능을 발휘하고 있으며, 다양한 변수가 있는 환경에서도 효과적으로 사용할 수 있음을 보여주었습니다.

   **결론**
   DREAMRUNNER는 이야기-비디오 생성에서 물체 간 상호작용과 장면 일관성 유지를 통해 더 나은 성능을 발휘함을 증명합니다. 특히 다중 장면 전환에서 원활한 실행을 보장합니다.

2. **전체 요약**
   이 논문은 이야기-비디오 생성의 새로운 패러다임을 제시하는 것으로, 복잡한 장면과 다채로운 동작을 효과적으로 생성할 수 있는 DREAMRUNNER 방법론을 소개하고 있습니다. 주요 기여 부분은 LLM 및 검색을 활용한 계층적 계획, 동작 및 주제 선행 학습, 그리고 SR3AI 모듈을 통한 정교한 비디오 생성입니다. 이 접근법은 기존 방법보다 캐릭터 일관성과 텍스트 적합성 면에서 뛰어난 성능을 보이며, 실험적으로 그 가능성을 뒷받침하고 있습니다.