# FinMTEB: Finance Massive Text Embedding Benchmark
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.10990.pdf](https://arxiv.org/pdf/2502.10990.pdf)

각 섹션의 요약은 다음과 같습니다:

1. **소개**
   이 논문은 자연어 처리에서 중요하게 사용되는 임베딩 모델에 대해 논의하며, 특히 금융 분야에서의 임베딩 모델의 효과성을 탐구합니다.

2. **관련 연구**
   다양한 일반적 임베딩 모델과 그 발전 과정, 그리고 기존의 평가 방식들에 대해 설명합니다. 특히 금융과 같은 특정 분야에서는 기존 모델의 한계가 드러난다고 지적합니다.

3. **FinMTEB 벤치마크**
   금융 분야에 특화된 임베딩 평가 벤치마크인 FinMTEB를 소개하고, 이를 통해 다양한 임베딩 모델의 성능을 비교합니다. FinMTEB는 금융 분야의 특수성을 반영하여 여러 과제에서의 성능을 포괄적으로 평가할 수 있습니다.

4. **데이터 형성 및 훈련 데이터 구성**
   금융 분야에 적합한 데이터를 구성하는 방법을 설명하며, 특히 전문가가 검증한 데이터와 페르소나 기반의 데이터를 활용하여 종합적인 훈련 데이터를 구축합니다.

5. **훈련 파이프라인**
   다양한 임베딩 모델의 성능을 향상시키기 위해 훈련 파이프라인을 설명하고, 특히 정보 대조 학습을 위한 부정 샘플을 식별하는 방법에 대해 논의합니다.

6. **실험 결과 및 분석**
   실험 결과, 도메인 적응이 모델의 성능을 상당히 향상시킴을 보여주며, LLM 기반 모델이 전통적인 접근 방식에 비해 우수한 성능을 보였습니다.

7. **결론 및 미래 작업**
   금융 분야에 특화된 임베딩 모델의 필요성과 그 성과를 강조하며, 향후 연구 방향을 제시합니다.

**논문의 전체 요약:**
이 논문은 금융 분야에 최적화된 임베딩 모델을 개발 및 평가하는 데 중점을 두고 있습니다. 기존의 일반적 임베딩 모델의 한계를 극복하고, 금융 분야의 특수성을 반영한 FinMTEB 벤치마크를 통해 성능을 측정하여, 도메인 적응이 효과적임을 실증적으로 보여줍니다. 주요 기여는 금융 분야에 적합한 훈련 데이터 구성과 평가를 통한 LLM 기반 모델의 성능 향상입니다.