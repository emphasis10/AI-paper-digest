# Training Large Language Models to Reason in a Continuous Latent Space
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.06769.pdf](https://arxiv.org/pdf/2412.06769.pdf)

1. 논문의 각 섹션 요약:

1.1 **서론**: 대형 언어 모델(LLM)은 인간 언어에 대한 광범위한 사전 훈련을 통해 놀라운 추론 능력을 보여주었습니다. 하지만 전통적인 언어 공간에서의 이유 추론은 특정 제약이 있습니다. 본 논문에서는 LLM이 언어 제약 없이 잠재 공간에서 이유 추론을 수행할 수 있는 새로운 패러다임인 Coconut(Chain of Continuous Thought)을 제안합니다.

1.2 **Coconut의 이론적 배경**: Coconut은 전통적인 연속사고(CoT) 추론과 달리, 마지막 숨겨진 상태를 다음 입력 임베딩으로 사용하는 방식을 채택하여 이유 추론을 언어 공간이 아닌 잠재 공간에서 수행할 수 있도록 합니다. 이를 통해 CoT에서의 제약을 극복하고 모델의 추론 능력을 크게 향상시킬 수 있습니다.

1.3 **실험 설계 및 결과**: 다양한 데이터 세트에 대한 실험을 통해 Coconut이 논리적 추론 및 수학적 문제 해결에 있어 효과적인 이유 추론을 가능하게 한다는 것을 보여줍니다. 특히, 논리적 및 계획 집약적 과제에서 Coconut이 더 적은 토큰을 생성하면서도 CoT를 넘어서는 성능을 보임으로써 잠재 추론의 가능성을 입증합니다.

1.4 **결론**: 잠재 공간을 활용한 이유 추론의 장점을 강조하면서 Coconut이 LLM의 이유 추론 능력을 증대시키는 데 크게 기여함을 결론짓습니다. 향후 연구를 통해 잠재 추론 방법을 더욱 발전시킬 필요가 있으며, 이는 고급 기계 추론 시스템의 발전에 기여할 것입니다.

2. 종합 요약:

본 논문은 대형 언어 모델(LLM)이 전통적인 언어 공간이 아닌 잠재 공간에서 이유 추론을 수행할 수 있는 새로운 패러다임인 Coconut(Chain of Continuous Thought)을 제안합니다. Coconut은 마지막 숨겨진 상태를 다음 입력 임베딩으로 활용하여, 언어 토큰 생성을 뛰어넘는 잠재 공간에서의 추론 과정을 가능하게 합니다. 이를 통해 논리적 추론 및 계획을 필요로 하는 과제에서 놀라운 성능을 발휘하며, LLM의 추론 능력을 확장합니다. 향후 Coconut과 유사한 잠재 추론 방법들이 기계 추론의 발전에 기여할 가능성을 제시합니다.