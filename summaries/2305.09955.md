# Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2305.09955.pdf](https://arxiv.org/pdf/2305.09955.pdf)

### 섹션 요약

#### 1. 서론 (Introduction)
대형 언어 모델(LLMs)은 방대한 지식을 인코딩하는 능력을 보여줬지만, 새로운 지식 업데이트가 어려워 오류가 발생하고 긴꼬리(rare) 사실을 인코딩하는 데 한계를 보임. 기존 접근법으로는 검색 시스템을 통해 외부 지식을 활용하거나 생성된 지식을 통한 프롬프트 방법이 있음.

#### 2. 주요 기여 및 혁신점
KNOWLEDGE CARD는 모듈형 프레임워크로, LLM에 새로운 지식을 추가하기 용이하게 설계됨. 지식 카드는 특정 도메인과 소스로부터 교육된 작은 언어 모델이며, 이를 통해 배경 지식을 생성하고 통합함. 세 가지 선택자를 통해 문서의 품질을 관리하고, 두 가지 통합 방식을 제시하여 LLM 성능을 향상시킴.

#### 3. 방법론 (Methodology)
- **지식 카드(Knowledge Cards):** 특정 도메인에서 교육된 작은 언어 모델로, 모듈형 지식 저장소 역할을 함.
- **지식 선택자(Knowledge Selectors):** 문서의 관련성, 간결성, 사실성 등을 평가하여 문서 품질을 관리.
- **통합 접근법(Integration Approaches):** 지식 카드를 LLM에 통합하는 두 가지 방식을 제시: 아래로부터 위로(Bottom-Up)와 위로부터 아래로(Top-Down).

#### 4. 실험 및 결과
KNOWLEDGE CARD는 MMLU, 미드텀 QA, 그리고 다중 도메인 지식 통합 등 다양한 태스크에서 기존 모델들을 능가하는 성능을 보임. 특히, 미국 중간선거와 관련된 문제에서 55.6% 이상의 정확도 증가를 보였음. 이는 작은 모델을 통해 대형 모델의 지식 공백을 채우는 가능성을 시사함.

#### 5. 결론 (Conclusion)
KNOWLEDGE CARD는 LLM 성능 향상을 위한 혁신적 방법으로, 지식의 모듈성과 협업적 통합을 통해 지속적으로 업데이트 가능함. 이는 대형 모델을 반복적으로 재교육하는 비용과 탄소 발자국을 줄일 수 있는 잠재력을 가짐.

### 전반적인 요약
본 논문은 KNOWLEDGE CARD라는 모듈형 프레임워크를 통해 대형 언어 모델(LLMs)의 지식 공백을 채우는 방법을 제시함. KNOWLEDGE CARD는 작은, 특정 도메인 지식을 담고 있는 언어 모델들을 활용하여, LLM에 모듈형으로 새 지식을 플러그인 방식으로 통합함. 다양한 태스크에서 기존 모델을 능가하는 성능을 보이며, 특히 최신 정보 업데이트가 중요한 환경에서 우수한 성과를 보임. 이는 커뮤니티 기반의 협업을 통해 지속적으로 지식을 추가하고, 이를 통한 탄소 발자국 감소와 비용 절감을 목표로 함.

## Similar Papers
- [Estimating Knowledge in Large Language Models Without Generating a Single Token](2406.12673.md)
- [Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting](2407.08223.md)
- [T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings](2406.19223.md)
- [Improving Retrieval Augmented Language Model with Self-Reasoning](2407.19813.md)
- [In-Context Learning with Long-Context Models: An In-Depth Exploration](2405.00200.md)
- [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](2405.19325.md)
- [BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine](2405.00465.md)
- [LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report](2405.00732.md)
- [Stronger Random Baselines for In-Context Learning](2404.13020.md)
