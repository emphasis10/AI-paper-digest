# EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.16858.pdf](https://arxiv.org/pdf/2406.16858.pdf)

### 논문 요약 (각 섹션 요약)

#### 1. 서론 (Introduction)
현대의 대형 언어 모델(LLM)은 다양한 분야에서 뛰어난 성능을 보여주지만, 매개변수의 크기가 커짐에 따라 추론 속도가 느려지고 비용이 증가합니다. 이러한 문제를 해결하기 위해 비선형 샘플링 방법이 제안되었으며, 주어진 문맥에서 여러 개의 토큰을 한 번에 생성하여 추론 지연을 줄입니다. EAGLE-2는 기존의 EAGLE 모델을 확장하여 문맥-의존 동적 초안 트리를 도입함으로써 초안 토큰의 수용률을 높이는 방식을 제시합니다. 이를 통해 20%-40%의 속도 향상을 이루고, 생성된 텍스트의 분포 변화 없이 손실 없는 가속화를 구현합니다.

#### 2. 관련 연구 (Related Work)
LLM의 추론을 가속화하기 위한 다양한 방법들이 연구되었으며, 이는 양자화, 가지치기, 지식 증류 등의 기술로 구현되었습니다. 이러한 방식들은 모델의 연산량을 줄여 생성 지연을 감소시키지만 품질 저하의 우려가 있습니다. 손실 없는 가속화를 위한 비선형 샘플링 방법도 EAGLE-2의 중요한 배경입니다.

#### 3. EAGLE-2 모델 (EAGLE-2 Model)
EAGLE-2는 기존의 정적인 초안 트리 대신 문맥-의존 동적 초안 트리를 사용합니다. 이는 초안 토큰의 수용률이 위치 뿐만 아니라 문맥에 따라 달라진다는 점을 활용한 것입니다. EAGLE-2 모델의 초안 모델은 신뢰 점수를 사용하며 정확도가 높아, 초안 토큰의 수용률을 잘 근사합니다. 실험 결과, EAGLE-2는 다양한 데이터셋과 LLM에서 높은 속도 향상을 보였습니다.

#### 4. 실험 및 평가 (Experiments and Evaluation)
EAGLE-2는 Vicuna, LLaMA-Chat 등의 모델에 적용하여 성능을 평가했으며, MT-Bench, HumanEval, GSM8K, Alpaca 등 다양한 데이터셋에서 시험했습니다. 실험 결과 EAGLE-2는 평균적으로 3.05배에서 4.26배까지 속도 향상을 이루어 기존의 방법들보다 뛰어났습니다. 특히, EAGLE-2는 초안 검증 주기 동안 평균적으로 4-5.5개의 토큰을 생성하여 다른 방법에 비해 두 배에 달하는 효율성을 보였습니다.

#### 5. 결론 (Conclusion)
EAGLE-2는 LLM을 위한 효율적이고 손실 없는 비선형 샘플링 방법을 제안합니다. 초안 모델의 신뢰도가 높아 초안 토큰의 수용률을 잘 근사하므로, 문맥-의존 초안 트리를 사용해 속도 향상을 이루었습니다. 실험 결과 EAGLE-2는 다양한 모델과 데이터셋에서 최고 속도 향상을 보였습니다.

### 전체 요약
논문 "EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees"는 대형 언어 모델(LLM)의 추론 속도를 대폭 향상시키기 위한 혁신적인 방법인 EAGLE-2를 제시합니다. 기본 개념은 기존의 정적 초안 트리 대신 문맥-의존 동적 초안 트리를 도입하여 초안 토큰의 수용률을 높이는 것입니다. EAGLE-2는 다양한 모델과 데이터셋에서 3.05배에서 4.26배의 속도 향상을 이루었으며, 추가적인 훈련 없이 손실 없는 가속화를 구현합니다. 이 논문은 특히 신뢰 점수 기반의 초안 모델을 사용해 효율성을 극대화했으며, LLM의 실시간 응답성을 크게 향상시킬 수 있는 가능성을 보여줍니다.