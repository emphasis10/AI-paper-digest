# MotionBench: Benchmarking and Improving Fine-grained Video Motion Understanding for Vision Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.02955.pdf](https://arxiv.org/pdf/2501.02955.pdf)

### 주제별 요약

1. **서론**
   - 이 논문은 시각 언어 모델(VLMs)이 비디오 이해에 미치는 최근의 발전을 강조합니다. 그러나, 대부분의 기존 벤치마크는 모션 수준의 세분화된 이해를 충분히 평가하지 않으며, 이를 해결하기 위해 MotionBench라는 새로운 평가 벤치마크를 제안합니다.

2. **평가 벤치마크**
   - MotionBench는 비디오 이해 모델의 모션 인식 능력을 평가합니다. 이 벤치마크는 모션 인식, 이벤트 인식, 스토리 인식 세 가지 수준으로 나누어져 있으며, 이는 비디오에서의 동작을 감지하고 해석하는 데 중요한 역할을 합니다.

3. **TE Fusion 방법론**
   - Through-Encoder(TE) Fusion은 시각 인코더 내에서 피처 융합을 깊이 통합하여 비디오 피처 표현을 개선하는 혁신적인 방법입니다. TE Fusion은 특히 고압축 환경에서 최첨단 결과를 달성하며, 모션 인지 능력의 발전에 기여합니다.

4. **주요 기여 및 혁신점**
   - 논문은 비디오 모델이 모션 수준의 이해에 어려움을 겪고 있음을 실험적으로 보여주며, 이를 해결하기 위한 전용 벤치마크의 필요성을 강조합니다. 특히, TE Fusion 방법은 높은 압축률에서도 성능 저하가 거의 없으며, 기존 방법보다 11.8%에서 18.7% 이상의 성능 향상을 보여주었습니다.

5. **결론**
   - MotionBench를 통해 모션 수준의 이해가 중요한 비디오 모델 성능에서 상당 부분 간과되고 있음을 발견했습니다. TE Fusion 방법을 통해 비디오 피처 표현을 개선하고 모션 인지 능력을 향상시키기 위한 도전 과제를 제시합니다.

### 전체 요약

이 논문은 시각 언어 모델이 비디오 이해에서 세밀한 모션 이해 능력을 향상시키기 위한 새로운 벤치마크인 MotionBench를 제안합니다. MotionBench는 모션 인식, 이벤트 인식, 스토리 인식의 세 가지 수준으로 VLMs의 이해도를 평가하며, 특히 모션 수준의 세분화를 강조합니다. TE Fusion 방법은 기존 모델들이 가진 모션 이해의 한계를 극복하고, 특히 고압축 환경에서 우수한 성능을 발휘합니다. 이를 통해 모션 인지가 중요한 비디오 앱의 성능 향상에 기여할 수 있음을 보여줍니다.