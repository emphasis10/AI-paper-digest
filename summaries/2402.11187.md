# LaCo: Large Language Model Pruning via Layer Collapse
## TL;DR
## Summary
- [https://arxiv.org/pdf/2402.11187.pdf](https://arxiv.org/pdf/2402.11187.pdf)

### 섹션 요약

#### 1. 소개
최근 트랜스포머(Transformer)를 기반으로 한 대형 언어 모델(LLM)은 다양한 작업에서 뛰어난 능력을 보여주고 있습니다. 그러나 모델이 커지면서 계산 비용이 증가하고 이는 연구자들과 기업에게 큰 부담이 됩니다. 이를 해결하기 위해 모델 양자화, 지식 증류, 모델 프루닝(pruning) 등의 다양한 접근 방식이 제안되었습니다. 그러나 기존 방법들은 하드웨어 지원 제한, 높은 훈련 비용, 모델 구조의 변경 등의 문제점을 가지고 있습니다. 이에 본 논문에서는 Layer Collapse(LaCo)라는 새로운 레이어별 프루닝 방법을 제안합니다. 이는 모델의 후방 레이어들을 앞쪽 레이어로 합쳐서 구조를 유지하면서 모델 크기를 빠르게 줄이는 방법입니다.

#### 2. 방법
LaCo의 핵심 개념은 연속되는 레이어들의 파라미터 차이를 보존하면서 공통된 파라미터를 병합해나가는 것입니다. 이 과정을 Reserving-Differences-while-Seeking-Common(RDSC) Layer Merge라고 명명합니다. 이 방법을 통해 특정 레이어와 그 뒤를 잇는 레이어들의 파라미터 차이를 합치고, 이를 기반으로 레이어들을 제거합니다. LaCo는 모델의 출력 표현을 최대한 유지하면서 레이어들을 병합하여 모델 크기를 줄입니다.

#### 3. 실험 및 결과
LaCo는 모델의 크기를 25-30% 프루닝 비율에서 평균 작업 성능을 80% 이상 유지하며, 기존의 구조적 프루닝 방법보다 뛰어난 성능을 보였습니다. 또한, 후속 훈련 후에도 원래 모델의 파라미터를 효과적으로 계승하여, 적은 양의 훈련으로도 원래 모델의 손실 수렴 수준으로 빠르게 복구할 수 있음을 확인했습니다. 10-15% 프루닝 비율에서 모델 성능 감소가 크지 않으며, 50% 프루닝 비율에서도 모델 성능이 약 70%를 유지할 수 있는 안정성을 보여줍니다.

#### 4. 관련 연구
모델 크기 증가로 인한 높은 훈련 및 추론 비용을 줄이기 위한 주요 방법으로 모델 양자화, 지식 증류, 모델 프루닝이 존재합니다. 모델 양자화는 고정밀도를 낮추는 방식으로, 지식 증류는 큰 모델의 지식을 작은 모델로 전이합니다. 기존의 모델 프루닝 방법은 비구조적 프루닝과 구조적 프루닝으로 나눌 수 있으며, 비구조적 프루닝은 주로 모델 희소성을 높이는 방식이고, 구조적 프루닝은 모델 구조를 수정하거나 제거하는 방식입니다. 그러나 기존 방법들은 모델 성능에 큰 영향을 미치거나 특정 하드웨어 지원이 필요합니다. 반면에 LaCo는 모델 내부 구조를 유지하면서도 간결한 구조를 가집니다.

#### 5. 결론
본 논문에서는 Layer Collapse라는 간결한 레이어별 구조적 프루닝 방법을 제안합니다. 이는 후방 레이어를 전방 레이어로 병합하여 모델 크기를 빠르게 줄이며, 특별한 하드웨어 지원 없이 모델의 내부 구조를 유지할 수 있습니다. 실험 결과, LaCo는 기존의 최신 구조적 프루닝 방법보다 뛰어난 성능을 보였으며, 후속 훈련을 통해 모델 성능을 신속하게 회복할 수 있음을 확인했습니다. 또한, LaCo의 프루닝 동기와 다양한 프루닝 비율에서의 성능을 평가했습니다.

### 전체 요약

본 논문은 트랜스포머 기반의 대형 언어 모델(LLM)의 크기 증가로 인한 비용 문제를 해결하기 위해 Layer Collapse(LaCo)라는 새로운 레이어별 프루닝 방법을 제안합니다. LaCo는 모델의 후방 레이어들을 앞쪽 레이어로 병합하여 구조를 유지하면서 모델 크기를 빠르게 줄이며, 평균 작업 성능의 80% 이상을 유지합니다. 또한 LaCo는 후속 훈련을 통해 적은 양의 훈련으로 원래 모델의 손실 수렴 수준으로 빠르게 복구할 수 있습니다. LaCo는 기존의 모델 양자화, 지식 증류, 모델 프루닝 방법들과 비교하여 모델 성능을 유지하면서도 구조적 변화를 최소화하는 간결한 접근 방식을 제공합니다. 이를 통해 더 많은 연구자들과 기업들이 대형 모델을 효율적으로 사용할 수 있게 되어 AI 발전에 기여할 수 있습니다.