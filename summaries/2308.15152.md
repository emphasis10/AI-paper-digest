# Reducing shared memory footprint to leverage high throughput on Tensor Cores and its flexible API extension library
## TL;DR
## Summary
- [https://arxiv.org/pdf/2308.15152.pdf](https://arxiv.org/pdf/2308.15152.pdf)

### 논문의 주요 내용 요약

#### 1. 서론 (Introduction)
이 논문은 텐서 코어(Tensor Core)의 높은 성능을 최대한 활용하기 위해 공유 메모리 사용을 최적화하는 방법을 제안합니다. 특히, 텐서 코어와 공유 메모리 간의 비효율적인 비율(Bytes-per-Flops)을 해결하기 위해 WMMA API 확장 라이브러리를 개발하였습니다.

#### 2. 배경 (Background)
- **공유 메모리 (Shared Memory)**: 공유 메모리는 높은 대역폭과 낮은 지연 시간을 가지며, 장치 메모리보다 크기가 작습니다. CUDA에서 스레드 블록의 모든 스레드가 공유하는 메모리입니다. 이 메모리의 사용량을 줄이는 것은 성능 최적화에 중요합니다.
- **매트릭스-매트릭스 곱셈의 블로킹 (Blocking for Matrix-Matrix Multiplication)**: 매트릭스 곱셈 시 데이터 재사용을 통해 메모리 사용을 최적화하는 방법입니다. 이는 메모리 계층 구조를 활용하여 장치 메모리 사용을 줄이는 데 도움을 줍니다.
- **텐서 코어 (Tensor Cores)**: 텐서 코어는 혼합 정밀도 매트릭스 연산을 위한 특수화된 컴퓨팅 유닛으로, 높은 성능을 제공합니다. WMMA API는 텐서 코어를 사용자 정의 함수에서 사용할 수 있게 합니다.

#### 3. 텐서 코어 성능과 공유 메모리 대역폭의 균형 (The Balance of Tensor Cores Performance and Shared Memory Bandwidth)
텐서 코어의 높은 성능을 최대한 활용하려면 공유 메모리 접근을 줄이는 것이 중요합니다. 이를 위해 루프라인 모델을 사용하여 매트릭스 곱셈을 분석하고, 공유 메모리 대역폭이 성능의 한계가 될 수 있음을 밝혔습니다.

#### 4. WMMA API 확장 라이브러리 (WMMA API Extension Library)
- **원시 함수 (Primitive Functions)**: `foreach_ij`와 `map` 함수는 매트릭스 요소를 조작하고, 공유 메모리에 저장하지 않고도 프래그먼트를 생성할 수 있게 합니다.
- **WMMAe-TCEC (Tensor Cores Error Correction)**: 단일 정밀도 매트릭스 곱셈을 텐서 코어에서 에러 보정 방법을 사용하여 에뮬레이션하는 API를 제공합니다. 이를 통해 공유 메모리 사용을 줄이고, 성능을 향상시킬 수 있습니다.

#### 5. 결론 (Conclusion)
이 논문에서는 텐서 코어의 높은 성능을 최대한 활용하기 위해 공유 메모리 사용을 줄이는 것이 중요함을 밝혔습니다. 이를 위해 WMMA API 확장 라이브러리를 구현하였고, 이 라이브러리를 통해 텐서 코어의 성능을 크게 향상시킬 수 있음을 실험적으로 입증하였습니다. 이 라이브러리는 오픈 소스로 제공됩니다.

### 논문의 전체 요약
이 논문은 NVIDIA 텐서 코어의 높은 성능을 최대한 활용하기 위한 방법을 제시합니다. 텐서 코어와 공유 메모리 간의 비효율적인 비율 문제를 해결하기 위해 WMMA API 확장 라이브러리를 개발하였습니다. 이 라이브러리는 매트릭스 요소를 효율적으로 조작하고, 공유 메모리 사용을 줄이며, 성능을 향상시킬 수 있습니다. 또한, 단일 정밀도 매트릭스 곱셈을 텐서 코어에서 에뮬레이션하는 기능을 제공합니다. 실험 결과, 이 라이브러리를 사용하여 텐서 코어의 성능을 크게 향상시킬 수 있음을 입증하였습니다.

## Similar Papers
- [NVIDIA Tensor Core Programmability, Performance & Precision](1803.04014.md)
- [Matting by Generation](2407.21017.md)
- [Flexible Performant GEMM Kernels on GPUs](2009.12263.md)
- [AUITestAgent: Automatic Requirements Oriented GUI Function Testing](2407.09018.md)
- [A Survey of Multi-Tenant Deep Learning Inference on GPU](2203.09040.md)
- [TurboTransformers: An Efficient GPU Serving System For Transformer Models](2010.05680.md)
- [BiQGEMM: Matrix Multiplication with Lookup Table For Binary-Coding-based Quantized DNNs](2005.09904.md)
- [Talaria: Interactively Optimizing Machine Learning Models for Efficient Inference](2404.03085.md)
- [LogoMotion: Visually Grounded Code Generation for Content-Aware Animation](2405.07065.md)
