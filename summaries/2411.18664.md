# Spatiotemporal Skip Guidance for Enhanced Video Diffusion Sampling
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.18664.pdf](https://arxiv.org/pdf/2411.18664.pdf)

### 1. 각 섹션 요약 및 주요 기여와 혁신

**1. 서론**
이 논문은 비디오 생성에 있어서 중요한 발전을 이룬 새로운 확산 모델 기법인 Spatiotemporal Skip Guidance (STG)를 소개합니다. STG는 약한 모델을 사용함으로써 비디오 생성의 질을 높이고자 하는 기존 방법들의 한계를 극복하며, 별도의 추가 학습 없이 고품질의 비디오 샘플을 생성합니다.

**2. 관련 연구**
이 기술은 기존의 Classifier-Free Guidance (CFG) 등에서 제기된 다양한 문제점, 특히 샘플 다양성 감소나 부차적인 모델 학습의 필요성을 해결하고자 하며, 이는 비영상 기반 확산 모델의 접근법을 비디오에 적용시키는 것으로 확장하고자 합니다.

**3. 방법론: STG의 구현**
STG는 고유한 시공간 변형을 통해 자연스러운 낮은 질의 모델을 시뮬레이션하여 특히 대규모 비디오 확산 모델에서 추가적인 모델 학습 없이 높은 성능을 발휘합니다. 이는 Residual 블록을 건너뛰는 방법을 통해 구현되며, 이는 자원 절약 이점이 큽니다.

**4. 실험 결과**
STG의 도입으로 다양한 비디오 생성 모델들에 걸쳐 질적 및 양적 개선이 현저히 나타났습니다. 다양한 STG 변형이 실험되었으며, 특정 모델에 따라 최적화된 결과가 도출되었습니다. 예를 들어, Mochi 모델에서는 STG-R이 보다 나은 결과를 보였습니다.

**5. 결론**
STG는 시공간 레이어를 이용한 간단하면서도 효과적인 가이드 기술로, 비디오 확산 모델에서 고도로 양질의 비디오 생성이 가능함을 보여주었습니다. 이는 추가적인 학습이 필요 없는 특성 때문에 경제적이고 사용이 용이합니다.

### 2. 전체 요약
이 논문의 STG는 비디오 확산 모델의 새로운 지평을 여는 중요한 기술로 평가됩니다. 이 기법은 약한 모델의 시뮬레이션을 통해 고품질의 비디오를 생성하며, 기존의 약한 모델 기반 접근 방식의 한계를 넘어서고 있습니다. 이를 통해 비디오의 질적 향상과 샘플의 다양성을 동시에 달성할 수 있으며, 대규모 모델에서도 효율적인 성능을 발휘합니다.