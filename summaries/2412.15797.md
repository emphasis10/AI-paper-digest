# Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.15797.pdf](https://arxiv.org/pdf/2412.15797.pdf)

### 1. 섹션 요약 및 주요 기여와 혁신적인 부분 설명

**초록 (Abstract)**
LE-MCTS라는 새로운 프레임워크를 소개하며, 이 방법은 언어 모델을 프로세스 수준에서 결합하여 복잡한 문제 해결을 개선합니다. 이 접근법은 여러 수학적 추론 벤치마크에서 성능을 향상시켰습니다. LE-MCTS는 특히 MATH와 MQA 데이터셋에서 각각 3.6%, 4.3%의 성능 증가를 보여줍니다.

**소개 (Introduction)**
대규모 언어 모델은 다양한 작업에서 뛰어난 성능을 보여왔지만, 오픈 소스 모델은 종종 복잡한 추론 작업에서 일관된 성능을 발휘하지 못합니다. 기존의 앙상블 방법은 이러한 문제를 해결하지 못합니다. 이 논문에서는 마르코프 결정 과정을 사용하여 언어 모델의 프로세스 수준 앙상블을 설명하는 새로운 프레임워크, LE-MCTS를 제안했습니다.

**방법론 (Methods)**
LE-MCTS는 언어 모델의 단계별 추론을 마르코프 결정 프로세스로 공식화합니다. 각 상태는 중간 추론의 경로를 나타내고 행위는 다음 추론 단계를 생성하는 것으로 정의됩니다. 이 접근방식은 PRM(프로세스 보상 모델)의 지침을 따름으로써 다양한 언어 모델이 생성한 추론 단계를 탐색하고 가장 정확한 추론 체인을 식별합니다.

**결과 (Results)**
다섯 개의 수학적 추론 벤치마크에서 LE-MCTS는 기존의 여러 언어 모델 앙상블 방법을 능가하거나 비슷한 성능을 보였습니다. 복잡한 수학 문제에서 단일 언어 모델보다 더 나은 성능을 보여주었습니다.

**결론 (Conclusion)**
LE-MCTS는 복잡한 추론 문제를 해결하는 데 있어 기존의 언어 모델 앙상블 방법의 한계를 해결하는 유용한 도구입니다. 이 접근법은 모든 단계별 추론 문제에 적용될 수 있으며, 더 넓은 프로세스 수준의 언어 모델 앙상블로의 길을 열 수 있습니다.

**제한사항 (Limitations)**
LE-MCTS는 프로세스 보상 모델의 신호에 크게 의존하므로 보상이 정확하지 않으면 성능이 떨어질 수 있습니다. 따라서, 강력하고 일반화 가능한 PRM의 개발이 중요한 방향으로 제시됩니다.

### 2. 전체 요약

이 논문에서는 LE-MCTS라는 혁신적인 프로세스 수준의 언어 모델 앙상블 방법을 소개합니다. 기존의 토큰 수준과 출력 수준의 앙상블 방법이 복잡한 문제를 해결하는 데 비효율적이라는 점을 극복하고자 하며, 마르코프 결정 프로세스를 통해 다양한 언어 모델의 중간 추론 단계를 효율적으로 탐색합니다. 수학적 추론 벤치마크에서 우수한 성능을 보이며, 특히 복잡한 문제 해결에서 큰 효과를 발휘하는 것으로 나타났습니다. 그러나, 프로세스 보상 모델의 성능에 의존하는 점과 기본 모델 선택의 필요성이 한계로 남아 있으며, 이 부분에서의 개선이 향후 중요한 연구 방향으로 제안됩니다.