# Large Scale Transfer Learning for Tabular Data via Language Modeling
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.12031.pdf](https://arxiv.org/pdf/2406.12031.pdf)

### 주요 내용 요약 - 각 섹션별 정리

#### 1. 서론 (Introduction)
이 논문에서는 대규모 전이 학습을 위해 설계된 새로운 모델과 데이터셋을 소개합니다. 특히 엑셀이나 스프레드시트 형식의 표 형태 데이터를 대상으로 합니다. 기존의 방법들은 특정 작업을 위해 개별적으로 모델을 훈련시키는데, 우리는 이러한 한계를 극복하고자 합니다. 우리의 새로운 모델 TABULA-8B는 작은 샘플에도 높은 정확도를 보이며, 새로운 데이터셋인 Tremendous TabLib Trawl (T4)을 구축해 몇 배나 많은 데이터로 학습을 가능하게 했습니다.

주요 기여:
1. TABULA-8B 모델: 새로운 도메인에서 분류 작업을 효과적으로 처리할 수 있는 모델.
2. T4 데이터셋: 고품질 학습 데이터셋.
3. 오픈 소스 공개: 코드, 모델, 데이터 모두 공개.

#### 2. 데이터셋 구축 (Dataset Construction: Building The Tremendous TabLib Trawl (T4))
이 섹션에서는 T4 데이터셋을 만드는 과정을 설명합니다. TabLib로부터 3.1백만 개의 고유 테이블을 걸러내어 사용했습니다. 여러 레벨(테이블, 행, 열)에서 데이터를 필터링해 고품질 데이터를 유지하고, 개인 식별 정보(PII)와 코드를 제거했습니다.

#### 3. 모델 설계 및 학습 (TabuLa-8B - Model Design and Training)
TABULA-8B 모델은 Llama 3-8B를 기반으로 하며, 표 데이터를 이용한 분류 및 이산형 회귀작업을 위해 설계되었습니다. 혁신적인 주의 마스킹 기법을 도입하여 샷(샘플) 개수에 따라 높은 성능을 발휘할 수 있도록 했습니다.

#### 4. 실험 결과 (Experimental Results)
다양한 실험을 통해 TABULA-8B의 성능을 평가했습니다. 아래는 주요 결과입니다:
- Zero-shot 학습: 특정 데이터셋에 대해 훈련되지 않은 상태에서도 우수한 성능을 발휘했습니다.
- Few-shot 학습: 기존의 최신 모델(XGBoost, TabPFN)보다 여러 샷에서 더 높은 정확도를 자랑했습니다.

#### 5. 모델의 강건성 평가 (Robustness Evaluation)
모델의 강건성을 평가하기 위해 다양한 실험을 수행했습니다:
- 특성 드롭아웃: 중요한 기능을 제거했을 때도 성능이 크게 떨어지지 않음을 확인했습니다.
- 열 순서 변경: 열 순서를 섞었을 때도 일관된 성능을 유지했습니다.

#### 6. 모델 및 데이터 공개 (Accessing Open-Source Code, Data, and Model Weights)
모델, 데이터, 그리고 코드 모두 오픈 소스로 공개되어 연구 커뮤니티가 이 작업을 발전시킬 수 있도록 했습니다. 이를 통해 많은 연구자들이 이 모델과 데이터를 쉽게 활용할 수 있게 되었습니다.

### 전체 요약

이 논문에서는 TABULA-8B라는 새로운 AI 모델과 T4 데이터셋을 소개합니다. TABULA-8B는 대규모 전이 학습을 통해 표 데이터에 대한 분류 작업을 수행하는 모델로, 기존의 모델들보다 더 높은 성능을 자랑합니다. T4 데이터셋은 TabLib에서 필터링된 고품질 데이터셋으로, 이 모델을 훈련시키는 데 사용되었습니다. 이 논문은 또한 코드, 데이터, 모델을 오픈 소스로 공개하여 다른 연구자들이 쉽게 활용할 수 있도록 했습니다. 혁신적인 주의 마스킹 기법을 도입한 것도 큰 장점 중 하나입니다. 다양한 실험에서 높은 정확도를 유지하며, 강건성 평가에서도 좋은 결과를 보였습니다.