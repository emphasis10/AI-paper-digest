# How Much Do LLMs Hallucinate across Languages? On Multilingual Estimation of LLM Hallucination in the Wild
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.12769.pdf](https://arxiv.org/pdf/2502.12769.pdf)

### 1. 섹션별 요약

#### 서론
이 논문은 대형 언어 모델(LLM)이 다양한 언어에서 "환상" 즉, 실질적인 정보와 일치하지 않는 정보를 생성하는 경향을 조사합니다. 이러한 환상이 언어 모델의 사용성을 제한하기 때문에 이를 감지하고 평가하는 연구가 진행 중입니다.

#### 배경 및 관련 연구
환상 감지는 주로 언어 모델이 사실적으로 잘못된 정보를 생성하는 경우를 식별하는 것으로, 이전 연구들은 주로 영어에 초점을 두고 있습니다. 이 논문은 다양한 언어를 대상으로 한 환상 감지에 초점을 맞추며, 다중 언어 모델을 통해 훈련된 데이터를 생성하였습니다.

#### 방법론
다중 언어 환상 감지 모델을 개발하여 30개 언어에 대한 대규모 연구를 실시하였습니다. 영어 환상 감지 데이터에 기초하여 번역된 데이터로 다국어 훈련을 진행하였으며, 5가지 언어에 대해 수작업으로 주석을 추가하여 모델의 성능을 평가했습니다.

#### 실험 결과
환상 발생률은 모델의 크기가 작을수록, 그리고 지원하는 언어가 많을수록 높았습니다. 고자원 언어의 경우 더 긴 응답을 생성하며, 이로 인해 더 많은 환상 토큰이 발생했습니다. 그러나 응답 길이에 따라 조정된 환상 발생률은 확인되지 않았습니다.

#### 결론
이 연구는 다국어 언어 모델이 "야생에서" 얼마나 환상을 발생시키는지 파악하기 위한 처음 시도를 나타냅니다. 이 실험을 통해 보다 신뢰할 수 있는 환상 발생률 추정 방법을 제안하였으며, 모델의 크기와 언어에 따른 환상 발생률 경향성을 발견했습니다.

### 2. 전체 요약

이 연구는 대형 언어 모델의 다국어 환상 발생에 대한 최초의 포괄적인 연구입니다. 다양한 언어에서의 환상 발생률을 추정하기 위한 독창적인 프레임워크를 제안하며, 다국어 감지 모델을 통해 보다 정확한 환상 발생률을 측정하고자 합니다. 분석 결과 모델 크기 및 지원 언어 수에 따라 환상 발생률이 다르게 나타났으며, 이는 향후 모델의 신뢰성을 높이기 위한 중요한 기준점을 제공합니다.