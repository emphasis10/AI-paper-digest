# Symbolic Learning Enables Self-Evolving Agents
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.18532.pdf](https://arxiv.org/pdf/2406.18532.pdf)

### 요약

#### 주요 내용 요약

1. **소개**
   - 기존의 언어 에이전트는 주로 모델 중심적 접근에서 데이터 중심적 접근으로의 전환의 필요성.
   - 언어 에이전트의 자기 최적화를 탐구하기 위한 새로운 프레임워크 제안.

2. **관련 연구**
   - 최근 언어 모델, 프롬프트, 그리고 언어 에이전트에 대한 연구 및 진전.
   - 자동화된 프롬프트 엔지니어링과 에이전트 최적화의 발전.

3. **에이전트 상징 학습**
   - 언어 에이전트를 훈련시키기 위한 상징 학습 프레임워크 제안.
   - 에이전트 파이프라인, 노드, 트랙터리, 언어 손실, 언어 그래디언트 등 주요 개념 설명.
   - 에이전트 상징 학습의 절차 및 알고리즘 제시.

4. **실험 결과 및 증명**
   - 표준 LLM 벤치마크와 복잡한 실제 문제에 대한 실험 결과 분석.
   - 자체 최적화의 효과와 데이터 중심 에이전트 학습의 가능성 제시.

5. **결론**
   - 에이전트 상징 학습이 언어 에이전트의 자기 진화를 가능하게 하며, 데이터 중심의 연구로의 전환이 AGI에 접근하는 중요한 단계임을 강조.
   - 전체 프레임워크를 오픈소스로 제공하여 후속 연구를 촉진.

#### 논문의 주요 기여 및 혁신적인 부분
- 언어 에이전트의 자기 최적화 및 진화 가능성을 제시하는 상징 학습 프레임워크 제안.
- 기존의 엔지니어링 중심 접근법을 데이터 중심 접근법으로 전환하도록 설계된 프레임워크.
- 언어 손실, 언어 그래디언트 등의 개념을 도입하여 자연 언어로 평가 및 최적화.
- 복잡한 실제 문제 해결을 위한 효과적인 최적화 방법론 증명.
- 오픈소스화하여 연구 커뮤니티의 발전을 도모.

---

### 전체 요약

이 논문은 인공지능 언어 에이전트가 자기 최적화하고 진화할 수 있는 '상징 학습' 프레임워크를 제안합니다. 기존의 엔지니어링 중심 접근법에서 벗어나 데이터 중심 접근법을 통해 언어 에이전트를 효율적으로 학습하고 최적화하는 방법을 탐구합니다. 상징 학습 프레임워크는 언어 손실과 언어 그래디언트를 활용하여 자연 언어로 에이전트 성능을 평가하고 개선합니다. 이를 통해 복잡한 실제 문제를 해결하는 능력을 발견하고 데이터 중심 연구로의 전환을 촉진합니다. 이 연구의 주요 기여는 상징 학습을 통해 언어 에이전트가 자체적으로 진화하고 최적화할 수 있는 가능성을 제시한 점이며, 이를 오픈소스로 제공하여 후속 연구를 장려합니다.

## Similar Papers
- [Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts](2405.19893.md)
- [AgentGym: Evolving Large Language Model-based Agents across Diverse Environments](2406.04151.md)
- [CCoE: A Compact LLM with Collaboration of Experts](2407.11686.md)
- [Searching for Best Practices in Retrieval-Augmented Generation](2407.01219.md)
- [Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond](2405.03520.md)
- [Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B](2406.07394.md)
- [Scalify: scale propagation for efficient low-precision LLM training](2407.17353.md)
- [OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework](2405.11143.md)
- [Demystifying Chains, Trees, and Graphs of Thoughts](2401.14295.md)
