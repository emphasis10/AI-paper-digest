# Efficient Continual Pre-training by Mitigating the Stability Gap
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.14833.pdf](https://arxiv.org/pdf/2406.14833.pdf)

### 1. 각 섹션 요약

#### 1. 서론 (Introduction)
이 논문은 대규모 언어 모델(LLM)을 새로운 도메인에 적응시키기 위한 지속적 사전 훈련의 중요성을 설명합니다. 특히, 의료 도메인에서 지속적 사전 훈련 동안 모델 성능이 초기 단계에서 떨어지고 이후 회복되는 안정성 격차 현상에 주목합니다.

#### 2. 관련 연구 (Related Work)
이 섹션은 대규모 언어 모델의 기본 학습 특성에 대한 기존 연구를 요약합니다. 예를 들어, 모델 크기와 데이터셋 크기의 관계, 낮은 품질의 데이터를 제거함으로써 성능을 향상시키는 방법 등이 포함됩니다.

#### 3. 지속적 사전 훈련에서 안정성 격차 식별 (Identifying the Stability Gap in Continual Pre-training)
- **실험 설정**: OpenLlama3B-v2 모델을 의료 도메인에서 지속적으로 사전 훈련하여 모델의 성능 변화를 관찰합니다.
- **관찰 결과**: 모든 실험에서 성능이 초기 단계에서 낮아졌다가 이후 다시 높아지는 V자 형태의 성능 변화를 보였습니다.

#### 4. 효율적인 지속적 사전 훈련 전략 (Efficient Continual Pre-training Strategies)
세 가지 주요 전략을 제안합니다:
1. 모델을 큰 데이터셋에서 한 번 훈련하는 대신, 적절한 크기의 서브셋에서 여러 번 훈련.
2. 고품질의 서브셋을 선택하여 빠른 성능 회복과 높은 성능 달성.
3. 사전 훈련 데이터와 유사한 데이터 혼합률을 사용하여 지식 망각을 줄임.

#### 5. 실험 (Experiments)
OpenLlama-3B와 Llama-3-8B 모델을 사용한 다양한 실험을 통해 제안된 전략의 유효성을 검증합니다. 예를 들어, OpenLlama-3B 모델의 평균 의료 작업 성능을 36.2%에서 40.7%로 향상시켰습니다.

#### 6. 결론 (Conclusion)
LLM의 지속적 사전 훈련 동안의 안정성 격차 현상과 이를 해결하기 위한 효율적인 전략을 제안하고 검증했습니다. 이러한 전략을 통해 의료 도메인에서 Llama-3-8B 모델의 성능을 크게 향상시켰습니다.

### 2. 종합 요약

이 논문은 대규모 언어 모델(LLM)을 새로운 도메인에 적응시키기 위한 지속적 사전 훈련 과정에서 나타나는 안정성 격차 문제를 해결하기 위한 전략을 제안합니다. 특히, 초기 성능 저하와 이후 회복의 V자 형태의 성능 변화를 관찰하고, 이를 해결하기 위한 세 가지 주요 전략(서브셋 훈련, 고품질 토큰 선택, 데이터 혼합)을 도입했습니다. 다양한 실험을 통해 이러한 전략이 모델의 도메인 적응 성능을 향상시키는 데 효과적임을 확인했습니다. 이러한 연구는 LLM의 도메인 특화 및 일반적인 작업 성능을 동시에 개선하는 데 중요한 기여를 합니다.

## Similar Papers
- [Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training](2405.15319.md)
- [Simple and Effective Masked Diffusion Language Models](2406.07524.md)
- [Attention as a Hypernetwork](2406.05816.md)
- [Octo-planner: On-device Language Model for Planner-Action Agents](2406.18082.md)
- [MoA: Mixture of Sparse Attention for Automatic Large Language Model Compression](2406.14909.md)
- [Step-Controlled DPO: Leveraging Stepwise Error for Enhanced Mathematical Reasoning](2407.00782.md)
- [Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models](2406.04271.md)
- [AI Agents That Matter](2407.01502.md)
- [Privacy Preserving Prompt Engineering: A Survey](2404.06001.md)
