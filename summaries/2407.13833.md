# Phi-3 Safety Post-Training: Aligning Language Models with a "Break-Fix" Cycle
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.13833.pdf](https://arxiv.org/pdf/2407.13833.pdf)

### 섹션 요약

#### 1. 소개 (Introduction)
Phi-3 시리즈는 스마트폰에서도 작동할 수 있는 소형 언어 모델(SLM)의 하나입니다. Microsoft가 개발한 이 모델은 사람의 선호와 안전 고려 사항에 맞추어 정렬되었습니다. 이 모델을 개발하기 위해 "break-fix" 사이클 방식을 사용하여 데이터셋 큐레이션, 안전성 포스트 트레이닝(safety post-training), 벤치마킹을 실시했습니다.

#### 2. 안전 정렬 (Safety Alignment)
안전 정렬 방법론에는 다섯 가지 주요 프로세스가 포함됩니다:

1. 데이터셋 큐레이션: 공개 데이터셋과 추가로 생성된 데이터셋을 사용.
2. 안전성 포스트 트레이닝: 안전 데이터셋을 표준 선호 데이터셋과 혼합해 사용.
3. 책임 있는 AI 평가: 여러 평가지표를 사용하여 모델 후보를 선정.
4. AI 레드 팀: 독립적인 팀이 모델의 유해 콘텐츠를 탐지.
5. 취약점 식별: 평가와 레드 팀 결과를 바탕으로 취약점을 찾아 추가 트레이닝에 반영.

#### 3. 실험 결과 (Experiment Results)
Phi-3 모델은 RAI 벤치마크와 유해 콘텐츠 탐지에서 뛰어난 성능을 보였습니다. 여러 번의 "break-fix" 사이클을 통해 75% 이상의 유해 콘텐츠 생성률 감소를 이뤘습니다.

#### 4. 개발자를 위한 책임 있는 AI 고려사항 (Responsible AI Considerations for Developers)
Phi-3 모델을 이용하는 개발자는 추가적인 안전 관련 툴과 방법론을 사용해 모델 출력이 적절하도록 보완해야 합니다. Microsoft는 추가적인 안전 툴킷을 제공합니다.

#### 5. 결론 (Conclusion)
Phi-3 시리즈 모델은 “break-fix” 접근법을 통해 유해 콘텐츠 생성률을 줄이는 데 성과를 보았습니다. 그러나 여전히 모든 언어 모델과 마찬가지로 몇 가지 기본적인 한계를 가지고 있으며, 특히 다른 사용 사례를 위한 추가 안전성 완화 조치를 취할 필요가 있습니다.

### 전체 요약

이 보고서는 Microsoft의 Phi-3 시리즈 언어 모델을 소개하며, 이 모델을 안전하게 정렬하기 위해 "break-fix" 사이클 방식이 사용되었다고 설명합니다. 이 사이클은 데이터셋 큐레이션, 안전성 포스트 트레이닝, 책임 있는 AI 벤치마킹, AI 레드 팀의 유해 콘텐츠 탐지, 그리고 취약점 식별의 다섯 가지 주요 단계로 이루어져 있습니다. 이러한 방법론을 통해 Phi-3 모델은 유해 콘텐츠 생성률을 대폭 줄이는 데 성공했습니다. 그러나 개발자는 모델의 한계를 인식하고 추가적인 안전 조치를 취해야 합니다.

Phi-3 모델의 주요 기여점과 혁신적인 부분은 소형 언어 모델임에도 불구하고 높은 성능을 유지하며 사람의 선호와 안전 고려 사항을 충족시킬 수 있도록 특별히 정렬되었다는 점입니다. 결과적으로, Phi-3 모델은 스마트폰과 같은 소형 장치에서 사용될 수 있는 고성능 언어 모델로 자리 매김했습니다.

## Similar Papers
- [SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages](2407.19672.md)
- [ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools](2406.12793.md)
- [Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](2404.14219.md)
- [AgentInstruct: Toward Generative Teaching with Agentic Flows](2407.03502.md)
- [Scaling Synthetic Data Creation with 1,000,000,000 Personas](2406.20094.md)
- [ShieldGemma: Generative AI Content Moderation Based on Gemma](2407.21772.md)
- [On the Transformations across Reward Model, Parameter Update, and In-Context Prompt](2406.16377.md)
- [Gemma: Open Models Based on Gemini Research and Technology](2403.08295.md)
- [Best Practices and Lessons Learned on Synthetic Data for Language Models](2404.07503.md)
