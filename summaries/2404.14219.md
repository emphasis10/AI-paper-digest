# Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.14219.pdf](https://arxiv.org/pdf/2404.14219.pdf)

### 도입부 요약
이 논문에서는 'phi-3-mini'라는 3.8억 개의 파라미터를 가진 언어 모델을 소개합니다. 이 모델은 3.3조 개의 토큰으로 학습되었으며, Mixtral 8x7B 및 GPT-3.5와 같은 모델의 성능과 유사하거나 더 나은 결과를 보여줍니다. 또한, 이 모델은 휴대전화에서 실행할 수 있을 정도로 충분히 작은 크기로 설계되었습니다. 여기서 혁신적인 점은 학습 데이터셋의 구성에 있으며, 웹 데이터와 인공 데이터를 대량으로 필터링하여 사용했습니다. 또한, 모델의 안정성, 안전성, 그리고 대화 형식을 강화하기 위한 노력이 있었습니다.

### 기술 사양 요약
'phi-3-mini' 모델은 트랜스포머 디코더 아키텍처를 사용하며, 기본적으로 4K의 컨텍스트 길이를 가지고 있습니다. 이 모델은 고품질의 학습 데이터를 사용하여 소형 언어 모델의 성능을 향상시키기 위한 방법을 따르고 있습니다. 'phi-3-mini'는 3.3조 개의 토큰으로 훈련되었으며, 다양한 오픈 인터넷 소스에서 얻은 웹 데이터와 인공 데이터를 사용합니다. 또한, 이 모델은 휴대전화에 설치하여 사용할 수 있으며, 4비트로 양자화하여 메모리 용량을 줄였습니다.

### 학문적 벤치마크 요약
'phi-3-mini'는 표준 오픈소스 벤치마크에서 여러 가지 추론 능력을 평가하였고, 'phi-2', 'Mistral-7b', 그리고 'GPT-3.5' 등과 같은 다른 모델들과 비교하였습니다. 이 모델은 특히 0-샷 및 5-샷 프롬프트 설정에서 상당한 성능을 보여주었습니다. 벤치마크 결과는 모델이 일반 지식, 언어 이해, 로지컬 리즈닝 및 틈새 기술을 학습하는 방식을 반영합니다.

### 안전성 요약
'phi-3-mini'는 마이크로소프트의 책임감 있는 AI 원칙에 따라 개발되었습니다. 모델은 포스트 트레이닝을 통해 안전성을 높이고, 여러 RAI(Responsible AI) 위해 카테고리에 대해 자동 테스트 및 평가를 수행했습니다. 안전성 조정, 레드팀 검토, 자체 생성된 데이터셋 사용 등이 포함되었습니다. 이러한 노력은 유해 반응률을 상당히 감소시켰습니다.

### 약점 요약
비록 'phi-3-mini' 모델이 대규모 모델과 유사한 언어 이해와 추론 능력을 달성했지만, 여전히 모델의 크기에 의한 일부 한계가 있습니다. 예를 들어, TriviaQA에서 저조한 성능을 보인 것은 모델이 저장할 수 있는 '실제

 지식'이 제한적이기 때문입니다. 이러한 약점은 검색 엔진과의 결합을 통해 해결할 수 있으며, 다양한 언어로 확장하는 것도 중요한 다음 단계입니다.

### 전체 요약
이 논문은 휴대전화에서 실행할 수 있는 소형 언어 모델 'phi-3-mini'를 소개하며, 이 모델은 대규모 데이터셋과 최적화된 학습 방법을 사용하여 대규모 모델과 비슷한 수준의 성능을 달성합니다. 혁신적인 데이터 처리와 아키텍처 최적화를 통해, 이 모델은 안전성과 성능 면에서 상당한 발전을 이루었습니다. 또한, 모델의 한계를 인식하고 이를 보완하기 위한 연구가 계속되고 있습니다.

## Similar Papers
- [Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost](2407.19825.md)
- [Phi-3 Safety Post-Training: Aligning Language Models with a "Break-Fix" Cycle](2407.13833.md)
- [Xmodel-VLM: A Simple Baseline for Multimodal Vision Language Model](2405.09215.md)
- [How Far Are We From AGI](2405.10313.md)
- [Xmodel-LM Technical Report](2406.02856.md)
- [The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale](2406.17557.md)
- [LAB-Bench: Measuring Capabilities of Language Models for Biology Research](2407.10362.md)
- [Qwen2 Technical Report](2407.10671.md)
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](2305.10601.md)
