# Shiksha: A Technical Domain focused Translation Dataset and Model for Indian Languages
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.09025.pdf](https://arxiv.org/pdf/2412.09025.pdf)

1. 논문 각 섹션 요약:

- **서론**: NPTEL(기술 향상 학습을 위한 국가 프로그램)은 다양한 전문 분야에서의 고등 교육 콘텐츠를 무료로 제공합니다. 이 논문은 NPTEL의 데이터를 활용하여 인도 언어에 특화된 번역 모델을 개발했습니다.

- **현대 기계 번역의 실패**: 현재의 번역 모델이 기술 도메인에서는 성과가 부족하다는 점을 지적하며 인도 언어 번역에서의 문제점들을 설명합니다.

- **관련 연구**: 기존 연구들, 특히 Samanantar와 IndicTrans2, 및 다른 인터넷 자원을 이용한 번역을 언급하며, 이들이 갖고 있는 데이터의 문제점, 예를 들면 잘못된 문장 정렬 및 비연속적인 데이터의 활용 부족 등을 지적하고 있습니다.

- **데이터셋**: NPTEL로부터 얻은 2.8백만 개의 문장 쌍을 기반으로 하여 번역 모델을 훈련했습니다. 데이터는 8개의 인도 언어로 구성되어 있으며, 정밀한 데이터 추출과 정제를 통해 높은 품질을 유지합니다.

- **모델**: NLLB-3.3B 모델을 기반으로 LoRA라는 방법을 사용하여 번역 모델을 교육하였습니다. 12백만 개의 샘플에서 훈련된 이 모델은 기술 도메인에서도 높은 성과를 보였습니다.

- **Translingua**: 이 연구는 Translingua라는 도구로 발전하여 인도의 인적 주석자들에 의해 NPTEL 강의 기록을 다양한 언어로 번역하는 데 사용되고 있습니다.

- **결론**: 과학적, 기술적, 교육적 도메인에 맞춘 새로운 번역 데이터셋과 모델을 제시하였으며, 기존 NMT 모델의 성능을 개선하는 방향을 제안합니다.

- **제한사항**: 데이터셋이 특정 도메인에 치우쳐있다는 점과 언어 방향성을 충분히 테스트하지 못한 점을 제한사항으로 언급하며, 다양한 콘텐츠의 보완을 추천합니다.

2. 전체 요약:

이 논문은 인도 언어의 과학, 기술, 교육 도메인에 특화된 번역 모델을 개발하는 과정을 다루고 있습니다. NPTEL로부터 고품질의 병렬 텍스트 데이터를 확보하여, 첨단 NMT 모델에 대해 성능을 끌어올렸고 Translingua라는 도구를 통해 인도 전역의 다양성을 포용하는 번역 시스템을 구현했습니다. 이 연구는 특히 데이터셋의 특정 도메인 편중과 같은 한계를 인식하며 다양한 영역에서의 데이터 보충의 필요성을 강조합니다.