# Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.04128.pdf](https://arxiv.org/pdf/2502.04128.pdf)

1. **각 섹션 요약**

   **1장: 서론**
   - AI와 머신러닝 기술은 음성 합성과 음성 인식의 질을 극적으로 향상시켰다.
   - 기존 TTS 시스템들은 모델의 구조 개선에 집중했지만, Llasa와 같은 통합된 접근 방법을 제안한다.

   **2장: 연구의 기초**
   - 본 연구는 텍스트 LLM과 비슷한 방식으로 TTS 모델 구조를 설계했다.
   - 모델은 Transformer와 음성 토크나이저를 기반으로 하며, 다음 토큰 예측(paradigm)을 사용한 훈련 방식이 특징이다.

   **3장: 훈련 시간 및 추론 시간 컴퓨트의 추진**
   - 훈련 시간을 늘리면 음성의 자연스러움과 감정 표현이 향상된다.
   - 추론 동안 처리한 정보를 통해 생성된 음성이 특정 요구에 더 적합하게 된다.

   **4장: 실험 및 결과**
   - Llasa 모델은 감정 표현, 목소리 유사성을 포함한 다양한 평가 지표에서 우수한 성능을 보였다.
   - 훈련 데이터와 모델 크기가 증가할수록 성능도 향상됨을 확인했다.

   **5장: 결론**
   - Llasa는 텍스트와 음성을 통합하여 고품질의 음성 합성을 가능하게 하는 새로운 TTS 시스템을 제안하고, 이는 앞으로의 연구 방향을 제시한다.

   **주요 기여 및 혁신 점**
   - 모델의 일관성과 효율성을 위한 통합된 접근 방법 제시.
   - 훈련 및 추론 시간 발생 가능성을 극대화하여 기존 TTS 시스템에 비해 향상된 성능 확보.

2. **전반적인 요약**
   - Llasa TTS 시스템은 텍스트 LLM 아키텍처와의 정렬을 통해 새로운 연구 방향을 제시하며, 효율적인 훈련 방법과 함께 고급 음성 합성 기능을 구현한다.
   - 실험 결과에서 Llasa는 특히 감정 표현 능력과 목소리 유사성을 잘 보였고, 이러한 특성은 훈련 및 추론 시간을 조절하는 방식과 결합되어 연구에 새로운 진전을 가져올 수 있음을 보여준다.