# Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context
## TL;DR
## Summary
- [https://arxiv.org/pdf/2403.05530.pdf](https://arxiv.org/pdf/2403.05530.pdf)

### 1. 요약 (각 섹션별 주요 내용 요약)

#### 1. Introduction (소개)
- **주요 내용**: 이 논문은 최신 멀티모달 모델인 Gemini 1.5 Pro를 발표합니다. 이 모델은 새로운 구조를 포함하여 매우 긴 문맥을 처리할 수 있습니다. 최대 10M 토큰을 처리하며, 텍스트, 비디오, 오디오 등 여러 모달리티를 아우릅니다. 이 모델은 기존의 Gemini 1.0 Pro를 능가하며, Gemini 1.0 Ultra와 유사한 성능을 발휘합니다.
- **혁신적 부분**: Gemini 1.5 Pro는 학습에서 매우 긴 문맥을 지속적으로 향상시키며, 새로운 언어 학습 능력을 포함한 여러 놀라운 기능을 보여줍니다.

#### 2. Model Architecture (모델 아키텍처)
- **주요 내용**: Gemini 1.5 Pro는 조건 계산을 사용하는 Sparse Mixture of Experts(MoE) Transformer 기반 모델입니다. 이 모델은 입력을 처리하는 데 필요한 일부 매개변수만 활성화하는 것을 목표로 합니다.
- **혁신적 부분**: MoE 구조의 설치로, 모델의 파라미터 수를 유지하면서도 모델의 전체 파라미터 수를 확대할 수 있다.

#### 3. Training Infrastructure and Dataset (훈련 인프라와 데이터셋)
- **주요 내용**: Gemini 1.5 Pro는 다양한 도메인의 멀티모달 및 다국어 데이터를 사용하여 Google의 TPUv4 가속기 클러스터에서 학습되었습니다.
- **혁신적 부분**: 다양한 도메인에서 얻은 데이터를 활용하여 멀티모달 데이터와 인간의 선호도를 기반으로 한 미세 조정을 포함합니다.

#### 4. Long-context Evaluation (긴 문맥 평가)
- **주요 내용**: 모델의 긴 문맥 능력을 평가하기 위해 형식적 기준과 실제 작업으로 다양한 평가를 수행했습니다. '바늘 찾기'와 같은 실험에서 Gemini 1.5 Pro는 수백만 토큰 내에서도 높은 정확도를 보여줍니다.
- **혁신적 부분**: 긴 문맥에서 정보 조회 및 복잡한 추론 능력을 통해 실제 작업을 수행할 수 있습니다.

#### 5. Core Capability Evaluations (핵심 기능 평가)
- **주요 내용**: 모델의 텍스트, 비전, 오디오 등 다양한 핵심 기능을 평가합니다. Gemini 1.5 Pro는 Gemini 1.0 Pro를 능가하며, Gemini 1.0 Ultra와 경쟁하거나 이를 능가하는 성능을 보여줍니다.
- **혁신적 부분**: 긴 문맥 기능과 더불어 핵심 기능도 유지하거나 향상됨.

#### 6. Responsible Deployment (책임 있는 배포)
- **주요 내용**: Gemini 1.5 Pro의 책임 있는 배포를 위해 평가 방법과 모델 완화 노력을 업데이트했습니다. 모델의 잠재적 사회적 영향을 정량화하고 안전 위험을 완화할 수 있는 방법을 포함합니다.
- **혁신적 부분**: 안전한 배포를 위해 인간 피드백을 활용한 강화 학습(RLHF) 및 감독 미세 조정(SFT) 프로세스 활용.

### 2. 전체 요약

Gemini 1.5 Pro는 최신 멀티모달 모델로, 매우 긴 문맥에서 정보를 기억하고 추론할 수 있는 능력을 갖추고 있습니다. 이 모델은 새로운 Sparse Mixture of Experts(MoE) Transformer 구조를 활용하며, 최대 10M 토큰까지 처리할 수 있는 능력을 통해 기존 모델들을 능가하는 성능을 보여줍니다. 또한, 다양한 멀티모달 데이터를 효율적으로 학습하고 안전한 배포를 위한 강화 학습 및 미세 조정 기술을 포함하여 실세계 문제 해결에 강력한 도구로 자리매김하고 있습니다. 이와 같은 특성 덕분에 Gemini 1.5 Pro는 AI와 머신 러닝 분야에서 중요한 발전을 이루고 있습니다.

## Similar Papers
- [ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools](2406.12793.md)
- [OlympicArena Medal Ranks: Who Is the Most Intelligent AI So Far?](2406.16772.md)
- [LLaVA-OneVision: Easy Visual Task Transfer](2408.03326.md)
- [MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains](2407.18961.md)
- [Multimodal Needle in a Haystack: Benchmarking Long-Context Capability of Multimodal Large Language Models](2406.11230.md)
- [The Llama 3 Herd of Models](2407.21783.md)
- [FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs](2407.04051.md)
- [VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models](2407.11691.md)
- [SambaLingo: Teaching Large Language Models New Languages](2404.05829.md)
