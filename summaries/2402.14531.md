# Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance
## TL;DR
## Summary
- [https://arxiv.org/pdf/2402.14531.pdf](https://arxiv.org/pdf/2402.14531.pdf)

### 섹션별 중요 내용 요약

#### 1. **서론 (Introduction)**
- **주요 내용**: 자연어 처리 (NLP) 분야에서 대형 언어 모델(LLMs)이 많은 주목을 받고 있으며, 특히 ChatGPT와 LLaMA와 같은 모델이 여러 과제에서 뛰어난 성능을 보인다. 이 연구는 프롬프트의 정중함 수준이 LLM의 성능에 미치는 영향을 조사한다.
- **주요 기여 및 혁신**:
  - 인간 소통에서 정중함이 중요한 역할을 하듯이, LLM에도 이러한 특성이 반영될 가능성을 탐구한다.
  - 언어 및 문화적 배경에 따른 LLM 성능의 변화를 다각도로 분석한다.

#### 2. **관련 연구 (Related Work)**
- **주요 내용**: 기존 연구에서는 LLM의 성능 개선, 문화적 편향성, 그리고 사용자 피드백에 대한 반응 등이 다루어졌다. 그러나 프롬프트의 정중함이 모델 성능에 미치는 영향에 대한 연구는 제한적이다.
  
#### 3. **JMMLU 구축 (JMMLU Construction)**
- **주요 내용**: 일본어 LLM 평가를 위해 일본어 대규모 다중 과제 언어 이해 벤치마크 (JMMLU)를 구축했다. 이는 MMLU를 번역하고 일본 문화 관련 과제를 추가하는 방식으로 이루어졌다.
- **주요 기여 및 혁신**:
  - 서구 문화 중심의 MMLU를 일본어 및 일본 문화에 알맞은 과제로 번역 및 수정.
  - 각 과제는 일본어로 유창하게 수정되어, 일본어 모델의 정확한 평가를 가능하게 함.

#### 4. **메서드 (Methodology)**
- **주요 내용**: 정중함 수준에 따른 프롬프트 템플릿을 설계하고 영어, 중국어, 일본어 각각에 대해 8가지 템플릿을 사용하여 실험을 진행했다. 각 언어의 네이티브들이 정중함 수준을 평가했다.
- **주요 기여 및 혁신**:
  - 다양한 정중함 수준의 프롬프트를 사용한 실험을 통해 LLM의 성능 변화를 체계적으로 분석.

#### 5. **실험 및 결과 (Experiments and Results)**
- **요약**:
  - **요약 (Summarization)**: 높은 정중함 수준이 요약 성능에 긍정적 영향을 미치나, 지나치게 정중한 언어는 반드시 더 나은 결과를 보장하지 않음.
  - **언어 이해 벤치마크 (Language Understanding Benchmarks)**: 정중함 수준에 따른 모델 성능 변동이 각 언어별로 다르게 나타남.
  - **고정관념 편향 탐지 (Stereotypical Bias Detection)**: 정중함이 부족한 프롬프트는 모델 편향성을 증가시킬 수 있음.
- **주요 기여 및 혁신**:
  - 정중함 수준에 따라 모델 성능이 달라지는 현상을 실험적으로 입증.

#### 6. **결론 (Conclusion)**
- **요약**: 프롬프트의 정중함이 LLM 성능에 영향을 미치며, 이는 인간의 사회적 행동을 반영하는 것으로 보인다기보다는 각 언어와 문화에 따라 최적의 정중함 수준이 다름을 발견했다.

### 전체 요약
이 논문은 프롬프트 정중함 수준이 대형 언어 모델(LLM)의 성능에 미치는 영향을 영어, 중국어, 일본어를 대상으로 연구하였다. 연구 결과, 정중하지 않은 프롬프트는 모델 성능을 저하시킬 수 있으며, 각 언어와 문화적 배경에 최적의 정중함 수준이 다르다는 것이 확인되었다. 이러한 발견은 LLM 사용 시 정중함을 고려해야 하며, 이는 특히 다양한 문화적 맥락에서 자연어 처리 애플리케이션의 성능을 향상시킬 수 있음을 시사한다.