# Distributed Speculative Inference of Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.14105.pdf](https://arxiv.org/pdf/2405.14105.pdf)

### 1. 섹션별 요약 및 설명

### Introduction
이 논문은 AI 및 머신러닝 연구 주제 중 하나인 대형 언어 모델(LLM)의 추론 속도 향상을 다룹니다. 저자들은 분산 사전 추론(Distributed Speculative Inference, DSI)이라는 새로운 알고리즘을 설계하여 기존의 사전 추론(Speculative Inference, SI) 및 비사전 추론(Non-Speculative Inference, Non-SI) 알고리즘보다 더 빠른 성능을 보입니다. 이 알고리즘은 LLM의 추론 속도를 크게 개선하며, 다중 GPU를 활용합니다.

#### 주요 기여
1. 다중 GPU를 활용한 최초의 분산 사전 추론 알고리즘 설계.
2. 다양한 실험을 통해 DSI가 SI보다 더 빠른 추론 속도를 보임을 입증.
3. DSI는 속도가 느리거나 정확성이 낮은 드래프터 모델을 사용해도 추론 속도를 가속화할 수 있음.

### Preliminaries
이 섹션에서는 자동 회귀 언어 모델, 다음 토큰 예측, 사전 추론 및 대기 시간 측정 방법을 설명합니다. 자동 회귀 언어 모델은 일정 맥락 내에서 다음 토큰을 예측하는 모델입니다. 이 모델들은 주어진 입력에 대해 벡터 형태의 출력을 생성하고, 이를 바탕으로 다음 토큰을 선택합니다.

### Distributed Speculative Inference (DSI)
DSI는 다중 GPU를 활용하여 대형 언어 모델의 추론 속도를 가속화하는 알고리즘입니다. 이 알고리즘은 여러 개의 드래프터 및 타겟 모델을 동시에 작동시킴으로써, 추론 대기 시간을 크게 단축시킵니다.

### Method Overview
방법론 섹션에서는 DSI의 구체적인 구현 방법을 설명합니다. 다중 프로세서를 활용하여 여러 드래프터 모델과 타겟 모델을 동시에 작동시키며, 이러한 병렬 처리를 통해 추론 시간을 줄이는 방법을 기술합니다. 이를 통해 DSI는 SI와 Non-SI보다 빠른 성능을 보입니다.

### Analysis
이 섹션에서는 DSI의 이론적 근거를 제시하고, 알고리즘이 왜 빠른지에 대한 수학적 증명을 제공합니다. 주요한 가정과 이론적인 증명을 통해 DSI가 SI와 Non-SI보다 빠르다는 것을 입증합니다.

### Experiments and Results
실험 및 결과 섹션에서는 DSI의 성능을 다양한 실제 데이터셋과 모델을 통해 검증합니다. CNN 데일리 메일, Alpaca, HumanEval 등의 데이터셋을 사용하여 DSI가 SI 및 Non-SI보다 더욱 빠른 추론 속도를 보임을 입증합니다. 이 실험들은 DSI가 다양한 설정에서도 안정적으로 높은 성능을 보인다는 것을 보여줍니다.

### Discussion
논의 섹션에서는 DSI 알고리즘이 가지고 있는 한계와 더불어, 미래의 연구 방향에 대해 논의합니다. 여러 GPU 간의 통신 지연, 물리적 서버에 대한 실험 등을 통해 현재 알고리즘의 한계와 이를 극복하기 위한 방법들을 검토합니다.

### 2. 종합 요약
이 논문은 대형 언어 모델의 추론 속도 향상을 위한 새로운 알고리즘인 분산 사전 추론(DSI)을 제안합니다. DSI는 다중 GPU를 동시에 활용하며, 이는 기존의 사전 추론(SI) 및 비사전 추론(Non-SI)보다 빠른 성능을 보입니다. 이 알고리즘은 특별한 훈련이나 모델 구조의 변경 없이 기존 LLM을 활용할 수 있어 실용성이 높습니다. 다양한 실험 결과, DSI는 SI 대비 1.29배에서 1.92배까지 빠른 성능을 보였으며, 이는 AI 및 머신러닝 연구에서 중요한 발전을 의미합니다.

논문은 실험의 한계를 인정하면서도, DSI가 가지는 가능성을 강조하며, 다중 GPU 사용을 통한 성능 최적화 방향의 미래 연구를 제시합니다.

이를 통해 DSI는 대형 언어 모델의 실시간 응용 분야, 예를 들어 알고리즘 트레이딩이나 자율 주행과 같은 분야에서 유용하게 활용될 수 있습니다.