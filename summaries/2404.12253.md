# Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.12253.pdf](https://arxiv.org/pdf/2404.12253.pdf)

이 문서는 대형 언어 모델(LLMs)의 자가 개선을 위해 몬테카를로 트리 탐색(MCTS)을 통합한 새로운 프레임워크, ALPHALLM을 소개합니다. ALPHALLM는 상상력-탐색-비평이라는 자가 개선 루프를 통해, 데이터 부족이나 높은 품질의 주석 데이터 없이도 LLMs의 능력을 향상시키는 방법을 제안합니다. 본 연구는 특히 수학적 추론 작업에서 ALPHALLM의 효과를 실험적으로 입증하며, 이를 통해 LLMs의 성능 향상 가능성을 보여줍니다.

**1. 요약 및 해석**

- **관련 연구**: 이 섹션에서는 복잡한 추론 및 계획을 요구하는 작업에 효과적인 탐색 전략의 중요성을 강조합니다. 대표적으로 구체적인 수학적 추론 작업에서 다양한 탐색 방법이 연구되었는데, 동적 가지치기를 포함한 빔 탐색과 반복적으로 확장되는 트리나 그래프를 유지하는 방법이 있습니다. 본 연구는 MCTS 알고리즘을 기반으로 하며, 탐색 단계의 정의 및 MCTS를 사용한 셀프-개선의 효과적 활용에 대해 설명합니다.

- **LLM 자가개선**: 자가 개선은 LLM이 인간의 선호도와 가치와 일치하도록 맞추기 위한 핵심 요소입니다. 초기 작업은 다양한 작업에 대한 입력 쿼리와 해당 출력을 LLM에 요청하고, 수작업의 발리스틱 규칙을 사용하여 중복되거나 낮은 품질의 데이터 쌍을 필터링했습니다. 후속 연구는 LLM 자체가 이러한 가이드라인을 기반으로 응답의 품질을 평가하도록 요청했습니다. 이 연구와 다른 점은 MCTS의 지도를 활용하여 LLM의 자가 개선을 돕는 점입니다.

- **서론**: ALPHALLM은 LLM에 MCTS를 통합하여 추가 주석 없이 자가 개선할 수 있는 새로운 프레임워크입니다. LLaMA-2 70B의 성능을 대폭 향상시켜 GPT-4와 유사한 수준에 이르게 한 실험 결과를 제공합니다.

- **예비사항**: 문제 형식화에서는 LLM을 확률 pθ로 표현하고, 입력 시퀀스 x에 대한 응답 y를 생성하는 과정을 마르코프 결정 프로세스(MDP) 문제로 조명합니다. MCTS는 결정 문제 정책 최적화를 위한 샘플링 기반 탐색 알고리즘이며, 선택, 확장, 평가, 백 프로퍼게이션의 네 단계를 반복하여 탐색 트리를 구성합니다.

**2. 전체 요약**

본 논문은 대량의 언어 모델(LLMs) 자가 개선을 위한 새로운 방법론인 ALPHALLM을 제시합니다. 이는 LLM과 MCTS의 결합을 통해 추가적인 데이터 주석 없이도 LLM의 성능을 향상시킬 수 있는 방법을 탐색합니다. 특히, 수학적 추론 문제에 대한 실험을 통해 그 효과를 입증하였습니다. 본 연구는 복잡한 추론 작업에 효과적인 탐색 전략의 중요성을 강조하고, 기존 연구와 비교하여 자가 개선 루프를 형성하는데 있어 핵심적인 요소로 MCTS의 사용을 제안합니다. ALPHALLM의 아키텍처는 상상력-탐색-비평의 자가 개선 루프를 가능하게 하여 LLM의 성능을 개선하는 새로운 길을 열었습니다.

## Similar Papers
- [LiteSearch: Efficacious Tree Search for LLM](2407.00320.md)
- [Improve Mathematical Reasoning in Language Models by Automated Process Supervision](2406.06592.md)
- [Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs](2406.18629.md)
- [Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching](2406.06326.md)
- [Synthesizing Text-to-SQL Data from Weak and Strong LLMs](2408.03256.md)
- [Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B](2406.07394.md)
- [THOUGHTSCULPT: Reasoning with Intermediate Revision and Search](2404.05966.md)
- [Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning](2406.14283.md)
- [Scaling Synthetic Data Creation with 1,000,000,000 Personas](2406.20094.md)
