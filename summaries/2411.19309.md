# GRAPE: Generalizing Robot Policy via Preference Alignment
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.19309.pdf](https://arxiv.org/pdf/2411.19309.pdf)

### 1. 섹션 요약

**서론**  
최신 비전-언어-행동(VLA) 모델의 발전에도 불구하고 이들은 과거의 성공적인 행동을 모방하는 것에만 의존하여 새로운 작업 환경에 대한 일반화가 어렵습니다. 이에 GRAPE라는 새로운 접근 방식을 제안하여 VLA 정책을 경로 수준에서 정렬하고 성공과 실패 실험 모두에서 보상을 모델링하여 다양한 작업에 대한 일반화 가능성을 높였습니다.

**방법론**  
GRAPE는 복잡한 조작 작업을 여러 독립적인 단계로 나누고, 각 단계를 위상적 제약에 맞추어 자동으로 선호도 모델링을 지도합니다. 이는 다양한 목표에 맞게 모델을 조정할 수 있어, 안전성, 효율성, 작업 성공 등의 목적에 맞춰 조정할 수 있는 유연성을 제공합니다.

**실험 결과**  
실험 결과, GRAPE는 기존의 VLA 모델들보다 성과가 향상되었으며, 내부 및 새로운 조작 작업에서의 성공률을 각각 51.79%와 60.36% 증가시켰습니다. 유연한 목표 정렬이 가능하다는 것이 입증되었습니다.

**결론 및 논의**  
GRAPE는 VLA 모델의 제한된 일반화 가능성과 적응성 문제를 해결하기 위해 제안되었습니다. GRAPE는 성공한 실험과 실패한 실험 모두에서 학습하여 유연한 목표 정렬을 가능하게 합니다. 하지만 선호도 정렬에 대한 의존성이 제한된 과제 설정 상황에서 제한이 있을 수 있으며, 특정 목적에 대한 경계값 조정 시 주관적 편향이 생길 수 있다는 한계가 있습니다.

### 2. 전체 요약

GRAPE(Generalizing Robot Policy via Preference Alignment)는 비전-언어-행동 모델의 일반화와 목표 정렬의 유연성을 개선하기 위해 제안된 혁신적인 방법론입니다. GRAPE는 경로 기반의 선호도 최적화를 통해 조작 작업을 여러 주요 단계로 나누고, 각 단계마다 공간적-시간적 제약 조건을 적용하여 모델을 특정 목표에 맞출 수 있는 유연성을 제공합니다. 실험적으로는 기존의 방법들보다 높은 성공률과 효율성을 보여주었으며, 안전, 효율성 등 다양한 목표에 맞춰 모델을 정렬할 수 있는 가능성을 입증했습니다.