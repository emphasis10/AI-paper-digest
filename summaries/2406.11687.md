# Tokenization Falling Short: The Curse of Tokenization
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.11687.pdf](https://arxiv.org/pdf/2406.11687.pdf)

### 논문의 주요 기여 및 혁신 부분 요약

논문은 대규모 언어 모델(LLM)이 다양한 토큰화 및 타이포그래피 변형에 대한 문제점을 다루고 있습니다. 특히, LLM이 텍스트의 내부 구조와 토큰 구성을 이해하는 데 어려움을 겪고 있다는 점을 강조합니다. 이를 해결하기 위해 셀프-규제 기법인 BPE-dropout을 도입하여 모델의 일반화 능력을 향상시키고자 합니다.

#### 섹션별로 요약

1. **서론 (Introduction)**:
   - 토큰화는 LLM의 성능과 견고성에 중요한 영향을 미치는 단계입니다.
   - 타이포그래피 오류, 길이 변형, 내부 구조를 이해하지 못하는 문제를 해결하기 위해 이 연구가 수행되었습니다.

2. **관련 연구 (Related Work)**:
   - 토큰화 및 그 관련 문제에 대해 기존 연구들과의 비교 및 차별성을 다룹니다.

3. **복잡한 문제 해결 (RQ1: Complex Problem Solving)**:
   - 아나그램 및 LaTeX 언어 이해와 같은 복잡한 문제 해결에 대한 모델의 성능을 평가합니다.
   - 모델 크기가 증가함에 따라 성능이 향상되지만, 내부 구조 이해에는 여전히 한계가 있습니다 .

4. **토큰 구조 탐색 (RQ2: Token Structure Probe)**:
   - 토큰 내부 및 토큰 간 관계를 평가하기 위한 다양한 과제를 설정했습니다.
   - 모델의 성능이 증가함에 따라 다양한 샷 조건에서 성능이 향상되는 경향을 보입니다  .

5. **타이포그래피 변형 (RQ3: Typographical Variation)**:
   - 모델이 다양한 타이포그래피 변형에도 견고한 성능을 보이는지 평가합니다.
   - GPT-4 등의 모델이 높은 성능을 보이지만, 여전히 과제가 존재합니다 .

6. **BPE-dropout의 중요성 (Does BPE-dropout Matter?)**:
   - 텍스트 토큰화를 보다 다양한 방법으로 수행하게 하여 토큰 간의 관계를 더 잘 이해하도록 돕습니다.
   - 중간 정도의 BPE-dropout 비율이 단일 데코딩 시나리오에서 주로 좋은 성능을 보였습니다  .

7. **한계 (Limitations)**:
   - 데이터 다양성과 크기, 평가 메트릭, 서브워드 규제화 및 타이포그래피 변형에 대한 추가 연구 필요성을 강조합니다  .

### 전체 요약

이 논문은 대규모 언어 모델(LLM)의 토큰화 과정에서 발생하는 문제들을 깊이 있게 분석하고, 다양한 문제 해결을 위한 연구 방향을 제시합니다. 특히, BPE-dropout 기법을 통해 모델의 일반화 능력을 향상시키고, 이를 통해 성능을 개선하는 방안을 탐구하였습니다. 결과적으로, 문자열 변형과 타이포그래피 오류에 견고한 모델의 필요성을 강조하며, 이는 향후 연구에서 개선되고 확장되어야 할 부분임을 시사합니다. 이 연구의 주요 기여는 LLM의 토큰화 문제를 해결하기 위한 새로운 접근 방식을 제시하고, 이를 통해 모델의 견고성과 성능을 향상시키는 데 있습니다.