# $\text{Memory}^3$: Language Modeling with Explicit Memory
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.01178.pdf](https://arxiv.org/pdf/2407.01178.pdf)

### 요약:

#### 1. **Introduction (소개)**
   대형 언어 모델(LLM)은 최근 몇 년간 엄청난 인기를 끌고 있으며, 이를 위해 많은 비용이 소요됩니다. 이 논문에서는 인적 두뇌의 메모리 계층을 본따 새롭게 설계된 메모리 형식을 통해 비용을 줄이는 방법을 제안합니다. 이 모델의 이름은 "Memory3"입니다.

#### 2. **Memory Circuitry Theory (메모리 회로 이론)**
   메모리 회로 이론을 소개하며 이에 따라 지식과 메모리를 정의합니다. 여기에는 LLM의 계산을 작은 반복 부분으로 나누고, 그 중 외부화 가능한 부분을 식별하는 것이 포함됩니다. 이를 통해 모델 매개변수가 적어지며, 비용이 절감됩니다.

#### 3. **Basic Design of Memory3 (Memory3의 기본 설계)**
   Memory3는 기존의 트랜스포머 모델과 호환 가능하며 적은 미세 조정으로도 작동할 수 있습니다. 이는 특정 지식을 메모리로 외부화하여 모델의 매개변수 부담을 줄이며, 의미 있는 개선을 가져옵니다. 메모리 형식이 명확하며 접근하기 쉽도록 설계되었습니다.

#### 4. **Training Memory3 (Memory3의 학습)**
   대규모 데이터셋을 통해 Memory3를 훈련시키며, 메모리를 효율적으로 축약하고, 높은 성능을 유지합니다. 여기에는 지식외부화 및 메모리 축약 기술이 포함됩니다.

#### 5. **Performance Evaluation (성능 평가)**
   Memory3는 더 큰 LLM 및 기존 모델(RAG)보다 성능이 뛰어나며, 높은 디코딩 속도를 유지합니다. 이는 LLM들이 전문 작업에 빠르게 적응하고 사실성을 높이며, 환상을 줄이는 데 도움을 줍니다.

#### 6. **Conclusion and Future Work (결론 및 미래 작업)**
   Memory3는 비용 절감 및 성능 향상을 위한 혁신적인 모델임을 강조합니다. 추가적인 연구와 최적화를 통해 더 많은 가능성을 탐색할 예정입니다.

### 전체 요약:
Memory3 모델은 대형 언어 모델의 훈련 및 추론 비용을 줄이는 데 중점을 둔 혁신적인 접근법입니다. 이 모델은 지식을 외부화하여 기존보다 적은 매개변수로도 높은 성능을 유지합니다. 메모리 회로 이론을 기반으로 설계된 Memory3는 높은 사실성, 빠른 속도 및 효율적인 메모리 사용을 통해 LLM의 새로운 표준을 제시합니다. 추가 연구를 통해 다양한 응용 가능성을 탐구할 계획입니다.

## Similar Papers
- [EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models](2308.14352.md)
- [ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers](2206.01861.md)
- [Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation](2402.18150.md)
- [Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters](2406.05955.md)
- [Tied-Lora: Enhancing parameter efficiency of LoRA with weight tying](2311.09578.md)
- [rLLM: Relational Table Learning with LLMs](2407.20157.md)
- [Searching for Best Practices in Retrieval-Augmented Generation](2407.01219.md)
- [Compression Represents Intelligence Linearly](2404.09937.md)
- [OneBit: Towards Extremely Low-bit Large Language Models](2402.11295.md)
