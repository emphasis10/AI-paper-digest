# Examination of Code generated by Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.16601.pdf](https://arxiv.org/pdf/2408.16601.pdf)

### 논문의 구성 요약

#### 1. 서론 (Introduction)
이 논문은 ChatGPT와 GitHub Copilot와 같은 대형 언어 모델(LLM)이 소프트웨어 개발에서 코드 생성 자동화를 통해 어떻게 변화를 일으키고 있는지에 대해 설명합니다. 이러한 모델이 생성하는 코드의 올바름과 품질을 평가하기 위해, 저자들은 Java와 Python의 간단한 알고리즘 및 단위 테스트를 생성하고 이를 평가하는 실험을 수행했습니다. 결과적으로, LLM 간의 성능 차이, 언어 간의 차이, 알고리즘 코드와 테스트 코드 간의 차이를 관찰했습니다.

#### 2. 문헌 검토 (Literature Review)
기존 연구에서는 LLM이 생성하는 코드의 품질에 대한 평가가 적절하지 않다는 결론을 내렸습니다. 다양한 연구가 LLM의 코드 생성 능력, 특히 Python의 Docstring에서 함수 생성에 집중했습니다. 이러한 연구는 코드 생성의 정확성과 효율성을 개선할 수 있는 방법을 제안했으나, 테스트 코드 생성에 대한 평가는 충분하지 않았습니다.

#### 3. 연구 방법론 (Methodology)
연구는 Java와 Python으로 된 12개의 알고리즘을 대상으로 ChatGPT와 GitHub Copilot의 코드 생성 성능을 평가했습니다. 각 알고리즘에 대해 50개의 코드 샘플과 30개의 테스트 코드 샘플을 생성하고, 생성된 코드와 테스트 코드의 정확성과 품질을 평가했습니다. 평가 메트릭에는 코드의 정확성, 품질 규칙 위반의 빈도, 및 테스트 커버리지가 포함되었습니다.

#### 4. 결과 (Results)
- **코드 정확성 (Code Correctness)**: ChatGPT가 GitHub Copilot보다 Java와 Python 코드 모두에서 높은 정확성을 보였습니다. 특히, Java에서의 성능 차이가 더 크게 나타났습니다.
- **테스트 코드 정확성 (Test Code Correctness)**: GitHub Copilot이 Java와 Python 모두에서 ChatGPT보다 약간 더 높은 정확성을 보였습니다. 그러나 전반적으로 두 모델 모두 중간 수준의 성능을 보였습니다.
- **코드 품질 (Code Quality)**: 두 모델 모두 높은 품질의 코드를 생성했으며, 품질 규칙 위반의 빈도가 낮았습니다. Java 코드의 경우 Python 코드보다 품질이 약간 더 높았습니다.

#### 5. 논의 (Discussion)
연구 결과, 두 LLM은 모두 높은 품질의 코드를 생성할 수 있지만, 여전히 사람이 작성한 코드의 품질에는 미치지 못합니다. 특히 테스트 코드 생성에서 그 한계가 두드러졌습니다. 그러나 이러한 도구들은 개발자의 생산성을 높이고, 단순 작업을 자동화하는 데 유용하게 사용될 수 있습니다.

### 전체 요약
이 논문은 ChatGPT와 GitHub Copilot의 코드 생성 및 테스트 코드 생성 능력을 Java와 Python을 대상으로 평가한 연구입니다. 두 모델 모두 특정한 장점이 있지만, 전반적으로 ChatGPT가 더 나은 정확성을 보였습니다. 그러나 품질 면에서는 두 모델이 비슷한 수준을 보였습니다. 테스트 코드 생성에서는 GitHub Copilot이 약간 더 나은 성능을 보였으나, 두 모델 모두 개선이 필요합니다. 이 연구 결과는 LLM 기반 코드 생성 도구가 현재 상태에서 개발자에게 유용한 보조 도구로 사용될 수 있음을 시사합니다.