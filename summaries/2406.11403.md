# Multimodal Structured Generation: CVPR's 2nd MMFM Challenge Technical Report
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.11403.pdf](https://arxiv.org/pdf/2406.11403.pdf)

### 1. 각 섹션 요약 및 주요 기여 내용 요약

#### Abstract 및 Introduction (초록 및 서론)
- **요약**: 논문은 멀티모달 파운데이션 모델(MMFMs)의 성능을 다양한 컴퓨터 비전 및 자연어 처리 작업에서 보여줍니다. 그러나 문서 이해와 같은 특정 작업에서는 성능이 제한적입니다. 논문은 문맥 내에서 여러 종류의 구조화된 생성 방식을 사용하여 비용을 절감하면서도 일반화된 성과를 보여줍니다.
- **주요 기여**: 원시 MMFMs의 출력을 강제적으로 구조화하여 다운스트림 API가 해석할 수 있는 출력물을 생성하는 "구조화된 생성" 기법을 제안합니다.

#### Methodology (방법론)
- **요약**: 모델의 출력을 구문 분석 가능한 형식으로 보장하기 위해 '강한' 제약과 '약한' 제약을 사용하는 다양한 접근법이 소개됩니다. '강한' 제약 방식은 무효한 토큰을 완전히 제거하는 반면, '약한' 제약 방식은 특정 스키마를 따르도록 모델에 요청합니다.
- **주요 기여**: 텍스트 생성 인터페이스(TGI) API를 사용하여 구조화된 생성을 적용하고, Huggingface의 여러 모델을 사용하여 다양한 형식을 생성하는 상세한 JSON 포맷이 제안되었습니다.

#### Implementation Details (구현 세부사항)
- **요약**: 논문은 Llava v1.5, Llava-Next(v1.6), Nous Hermes 2 Pro - Mistral 7B 등의 모델을 사용하여 Phase 1과 Phase 2의 데이터셋에서 구조화된 생성을 적용하는 과정에 대해 기술합니다. 이를 통해 모델이 어떻게 서로 다른 데이터셋과 형태에 따라 동작하는지를 분석합니다.
- **주요 기여**: 모델의 출력을 다양한 데이터셋에 맞추어 요청하는 구체적인 JSON 포맷을 제안합니다.

#### Results 및 Discussion (결과 및 논의)
- **요약**: 논문의 접근 방식이 여러 팀의 미세 조정 모델보다 우수한 성과를 보여줍니다. 특히 'mydoc' 데이터셋에서는 키 정보 추출 작업에서 시각 정보가 꼭 필요하지 않음을 증명합니다.
- **주요 기여**: 단순한 모델 조정 없이도 우수한 성과를 보여주는 점과 키 정보 추출에서 시각 정보가 불필요하다는 결론을 내립니다.

#### Conclusion (결론)
- **요약**: 논문은 단순한 구조화된 생성 방식이 다양한 미세 조정 모델을 능가한다는 점을 강조하며, 향후 연구 방향으로 미세 조정과 구조화된 생성의 조합에 주목할 필요가 있음을 시사합니다.
- **주요 기여**: 일반화된 접근 방식을 통해 기존의 복잡한 모델보다는 효율적이고 비용 효율적인 해결책을 제안합니다.

### 2. 전체 요약
이 논문은 멀티모달 파운데이션 모델(MMFMs)을 사용하여 문서 이해 등의 복잡한 작업에서도 우수한 성과를 얻기 위한 새로운 접근 방식을 제안합니다. '구조화된 생성'이라는 간단한 기법을 사용하여 모델의 출력을 다운스트림 API가 해석할 수 있도록 강제하는 방식입니다. 이 방식은 비용 효율적이며, 기존의 복잡한 모델링 단계를 대체할 수 있다고 주장합니다. 실제 평가에서도 여러 팀의 미세 조정 모델을 능가하는 성과를 보여주었으며, 키 정보 추출 작업에서 시각 정보의 필요성을 재고하게 만드는 중요한 결론을 도출하였습니다. 이를 통해 단순한 엔지니어링 접근법으로도 복잡한 문제를 해결할 수 있음을 입증하였습니다.

이 논문은 다양한 데이터셋에서 검증된 결과를 바탕으로 하고 있으며, 향후 구조화된 생성과 미세 조정의 조합에 대한 연구가 필요함을 언급합니다. 논문에서 제안한 방식은 쉽게 재현 가능하고, 비용 효율적이기에 연구 및 실용적 가치가 높습니다.

## Similar Papers
- [SpeechVerse: A Large-scale Generalizable Audio Language Model](2405.08295.md)
- [mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding](2403.12895.md)
- [PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents](2406.13923.md)
- [GLiNER multi-task: Generalist Lightweight Model for Various Information Extraction Tasks](2406.12925.md)
- [LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model](2404.01331.md)
- [Online normalizer calculation for softmax](1805.02867.md)
- [Adaptable Logical Control for Large Language Models](2406.13892.md)
- [VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models](2407.11691.md)
- [Towards Fast Multilingual LLM Inference: Speculative Decoding and Specialized Drafters](2406.16758.md)
