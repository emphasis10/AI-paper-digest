# EuroLLM: Multilingual Language Models for Europe
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.16235.pdf](https://arxiv.org/pdf/2409.16235.pdf)

### 1. 요약

#### Introduction (소개)
이 논문은 EuroLLM 프로젝트를 소개합니다. 이 프로젝트의 목표는 모든 유럽 연합의 공식 언어와 추가적으로 몇 가지 관련 언어들을 이해하고 생성할 수 있는 다국어 대형 언어 모델(LLM)을 개발하는 것입니다. 주요 기여는 다국어 데이터 수집 및 필터링, 다국어 토크나이저 생성, 데이터 믹스 구성 및 모델 구조를 설계하는 것입니다. 또한, 초기 모델인 EuroLLM-1.7B와 EuroLLM-1.7B-Instruct를 공개하고 다양한 다국어 벤치마크 및 기계 번역 성능을 보고합니다.

#### Data Collection and Filtering (데이터 수집 및 필터링)
데이터는 온라인 웹 데이터, 병렬 데이터, 코드/수학 데이터, 고품질 데이터로 구성됩니다. 웹 데이터를 필터링하고, 언어별로 퍼플렉시티 필터와 다양한 휴리스틱 필터를 적용했습니다. 병렬 데이터의 품질을 보장하기 위해 Bicleaner와 COMETKIWI-22를 사용하여 저품질 문장 쌍을 제거했습니다. 코드와 수학 데이터는 여러 오픈 소스 데이터셋에서 수집되었습니다.

#### Tokenizer (토크나이저)
LLaMa-2 및 Mistral 모델에서 사용된 방법을 따르며, 128,000개의 하위어(서브워드)를 가진 BPE 토크나이저를 SentencePiece 프레임워크를 사용하여 훈련했습니다. 다양한 언어에서 효율적이려면 큰 어휘 집합을 사용하는 것이 중요하지만, 이는 높은 임베딩 파라미터 수를 초래할 수 있습니다. 실험 결과 128,000개 조각이 최적의 균형을 이룬다고 결론지었습니다.

#### Modeling (모델링)
EuroLLM은 표준 트랜스포머 아키텍처를 사용하며, 그룹 쿼리 어텐션(GQA), RMSNorm, SwiGLU 활성화 함수 및 RoPE 위치 인코딩을 사용합니다. 모델은 4조 개의 토큰으로 예비 훈련되며, 고품질 데이터의 비율이 훈련의 마지막 10%에서 증가합니다. 훈련은 256개의 Nvidia H100 GPU를 사용하여 진행되었습니다.

#### Learning Rate Scheduler (학습률 조정)
코사인 스케쥴러와 트라페조이드 스케쥴러를 비교했을 때, 트라페조이드 스케쥴러가 다국어 성능과 기계 번역에서 더 높은 점수를 기록했습니다.

#### Post Training (후 훈련)
EuroLLM-1.7B 모델을 다양한 공개 데이터셋을 통합한 EuroBlocks 데이터셋으로 미세조정하여 EuroLLM-1.7B-Instruct 모델을 생성했습니다. 이 모델은 다국어 지시를 따를 수 있습니다.

#### Results (결과)
EuroLLM-1.7B-Instruct 모델은 Gemma-2b 및 Gemma-7b 모델과 비교하여 모든 데이터셋에서 우수한 성능을 보였습니다. EuroBlocks 데이터셋으로 미세조정을 진행한 결과, 다국어 성능 및 기계 번역 성능에서 우수한 결과를 얻었습니다.

#### Conclusions and Future Work (결론 및 향후 작업)
이 논문에서는 EuroLLM 프로젝트의 현재 작업을 설명하고, 데이터 수집 및 필터링 과정, 다국어 토크나이저 생성, 데이터 믹스 및 모델 구성에 대해 설명합니다. 향후에는 모델 파라미터 수를 확장하고 데이터 품질을 더욱 향상시키는 방향으로 연구를 계속할 예정입니다.

### 2. 전체 요약
EuroLLM 프로젝트는 유럽 내 모든 공식 언어와 추가적으로 몇 가지 관련 언어들을 이해하고 텍스트를 생성할 수 있는 다국어 대형 언어 모델(LLM)을 개발하는 것을 목표로 합니다. 이 프로젝트는 데이터 수집 및 필터링, 다국어 토크나이저 생성, 데이터 믹스 구성, 모델 구조 등 다국어 LLM의 다양한 요소를 다룹니다. 초기 결과는 매우 긍정적이며, EuroLLM-1.7B와 EuroLLM-1.7B-Instruct 모델이 다국어 성능 및 기계 번역에서 뛰어난 성능을 보였습니다. 향후 연구는 모델의 파라미터를 확장하고 데이터 품질을 향상시키는 데 중점을 둘 계획입니다.