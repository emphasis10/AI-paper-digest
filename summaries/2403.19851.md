# Localizing Paragraph Memorization in Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2403.19851.pdf](https://arxiv.org/pdf/2403.19851.pdf)

이 논문은 언어 모델이 훈련 데이터의 전체 문단을 기억하고 재현하는 메커니즘과 가중치를 어떻게 특정할 수 있는지에 대해 탐구합니다. 연구진은 GPT-NEO 125M 모델과 PILE 데이터셋을 사용하여, 모델이 특정 문단을 기억하는 과정에서 나타나는 공간적 패턴과 가중치의 변화를 분석합니다. 주요 발견은 다음과 같습니다:

- 기억된 문단은 주로 모델의 하위 레이어에서 더 큰 그래디언트를 보이며, 이러한 문단은 고도로 특정된 몇몇 토큰에 의해 '트리거'될 수 있습니다.
- 모델의 특정 어텐션 헤드(1층의 2번 헤드)가 문단 기억에 중요한 역할을 하며, 이 헤드는 특히 희귀 토큰에 주목합니다.
- 기억 메커니즘은 수정 가능하며, 특정 가중치를 미세 조정함으로써 기억된 내용을 '잊게' 하거나 변경할 수 있습니다.

### 1. 소개(Introduction)

언어 모델이 훈련 데이터에서 직접 복사한 문단을 출력할 수 있는 능력에 대해 소개하고, 이러한 기능이 모델 가중치 어딘가에 표현되어야 한다고 설명합니다.

### 2. 관련 연구(Related Work)

언어 모델의 기억력, 해석 가능성, 모델 편집 등 세 가지 주제에 대한 기존 연구를 요약합니다.

### 3. 기억된 문단 식별(Identifying Memorized Paragraphs)

GPT-NEO 125M 모델을 사용하여 기억된 문단을 식별하는 방법론을 설명합니다. 기억된 문단은 모델이 주어진 토큰의 접두사를 기반으로 정확히 연속적으로 생성할 수 있는 문단으로 정의됩니다.

### 4. 접두사 토큰 변조(Prefix Token Perturbation)

모델이 문단을 기억하는 과정에서 특정 접두사 토큰이 얼마나 중요한지를 평가합니다. 특정 토큰을 변조했을 때 모델 출력에 미치는 영향을 분석합니다.

### 5. 파라미터 로컬라이징(Localizing Parameters)

기억 과정에 관여하는 모델 파라미터를 식별하고, 그래디언트 기반 방법을 사용하여 특정 파라미터가 기억에 얼마나 기여하는지 평가합니다.

### 6. 기억 헤드(Memorization Head)

모델 내에서 특히 기억과 관련된 것으로 식별된 어텐션 헤드에 대해 논의합니다. 이 헤드는 희귀 토큰에 집중함으로써 문단을 기억하는 데 중요한 역할을 합니다.

### 7. 토론(Discussion)

논문에서 발견된 주요 결과와 이러한 결과가 언어 모델 해석 및 개선에 어떻게 기여할 수 있는지에 대해 토론합니다.

### 8. 결론(Conclusion)

논문의 주요 발견을 요약하고, 언어 모델이 훈련 데이터의 특정 부분을 어떻게 기억하고 재현하는지에 대한 이해를 높였다고 결론집니다.

이 논문은 언어 모델이 어떻게 데이터를 기억하고 이를 사용하여 문단을 재생산하는지에 대한 메커니즘을 탐구함으로써, AI와 기계 학습 분야에 중요한 기여를 합니다.

## Similar Papers
- [Confidence Regulation Neurons in Language Models](2406.16254.md)
- [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](2405.19325.md)
- [The Remarkable Robustness of LLMs: Stages of Inference?](2406.19384.md)
- [Prompt Sketching for Large Language Models](2311.04954.md)
- [Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models](2402.19427.md)
- [When can transformers reason with abstract symbols?](2310.09753.md)
- [Attention as a Hypernetwork](2406.05816.md)
- [Attention Is All You Need](1706.03762.md)
- [Transformers Can Represent $n$-gram Language Models](2404.14994.md)
