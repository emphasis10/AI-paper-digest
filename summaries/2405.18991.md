# EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.18991.pdf](https://arxiv.org/pdf/2405.18991.pdf)

### 섹션 요약

**1. 소개 (Introduction)**
이 논문은 고성능 비디오 생성 방법인 EasyAnimate를 소개합니다. 이 방법은 원래 2D 이미지 합성을 위해 설계된 DiT(Diffusion Transformer) 프레임워크를 확장하여 3D 비디오 생성을 가능하게 합니다. EasyAnimate는 모션 모듈 블록을 도입하여 시간적 역학을 포착하고 일관된 프레임과 부드러운 모션 전환을 생성합니다. 이 모듈은 다양한 스타일의 비디오를 생성할 수 있으며, 다양한 프레임 속도와 해상도로 비디오를 생성할 수 있습니다. 또한, 긴 시간 동안의 비디오 생성을 용이하게 하는 Slice VAE를 도입했습니다. 이 방법은 144프레임의 비디오를 생성할 수 있으며, DiT 기반의 포괄적인 비디오 제작 생태계를 제공합니다.

**2. 모델 아키텍처 (Model Architecture)**
EasyAnimate는 PixArt-α를 기반으로 하며, 텍스트 인코더, 비디오 VAE(비디오 인코더와 비디오 디코더), 그리고 Diffusion Transformer(DiT)를 포함합니다. 텍스트 인코더로는 T5 인코더를 사용하며, 비디오 VAE는 기존 이미지 VAE의 한계를 극복하고 시간적 차원을 압축하는 Slice VAE를 도입했습니다.

**3. 비디오 VAE (Video VAE)**
기존의 이미지 기반 VAE는 비디오 프레임을 개별 잠재 기능으로 인코딩하지만, 시간적 역학을 놓치고 큰 잠재 기능 크기를 초래합니다. 이를 해결하기 위해 Slice VAE는 시간적 차원을 압축하고, 공간 및 시간적 정보를 모두 포착하여 메모리 효율성을 높입니다. 이 방법은 이미지와 비디오 모두를 사용하여 훈련할 수 있습니다.

**4. 비디오 확산 변환기 (Video Diffusion Transformer)**
Diffusion Transformer는 PixArt-α를 기반으로 하며, 모션 모듈과 UViT 연결을 통합하여 2D 이미지 합성에서 3D 비디오 생성으로 확장합니다. 모션 모듈은 프레임 간의 시간적 정보를 통합하고, Grid Reshape 작업을 통해 공간적 세부 사항을 활용하여 생성 성능을 향상시킵니다. UViT 연결은 훈련 과정의 안정성을 강화합니다.

**5. 데이터 전처리 (Data Preprocess)**
데이터 전처리는 비디오 분할, 비디오 필터링, 비디오 캡션링의 세 단계로 구성됩니다. 비디오 분할은 PySceneDetect를 사용하여 장면 변화를 감지하고, 적절한 길이의 비디오 세그먼트를 유지합니다. 비디오 필터링은 모션 점수, 텍스트 영역 점수, 미적 점수를 사용하여 고품질 비디오 데이터를 선별합니다. 비디오 캡션링은 VideoChat2와 VILA 모델을 사용하여 세부적이고 시간 정보를 포함한 비디오 캡션을 생성합니다.

**6. 훈련 과정 (Training Process)**
EasyAnimate의 훈련은 약 1200만 개의 이미지 및 비디오 데이터를 사용하여 수행됩니다. 먼저 비디오 VAE를 훈련한 후, 새로운 VAE에 DiT 모델을 맞추기 위해 세 단계의 훈련 전략을 사용합니다. 초기에는 이미지 데이터를 사용하여 DiT 파라미터를 맞추고, 대규모 비디오 데이터셋을 사용하여 모션 모듈을 사전 훈련합니다. 마지막으로 고해상도 비디오 데이터를 사용하여 전체 DiT 모델을 정제합니다.

**7. 결론 (Conclusion)**
EasyAnimate는 DiT 프레임워크를 기반으로 하여 일관된 프레임 생성과 부드러운 모션 전환을 보장하는 모션 모듈을 통합한 고성능 AI 비디오 생성 및 훈련 파이프라인을 소개합니다. 이 모델은 다양한 프레임 수와 해상도로 비디오와 이미지를 생성할 수 있습니다.

### 전체 요약
EasyAnimate는 고성능 비디오 생성을 위한 혁신적인 방법으로, DiT 프레임워크를 확장하여 3D 비디오 생성을 가능하게 합니다. 이 방법은 시간적 역학을 포착하는 모션 모듈과 시간적 차원을 압축하는 Slice VAE를 도입하여 긴 시간 동안의 비디오 생성을 용이하게 합니다. EasyAnimate는 다양한 스타일과 해상도의 비디오를 생성할 수 있으며, 훈련 및 추론 과정에서의 효율성을 크게 향상시킵니다. 데이터 전처리, VAE 훈련, DiT 모델 훈련을 포함한 포괄적인 비디오 제작 생태계를 제공하여, 향후 비디오 합성 연구에 강력한 기준선을 제공합니다.

## Similar Papers
- [Tora: Trajectory-oriented Diffusion Transformer for Video Generation](2407.21705.md)
- [StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation](2405.01434.md)
- [ShareGPT4Video: Improving Video Understanding and Generation with Better Captions](2406.04325.md)
- [I4VGen: Image as Stepping Stone for Text-to-Video Generation](2406.02230.md)
- [MovieDreamer: Hierarchical Generation for Coherent Long Visual Sequence](2407.16655.md)
- [DiffIR2VR-Zero: Zero-Shot Video Restoration with Diffusion-based Image Restoration Models](2407.01519.md)
- [MiraData: A Large-Scale Video Dataset with Long Durations and Structured Captions](2407.06358.md)
- [NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing](2406.06523.md)
- [ExVideo: Extending Video Diffusion Models via Parameter-Efficient Post-Tuning](2406.14130.md)
