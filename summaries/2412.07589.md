# DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.07589.pdf](https://arxiv.org/pdf/2412.07589.pdf)

1. 각 섹션 요약:

- **서론**: 이 논문은 이야기를 시각화하는 작업을 다룹니다. 현재 텍스트에서 이미지를 생성하는 모델들은 캐릭터의 외모와 상호작용을 효과적으로 통제하지 못하는 문제를 가지고 있습니다. 이를 해결하기 위해 맞춤형 만화 생성이라는 새로운 작업을 제안하고, 이를 위해 DiffSensei라는 혁신적인 프레임워크를 소개합니다.

- **DiffSensei**: 이 프레임워크는 확산 기반 이미지 생성기와 MLLM(다중 모달 대형 언어 모델)을 통합하며, 캐릭터를 텍스트와 함께 변형할 수 있는 기능을 제공합니다. 마스크된 크로스-어텐션 기법을 사용하여 프레임 간에 일관된 스토리를 유지하면서 캐릭터의 표현, 자세, 행동 등을 조정할 수 있습니다.

- **MangaZero 데이터셋**: DiffSensei의 성능을 보여주기 위해 일본의 대규모 흑백 만화 데이터셋인 MangaZero를 소개합니다. 이 데이터셋은 43,264개의 만화 페이지와 427,147개의 패널로 구성되어 있으며, 다양한 캐릭터 상호작용과 움직임을 시각화하는 데 유용합니다.

- **실험 및 평가**: 여러 실험을 통해 DiffSensei가 기존 모델보다 뛰어난 성능을 발휘함을 입증합니다. 특히, 텍스트-적응형 캐릭터 사용자화를 통해 기존 방법을 뛰어넘는 스토리 비주얼라이제이션을 생성할 수 있음을 보여줍니다.

2. 전체 요약:

이 논문은 맞춤형 만화 생성을 위한 DiffSensei라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 다중 캐릭터의 컨트롤을 가능케 하며, 이를 통해 텍스트에 적응하는 캐릭터 사용자화를 실현합니다. 또한, MLLM을 사용해 유동적인 캐릭터 조정이 가능하며, 새로운 manga dataset인 MangaZero를 활용하여 실험적으로 이를 뒷받침합니다. DiffSensei는 이러한 점에서 기존의 모델을 능가하는 스토리 비주얼라이제이션의 혁신을 가져옵니다.