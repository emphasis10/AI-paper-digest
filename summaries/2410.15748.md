# Alchemy: Amplifying Theorem-Proving Capability through Symbolic Mutation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.15748.pdf](https://arxiv.org/pdf/2410.15748.pdf)

### 1. 각 섹션의 요약

**소개(Introduction)**:

이 연구 논문은 수학적 증명을 자동화하는 "Neural Theorem Proving (NTP)"라는 기계 학습 기반의 방법론을 다루고 있습니다. 수학적 증명을 작성하는 것은 일반 텍스트에 비해 데이터가 희소하기 때문에 어려운 작업이며, 이를 해결하기 위해 대형 언어 모델(LLM)을 사용한 데이터 증강 방법을 제안합니다. 본 연구에서는 상징적 변이를 통해 수학적 증명을 생성하고 그 양을 대폭 증가시켰습니다.

**연구 방법론 및 실험(Methods and Experiments)**:

이 논문에서는 Mathlib에서 수집한 110,000개의 정리를 바탕으로 상징적 변이를 통해 새로운 정리들을 생성합니다. 그러한 과정을 통해 약 600만 개의 정리를 생성하고, 이를 바탕으로 대형 언어 모델을 목표로 지속적인 사전 훈련과 감독된 미세 조정을 수행했습니다. 실험 결과, 이 방법이 Leandojo 및 miniF2F라는 벤치마크에서 약 5%의 성능 향상을 가져오는 것으로 나타났습니다.

**결과 및 분석(Results and Analysis)**:

증명 생성 및 정리 검증 과정은 주로 "rw" 및 "apply" 전술을 중심으로 이루어집니다. 대규모 상징 변이를 통해 데이터 희소성 문제를 크게 완화하고 정리 증명 능력을 향상시킵니다. 서로 다른 명령 조합에 따른 성능 비교를 통해 새로운 정리에서의 성능 향상을 확인할 수 있었습니다.

**주요 기여와 혁신(Main Contribution and Innovation)**:

이 논문의 주요 기여는 대형 언어 모델을 사용하여 기존의 기계 학습 모델이 어려워하던 수학적 증명을 데이터 증강을 통해 효율적으로 수행할 수 있도록 한 것입니다. 상징적 변이를 통해 생산한 대규모의 데이터 세트는 기존의 데이터 가용성 문제를 해결하며, 특정 도메인에 국한되지 않고 일반적인 수학적 영역에 적용 가능합니다.

이 연구는 새로운 데이터 생성 기술을 통해 AI의 증명 능력을 크게 향상시켰다는 데에 의미가 있습니다.

### 2. 전체 요약

이 논문은 상징적 변이 기법을 사용하여 기존의 마더보드에 비해 훨씬 많은 수학적 정리를 생성하고, 이를 통해 Neural Theorem Proving 모델의 훈련을 가능하게 합니다. 이를 통해 AI의 수학적 추론 능력을 향상시키고, 대형 언어 모델이 보다 복잡한 증명 문제를 해결할 수 있도록 하였습니다. 이러한 접근은 증명 데이터의 제한을 극복하고 대형 언어 모델의 활용 가능성을 확장하는 데 있어서 중요한 진전을 가져왔습니다.