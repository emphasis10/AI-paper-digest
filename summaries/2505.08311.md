# AM-Thinking-v1: Advancing the Frontier of Reasoning at 32B Scale
## TL;DR
## Summary
- [https://arxiv.org/pdf/2505.08311.pdf](https://arxiv.org/pdf/2505.08311.pdf)

1. 각 섹션의 중요 내용 요약:

- **초록**: 이 논문은 AM-Thinking-v1라는 32B 규모의 밀집형 언어 모델을 소개합니다. 이 모델은 오픈 소스 혁신의 협력 정신을 구현하며, 수학적 및 코드 생성 능력에서 최신 성능을 보여줍니다.

- **서론**: 최근 대규모 언어 모델(LLM)이 수학 문제 해결과 코드 생성에서 뛰어난 성과를 냈으며, 이는 실제 적용 가능성을 넓히고 있습니다.

- **데이터 및 접근법**: 모델은 공개 데이터세트를 사용하여 훈련되었으며 엄격한 데이터 전처리를 통해 정제된 쿼리를 사용합니다. 포스트 트레이닝 파이프라인은 두 단계로 이루어지며, 지도형 미세조정(SFT)과 강화 학습(RL)을 포함합니다.

- **실험 및 결과**: AM-Thinking-v1은 수학 및 코드 생성 벤치마크에서 뛰어난 성능을 보입니다.

- **결론**: AM-Thinking-v1은 오픈 소스 모델 중 비교 가능한 규모에서 최신의 추론 능력을 보여주며, 32B 규모의 밀집형 모델이 실제 적용에서 큰 잠재력을 지닌다는 것을 보여줍니다. 한계로는 구조화된 함수 호출, 도구 사용, 다중 모달 입력의 제한점이 있으며, 안전성 조정과 더 많은 리소스가 필요합니다.

2. 종합 요약:

이 논문은 AM-Thinking-v1라는 32B 규모의 언어 모델을 소개하며, 오픈 소스 모델 중 유사한 규모에서 최상의 추론 능력을 보여줍니다. 이 모델은 오픈 소스 데이터로 구축되었으며, 수학 문제 및 코드 생성 같은 복잡한 문제에서 뛰어난 성능을 발휘합니다. 데이터의 철저한 전처리와 지도형 미세조정 및 강화 학습을 이용한 포스트 트레이닝 파이프라인 덕분에 중간 규모의 모델이 실제 사용 가능한 성능을 보여주었다고 결론짓습니다. 다만, 구조화된 기능 호출과 다중 모달 입력이 부족하며, 안전성 면에서는 더 많은 연구가 필요하다는 점을 강조합니다.