# THREAD: Thinking Deeper with Recursive Spawning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.17402.pdf](https://arxiv.org/pdf/2405.17402.pdf)

### 논문의 주요 기여 및 혁신적인 부분

#### 1. 서론
본 논문은 "Thinking Recursively and Dynamically" (THREAD)라는 새로운 프레임워크를 제안합니다. 이 프레임워크는 큰 언어 모델(LLM)이 문맥의 길이와 복잡성이 증가함에 따라 성능이 저하되는 문제를 해결하고자 합니다. THREAD는 모델의 생성 과정을 스레드 실행으로 간주하여 문맥에 따라 새 스레드를 동적으로 생성하거나 기존 스레드를 완료할 수 있습니다. 이러한 동적 스레드 생성을 통해 모델은 필요한 만큼 중간 작업을 적응적으로 수행할 수 있습니다.

#### 2. 기여
THREAD는 기존 모델들이 긴 문맥에서 직면하는 문제를 해결하기 위해 다음과 같은 주요 기여를 합니다:
- 스레드 생성 및 동기화를 통해 부모 스레드가 필요한 정보만 반환받아 작업을 효율적으로 수행할 수 있게 합니다.
- LLM 작업 해결 및 질문 응답 설정에서 동적 스레딩을 적용하여 주어진 작업이나 질문을 점진적으로 더 간단한 하위 문제로 재귀적으로 분해합니다.
- 다양한 벤치마크에서 GPT-4와 GPT-3.5를 사용하여 상태 최첨단 성능을 달성합니다.

#### 3. 혁신적인 부분
THREAD의 혁신적인 부분은 다음과 같습니다:
- 모델 생성 과정을 동적으로 관리할 수 있는 스레드 구조로 설계하여 중간 작업의 양을 조절할 수 있습니다.
- 부모-자식 스레드 간의 정보 교환 및 동기화를 통해 모델이 더욱 효율적으로 작업을 분배하고 수행할 수 있습니다.
- GPT-4와 GPT-3.5뿐만 아니라 Llama-3-8b 및 CodeLlama-7b와 같은 소규모 모델에서도 기존 프레임워크 대비 10%에서 50%의 성능 향상을 보입니다.

#### 4. 결론
THREAD 프레임워크는 모델 생성 과정을 동적으로 관리하여 LLM의 작업 수행 능력과 질문 응답 정확성을 크게 향상시킵니다. 이를 통해 다양한 벤치마크에서 기존 방법보다 뛰어난 성능을 보여줍니다. 본 연구는 향후 LLM의 활용 가능성을 크게 확장할 수 있는 잠재력을 제시합니다.

### 전체 요약
본 논문은 LLM의 성능을 극대화하기 위해 THREAD라는 새로운 프레임워크를 제안합니다. THREAD는 모델의 생성 과정을 동적으로 관리하여 필요한 만큼 중간 작업을 수행할 수 있게 함으로써 긴 문맥에서도 높은 성능을 유지할 수 있습니다. 이를 통해 다양한 작업과 질문 응답 설정에서 뛰어난 성능을 입증하며, 특히 GPT-4, GPT-3.5, Llama-3-8b, CodeLlama-7b와 같은 모델에서 기존 방법 대비 최대 50%의 성능 향상을 보였습니다. THREAD는 부모-자식 스레드 간의 동기화 및 정보 교환을 통해 더욱 효율적인 작업 분배를 가능하게 하며, 이를 통해 LLM의 활용 가능성을 크게 확장할 수 있는 혁신적인 접근법을 제시합니다.

## Similar Papers
- [OmniJARVIS: Unified Vision-Language-Action Tokenization Enables Open-World Instruction Following Agents](2407.00114.md)
- [MindSearch: Mimicking Human Minds Elicits Deep AI Searcher](2407.20183.md)
- [Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning](2406.19502.md)
- [Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks](2408.03615.md)
- [Two Giraffes in a Dirt Field: Using Game Play to Investigate Situation Modelling in Large Multimodal Models](2406.14035.md)
- [Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning](2406.06469.md)
- [Sibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning](2407.10718.md)
- [Grounded 3D-LLM with Referent Tokens](2405.10370.md)
- [AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents](2407.04363.md)
