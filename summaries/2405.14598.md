# Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.14598.pdf](https://arxiv.org/pdf/2405.14598.pdf)

### 논문 내용 요약

#### 1. 개요
논문은 텍스트 입력 외에도 다양한 모달리티(이미지, 오디오)의 조건부 생성 모델에 대한 연구를 다룹니다. 이미지를 오디오로 변환(image2audio), 오디오를 이미지로 변환(audio2image)하고 공동 생성(co-generation)할 수 있는 가벼운 트랜스포머 모델을 제안합니다. 제안된 모델은 간단하지만 기존 방법들보다 뛰어난 성능을 보입니다.

#### 2. 관련 연구
최근 텍스트에서 이미지로의 생성(text2image)이 활발히 연구되고 있으며, 이에 성공적인 연구 성과들이 있는 반면, 이미지에서 오디오로의 변환은 상대적으로 연구가 적습니다. 본 논문은 이 분야에서의 공백을 채우기 위해 노력합니다.

#### 3. 데이터 전처리
VGGSound 데이터셋을 사용하여 오디오와 이미지 데이터를 토큰화합니다. 오디오는 멜 스펙트로그램으로 변환되고, 이미지는 256×256 해상도 프레임으로 샘플링됩니다.

#### 4. 모델 구조
비교적 간단한 트랜스포머 구조를 채택하였습니다. 트랜스포머는 전체 어텐션을 사용하며, 마스킹된 입력을 디노이징(masks denoising)하는 과정에서 학습합니다. 학습된 모델은 어느 모달리티에도 적용될 수 있습니다.

#### 5. 실험 및 결과
제안된 방법은 이미지에서 오디오로 변환하는 데 있어서 기존 방법들보다 월등히 뛰어납니다. 또한, 방법론의 성능을 향상시키기 위해 분류자 없는 가이드(classifier-free guidance, CFG)를 사용할 수 있습니다.

#### 6. 결론
본 논문의 연구는 텍스트와 이미지의 결합을 넘어 오디오와 이미지의 결합에 대한 연구 공백을 메우고자 하였습니다. 가벼운 트랜스포머 모델이 어떻게 오디오-비주얼 생성에서 뛰어난 성능을 발휘할 수 있는지를 보였습니다.

### 전체 요약
이 논문은 다중 모달리티 생성 분야, 특히 이미지와 오디오의 상호 변환에 중점을 둡니다. 기존 연구들과 달리, 간단하고 가벼운 트랜스포머를 통해 효율적인 이미지2오디오, 오디오2이미지 변환 및 공동 생성을 실현합니다. 실험 결과, 본 방법론이 기존의 무거운 모델보다 성능이 뛰어남을 보여줍니다. 이러한 가벼운 트랜스포머 모델은 대규모 데이터 없이도 강력한 성능을 발휘하며, 향후 다중 모달리티 생성 연구의 강력한 기준점이 될 것입니다.