# LLMs Still Can't Plan; Can LRMs? A Preliminary Evaluation of OpenAI's o1 on PlanBench
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.13373.pdf](https://arxiv.org/pdf/2409.13373.pdf)

### 주요 섹션 요약 및 전체 요약

#### 섹션별 요약

1. **서론**
   - 본 연구는 OpenAI의 새로운 모델인 o1(딸기) 릴리스와 함께 최신 PlanBench에 대한 평가를 제공합니다. 기존 대형 언어 모델(LLMs)은 대략적인 검색자로 볼 수 있는 반면, o1 모델은 대략적인 추론자로 훈련된 것으로 보입니다. 이러한 새로운 모델이 이전 모델과 어떻게 다른지 평가하기 위해 새로운 도구와 평가 방법이 필요합니다.

2. **LLM의 계획 능력**
   - PlanBench는 LLM의 계획 및 추론 능력을 테스트하기 위한 중요한 벤치마크로 남아있습니다. 그러나 최근까지 LLM은 가장 기본적인 계획 문제에서도 높은 성과를 내지 못했고 발전이 일반적이지 않다고 평가됩니다. 특히, 신비 블럭월드(Mystery Blocksworld)와 같은 복잡한 문제에서는 성과가 거의 없습니다.

3. **LRM의 평가**
   - OpenAI의 o1 미리보기와 LLM은 블럭월드 테스트 세트에서 보다 우수한 성능을 발휘하였으나, 신비 블럭월드에서는 성과가 저하되었습니다. 이 모델들은 기존 LLM을 뛰어넘는 성능을 보여주지만, 문제의 복잡성이 증가함에 따라 성능이 급격히 떨어집니다.

4. **결론**
   - SOTA LLMs와 OpenAI의 새로운 o1 모델의 계획 능력을 재평가하였습니다. o1 모델은 강점과 한계를 지닌 체험적인 자료를 제공하며, 특히 계획 영역에서 LRM과 LLM의 현실적인 평가에 대한 제안을 제공합니다.

#### 전체 요약

이 연구는 OpenAI의 새로운 모델인 o1과 기존의 LLMs의 계획 및 추론 능력을 PlanBench를 통해 분석하였습니다. o1은 기존 LLMs와 비교했을 때 혁신적인 진전을 보였으며, 특히 복잡한 문제 해결에서 새로운 가능성을 보여주었습니다. 그러나 이러한 성과는 문제의 복잡성이 커짐에 따라 일반적이고 견고하지 않음을 시사합니다. 본 연구는 LRM과 LLM의 계획 능력 실사 평가를 위해 효율성, 비용 및 보장에 대한 고려가 필요하다고 강조합니다.