# S*: Test Time Scaling for Code Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.14382.pdf](https://arxiv.org/pdf/2502.14382.pdf)

### 1. 섹션 요약 및 주요 기여

**소개(Introduction):**
이 논문은 대규모 언어 모델(LLM)의 성능을 다양한 과제에서 개선하기 위해 시험 시간 내 계산을 증가시키는 방법을 탐구하고 있습니다. 특히 코드 생성 분야는 수학적 추론과는 다른 독특한 도전 과제를 가지고 있습니다. 코드 생성은 프로그램의 기능적 정확성을 검증하기 위한 실행 과정이 필요합니다. 이 논문은 S*라는 하이브리드 시험 시간 스케일링 프레임워크를 제안합니다. S*는 병렬 스케일링을 순차적 디버깅과 통합하여 생성된 코드의 적용 범위와 선택 정확성을 크게 향상시킵니다.

**관련 연구(Related Work):**
기존의 LLM 시험 시간 스케일링 방법은 병렬 및 순차적 스케일링으로 나눌 수 있습니다. 이 논문은 코드 생성 작업에 하이브리드 스케일링을 적용하여 그 성능을 개선하려고 합니다.

**방법론(Methodology):**
S*는 코드 생성 성능을 향상시키기 위해 두 가지 주요 단계로 동작합니다. 첫째, 생성 단계에서는 각 예제가 디버깅을 통해 개선됩니다. 둘째, 선택 단계에서는 적응형 입력 합성을 통해 최상위 샘플을 선택합니다. 이 과정은 실행 중심의 피드백을 포함하여 LLM 평가를 강화시킵니다.

**평가 및 결과(Results and Evaluation):**
S*는 다양한 모델에서 성능을 향상시킵니다. 특히, 작은 모델이 큰 모델 이상의 성능을 발휘하게 하며, 명령 기반 모델이 추론 모델을 초과할 수 있도록 합니다. LiveCodeBench와 CodeContests를 사용한 평가에서는, S*가 기존의 기술들을 넘어서는 향상된 성능을 보여주고 있습니다.

**결론(Conclusion):**
논문은 S*의 효과성을 강조하며, 이를 통해 다양한 모델 및 환경에서 일관되게 성능을 향상시킴을 보여줍니다. 전반적으로, S*는 시험 시간에 코드 생성의 범위와 정확성을 모두 향상시키는 강력한 기법으로 자리잡고 있습니다.

### 2. 전체 요약
이 논문은 코드 생성의 성능을 향상시키기 위한 S*라는 새로운 하이브리드 시험 시간 스케일링 프레임워크를 제안합니다. S*는 병렬 스케일링과 순차적 디버깅의 통합을 통해 생성된 코드의 적용 범위와 선택 정확성을 크게 개선합니다. 이는 다양한 모델에서 성능을 일관되게 향상시켜 주고 있으며, 특히 작은 모델이 더 큰 모델 이상의 효율성을 발휘하고 명령 기반 모델이 추론 모델보다 우수한 성능을 나타내도록 합니다. 이 프레임워크는 새로운 시험 시간 기법의 기반이 될 수 있으며, 향후 연구 및 개발에서도 중요한 기여를 할 것입니다.