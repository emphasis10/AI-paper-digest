# Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.19263.pdf](https://arxiv.org/pdf/2406.19263.pdf)

### 1. 섹션별 요약 및 주요 기여

**초록**
이 논문은 ToL(Tree-of-Lens) 블록들과 함께 ToL 에이전트를 제안하며, 이를 통해 GUI 스크린 샷에서 지정된 영역의 내용과 레이아웃을 설명합니다. 이를 통해 시각 장애인을 위한 접근성을 향상시키는 데 기여합니다.

**1. 도입**
GUI는 디지털 인터페이스의 핵심입니다. 사용자가 지정한 스크린 포인트를 읽는 Screen Point-and-Read (ScreenPR) 작업은 기존의 도구로는 한계가 있습니다. 이 논문은 이를 해결하기 위해 ToL 에이전트를 제안합니다.

**2. 관련 연구**
GUI 이해를 위한 다중모델 대형 언어모델(Multimodal Large Language Models, MLLMs)의 최근 발전은 GUI 작업을 다루는 강력한 모델을 가능하게 했습니다. 예를 들어, CogAgent, Ferret-UI 등이 있습니다.

**3. ToL 에이전트**
ToL 에이전트는 스크린 샷으로부터 계층적 레이아웃 트리를 구성하여 사용자의 포인트를 입력으로 받아들입니다. 그런 다음, 다중 렌즈 시리즈를 통해 GUI의 내용 및 레이아웃을 시각적으로 설명합니다.

**4. Screen Point-and-Read 벤치마크**
650개의 스크린샷과 1,500개의 타겟 포인트로 이루어진 ScreenPR 벤치마크를 도입하여 ToL 에이전트의 성능을 엄격하게 평가합니다. 이 벤치마크는 웹, 모바일, 운영 체제의 다양한 GUI를 포괄합니다.

**5. 실험**
ToL 에이전트는 내용과 레이아웃 설명의 정확도에서 GPT-4o 모델을 포함한 다른 모델들을 능가합니다. 그리고 모바일 GUI 네비게이션 에이전트의 실행 경로에서 잘못된 동작을 식별하는데 유용성을 입증했습니다.

**6. 결론 및 논의**
ToL 에이전트는 디지털 장치의 접근성을 크게 개선할 수 있을 뿐만 아니라, 모바일 네비게이션 에이전트의 성능을 향상시킬 수 있는 가능성을 보였습니다.

**7. 한계**
GPT-4o 서비스를 활용하는데 따르는 서버 지연 및 높은 비용은 현실 세계 적용에서의 이슈가 될 수 있습니다. 따라서 더 효율적이고 현지 호스팅 가능한 모델이 필요합니다.

### 2. 전체 요약
이 논문은 GUI 스크린 샷에서 지정된 영역의 내용과 레이아웃을 설명하는 ToL(Tree-of-Lens) 에이전트를 제안합니다. 이 에이전트는 스크린 포인트를 읽는 Screen Point-and-Read 작업을 수행하며, 사용자가 지정한 포인트로부터 스크린 내용을 이해하고 정확하게 설명합니다. 새로운 ScreenPR 벤치마크를 도입하고, 다양한 GUI에서 ToL 에이전트의 성능을 평가하여 다른 모델보다 뛰어난 성능을 보였습니다. 이 연구는 시각 장애인을 위한 접근성을 개선하고, 모바일 네비게이션 에이전트의 성능 향상에 기여할 수 있는 중요한 가능성을 보여줍니다.

이 논문은 특히 고유의 '계층적 레이아웃 트리' 방법을 통해 구체적인 영역을 다중 렌즈 시리즈로 설명하여 더 정밀한 내용과 레이아웃 설명을 가능하게 합니다. 이를 통해 접근성 도구의 가능성을 확장하고 더 효율적인 GUI 해석을 실현합니다.

## Similar Papers
- [OmniParser for Pure Vision Based GUI Agent](2408.00203.md)
- [AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents](2407.17490.md)
- [Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs](2404.05719.md)
- [ScreenAI: A Vision-Language Model for UI and Infographics Understanding](2402.04615.md)
- [Very Large-Scale Multi-Agent Simulation in AgentScope](2407.17789.md)
- [MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos](2406.08407.md)
- [WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents](2404.05902.md)
- [VideoGUI: A Benchmark for GUI Automation from Instructional Videos](2406.10227.md)
- [MMInA: Benchmarking Multihop Multimodal Internet Agents](2404.09992.md)
