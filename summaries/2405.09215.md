# Xmodel-VLM: A Simple Baseline for Multimodal Vision Language Model
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.09215.pdf](https://arxiv.org/pdf/2405.09215.pdf)

### 주요 내용 요약

1. **서론 및 배경**:
   - 이 논문은 **Xmodel-VLM**이라는 최신 멀티모달 비전 언어 모델을 소개합니다. Xmodel-VLM은 소비자 GPU 서버에서 효율적으로 배포될 수 있도록 설계되었으며, 대규모 멀티모달 시스템의 높은 서비스 비용 문제를 해결하고자 합니다. 이 모델은 LLaVA 패러다임을 활용하여 모달 정렬을 수행하는 1B 규모의 경량 언어 모델입니다. Xmodel-VLM은 크기는 작지만 더 큰 모델과 비슷한 성능을 제공하는 것으로 나타났습니다.

2. **방법론**:
   - **네트워크 아키텍처**: Xmodel-VLM의 아키텍처는 세 가지 주요 구성 요소로 이루어져 있습니다: 비전 인코더, 경량 언어 모델(LLM), 그리고 시각적 및 텍스트 공간을 정렬하는 프로젝터.
   - **비전 인코더**: 사전 훈련된 CLIP ViT-L/14 (336x336 해상도)를 비전 인코더로 사용합니다.
   - **언어 모델**: 운영 비용을 줄이기 위해 Xmodel-LM 1.1B라는 경량 언어 모델을 처음부터 훈련했습니다.
   - **프로젝터**: 2층 MLP를 사용하여 비전 인코더와 LLM 간의 연결을 강화하고, Mish 활성화 함수를 사용합니다. 프로젝터는 시각적 토큰 수를 75% 줄이는 다운샘플링 메커니즘으로도 작동합니다.

3. **실험**:
   - **훈련**: CC-595K 데이터셋을 사용한 1차 사전 훈련과 LLaVA-Instruct-150K 데이터셋을 사용한 2차 미세 조정을 통해 모델을 훈련합니다. 1차 사전 훈련에서는 시각적 인코더와 LLM 가중치를 고정한 상태에서 프로젝터의 학습에 집중합니다.
   - **성능 평가**: VizWiz, ScienceQA-IMG, TextVQA, POPE, GQA, MMBench 등 다양한 벤치마크에서 성능을 평가했습니다. Xmodel-VLM은 작은 크기에도 불구하고 경쟁력 있는 성능을 보여주었습니다.
   - **추론 지연 시간 평가**: Xmodel-VLM은 LLaVA-7B 및 MobileVLM 모델과 비교하여 빠른 추론 속도를 보였습니다. 이는 소형 모델의 장점을 부각시킵니다.

4. **Ablation Study**:
   - **프로젝터**: 다양한 프로젝터 아키텍처의 영향을 분석하여 MLP와 XDP의 성능을 비교했습니다.
   - **토큰 수**: 시각적 토큰 수가 성능에 미치는 영향을 평가했습니다. 토큰 수가 감소할수록 평가 지표의 성능이 점진적으로 감소하는 경향을 보였습니다.
   - **언어 모델**: 다양한 크기의 언어 모델이 성능에 미치는 영향을 분석했습니다. 더 큰 언어 모델이 성능 향상에 효과적임을 확인했습니다.

### 혁신적인 부분
Xmodel-VLM의 혁신성은 경량 언어 모델과 효율적인 프로젝터 설계를 통해 대규모 멀티모달 시스템의 높은 운영 비용 문제를 해결하고자 한 점에 있습니다. 이 모델은 크기는 작지만 경쟁력 있는 성능을 제공하며, 다양한 벤치마크에서 우수한 성과를 입증했습니다. 또한, 소형 모델의 빠른 추론 속도는 실시간 응용 프로그램에서 중요한 이점을 제공합니다.