# Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.06545.pdf](https://arxiv.org/pdf/2405.06545.pdf)

### 주요 내용 요약

1. **서론 및 배경**:
   - 대형 언어 모델(LLMs)은 다양한 분야에서 뛰어난 능력을 보여주지만, 현실 세계의 사실과 일치하지 않는 응답을 생성하는 '환각' 문제로 인해 특히 의료, 금융, 법률과 같은 중요 분야에서의 활용에 어려움이 있습니다. 이 연구에서는 의료 분야에서 LLM의 응답 사실성을 높이기 위해 적은 검색 노력으로 지식 그래프를 활용하는 자체 정제 강화 지식 그래프 검색(Re-KGR)을 제안합니다.

2. **방법론**:
   - Re-KGR 방법은 응답 생성 후 외부 지식을 통합하는 정제 후 검색 패러다임을 따릅니다. 토큰의 다음 토큰 예측 확률 분포의 속성을 활용하여 환각이 발생할 가능성이 높은 토큰을 식별하고, 이와 관련된 지식 트리플을 정제하여 검색 횟수를 줄입니다.

3. **실험 및 평가**:
   - 의료 데이터셋(MedQuAD)과 최신 대조 디코딩 기술(DoLa)을 사용하여 실험을 수행했습니다. 실험 결과, 제안한 방법이 LLM의 응답 사실성을 향상시킬 수 있음을 보여주며, 특히 DoLa 모델과 함께 사용할 때 가장 높은 진실성 점수를 달성했습니다.

### 혁신적인 부분
Re-KGR의 혁신성은 의료 QA 작업에서 지식 그래프를 통해 구조화된 외부 지식을 효율적으로 통합함으로써 LLM의 환각을 줄이고 사실 검증 과정을 간소화한다는 점입니다. 이 접근 방식은 직접 지식을 LLM에 주입하는 기존 방식의 문제점을 해결하고, 실제 응용에서 LLM의 이용 가능성을 크게 향상시킬 수 있습니다.

이 연구는 특히 의료 분야에서 LLM의 사실성과 응답 품질을 개선하는 방법을 제시하며, 향후 다양한 시나리오에서 이 방법의 일반화 가능성을 탐구할 계획입니다.