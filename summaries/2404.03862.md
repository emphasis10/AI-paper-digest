# Verifiable by Design: Aligning Language Models to Quote from Pre-Training Data
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.03862.pdf](https://arxiv.org/pdf/2404.03862.pdf)

**1. 개요**

본 논문은 'QUOTE-TUNING'이라는 새로운 기법을 소개하며, 이는 대규모 언어 모델(LLMs)이 사전 훈련 데이터에서 직접 인용하여 생성물의 정확성을 검증할 수 있도록 함으로써 사용자의 신뢰를 구축합니다. 이 방법은 모델이 사전 훈련 데이터의 고품질 소스에서 문장을 문자 그대로 인용하게 하여 생성된 내용의 신뢰성을 높이는 데 중점을 둡니다.

**2. QUOTE-TUNING 기법**

QUOTE-TUNING은 선호 최적화 알고리즘을 사용하여 LLMs가 특정 코퍼스에서 인용하는 것을 선호하도록 합니다. 이 과정은 인간의 주석 없이도 효율적인 멤버십 테스트 도구를 사용하여 대규모 코퍼스에서 문자열이 인용되었는지를 확인하고, 인용 정도를 측정하여 자동으로 피드백을 제공합니다.

**3. 실험 및 결과**

QUOTE-TUNING은 장문의 질문 응답 및 개방형 텍스트 완성 작업에서 기존 모델보다 인용을 55%에서 130% 향상시키는 것으로 나타났습니다. 또한, 이 방법은 도메인 간 일반화가 가능하며, 모델의 진실성을 높이는 데에도 도움을 줍니다.

**4. 결론**

QUOTE-TUNING은 LLMs의 출력물이 신뢰할 수 있는 정보를 바탕으로 생성되도록 보장함으로써, 인용을 통해 생성물의 정확성을 쉽게 검증할 수 있는 방법을 제공합니다. 이는 LLMs의 신뢰성을 향상시키고, 사용자가 모델의 응답을 더욱 신뢰할 수 있게 만드는 유망한 접근법입니다.


## Similar Papers
- [Tuning Language Models by Proxy](2401.08565.md)
- [ExoViP: Step-by-step Verification and Exploration with Exoskeleton Modules for Compositional Visual Reasoning](2408.02210.md)
- [CodecLM: Aligning Language Models with Tailored Synthetic Data](2404.05875.md)
- [SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation](2406.19215.md)
- [DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model](2405.04434.md)
- [Improving Retrieval Augmented Language Model with Self-Reasoning](2407.19813.md)
- [Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact Checking News Claims with Black-Box LLM](2404.17283.md)
- [Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models](2404.18796.md)
- [TroL: Traversal of Layers for Large Language and Vision Models](2406.12246.md)
