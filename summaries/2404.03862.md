# Verifiable by Design: Aligning Language Models to Quote from Pre-Training Data
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.03862.pdf](https://arxiv.org/pdf/2404.03862.pdf)

파일을 철저히 읽고 각 섹션의 중요한 내용을 요약한 내용을 다음과 같이 제공합니다:

### 1. 각 섹션의 요약

#### 서론
이 논문은 대규모 언어 모델(LLM)이 신뢰할 수 있는 출처로부터 정확한 인용을 생성하도록 하는 QUOTE-TUNING 기법을 소개합니다. 주요 목표는 모델의 결과를 정확한 출처에 기반하여 검증 가능하도록 하여 사용자 신뢰성을 높이는 것입니다.

#### 기초 정보 및 방법론
QUOTE-TUNING은 사전 훈련 데이터로부터 직접 인용을 생성하기 위해 모델을 조정하는 알고리즘입니다. 주어진 문장에 대한 사실 여부를 확인하는 빠른 멤버십 검증 함수를 사용하여 모델의 반응에서 인용을 양적으로 측정하는 보상 함수를 설계합니다.

#### 실험 결과
둔화되지 않은 모델에 비해 QUOTE-TUNING을 적용했을 때 인용이 55%에서 130%까지 증가하는 모습을 보였습니다. 또한, 모델의 진실성이 증가하는 것을 실험적으로 증명했습니다.

#### 결론 및 논의
QUOTE-TUNING은 다양한 작업과 도메인에서도 일반화할 수 있으며, 모델 결과의 검증 용이성을 강화합니다. 이는 인간과 기계 간의 신뢰를 구축하는 데 중요한 역할을 할 수 있습니다.

### 2. 전체 요약
이 연구의 주요 기여는 언어 모델이 사전 훈련된 데이터로부터 직접 인용을 생성하여 결과의 신뢰도를 높이는 기술을 개발한 것입니다. QUOTE-TUNING 알고리즘은 다양한 상황에 일반화될 수 있는 잠재력을 가지며, 모델의 진실성을 높이는 동시에 검증을 수월하게 만듭니다. 이는 AI의 투명성과 신뢰성 문제를 해결하는 데 있어 중요한 진보로 볼 수 있습니다.