# Multilingual Large Language Model: A Survey of Resources, Taxonomy and Frontiers
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.04925.pdf](https://arxiv.org/pdf/2404.04925.pdf)

**1. 개요**

본 논문은 다양한 언어로 질문에 응답할 수 있는 다국어 대규모 언어 모델(MLLMs)에 관한 첫 번째 종합적인 리뷰를 제공합니다. 이 연구는 다국어 정렬에 따라 MLLMs 연구 분야의 최근 진전을 요약하고, 새로운 분류 체계와 선도적인 연구 분야를 제시하여 다국어 언어 모델의 발전을 도모합니다.

**2. 데이터 리소스 및 전처리**

다국어 대규모 언어 모델의 사전 학습과 미세조정을 위해 사용되는 데이터 자원을 설명합니다. 이는 수동 생성, 웹 크롤링, 벤치마크 적응 등의 방법으로 다양한 언어 데이터를 수집하며, 이는 MLLMs의 효과적인 학습에 기여합니다.

**3. 정렬 분류**

MLLMs의 진전을 이해하기 위한 새로운 분류 체계를 제시합니다. 이는 '파라미터 튜닝 정렬'과 '파라미터 고정 정렬'의 두 가지 주요 전략을 포함합니다. 각 정렬 전략은 다양한 훈련 단계(예: 사전 훈련, 미세조정 등)에서 언어 간 정렬을 달성하기 위해 설계되었습니다.

**4. 새로운 연구 전선**

다국어 모델의 잠재적인 연구 분야와 해당 도전 과제를 강조합니다. 이는 향후 연구 개발을 위한 길잡이 역할을 하며, 특히 지식 편집, 안전성, 공정성 문제 등에 초점을 맞춥니다.

**5. 결론**

이 논문은 다국어 대규모 언어 모델의 발전에 대한 체계적인 이해를 돕고, 연구자들이 이 분야에서 새로운 돌파구를 이룰 수 있도록 지원하는 자료를 제공합니다.

이 내용을 바탕으로 전체적인 요약을 제공하겠습니다.

본 논문은 다국어 대규모 언어 모델(MLLMs)에 대한 첫 번째 종합적 리뷰를 제공합니다. 이 연구는 다양한 언어로 질문에 응답할 수 있는 MLLMs의 사용을 중점적으로 다루면서, 새로운 분류 체계와 선도적 연구 분야를 소개합니다. 또한, 다양한 데이터 자원과 전처리 방법을 통해 MLLMs의 학습 효과를 극대화하는 방법을 설명하고, 파라미터 튜닝 정렬과 파라미터 고정 정렬이라는 두 가지 주요 정렬 전략을 상세히 논의합니다. 이러한 전략들은 다국어 모델의 사전 학습과 미세조정에서 언어 간 정렬을 달성하기 위해 사용됩니다.

새로운 연구 전선으로는 지식 편집, 모델의 안전성 증진, 공정성 확보 등 다양한 도전 과제들이 강조되며, 이는 향후 MLLMs의 발전 방향을 제시합니다. 본 리뷰는 다국어 모델 연구의 깊이를 더하고, 이 분야에서의 새로운 연구 개발을 촉진하는 데 중요한 기여를 합니다. 이러한 내용은 다국어 처리 기능을 갖춘 인공지능 시스템의 개발을 이해하고, 관련 연구나 응용 프로그램에 참여하는 데 유용한 자원이 될 것입니다.

## Similar Papers
- [Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models](2402.14714.md)
- [Beyond the Speculative Game: A Survey of Speculative Execution in Large Language Models](2404.14897.md)
- [LAB: Large-Scale Alignment for ChatBots](2403.01081.md)
- [Mixture-of-Agents Enhances Large Language Model Capabilities](2406.04692.md)
- [SambaLingo: Teaching Large Language Models New Languages](2404.05829.md)
- [PECC: Problem Extraction and Coding Challenges](2404.18766.md)
- [OneBit: Towards Extremely Low-bit Large Language Models](2402.11295.md)
- [Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs](2406.18629.md)
- [On LLMs-Driven Synthetic Data Generation, Curation, and Evaluation: A Survey](2406.15126.md)
