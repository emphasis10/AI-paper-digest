# Denoising LM: Pushing the Limits of Error Correction Models for Speech Recognition
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.15216.pdf](https://arxiv.org/pdf/2405.15216.pdf)

### 1. 각 섹션 요약 및 주요 기여와 혁신적인 부분 설명

#### Introduction
이 논문은 전통적인 언어 모델(LM) 대신 에러 수정 모델을 활용하여 자동 음성 인식(ASR)의 성능을 향상시키고자 하는 연구입니다. 주요 기여는 텍스트-음성 변환(TTS) 시스템을 사용하여 대규모 합성 데이터를 생성하고 이 데이터를 통해 에러 수정 모델을 훈련한 것입니다. 이 새로운 접근방식은 기존의 LM 융합 방식보다 뛰어난 성능을 보였습니다.

#### Related Work
기존 연구들은 LMs를 효과적으로 활용하려는 시도 및 에러 수정 모델들의 발전을 다루었습니다. 그러나 에러 수정 모델은 주로 제한된 훈련 데이터로 인해 큰 성과를 거두지 못했습니다. 이 논문은 다양한 TTS 시스템을 활용한 대규모 합성 데이터를 사용하여 이를 극복하려 했습니다.

#### Denoising Speech Recognition (DSR)
DSR 모델은 ASR이 생성한 문장(Y~)을 입력으로 받아 깨끗한 문장(Y)으로 수정하는 모델입니다. 이 과정을 통해 ASR의 성능을 상당히 향상시킬 수 있습니다.이는 TTS 시스템에서 생성된 오디오와 ASR 모델에서 생성된 문장 쌍을 사용하여 훈련되었습니다.

#### Data Generation
TTS와 ASR 시스템을 연계 활용하여 대량의 합성 데이터를 생성해, 이를 바탕으로 DLM을 훈련시켰습니다. 데이터의 다변화를 위해 다양한 스타일의 TTS 시스템을 활용하고, 여러 소음 증가 기법을 사용해 모델을 더욱 강건하게 만들었습니다.

#### Decoding Techniques
DLM을 활용한 디코딩 기법은 greedy decoding 방식을 사용하여 전통적인 beam search 방식보다 효율적으로 성능을 향상시켰습니다.

#### Experimental Details
TTS 시스템을 통해 합성된 데이터와 실제 데이터의 혼합이 DLM 훈련에 사용되었습니다. 실험 결과, DLM은 다양한 ASR 모델과 데이터셋에서 일관되게 우수한 성능을 보였습니다.

#### Results
DLM은 LibriSpeech 데이터셋에서 신기록의 WER을 달성하였고, 특히 외부 오디오 데이터를 사용하지 않고도 우수한 성능을 보였습니다. 이는 기존의 self-supervised 방식보다도 뛰어난 성과입니다.

#### Conclusion
논문은 DLM이 다양한 ASR 시스템과 데이터셋에서 효율적이고 보편적으로 사용될 수 있음을 보였습니다. 이는 전통적인 LM을 대체할 수 있는 가능성을 보여줍니다. 추가적인 한계와 확장 가능성 또한 논의되었습니다.

### 2. 전체 요약
이 논문은 전통적인 언어 모델(LM) 대신 에러 수정 모델(DLM)을 사용하여 자동 음성 인식(ASR)의 성능을 획기적으로 향상시키는 방법을 제시합니다. TTS 시스템을 통해 대규모 합성 데이터를 생성하고 이를 바탕으로 DLM을 훈련해, 기존의 데이터를 사용하는 방법보다 훨씬 우수한 성능을 입증했습니다. 이 모델은 LibriSpeech 데이터셋에서 WER 1.5%라는 놀라운 성과를 보였으며, 다양한 ASR 시스템과 데이터셋에서 일관되게 뛰어난 성능을 보였습니다. 결과적으로, 이 연구는 DLM이 전통적인 LM을 대체할 수 있는 가능성을 보여주며 더욱 정확한 ASR 시스템 개발의 길을 열었습니다.