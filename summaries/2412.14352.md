# A Survey on LLM Inference-Time Self-Improvement
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.14352.pdf](https://arxiv.org/pdf/2412.14352.pdf)

### 1. 섹션별 요약:

**소개 (Introduction)**
이 논문은 대규모 언어모델(LLM)의 추론 시간 자가 향상 방법을 분석한 것입니다. 최근에는 테스트 시간에 계산을 증가시켜 모델의 성능을 향상시키려는 기술이 주목받고 있습니다. 독립적 자가 향상, 맥락 인식 자가 향상, 모델 지원 자가 향상이라는 세 가지 관점에서 그 현황을 조사하며, 해당 방식들의 분류체계를 제시하고 도전과제와 한계를 논의합니다.

**독립적 자가 향상 (Independent Self-Improvement)**
모델의 고정된 매개변수를 사용하여 성능을 개선하는 방법으로, 디코딩 과정을 수정하거나 병렬 디코딩, 샘플링 및 레이어 격리를 통해 성능을 높입니다.

**맥락 인식 자가 향상 (Context-Aware Self-Improvement)**
맥락 또는 데이타 스토어 검색을 활용해 성능을 향상할 수 있는 방법입니다. 여기에는 고급 프롬프트 기법, 검색 기반 방법이 포함됩니다. 이를 통해 모델이 더 나은 학습과 성능을 발휘할 수 있도록 합니다.

**모델 지원 자가 향상 (Model-Aided Self-Improvement)**
외부 모델(작은 모델)을 이용하여 성능을 향상하는 방법으로, 전문가 및 반전문가 모델, 초안 모델 등의 사용을 포함합니다. 이러한 외부 지원 모델을 통해 디코딩 과정을 개선하거나 가이드를 제공합니다.

**논의 및 미래 연구 방향 (Discussion and Future Work)**
논문은 이러한 방법들이 주는 이점을 언급하는 한편, 유지보수 필요성, 모델 접근성 문제, 추론 비용의 주요 고려사항, 일반화 가능성, 생성 품질 등의 도전과제도 조명합니다. 방법 선택 시 고려할 요소를 다루며, 앞으로 기술을 발전시킬 방향을 제안합니다.

**제약 사항 및 윤리적 고려 (Limitations and Ethical Considerations)**
모든 방법에 대한 기술적 상세를 다 담기는 공간이 부족하여 주요 방법들에 집중했습니다. LLM의 편향성 문제 및 윤리적 관점도 언급하며, 모델 사용에서 발생할 수 있는 문제를 해결하기 위한 방향성을 제시합니다.

### 2. 전체 요약:

이 논문은 대규모 언어 모델(LLM)의 추론 시간 자가 향상 방법에 대한 포괄적인 분석을 제공합니다. 주요 기여는 세 가지 주요 범주(독립적, 맥락 인식, 모델 지원 자가 향상)로 분류하여 각 기술의 가능성, 도전과제, 그리고 한계를 체계적으로 제시하는 것입니다. 특히, 테스트 시간에 더 많은 계산을 도입해 모델의 성능을 효과적으로 향상시킬 수 있는 다양한 접근 방식을 제안합니다. 윤리적 고려 사항과 편향성을 줄이기 위한 해결책도 제공되며, 추후 연구 방향에서 더욱 발전된 방법론을 모색할 기회를 제시합니다.