# Part123: Part-aware 3D Reconstruction from a Single-view Image
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.16888.pdf](https://arxiv.org/pdf/2405.16888.pdf)

### 1. 각 섹션 요약

#### 1.1. 서론 (Introduction)
본 논문은 단일 뷰 이미지로부터 구조 분해된 3D 모델을 재구성하는 새로운 프레임워크인 Part123을 소개합니다. Diffusion 모델을 사용해 다방향 이미지를 생성하고, 이를 기반으로 SAM (Segment Anything Model)을 활용해 다각도의 2D 분할 마스크를 생성합니다. 이 마스크들을 3D 재구성 과정과 통합하여 대조적 학습을 통해 부분-의식적 특징 공간을 학습합니다.

#### 1.2. 관련 연구 (Related Work)
- **단일 뷰 재구성 (Single-view Reconstruction)**: 최근의 Diffusion 모델은 단일 뷰 재구성 작업에 성공적으로 적용되었습니다. 그러나 기존 방법들은 주로 구조 정보를 무시하고 전체 형태로만 3D 모델을 생성했습니다.
  
- **부분-의식적 3D 생성 (Part-Aware 3D Generation)**: 여러 연구들이 단일 이미지로부터 3D 부분 구조를 생성하는 방법을 제안했습니다. 그러나 이들은 주로 사전에 정의된 구조에 의존하며, 범용성이 부족합니다.

- **3D 분할 (3D Segmentation)**: 3D 분할 방법들은 기존의 높은 품질의 데이터셋에만 유효하며, 실제 응용에는 한계가 있습니다.

#### 1.3 방법 (Methods)
- **다방향 Diffusion (Multiview Diffusion)**: SyncDreamer를 사용해 고정된 뷰포인트에서 다각도 이미지를 생성합니다.
- **대조적 학습을 통한 부분-의식적 재구성 (Part-Aware Reconstruction with Contrastive Learning)**: NeuS 모델에 대조적 학습을 적용해 다각도의 2D 분할 마스크를 3D 모델 재구성과 통합합니다.
- **자동 부분 분할 (Automatic Part Segmentation)**: 다각도 2D 분할 마스크를 기반으로 부분 수를 자동으로 결정하고, 클러스터링을 통해 최종적으로 3D 부분 분할 모델을 생성합니다.

#### 1.4 실험 (Experiments)
Google Scanned Object 데이터셋과 실제 이미지에서 실험을 진행하였으며, 고품질의 3D 부분 분할 모델을 생성할 수 있음을 증명했습니다.

#### 1.5 분석 및 논의 (Analysis and Discussions)
- **중첩 비율 (Overlapping Ratio)**: 중첩 비율에 따라 더 세밀한 부분 분할이 가능함을 보였습니다.
- **KMeans 초기화 (KMeans Initialization)**: KMeans 클러스터링 중심을 추정된 마스크 중심으로 초기화하여 더 신뢰성 있는 부분 분할 결과를 얻었습니다.
- **다방향 이미지 수량 (Amount of Multi-view Images)**: 다각도 이미지의 수량이 적어지더라도 Part123 모델이 일관된 부분 분할 결과를 유지할 수 있음을 보였습니다.

#### 1.6 응용 (Applications)
- **기능 보존 재구성 (Feature-preserving Reconstruction)**: 재구성된 모델을 활용해 원본 이미지의 세부 기능을 보존합니다.
- **기본 기반 재구성 (Primitive-based Reconstruction)**: 기본 모양을 기반으로 3D 모델을 재구성합니다.
- **형상 편집 (Shape Editing)**: 재구성된 3D 모델을 편집합니다.

#### 1.7 결론 (Conclusion)
Part123은 단일 뷰 이미지를 기반으로 구조적으로 다양한 3D 모델을 재구성할 수 있는 유망한 방법입니다. 대조적 학습과 자동 부분 분할 알고리즘을 통해 효과적인 3D 재구성이 가능함을 실험적으로 증명했습니다.

### 2. 전체 요약
Part123는 단일 이미지에서 고품질의 부분 분할 3D 모델을 생성할 수 있는 혁신적인 방법론입니다. SyncDreamer와 SAM 모델을 활용해 다각도 이미지를 생성하고, 대조적 학습을 통해 3D 재구성을 효과적으로 통합합니다. 이 방법론은 특히 3D 모델의 구조적 정보 분할과 같은 다양한 실제 응용에서 큰 이점을 제공합니다. 또한, 다양한 데이터셋과 실제 이미지에서 그 효과를 입증하여, 단일 이미지 기반의 3D 재구성 기술을 크게 향상시킬 잠재력이 있습니다.

## Similar Papers
- [CraftsMan: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner](2405.14979.md)
- [PointInfinity: Resolution-Invariant Point Diffusion Models](2404.03566.md)
- [RodinHD: High-Fidelity 3D Avatar Generation with Diffusion Models](2407.06938.md)
- [CLAY: A Controllable Large-scale Generative Model for Creating High-quality 3D Assets](2406.13897.md)
- [Dynamic Typography: Bringing Text to Life via Video Diffusion Prior](2404.11614.md)
- [MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization](2408.02555.md)
- [HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors](2406.12459.md)
- [Urban Architect: Steerable 3D Urban Scene Generation with Layout Prior](2404.06780.md)
- [Interactive3D: Create What You Want by Interactive 3D Generation](2404.16510.md)
