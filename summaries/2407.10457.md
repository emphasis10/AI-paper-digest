# The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.10457.pdf](https://arxiv.org/pdf/2407.10457.pdf)

### 요약

#### 1. 논문의 각 섹션 요약

**1. 요약 (Abstract)**
논문은 큰 언어 모델(LLM) 평가에서 비결정론의 문제를 다룹니다. 일반적으로 하나의 출력만을 평가 대상으로 삼는 기존 방식은 LLM의 성능 변동성을 충분히 반영하지 못한다고 지적합니다. 논문은 탐욕적 디코딩과 샘플링 간 성능 차이를 조사하며, 비결정론에 따른 벤치마크 일관성을 분석합니다. 주요 발견은 다음과 같습니다:
- 다양한 디코딩 설정에서 모델 성능이 일정하게 유지됨
- 적응 방법이 샘플링 변동성을 줄이는 데 도움 줌
- 작은 LLM도 최적의 샘플링을 통해 더 큰 모델을 능가할 가능성이 있음

**2. 서론 (Introduction)**
LLM 평가에서 탐욕적 디코딩과 누클리어스 샘플링이 일반적이지만, 비결정론적인 출력을 고려하지 않으면 LLM의 실제 성능을 제대로 파악할 수 없습니다. 연구는 LLM 성능의 변동성을 탐구하며, 이를 통해 미래 모델 평가 및 개발 방향을 제시합니다.

**3. 실험결과 (Experimental Results)**
탐욕적 디코딩과 샘플링 간 성능 차이가 일관되게 관찰되며, 일부 벤치마크에서는 모델 랭킹에도 영향을 미칠 수 있습니다. 대부분의 경우 탐욕적 디코딩이 우수한 성능을 보였으며, 단순한 문제에서는 샘플링이 더 나은 성과를 보이기도 했습니다.

**4. 비결정론에 영향을 미치는 여러 요인 (How Various Factors Influence Non-Determinism)**
이 섹션에서는 스케일링, 정렬, 디코딩 파라미터 등의 요인이 비결정론에 영향을 미치는 방식을 다룹니다. 스케일링이 성능 변동성을 줄이지 않는다는 결과도 포함됩니다.

**5. 비결정론의 잠재력 (What is the Full Potential of Non-Determinism)**
논문은 다중 샘플링 전략을 통해 LLM의 잠재력을 극대화할 수 있음을 보입니다. 예를 들어, 작은 모델도 최상의 응답을 선택함으로써 더 큰 모델을 능가할 수 있다는 것을 강조합니다.

**6. 결론 및 미래 방향 (Conclusion & Future Directions)**
연구는 비결정론의 중요성을 강조하며, 다양한 설정에서 LLM의 성능을 분석합니다. 향후 연구는 비결정론적 생성의 동적 메커니즘을 더 깊이 탐구해야 한다고 결론짓습니다.

#### 2. 논문의 전체 요약

이 논문은 LLM 평가 시 비결정론적 출력을 고려해야 한다는 점을 강조합니다. 현재 대부분의 LLM 평가가 단일 출력을 기준으로 이루어져 실제 성능 변동성을 반영하지 못합니다. 연구는 탐욕적 디코딩이 샘플링보다 일반적으로 우수하지만, 단순한 문제에서는 샘플링이 더 나을 수 있다는 사실을 발견했습니다. 또한, 적응 방법이 샘플링 변동성을 줄이는 데 효과적이며, 작은 LLM도 최적의 샘플링을 통해 더 큰 모델과 경쟁할 수 있다는 가능성을 제시합니다. 이 연구는 LLM 평가와 개발에 중요한 통찰을 제공하며, 비결정론적 생성의 중요성을 부각시킵니다.

