# PAFT: Prompt-Agnostic Fine-Tuning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.12859.pdf](https://arxiv.org/pdf/2502.12859.pdf)

1. 각 섹션 요약:

- **소개 및 배경**: 이 논문은 대규모 언어 모델(LLM)의 하향식 과제 적합성을 높이는 도입 방식으로, 일반적인 미세 조정(SFT)이 동일한 프롬프트 변형에 대해 약점을 보인다는 점에 착안하여, 프롬프트 비민감적 미세 조정(PAFT)를 제안합니다.

- **PAFT 프레임워크**: PAFT는 두 단계로 구성됩니다. 첫째, 다양한 후보 프롬프트를 생성하고 둘째, 학습 중 다양하게 샘플링하여 모델에 다양한 프롬프트 스타일을 노출시켜 일관성을 높입니다. 이를 통해 모델이 다양한 실제 시나리오에서 잘 작동하도록 합니다.

- **동적 미세 조정**: 학습 동안 실시간 프롬프트 샘플링 전략을 활용하여 모델이 특정 프롬프트 형식에 과적합되지 않도록 합니다. 이러한 방법은 여러 과제에서 강한 일반화 능력을 발휘하며, 처리 속도를 높이고 훈련 효율성을 유지합니다.

- **실험 결과 및 논의**: 다양한 데이터셋 및 모델을 통해 PAFT의 유효성을 검증하였고, 고정된 프롬프트를 사용한 미세 조정의 한계를 극복함을 증명하였습니다. 또한 PAFT는 고품질의 소량의 프롬프트만으로도 충분한 성능을 발휘하여 자원 비효율성을 줄였습니다.

2. 전체 요약:

이 논문은 대규모 언어 모델의 프롬프트에 대한 민감성을 감소시키고 다양한 프롬프트에 대한 광범위한 적응력을 갖추기 위해 프롬프트 비민감적 미세 조정(PAFT) 방법을 제안합니다. PAFT는 다양한 후보 프롬프트를 생성하고 이를 학습 중 동적으로 사용하여 모델이 많은 다양한 프롬프트에 대해 일관되게 성능을 유지하도록 합니다. 실험 결과, PAFT는 다양한 테스트 프롬프트에 대해 탁월한 강건성과 일반화 능력을 보이며, 이는 모델을 실용적인 AI 시스템에 보다 유연하게 적용시킬 수 있는 가능성을 제시합니다.