# MotionGPT: Finetuned LLMs Are General-Purpose Motion Generators
## TL;DR
## Summary
- [https://arxiv.org/pdf/2306.10900.pdf](https://arxiv.org/pdf/2306.10900.pdf)

### 1. 섹션별 요약 및 상세 설명

#### Introduction
소개 섹션에서는 인간의 모션이 비디오 게임, 영화 제작, 가상 현실 등 다양한 애플리케이션에서 중요한 역할을 한다고 설명합니다. 그러나 기존 연구는 단일 제어 조건에만 초점을 맞추어 실제 애플리케이션에서의 한계를 드러냅니다. 이를 해결하기 위해 MotionGPT라는 모델을 제안하며, 이 모델은 여러 제어 신호를 동시에 사용하여 인간의 모션을 생성할 수 있습니다.

#### Related Work
이 섹션에서는 대형 언어 모델(LLM)의 발전과 모션 생성의 기존 연구를 검토합니다. 기존 연구에는 텍스트 설명을 기반으로 모션을 생성하는 접근법들이 포함되며, MotionGPT는 여러 제어 신호를 활용해 더 통합된 접근법을 제시합니다.

#### MotionGPT: A Motion General-Purpose Generator
MotionGPT 모델은 텍스트와 인간의 포즈를 활용하여 일관된 모션 생성 답변을 생성합니다. 이 모델은 VQ-VAE를 사용하여 모션 컨트롤을 이산 코드로 분해하고, 이를 LLM의 질문 템플릿으로 정리하여 사용합니다. LoRA 기법을 활용한 효율적인 LLM 튜닝이 가능하며, 다중 제어 신호를 사용한 모션 생성 작업을 지원합니다.

#### Experiments
실험 섹션에서는 HumanML3D 및 KIT-ML 데이터셋에서 MotionGPT의 성능을 평가합니다. 모델은 여러 제어 조건 하에서 강력한 모션 생성 능력을 보여주며, 훈련 파라미터 수가 적고 훈련 시간이 짧아 효율성을 입증합니다. 다양한 제어 신호의 조합이 단일 제어 신호보다 더 나은 성능을 발휘한다는 점을 강조합니다.

#### Evaluation
평가 섹션에서는 모션 생성 품질을 평가하기 위한 새로운 메트릭스를 제안합니다. 재구성 손실(Reconstruction Loss)와 속도 손실(Velocity Loss) 등을 통해 텍스트 조건 및 포즈 제어 조건의 일관성을 평가합니다.

#### Conclusion and Limitations
결론 섹션에서는 MotionGPT의 주요 기여와 한계를 요약합니다. MotionGPT는 텍스트와 단일 프레임 포즈와 같은 멀티모달 제어 신호를 활용하여 더욱 실용적이고 다양한 모션 생성 시스템을 제시합니다. 현재는 텍스트와 인간 포즈에 대해서만 유효성을 검증하였으나, 다른 제어 신호에 대해서도 확장이 필요합니다.

### 2. 전체 요약

MotionGPT는 다양한 제어 신호를 활용한 인간 모션 생성에 새로운 통합 모델을 제시합니다. 이 모델은 텍스트와 인간 포즈를 입력으로 받아 일관된 모션을 생성하며, 효율적인 LLM 튜닝을 통해 훈련 파라미터 수를 최소화하고 훈련 시간을 단축하였습니다. 다양한 제어 신호의 조합을 통해 더욱 현실적인 모션 생성이 가능함을 실험적으로 입증하였습니다. 그러나 현재는 텍스트와 인간 포즈에 대해서만 유효성을 검증하였으며, 다른 제어 신호에 대한 확장이 필요합니다. MotionGPT는 인간 모션 생성 분야에 새로운 방향을 제시할 가능성이 높습니다.

## Similar Papers
- [Muse: Text-To-Image Generation via Masked Generative Transformers](2301.00704.md)
- [MotionLCM: Real-time Controllable Motion Generation via Latent Consistency Model](2404.19759.md)
- [MotionLLM: Understanding Human Behaviors from Human Motions and Videos](2405.20340.md)
- [Training-free Camera Control for Video Generation](2406.10126.md)
- [Reenact Anything: Semantic Video Motion Transfer Using Motion-Textual Inversion](2408.00458.md)
- [F-HOI: Toward Fine-grained Semantic-Aligned 3D Human-Object Interactions](2407.12435.md)
- [MotionClone: Training-Free Motion Cloning for Controllable Video Generation](2406.05338.md)
- [EvTexture: Event-driven Texture Enhancement for Video Super-Resolution](2406.13457.md)
- [MotionMaster: Training-free Camera Motion Transfer For Video Generation](2404.15789.md)
