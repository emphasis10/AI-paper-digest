# V2V-LLM: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multi-Modal Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.09980.pdf](https://arxiv.org/pdf/2502.09980.pdf)

1. **요약**

   - **서론**: 자율 주행 기술은 심층 학습 알고리즘, 컴퓨팅 인프라, 대규모 실제 주행 데이터셋 및 벤치마크 발전 덕분에 크게 발전했습니다. 그러나 개별 차량의 라이더 센서나 카메라에 의존하기 때문에 큰 객체에 의해 센서가 차단될 경우 안전 문제가 발생할 수 있습니다.

   - **관련 연구검토**: 협력 인지는 개별 자율 주행 차량에서 발생할 수 있는 감지 문제를 완화하기 위해 제안되었습니다. 예를 들어, F-Cooper는 특징 맵을 융합하는 방식을 제안하고, V2VNet은 그래프 신경망을 구축하는 방식으로 협력 인지를 수행합니다. 이러한 접근법들은 주로 감지 작업에 집중했습니다.

   - **본 연구의 제안**: 본 연구는 LLM 기반 방법들을 CAV에 적용하여 안전한 주행 정보를 제공할 수 있는 새로운 문제 설정을 제안합니다. V2V-QA 데이터셋을 만들었고, 각 CAV가 감지한 정보를 공유하면서 주행 관련 질문에 답변할 수 있는 V2V-LLM 모델을 제안합니다.

   - **실험**: V2V-LLM은 다른 융합 방식의 기초 모델들에 비해 주요 객체 식별 및 계획 과업에서 더 나은 성능을 보였으며, 전반적인 CAV 시스템의 성능 향상을 입증했습니다.

   - **결론**: 본 연구는 협력 자율 주행을 위한 새로운 연구 방향을 제시함으로써 차세대 자율 주행 시스템의 안전성을 향상시킬 수 있는 잠재력을 보여주었습니다.

2. **전체 요약**
   
   이 논문은 자율 주행 차량의 안전성을 높이기 위해 협력 자율 주행 상황에서 LLM을 활용하는 새로운 문제 설정과 데이터셋을 제안합니다. 여러 차량 간의 협력적 인지 및 계획 능력을 통해 기존의 개별 차량 중심의 접근법보다 뛰어난 성능을 보여주었으며, 안전한 주행의 새로운 방향을 제시합니다. 연구는 특히 감지와 계획 작업에서 효과적인 성능을 입증하여, 차세대 자율 주행 시스템의 토대를 마련하였습니다.