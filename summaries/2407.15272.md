# MIBench: Evaluating Multimodal Large Language Models over Multiple Images
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.15272.pdf](https://arxiv.org/pdf/2407.15272.pdf)

### 1. 논문의 각 섹션 요약

#### 서론 (Introduction)
최근 여러 대형 언어 모델(LLM)을 활용한 멀티모달 대형 언어 모델(MLLM)은 이미지 캡션 생성, 시각적 질문 응답(VQA), 시각적 그라운딩 등 다양한 비전-언어 태스크에서 뛰어난 성과를 보였습니다. 그러나 대부분의 기존 MLLM과 벤치마크는 단일 이미지 입력 시나리오에 중점을 두고 있으며, 여러 이미지 입력 상황에서의 성능은 충분히 탐구되지 않았습니다. 이 논문에서는 이를 해결하기 위해 MIBench라는 새로운 벤치마크를 제안하며, 이를 통해 여러 이미지 입력 상황에서의 MLLM의 능력을 포괄적으로 평가합니다.

#### 관련 연구 (Related Work)
기존의 여러 연구에서는 LLM을 멀티모달 시나리오로 확장하여 시각적 및 텍스트 정보를 모두 처리하는 능력을 가지고 있으며, 여러 벤치마크가 이들을 평가하기 위해 등장했습니다. 그러나 대부분의 벤치마크는 단일 이미지 입력 평가에 중점을 둡니다.

#### 멀티모달 대형 언어 모델 (Multimodal Large Language Models)
MLLM의 구체적인 능력에 대한 연구와 평가를 위해 세 가지 주요 시나리오로 나눕니다:
1. 다중 이미지 지시 (Multi-Image Instruction, MII)
2. 멀티모달 지식 탐색 (Multimodal Knowledge-Seeking, MKS)
3. 멀티모달 맥락 학습 (Multimodal In-Context Learning, MIC)

각 시나리오는 MLLM이 다양한 유형의 지시와 질문에 어떻게 반응하는지를 분석하고 평가합니다.

#### 벤치마크 (MLLM Benchmarks)
MIBench는 총 13개의 태스크와 13,000개의 주석 샘플로 구성되며, 다중 이미지 지시, 멀티모달 지식 탐색, 멀티모달 맥락 학습 각각에서 MLLM을 평가합니다. 이를 통해 MLLM의 정밀한 인식, 비교 및 추론 능력을 테스트할 수 있습니다.

#### 데이터 생성 (Data Generation)
다양한 데이터 출처에서 샘플링된 이미지를 사용하여 질문과 정답 옵션을 생성하고, GPT-4를 이용해 여러 형태의 질문을 생성합니다. 또한 불명확하거나 중복된 샘플을 제거하기 위해 자동 필터링과 수동 검증을 결합합니다.

#### 실험 결과 (Results)
MIBench에서 여러 MLLM을 평가한 결과, 단일 이미지 모델보다 다중 이미지 모델이 대부분의 태스크에서 더 나은 성능을 보였습니다. 특히 시각적 참조(VR) 태스크와 정밀한 시각 인식(FVR) 태스크에서 현저한 성과 차이를 보였습니다. 그러나 대부분의 오픈 소스 MLLM은 멀티모달 지식 탐색 시나리오에서 낮은 성능을 보였습니다.

#### 한계 (Limitations)
현재의 MLLM은 입력 길이 제한 때문에 하나의 샘플에 2-8개의 이미지만 포함할 수 있습니다. 그러나 실제 시나리오는 더 많은 이미지를 포함할 수 있으며, 향후 연구에서 이러한 제한을 극복할 필요가 있습니다.

#### 결론 (Conclusion)
MIBench는 MLLM의 다중 이미지 입력 능력을 평가하기 위한 포괄적인 벤치마크입니다. 평가 결과, 현재의 모델들이 단일 이미지 태스크에서 좋은 성능을 보였으나, 다중 이미지 입력에서 큰 도전에 직면함을 확인했습니다. 우리는 이 벤치마크를 공개하여 MLLM의 다중 이미지 능력 향상에 기여하고자 합니다.

### 2. 전체 요약
이 논문은 MLLM의 다중 이미지 입력 능력을 평가하기 위한 포괄적인 벤치마크인 MIBench를 제안합니다. MIBench는 총 13개의 태스크와 13,000개의 주석 샘플로 구성되어, 다중 이미지 지시, 멀티모달 지식 탐색, 멀티모달 맥락 학습 세 가지 주요 시나리오에서 MLLM을 평가합니다. 평가 결과, 단일 이미지 모델보다 다중 이미지 모델이 대부분의 태스크에서 더 나은 성능을 보였으며, 특히 시각적 참조와 정밀한 시각 인식 태스크에서 현저한 성과 차이를 보였습니다. 그러나 대부분의 오픈 소스 MLLM은 멀티모달 지식 탐색 시나리오에서 낮은 성능을 보였습니다. 향후 연구에서는 더 많은 이미지를 포함하여 실제 시나리오를 더욱 반영할 필요가 있습니다.