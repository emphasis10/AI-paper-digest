# ZipAR: Accelerating Autoregressive Image Generation through Spatial Locality
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.04062.pdf](https://arxiv.org/pdf/2412.04062.pdf)

1. 논문의 섹션별 요약

- **초록 및 서론**: 이 논문은 ZipAR이라는 새로운 병렬 디코딩 프레임워크를 소개합니다. 이는 시각적 콘텐츠의 공간적 인접성을 활용하여 다수의 이미지를 동시에 생성함으로써 생성 속도를 획기적으로 향상시킵니다.

- **관련 연구**: 기존의 자기 회귀 모델이나 병렬 디코딩 방법론의 한계를 지적하며, 이러한 한계를 극복하기 위한 많은 연구가 진행되어 왔음을 설명합니다. 특히, LLMs의 '다음 세트 예측' 패러다임을 활용한 다양한 시도가 있었지만, 결과적으로 그 효율성은 제한적이라는 것을 언급합니다.

- **방법론**: ZipAR의 핵심은 임의의 인접 토큰들을 한 번에 디코딩하여, 기존의 순차적 토큰 예측 방식보다 디코딩 속도를 크게 개선하는 것입니다. 적절한 윈도우 크기를 정함으로써, 여러 행을 동시에 디코딩할 수 있게 합니다.

- **실험 및 결과**: 연구는 다양한 자기 회귀 시각 생성 모델에서 ZipAR의 성능을 검증합니다. 이 방법은 Emu3-Gen 모델에서 최대 91%의 전진 스텝 감소를 달성하면서도 이미지 품질의 최소한의 손실을 유지합니다.

- **결론 및 미래 연구 방향**: ZipAR은 기존의 '다음 토큰 예측' 패러다임보다 더 높은 생성 효율성을 달성합니다. 또한, Medusa와 Jacobi 디코딩 등 다른 시도들과 결합함으로써 가속화 비율을 더욱 향상시킬 수 있는 가능성을 엿봅니다.

논문의 주요 기여는 생성 이미지의 공간적 특성을 최대한 활용하여 기존의 방법보다 빠르고, 효율적으로 고품질의 이미지를 생성하는 ZipAR 프레임워크를 제안한 것입니다.

2. 전체 요약

이 논문은 고품질 이미지를 신속하게 생성할 수 있는 ZipAR이라는 프레임워크를 제안합니다. ZipAR은 이미지의 공간적 인접성을 활용하여 다수의 시각적 토큰을 동시에 디코딩함으로써, 기존의 순차적 토큰 예측보다 훨씬 빠른 속도와 효율성을 자랑합니다. 실험 결과, ZipAR은 다양한 모델에서 최소한의 품질 손실로 상당한 가속을 달성하였으며, 이는 앞으로의 시각적 콘텐츠 생성의 표준이 될 가능성이 있습니다.