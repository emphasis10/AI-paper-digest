# Chameleon: Mixed-Modal Early-Fusion Foundation Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.09818.pdf](https://arxiv.org/pdf/2405.09818.pdf)

### 주요 내용 요약

1. **서론 및 배경**:
   - 이 논문은 **Chameleon**이라는 초기 융합 기반의 혼합 모달 모델을 소개합니다. Chameleon은 이미지와 텍스트를 임의의 순서로 이해하고 생성할 수 있는 능력을 가지고 있으며, 훈련의 안정성을 보장하면서 이러한 혼합 모달 설정을 위한 아키텍처와 파라미터 설정을 설명합니다. Chameleon은 시각적 질문 응답, 이미지 캡션 생성, 텍스트 생성, 이미지 생성, 혼합 모달 생성 등 다양한 작업에서 평가됩니다.

2. **방법론**:
   - **토큰 기반 융합 모델**: Chameleon은 이미지와 텍스트를 모두 이산적인 토큰으로 표현하며, 동일한 트랜스포머 아키텍처를 사용하여 시퀀스를 처리합니다. 이 방법은 별도의 이미지/텍스트 인코더를 사용하지 않고, 모든 모달리티를 통합된 표현 공간에 투영하여 시퀀스를 처리합니다.
   - **훈련 기술**: 훈련의 안정성을 위해 쿼리-키 정규화(Query-Key Normalization)와 레이어 노름 재배치 등의 새로운 아키텍처 수정 사항을 도입합니다. 이를 통해 혼합 모달 설정에서의 훈련을 안정화하고 확장할 수 있습니다.
   - **정렬 및 최적화**: 텍스트 전용 LLM에서 사용되는 감독된 미세 조정 접근 방식을 혼합 모달 설정에 적응시켜 대규모 정렬을 수행합니다.

3. **실험**:
   - **벤치마크 평가**: Chameleon은 시각적 질문 응답과 이미지 캡션 생성에서 최첨단 성능을 보였으며, 텍스트 전용 작업에서도 경쟁력 있는 성능을 유지했습니다. 특히, 긴 형태의 혼합 모달 생성 평가에서 더 큰 모델인 Gemini Pro와 GPT-4V를 능가했습니다.
   - **인간 평가**: 인간 평가 실험에서 Chameleon은 Gemini-Pro와 GPT-4V를 능가하는 선호율을 기록했습니다. 이 실험은 혼합 모달 장문의 생성 응답의 품질을 측정했습니다.

4. **결론**:
   - Chameleon은 이미지와 텍스트를 통합하여 혼합 모달 문서를 생성할 수 있는 능력을 갖춘 초기 융합 토큰 기반 모델입니다. 이 모델은 다양한 시각-언어 벤치마크에서 강력한 성능을 입증했으며, 텍스트 전용 작업에서도 높은 성능을 유지합니다.
   - Chameleon은 혼합 모달 이해 및 생성에서 새로운 가능성을 열었으며, 이를 통해 통합된 기초 모델의 비전을 실현하는 중요한 진전을 이루었습니다.

### 혁신적인 부분
Chameleon의 혁신성은 이미지와 텍스트를 통합하여 처리하는 초기 융합 토큰 기반 아키텍처를 사용한 데 있습니다. 이는 별도의 모달리티 특정 인코더 없이 모든 모달리티를 동일한 표현 공간에서 처리할 수 있게 하여, 시퀀스 전반에 걸친 매끄러운 추론과 생성을 가능하게 합니다. 또한, 새로운 아키텍처 수정 사항과 훈련 기술을 도입하여 혼합 모달 설정에서의 훈련 안정성과 확장성을 확보하였습니다. 이 연구는 혼합 모달 작업에서의 새로운 표준을 설정하며, 다양한 벤치마크에서 높은 성능을 입증했습니다.

## Similar Papers
- [The Llama 3 Herd of Models](2407.21783.md)
- [Multimodal Needle in a Haystack: Benchmarking Long-Context Capability of Multimodal Large Language Models](2406.11230.md)
- [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](2405.19325.md)
- [LLMs achieve adult human performance on higher-order theory of mind tasks](2405.18870.md)
- [KorNAT: LLM Alignment Benchmark for Korean Social Values and Common Knowledge](2402.13605.md)
- [MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts](2407.21770.md)
- [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](2305.18290.md)
- [MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding](2404.05726.md)
- [From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting](2309.04269.md)
