# Heavy Labels Out! Dataset Distillation with Label Space Lightening
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.08201.pdf](https://arxiv.org/pdf/2408.08201.pdf)

### 1. 각 섹션 요약

#### Introduction
본 논문에서는 대규모 데이터셋 증류의 문제를 다루며, 특히 저장 공간과 연산비용 문제를 해결하고자 `HeLlO`라고 불리는 새로운 레이블 경량화 프레임워크를 제안했습니다. 이 방법은 전통적인 소프트 레이블 저장방식의 비효율성을 극복하기 위해, 대신 이미지에서 직접 레이블을 생성하는 경량의 프로젝터를 이용합니다.

#### Related Works
기존의 데이터셋 증류 방법들은 대부분 소프트 레이블을 사용하는데, 이로 인해 저장 공간이 많이 요구됩니다. 최신 연구들은 데이터 증류를 개선하기 위해 다양한 데이터 증강 기법을 채택하고 있지만, 여전히 저장 공간 문제는 미해결 상태로 남아 있습니다.

#### Methods
`HeLlO`는 CLIP와 같은 사전 학습된 대규모 모델을 사용해 이미지 특징을 기반으로 레이블을 예측할 수 있는 경량 프로젝터를 구축합니다. 전통적 방식 대신, 저차원 행렬 분해를 통한 LoRA-like 지식 전이 방법을 도입해 저장 공간을 크게 절약합니다.

#### Experiments
본 논문은 다양한 실험을 통해 제안된 방법의 효율성을 검증합니다. ImageNet-100 및 ImageNet-1K 데이터를 사용하여, 기존 최첨단 방법들과 비교한 결과, `HeLlO`는 현저히 낮은 저장 공간으로도 비슷하거나 더 나은 성능을 보였습니다.

#### Results on Cross-Architecture Generalization
다양한 네트워크 아키텍처 간의 일반화 성능을 비교했을 때, `HeLlO`는 기존의 RDED 방식보다 뛰어난 성능을 보였습니다. 특히, Transformer 아키텍처(Swin-V2-Tiny)에서는 최대 11.7%의 성능 향상을 보였습니다.

#### Ablation Study
각 구성 요소의 영향을 평가하기 위한 실험들에서, 저차원 행렬과 텍스트 임베딩 초기화 전략이 주요 성능 향상 요인임을 확인하였습니다. 다단계 교사 모델 사용과 이미지 업데이트도 성능 향상에 기여했습니다.

### 2. 전체 요약
논문은 대규모 데이터셋 증류 과정에서 발생하는 저장 공간 과부하 문제를 해결하기 위해 `HeLlO`라는 혁신적인 프레임워크를 제안합니다. 이 방법은 사전 학습된 CLIP 모델을 기반으로 하며, 저차원 행렬 분해와 텍스트 임베딩 초기화 전략을 도입해 기존 방식보다 훨씬 적은 저장 공간으로도 탁월한 성능을 발휘합니다. 다양한 실험 결과, `HeLlO`는 여러 아키텍처에 걸쳐 높은 일반화 성능을 보여주며, 특히 Transformer 아키텍처에서 두드러진 성능 향상을 입증했습니다. 이러한 혁신적인 접근은 대규모 데이터셋 증류의 실용성을 높이는 중요한 기여를 합니다.