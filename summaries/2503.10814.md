# Thinking Machines: A Survey of LLM based Reasoning Strategies
## TL;DR
## Summary
- [https://arxiv.org/pdf/2503.10814.pdf](https://arxiv.org/pdf/2503.10814.pdf)

1. 섹션별 요약:

- **서론:** 이 논문은 대형 언어 모델(LLM)의 언어와 추론 능력 간의 차이를 해결하기 위해 다양한 추론 기술을 조사하고 비교하며, 최신의 LLM 추론 발전을 체계적으로 정리합니다.

- **기초 개념:** 언어 모델의 목적과 샘플링, 강화 학습의 기본 원칙을 설명합니다.

- **추론 기법:** Monte Carlo Tree Search (MCTS), 보상 모델링, 및 자기 훈련 같은 검사 방법이 LLM의 내적 사고 공간을 탐색해 더 나은 결론에 이르게 함을 설명합니다.

- **자기 훈련 방법:** 사전 훈련된 LLM을 세부적인 과정 감독 신호로써 강화 학습을 통해 개선합니다.

- **테스트 시간 컴퓨팅 확장:** 테스트 시간에 컴퓨팅을 확장하면 모델이 더 큰 모델과 경쟁할 수 있으며, 이는 작은 모델이 더 큰 모델을 능가할 수 있음을 보여줍니다.

- **결론:** 이 논문은 LLM이 고도화된 문제 해결 능력을 갖추기 위해 어떻게 추론을 적용할 수 있는지 설명합니다.

2. 총괄 요약:

이 논문은 대형 언어 모델이 인간과 유사한 추론 능력을 갖추는 방법에 대한 체계적이고 최신의 기술들을 조사합니다. 특히, LLM이 다양한 추론 기술을 통해 문제를 해결할 수 있게 하는 여러 혁신적인 방법을 검토하며, 이는 추후 LLM이 더 민감한 영역에서 신뢰성을 갖추게 하는 데 초점을 맞추고 있습니다.