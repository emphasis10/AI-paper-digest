# Temporally Aligned Audio for Video with Autoregression
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.13689.pdf](https://arxiv.org/pdf/2409.13689.pdf)

### 요약

#### 1. 도입 (Introduction)

- 비디오-오디오 생성(V2A)은 영상 시퀀스를 기반으로 오디오를 합성하는 작업입니다. 합성된 오디오는 시각적 이벤트와 시간, 의미적으로 일치해야 합니다.
- 기존 최첨단 모델들은 Diffusion 및 Rectified Flow Matching(RFM) 기반 기법을 사용하지만, 이들은 복잡성이 높고, 오디오를 Mel-spectrogram으로 변환하는 이미지 기반 접근 방식을 사용합니다. 이는 세부 오디오 정보를 잃게 할 수 있습니다.
- V-AURA는 사전학습된 오디오 코덱을 사용하여 손실 없는 오디오 변환을 제공하고, 새롭게 제안된 VisualSound 데이터셋을 사용하여 학습 데이터를 강화합니다.

#### 2. 관련 연구 (Related Work)

- 이전의 방법들은 GAN이나 각종 토큰 예측 방법을 사용했지만, 이들은 시간적 일치도와 오디오 품질이 떨어졌습니다.
- 최신 Diffusion 및 RFM 접근법은 시간적 일치를 강조하지만, 저해상도 비디오 프레임 속도로 인해 여전히 문제를 겪습니다.
- VisualSound는 높은 음성-영상 일치도를 지닌 데이터를 제공하여 이러한 문제를 극복합니다.

#### 3. 연구 방법 (Method)

- V-AURA 모델은 고해상도의 시각적 특징을 추출하고, 이를 오디오와 시간적으로 맞추어 특징을 융합하여 예측합니다.
- 시각적인 특징을 Segment AVCLIP으로 추출하고, DAC를 사용하여 오디오 토큰을 변환합니다.
- 오디오와 시각적 특징을 융합한 후, 다음 오디오 토큰을 생성하여 방법.

#### 4. 실험 (Experiments)

- VisualSound, VGGSound-Sparse, VAS 데이터셋을 사용하여 모델을 검증합니다.
- 실험 결과, V-AURA는 시간적 품질(Sync)과 관련성(KLD, IB)에서 최고 성능을 보여주었습니다.
- 특히 VGGSound-Sparse와 VisualSound 데이터셋에서 V-AURA는 다른 모델보다 우수한 결과를 보였습니다.

#### 5. 결론 (Conclusion)

- V-AURA는 비디오-오디오 모델 중 시간적 및 의미적으로 일치하는 오디오를 생성하는 데 성공했습니다.
- 고해상도의 시각적 특징을 추출하고, 크로스-모달 특징 융합을 통해 기존 방법보다 나은 결과를 얻었습니다.
- VisualSound 데이터셋은 음성-영상 일치도를 높여 모델의 성능을 더욱 향상시켰습니다.

---

### 전체 요약

이 연구는 V-AURA라는 혁신적인 비디오-오디오 생성 모델을 소개합니다. 이 모델은 고해상도의 시각적 특징을 추출해 오디오와 시간적으로 맞추어 융합하여, 의미적 일치도를 높이며 고품질의 오디오를 생성합니다. 비디오-오디오 생성의 새 기준이 될 VisualSound 데이터셋을 통해 우수한 성능을 입증했습니다.