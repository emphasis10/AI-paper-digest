# CARP: Visuomotor Policy Learning via Coarse-to-Fine Autoregressive Prediction
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.06782.pdf](https://arxiv.org/pdf/2412.06782.pdf)

### 1. 각 섹션 요약

- **서론**
  - 로봇 정책 학습에서 관찰을 행동으로 지도 학습 방식으로 매핑하는 데 있어 효과적이라고 제시합니다. 기존의 모델은 비디오 커뮤니티에서 파생된 생성 모델로 교체하면서 새로운 성능 향상 방법을 제안합니다. CARP(조잡-정밀 오토리그레시브 정책)를 통해 새로운 생성 패러다임을 도입하여 로봇 시각-운동 정책 학습을 혁신합니다.

- **배경 및 문제 정의**
  - 문제가 정의되는 방법을 설명하고, 기존 자동회귀 정책과 확산 기반 정책에 대해 소개합니다. 이들 방법론의 한계를 극복하기 위한 새로운 접근법으로 CARP를 개발하여, 시각적인 데이터에서 더 나은 정책을 학습할 수 있도록 돕습니다.

- **방식론**
  - CARP는 다중 스케일 행동 토큰화를 활용하여 오토리그레시브 모델링의 효율성과 확산 모델링의 높은 성능을 결합합니다. 이는 전체 행동 시퀀스를 조잡한 단계에서 정밀한 단계로 예측하며 동시에 높은 성능과 효율성을 가진 정책을 생성할 수 있도록 합니다.

- **실험 결과**
  - CARP는 시뮬레이션 및 실제 로봇 작업에서 기존 자동회귀 및 확산 정책과 비교하여 높은 성과와 효율성을 보였습니다. 주목할 만한 성과는 최고 성공률이 10% 향상되었고, 추론 속도가 10배 빠르다는 점입니다.

- **결론**
  - CARP는 생성 모델의 효율성과 성능을 결합한 새로운 혼합 프레임워크를 제공하여, 기존의 로봇 비주모터 정책 학습의 한계 해결에 기여하고 있습니다. CARP의 장점을 통해 새로운 세대의 정책 학습을 촉진하는 데 도움이 될 것입니다.

### 2. 전반적 요약
CARP는 로봇 시각-운동 정책 학습에서 필수적인 성능과 효율성의 균형을 달성하기 위해 오토리그레시브 모델과 확산 모델의 장점을 융합한 혁신적인 패러다임입니다. 이는 다양한 로봇 작업에서 높은 성공률과 빠른 추론을 제공하며, 복잡한 작업에 있어 더 고도화된 정책 학습의 새로운 길을 열어줍니다. CARP의 도입은 로봇의 고정밀 작업 수행을 위하여 기존의 자동회귀 및 확산 모델의 제약을 효과적으로 해결하였습니다.