# $γ-$MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.13859.pdf](https://arxiv.org/pdf/2410.13859.pdf)

1. 각 섹션의 요약 및 논문의 주요 기여와 혁신 부분:

- **서론**: 최근 대형 언어 모델(LLMs)의 성공은 자연어 처리(NLP)뿐만 아니라 시각-언어(VL) 작업으로도 확장되고 있습니다. 그러나 기존 멀티모달 대형 언어 모델(MLLMs)은 높은 계산 비용으로 비판받고 있으며, 이는 실제 사용에 큰 장벽이 됩니다.

- **방법론**: 이 논문에서 제안하는 γ-MoD는 기존 MLLMs의 밀집 레이어를 대체하여 효율성을 극대화하는 새로운 접합 방법입니다. 이 접근의 핵심은 '주의 지도 랭크'라는 새로운 메트릭을 사용하는 것입니다. 이 메트릭은 각 레이어의 토큰 단위 중복성을 추정하여, 불필요한 레이어를 MoD 레이어로 대체할 수 있도록 합니다.

- **결과 및 논의**: γ-MoD는 다양한 MLLM 구조와 크기에서 일반화 능력을 보여주며, 특히 LLaVA-HR 모델에서 31%의 트레이닝 시간 감소와 53.2%의 추론 시간 감소를 달성하며 성능 저하를 최소화했습니다.

- **결론**: γ-MoD는 MoD를 사용하여 계산 효율성을 극대화하면서도 MLLM에서 성능을 유사하게 유지할 수 있는 방식을 제안합니다. 랭크 기반 모드 레이어 대체 전략은 MLLM의 효과적인 계산 희소성을 제공합니다.

- **주요 기여 및 혁신**: γ-MoD는 '층 중복성'이라는 새로운 개념을 도입하여, 필요 없는 밀집 레이어를 MoD로 효과적으로 대체합니다. 사전 정의된 희소 목표를 통해 γ-MoD는 최대 51.6%의 계산 희소성을 달성합니다.

2. 전체 요약:

이 논문은 대형 멀티모달 언어 모델(MLLM)의 높은 계산 비용 문제를 해결하기 위해, γ-MoD라는 새로운 접합 방법을 제안합니다. γ-MoD는 밀집 레이어의 희소성을 극대화하면서도 성능을 유지할 수 있는 '혼합 깊이' 방법을 사용합니다. 이 방법론은 기존의 MoE와는 다른 접근을 취하며, 불필요한 토큰을 간과하고 중요한 토큰에 계산 자원을 집중하여 계산 효율성을 높입니다. 실험 결과, γ-MoD는 다양한 모델 구조에서 효율성을 크게 개선하며, 실질적인 애플리케이션의 가능성을 제시합니다.