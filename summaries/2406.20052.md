# Understanding and Mitigating Language Confusion in LLMs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.20052.pdf](https://arxiv.org/pdf/2406.20052.pdf)

### 1. 각 섹션의 요약 및 주요 기여 및 혁신적인 부분

#### 1.1 도입 (Introduction)
이 섹션에서는 대규모 언어 모델(LLMs)이 여러 언어를 처리하면서 겪는 문제를 소개합니다. 특히 특정 언어를 일관되게 생성하지 못하는 문제를 다룹니다. 여러 언어와 다양한 사용 사례를 반영하는 'Language Confusion Benchmark' (LCB)를 제안하고 이를 활용해 다양한 모델의 성능을 평가합니다. 주요 기여는 새로운 벤치마크 데이터를 제안하고, LLM이 언어 혼동을 겪는 다양한 상황을 체계적으로 분석한 점입니다.

#### 1.2 관련 연구 (Literature Review)
LLMs와 관련된 다양한 연구를 다룹니다. 초기 연구는 주로 영어에 집중했으나, 최근에는 다국어 모델에 대한 연구가 활발합니다. 그러나 다국어 모델에도 여전히 비영어권 사용자들에게 실질적인 효용을 제공하는 데 한계가 있다는 것을 강조합니다. 언어 혼동에 대한 데이터셋이 부족한 상황에서 LCB를 통해 이 문제를 해결하고자 합니다.

#### 1.3 Methodology
이 섹션에서는 제안된 LCB 데이터셋의 생성 및 구성에 대해 설명합니다. 두 가지 설정, 즉 단일 언어 생성과 교차 언어 생성을 통해 언어 혼동을 어떻게 측정하는지를 설명합니다. 특히, 영어 단어가 포함된 비영어 텍스트를 탐지하는 방법과 언어 식별 도구(fastText)를 사용해 문장 수준 및 단어 수준에서 언어 혼동을 평가하는 방법을 다룹니다.

#### 1.4 실험 (Experiments)
LCB를 활용해 다양한 LLM을 평가한 결과를 제공합니다. LLama, Mistral, Command R, GPT-3.5 Turbo, GPT-4 Turbo 등을 평가하며, 각 모델의 단일 언어 및 교차 언어 성능을 비교합니다. 주요 결과로는 Command R과 OpenAI 모델이 교차 언어 설정에서 가장 높은 성능을 보였고, Llama 모델이 영어 응답을 선호해 성능이 낮다는 점이 있습니다.

#### 1.5 논의 (Discussion)
모델의 언어 혼동 문제를 해결하기 위한 다양한 방법을 제안합니다. few-shot prompting, 다국어 SFT 및 선호도 튜닝 등의 방법을 통해 언어 혼동을 일정 부분 완화할 수 있음을 보입니다. 특히 복잡한 프롬프트와 높은 샘플링 온도에서 언어 혼동이 악화될 수 있음을 강조합니다.

### 2. 전체 요약
이 논문은 대규모 언어 모델(LLM)이 특정 언어를 일관되게 생성하지 못하는 문제, 즉 '언어 혼동'을 다룹니다. 이를 해결하기 위해 'Language Confusion Benchmark' (LCB)를 제안하고 다양한 모델(Llama, Mistral, Command R, GPT-3.5 Turbo, GPT-4 Turbo)을 이 벤치마크로 평가합니다. 실험 결과, Command R과 OpenAI 모델이 교차 언어 설정에서 가장 높은 성능을 보여주었으며, 복잡한 프롬프트와 높은 샘플링 온도에서 언어 혼동이 악화될 수 있음을 발견했습니다. 또한, few-shot prompting, 다국어 SFT 및 선호도 튜닝 등의 방법이 일부 도움이 될 수 있음을 논의했습니다.