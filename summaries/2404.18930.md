# Hallucination of Multimodal Large Language Models: A Survey
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.18930.pdf](https://arxiv.org/pdf/2404.18930.pdf)

이 연구 논문은 "Hallucination of Multimodal Large Language Models: A Survey"라는 제목으로, 다양한 모달을 가진 대형 언어 모델에서 발생하는 환각 현상에 대한 종합적인 조사를 제공합니다. 특히, 이 논문은 다중 모달 언어 모델(MLLMs)에서의 환각 문제를 깊이 있게 분석하고, 그 원인, 평가 기준, 그리고 완화 전략을 상세히 논의합니다.

### 주요 내용 요약

1. **서론 및 배경**:
   - 최근 LLMs의 발전에 힘입어 MLLMs가 주목을 받고 있습니다. 그러나 이 모델들은 종종 시각적 내용과 일치하지 않는 출력을 생성하는 경향이 있으며, 이러한 환각은 실제 응용에서의 신뢰성에 문제를 일으킬 수 있습니다.

2. **환각의 원인 분석**:
   - 환각은 데이터, 모델, 훈련 및 추론의 네 가지 주요 측면에서 기인합니다. 이러한 요인들이 어떻게 환각을 유발하는지에 대한 심도 있는 분석이 제공됩니다.

3. **환각 평가 및 기준**:
   - MLLMs의 환각을 평가하기 위한 다양한 메트릭과 벤치마크가 소개됩니다. 이들은 환각의 정도를 측정하고, 모델의 성능을 평가하는 데 사용됩니다.

4. **환각 완화 전략**:
   - 데이터 관련 환각을 줄이기 위한 전략, 모델 수정, 훈련 방법의 개선, 추론 과정에서의 개입 등을 포함하여 환각을 완화하기 위한 다양한 접근 방식이 논의됩니다.

### 혁신적인 부분
이 논문의 혁신성은 MLLMs에서 발생하는 환각 문제를 체계적으로 분석하고, 그 원인과 완화 전략을 종합적으로 제시한다는 점에 있습니다. 특히, 환각의 원인과 평가 방법에 대한 새로운 분류를 도입하고, 이를 기반으로 효과적인 완화 전략을 개발함으로써 이 분야의 연구를 한 단계 발전시키는 기여를 합니다.

이 논문은 MLLMs의 신뢰성과 강건성을 향상시키기 위한 중요한 지침을 제공하며, 다양한 응용 분야에서 MLLMs의 활용 가능성을 높이는 데 기여할 것입니다.

## Similar Papers
- [Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs](2406.14544.md)
- [A Survey on Mixture of Experts](2407.06204.md)
- [A Survey of Large Language Models for Graphs](2405.08011.md)
- [Improved Baselines with Visual Instruction Tuning](2310.03744.md)
- [Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models](2404.07973.md)
- [Machine Unlearning in Generative AI: A Survey](2407.20516.md)
- [AlignGPT: Multi-modal Large Language Models with Adaptive Alignment Capability](2405.14129.md)
- [A Systematic Survey of Text Summarization: From Statistical Methods to Large Language Models](2406.11289.md)
- [Imp: Highly Capable Large Multimodal Models for Mobile Devices](2405.12107.md)
