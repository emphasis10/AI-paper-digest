# LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.15035.pdf](https://arxiv.org/pdf/2412.15035.pdf)

**1. 각 섹션 요약**

- **서론 및 배경**: 이 논문은 다국어 안전성 벤치마크인 M-ALERT를 소개합니다. M-ALERT는 5개 언어로 구성된 75,000개의 프롬프트를 포함하고 있으며, 다양한 언어 모델(LLM)을 평가합니다. 이 작업은 LLM이 생성하는 언어의 독성과 편향성을 지적하고, 이러한 모델의 안전성과 윤리적 사용 가능성을 강조합니다.

- **관련 연구**: 엄청난 잠재력에도 불구하고, LLM은 주목할 만한 안전 문제와 윤리적 고려 사항을 수반합니다. 여러 연구에서는 LLM이 생성하는 언어의 독성과 편향성, 그리고 이러한 문제가 현실 세계에서의 활용에 미치는 영향을 지적하고 있습니다.

- **LLM 안전성 평가**: M-ALERT를 통한 실험에서, 다양한 최신 LLM이 평가되었습니다. 대부분의 모델은 일반적으로 안전하지만 특정 언어 및 카테고리에서 안전상의 차이를 보였습니다. 특별히, Gemma-2 모델은 스페인어, 프랑스어, 이탈리아어에서 99% 이상의 안전성을 달성하여 주목받았습니다.

- **정책 평가 및 윤리적 고려**: M-ALERT는 다양한 정책 적용의 가능성을 평가하고 있으며, 이 프로세스는 시간이 지남에 따라 어떻게 모델들이 더 안전해지는지를 보여줍니다. 하지만 모델의 도움과 회피 성능의 균형까지 포함하여 더 포괄적인 연구가 필요합니다.

- **결론**: M-ALERT는 LLM의 안전성 평가에 있어 정책-특화적인 평가를 통해 그 가능성과 범위를 보여주고, 모델의 크기가 안전성에 직접적으로 연관되지 않을 수 있음을 지적합니다.

**2. 전체 요약**

이 논문은 다국어 안전 벤치마크인 M-ALERT를 개발하여 5개 언어를 포함하는 75,000개 프롬프트로 10개의 최신 LLM의 안전성을 평가합니다. M-ALERT는 LLM의 안전성과 윤리적 문제를 심층 분석하며, 언어 및 카테고리별로 모델의 강점과 약점을 밝힙니다. M-ALERT는 모델의 안전성을 높이기 위해 다언어 평가를 실시하였으며, LLM들이 시간이 지나면서 더 안전해지는 경향이 있음을 보입니다. 이 연구는 LLM의 실질적 활용과 안전성 개선을 위한 기초를 제공하며, AI의 발전에 중요한 기여를 할 수 있는 잠재적 도구로 작용합니다.