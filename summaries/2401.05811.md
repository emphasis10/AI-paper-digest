# Tuning LLMs with Contrastive Alignment Instructions for Machine Translation in Unseen, Low-resource Languages
## TL;DR
## Summary
- [https://arxiv.org/pdf/2401.05811.pdf](https://arxiv.org/pdf/2401.05811.pdf)

## 1. 각 섹션 별 요약

### Abstract
이 논문은 큰 언어 모델(LLM)을 사용하여 낮은 자원 언어에 대한 기계 번역(MT) 성능을 개선하고자 한다. 여기서 제안된 AlignInstruct는 통계적 단어 정렬을 활용하여 교차 언어적 지도를 강조한다. 실험 결과, AlignInstruct는 24개의 새로운 언어로 번역 성능을 향상시켰다.

### Introduction
LLM은 주로 고자원 언어에서 뛰어난 성능을 보이지만, 낮은 자원 언어에서는 아직 제한적이다. 이 논문의 목표는 새로운 언어와 낮은 자원 환경에서 LLM의 번역 성능을 증진하는 방법을 찾는 것이다.

### Methodology
여기서는 두 가지 접근법을 제안한다. 첫째, MTInstruct는 일반적인 기계 번역 지시이며, 주로 고자원 언어에서 사용된다. 둘째, AlignInstruct는 낮은 자원 환경에서 교차 언어적 교정을 통해 번역 성능을 높인다.

### Results
AlignInstruct를 사용하여 전체적으로 번역 성능이 향상되었으며, 특히 낮은 자원 언어에서 좋은 결과를 얻었다. LLM은 24개의 새로운 언어로 번역 성능을 개선했고, 특정 언어쌍에서는 눈에 띄는 발전을 보였다.

### Discussion
AlignInstruct는 낮은 자원 언어에서 LLM의 번역 성능을 증진시키기 위한 혁신적인 접근법이다. 교차 언어적 지도와 통계적 단어 정렬을 활용하여 기존 방법보다 우수한 성능을 보였다.

### Conclusion
AlignInstruct는 낮은 자원 언어와 새로운 언어로 번역 성능을 높이기 위한 효과적인 방법으로 입증되었다. 향후 연구 방향으로는 더 많은 단일 언어 말뭉치를 활용하는 방법과 다양한 지시 템플릿의 효율성을 탐구하는 것이 포함된다.

## 2. 전체 요약
이 논문은 기계 번역을 위한 큰 언어 모델을 낮은 자원 언어에서 더 효과적으로 작동하게 하기 위한 새로운 방법인 AlignInstruct를 제안합니다. AlignInstruct는 교차 언어적 지도를 강화하기 위해 통계적 단어 정렬을 사용합니다. 실험 결과, AlignInstruct는 다양한 새로운 언어와 낮은 자원 언어 조합에서 번역 성능을 크게 향상시켰습니다. 이 접근법은 특히 부족한 데이터를 보완하여 높은 퍼포먼스를 유지할 수 있도록 설계되었습니다. 향후 연구에서는 더 많은 데이터를 활용하고 다양한 지시 템플릿을 실험하여 성능을 더욱 개선할 수 있는 가능성을 탐구하고자 합니다.