# MAmmoTH2: Scaling Instructions from the Web
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.03548.pdf](https://arxiv.org/pdf/2405.03548.pdf)

### 주요 내용 요약

1. **서론 및 배경**:
   - 본 연구에서는 인터넷에서 자연스럽게 존재하는 지시 데이터를 발굴하여 대규모 언어 모델(LLM)의 추론 능력을 향상시키는 새로운 접근 방식을 제안합니다. 기존의 지시 튜닝 데이터는 주로 비용이 많이 드는 인간 주석이나 GPT-4에서의 정보 추출을 통해 생성되었는데, 이 연구에서는 더 경제적이고 규모가 큰 데이터 생성 방법을 개발합니다.

2. **웹에서의 지시 데이터 발굴 방법**:
   - 공개 웹 코퍼스(Common Crawl)에서 고품질의 지시 데이터를 찾아내기 위한 3단계 파이프라인을 사용합니다. 이 방법은 문제지 웹사이트에서 다양한 퀴즈를 크롤링하여 초기 데이터를 생성하고, fastText 모델을 통해 관련 문서를 추출한 후, Mixtral과 Qwen 모델을 사용하여 데이터를 정제합니다.

3. **MAmmoTH2 모델 훈련 및 평가**:
   - 추출 및 정제된 10M의 지시 반응 쌍을 사용하여 MAmmoTH2 모델을 훈련시키고, 이 모델은 여러 벤치마크에서 기존 모델들보다 우수한 성능을 보입니다. 특히, 이 모델은 수학, 과학, 챗봇 등 다양한 분야에서 최고의 성능을 달성합니다.

### 혁신적인 부분
이 연구의 혁신성은 기존에 인간 주석이 필요했던 지시 튜닝 데이터를 인터넷에서 자동으로 추출하고 정제하는 경제적인 방법을 제시한 것입니다. 특히, 이 방법은 대규모 언어 모델의 지시 추론 능력을 크게 향상시킬 수 있는 새로운 데이터셋을 생성할 수 있는 가능성을 보여줍니다.

이 연구는 인터넷에서 자동으로 지시 데이터를 수집하고 활용하는 새로운 패러다임을 제시하며, 언어 모델의 지시 튜닝 및 추론 능력 향상에 중요한 기여를 합니다.

## Similar Papers
- [Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large Language Models](2406.17294.md)
- [Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On](2407.08348.md)
- [AutoDetect: Towards a Unified Framework for Automated Weakness Detection in Large Language Models](2406.16714.md)
- [Weak-to-Strong Reasoning](2407.13647.md)
- [A Careful Examination of Large Language Model Performance on Grade School Arithmetic](2405.00332.md)
- [StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation](2408.03281.md)
- [LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs](2406.15319.md)
- [Self-Taught Evaluators](2408.02666.md)
- [Long-context LLMs Struggle with Long In-context Learning](2404.02060.md)
