# Yi-Lightning Technical Report
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.01253.pdf](https://arxiv.org/pdf/2412.01253.pdf)

### 1. 각 섹션의 요약 및 논문의 주 기여와 혁신적인 부분

1. **소개**  
   이 논문은 대형 언어 모델(LLM) Yi-Lightning의 기술 보고서입니다. 이 모델은 Chatbot Arena에서 전체적으로 6위를 차지하며 특히 중국어, 수학, 코딩 및 어려운 프롬프트에서 강력한 성능을 보였습니다. Yi-Lightning은 향상된 Mixture-of-Experts(MoE) 구조를 사용해 효율적인 훈련 및 추론을 달성했습니다.

2. **모델 아키텍처**  
   - **세분화된 전문가 구분**: 복잡한 모델의 비효율성을 해결하기 위해 MoE 아키텍처와 세분화된 전문가 구분 방식을 도입했습니다. 이는 효율적인 파라미터 활용을 가능케 하며 훈련 중에 더 나은 성능을 보장합니다.
   - **전문가 라우팅 전략**: 균형 잡힌 부하 분산 메커니즘을 사용해 전문가들 간의 균형적인 라우팅을 통해 모델 품질 향상을 추구합니다.

3. **사전 훈련**  
   다국어 웹 문서와 학술 데이터를 포함한 다양한 데이터셋을 사용하여 모델을 훈련시켰습니다. 이 데이터들은 강력한 필터링 메커니즘을 통해 안전하고 유용한 정보로 구성되었습니다.

4. **후속 훈련**  
   - **감독 학습**: Yi-Lightning은 여러 단계의 훈련을 거치며 특정 분야에서 모델의 성능을 극대화했습니다.
   - **인간 피드백에서 강화 학습**: 모델이 인간의 선호도에 맞춰 작동할 수 있도록 다양한 보상 모델과 훈련 방식을 도입했습니다.

5. **인프라 구조 최적화**  
   효율적인 GPU 클러스터 관리를 통해 높은 수준의 성능을 유지하며 추론 비용을 대폭 줄였습니다.

6. **안전성**  
   전체 모델 수명 주기 동안 안전성을 확보하기 위한 포괄적인 프레임워크 RAISE를 개발하였습니다. 이 시스템은 개발부터 배포까지 모든 단계에서 안전 문제를 해결합니다.

### 2. 전체 요약

Yi-Lightning은 대형 언어 모델의 효율성과 성능을 극대화하기 위한 다양한 기술을 도입하여 개발되었습니다. 특히, 세분화된 전문가 시스템과 균형 잡힌 전문가 라우팅 전략을 통해 모델이 큰 규모에서도 효율적으로 작동할 수 있도록 설계되었습니다. 이 모델은 데이터의 다양성과 품질을 극대화하여 다국어와 복합적인 과제를 효율적으로 처리하며, 인프라 최적화를 통해 자원을 절약하면서도 높은 처리 성능을 자랑합니다. 또한, 전 과정을 아우르는 RAISE 프레임워크를 통해 모델의 안전성을 보장합니다. 이를 통해, Yi-Lightning은 실사용 환경에서 강력한 성능을 발휘하며 학술적인 벤치마크에서도 뛰어난 결과를 보였습니다.