# Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.19502.pdf](https://arxiv.org/pdf/2406.19502.pdf)

### 섹션별 요약

#### 1. 서론
대형 언어 모델(LLM)의 발전으로 복잡한 질문에 대한 추론 능력에 대한 연구가 증가했습니다. 하지만 LLM이 사실 지식을 기억하고 이를 추론 과정에서 어떻게 사용하는지에 대한 연구는 부족합니다.

#### 2. 관련 연구
최근의 연구는 트랜스포머 언어 모델의 추론 능력 발전에 주목하고 있습니다. 그러나 이러한 모델들은 여전히 상식적이고 논리적인 추론에서 어려움을 겪고 있습니다. 이 문제를 해결하기 위해 LLM이 추론 중간 단계를 언어적으로 표현하도록 유도하는 방법이 효과적임이 입증되었습니다.

#### 3. DEPTHQA 데이터셋
DEPTHQA는 튜터 평가(TutorEval) 데이터셋에서 인간이 작성한 복잡한 질문(D3)을 기반으로 한 계층적 그래프 구조입니다. 이 데이터셋은 다양한 수준의 지식과 추론을 요구하는 복잡한 현실 질문을 모델이 어떻게 해결하는지 평가합니다. 节는 모델의 앞으로의 추론 능력을 측정합니다.

#### 4. 그래프 기반 추론 프레임워크
이 연구에서는 복잡한 질문을 그래프 구조로 분해하여 모델이 어떻게 여러 지식을 사용해서 추론을 수행하는지 분석합니다. 이 프레임워크를 통해 모델의 지식 추론 능력을 다양한 깊이에서 평가합니다.

#### 5. 실험 결과
LLaMA 2와 3, Mistral, GPT-3.5 Turbo 등의 다양한 LLM을 DEPTHQA에서 평가한 결과, 모델의 크기가 클수록 복잡한 질문에 대한 성능이 더 우수했습니다. 작은 모델은 더 큰 역방향 불일치를 보였고, 추론 성능은 중간 단계를 통한 다중 회차 상호작용을 통해 개선되었습니다.

### 논문의 주요 기여 및 혁신 점
이 논문의 주요 기여는 다음과 같습니다:
1. 복잡한 질문을 단순한 하위 질문으로 연결하여 계층적 그래프 구조로 분해하는 방법을 제안합니다.
2. 다양한 복잡도 수준의 질문에 걸쳐 LLM의 지식 추론 능력을 평가하기 위해 DEPTHQA 데이터셋을 설계합니다.
3. 모델 크기와 훈련 데이터 암기 현상이 불일치에 미치는 영향을 분석하고, 다중 회차 상호작용을 통해 추론 성능을 개선함을 입증합니다.

### 전체 요약
이 논문은 LLM의 복잡한 현실 질문에 대한 추론 능력을 평가하기 위해 DEPTHQA 데이터셋과 그래프 기반 추론 프레임워크를 제안합니다. 다양한 크기의 LLM을 DEPTHQA로 평가한 결과, 모델 크기가 클수록 복잡한 질문에 대한 성능이 뛰어나며, 중간 단계를 통한 다중 회차 상호작용이 모델 성능을 안정화시킴을 확인했습니다. 이 연구는 LLM의 추론 능력을 심층적으로 이해하고 개선하는 방법에 중요한 통찰을 제공합니다.

## Similar Papers
- [Cognitive Map for Language Models: Optimal Planning via Verbally Representing the World Model](2406.15275.md)
- [PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing](2407.16318.md)
- [FIRE: A Dataset for Feedback Integration and Refinement Evaluation of Multimodal Models](2407.11522.md)
- [Estimating Knowledge in Large Language Models Without Generating a Single Token](2406.12673.md)
- [Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning](2406.09170.md)
- [CodecLM: Aligning Language Models with Tailored Synthetic Data](2404.05875.md)
- [GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models](2407.02936.md)
- [Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps](2407.07071.md)
- [Memory-Efficient Fine-Tuning of Compressed Large Language Models via sub-4-bit Integer Quantization](2305.14152.md)
