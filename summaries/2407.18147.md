# The FIGNEWS Shared Task on News Media Narratives
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.18147.pdf](https://arxiv.org/pdf/2407.18147.pdf)

### 1. 섹션별 요약 및 설명

#### 서론 및 배경 
이 논문은 AI와 머신러닝을 사용하여 뉴스 콘텐츠의 편향성과 선전(Propaganda)을 탐지하는 방법에 대해 다룹니다. 이 작업의 주요 목표는 'FIGNEWS 2024'라는 대회에 참여하여 다양한 팀들이 뉴스 기사의 편향성과 선전을 효과적으로 식별하고 주석을 다는 방법을 제안하는 것입니다.

#### 관련 연구
선전과 편향은 정치적, 사회적 맥락에서 광범위한 영향을 미칠 수 있습니다. 특히 뉴스 미디어의 보도가 어떻게 대중의 인식을 형성하는지에 대한 다양한 연구들이 소개됩니다. 이 연구들은 뉴스 기사에서 단어 선택과 레이블링을 통해 미디어 편향을 자동으로 식별하는 방법을 포함합니다.

#### 데이터 및 방법론
이 논문에서 사용된 데이터는 다언어로 된 소셜 미디어 게시물들을 포함하며, 주로 이스라엘-팔레스타인 갈등의 초기 날들에 초점을 맞추고 있습니다. 참가팀들은 최소 두 개의 배치를 주석 달아야 하며, 이는 약 2,000개의 게시물입니다. 각 팀은 자체적으로 주석 가이드를 제공해야 하며, 이 가이드는 편향과 선전 두 가지 하위 과제로 나누어집니다.

#### 결과 및 분석
결과 섹션에서는 각 팀이 제출한 주석 데이터에 대한 분석이 포함됩니다. 예를 들어, '편향 없음'으로 표시된 데이터가 가장 많았으며, 팔레스타인에 대해 편향된 기사와 이스라엘에 대해 편향된 기사로 구분됩니다. 또한 다양한 언어에서 편향과 선전 레이블의 분포를 비교합니다.

#### 결론 및 향후 과제
이 논문은 FIGNEWS 대회가 AI와 머신러닝을 사용하여 뉴스 미디어의 편향성과 선전을 탐지하는 데 있어 큰 진보를 이루었다고 결론짓습니다. 향후 과제로는 더 다양한 언어와 주제에 대한 주석 작업 확대, 주석 가이드라인의 정제, 그리고 자동화된 편향 및 선전 탐지 기술의 발전이 제안됩니다.

### 2. 전체 요약

이 논문은 뉴스 콘텐츠에서 편향성과 선전을 탐지하는 방법을 개발하기 위해 다양한 AI와 머신러닝 기술을 사용합니다. 주요 기여는 FIGNEWS 2024 대회를 통해 뉴스 기사의 다층적 주석을 위한 가이드라인을 제안하고, 이를 통해 편향성과 선전 탐지의 정확도와 신뢰성을 높이는 것입니다. 대회의 결과는 다언어 소셜 미디어 게시물에서 편향성과 선전을 효과적으로 식별할 수 있는 다양한 방법론들을 포함하고 있으며, 주석의 질을 높이기 위한 협력적 접근이 특히 강조됩니다. 전체적으로 이 연구는 AI 기반의 자동 뉴스 분석 및 비판적 미디어 소비를 촉진하는 중요한 발판이 될 것입니다.

## Similar Papers
- [Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models](2407.19914.md)
- [Evaluating the IWSLT2023 Speech Translation Tasks: Human Annotations, Automatic Metrics, and Segmentation](2406.03881.md)
- [ResumeAtlas: Revisiting Resume Classification with Large-Scale Datasets and Large Language Models](2406.18125.md)
- [CVQA: Culturally-diverse Multilingual Visual Question Answering Benchmark](2406.05967.md)
- [DataComp-LM: In search of the next generation of training sets for language models](2406.11794.md)
- [A Survey on Retrieval-Augmented Text Generation for Large Language Models](2404.10981.md)
- [ContextQ: Generated Questions to Support Meaningful Parent-Child Dialogue While Co-Reading](2405.03889.md)
- [LLM-jp: A Cross-organizational Project for the Research and Development of Fully Open Japanese LLMs](2407.03963.md)
- [MINT-1T: Scaling Open-Source Multimodal Data by 10x: A Multimodal Dataset with One Trillion Tokens](2406.11271.md)
