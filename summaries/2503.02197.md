# ATLaS: Agent Tuning via Learning Critical Steps
## TL;DR
## Summary
- [https://arxiv.org/pdf/2503.02197.pdf](https://arxiv.org/pdf/2503.02197.pdf)

1. 각 섹션의 요약:

- **소개**: 논문에서는 에이전트 튜닝을 위한 새로운 접근법인 ATLAS(Agent Tuning via Learning Critical Steps)를 제안합니다. 이 방법은 전문가의 경로에서 중요한 단계를 식별하고, 그 단계만으로 대형 언어 모델(LLM)을 미세 조정(파인튜닝)하는 방법입니다.

- **이론적 배경**: 멀티태스크 학습 구조에서 ATLAS는 Partially Observable Markov Decision Process (POMDP)을 사용하여 각 환경에서 에이전트가 최적의 정책을 학습하도록 합니다.

- **기존 연구와의 비교**: ATLAS는 기존의 모든 경로를 사용하는 방법에 비해 훨씬 적은 양의 데이터(30%만)로도 에이전트의 일반화 능력과 효율성을 향상시킵니다.

- **실험 결과**: ATLAS로 미세 조정한 에이전트는 전체 경로를 사용한 에이전트를 능가하며, 이는 특히 멀티태스크 학습에서 두드러집니다.

- **결론**: ATLAS는 적은 데이터로 효과적인 LLM 에이전트 튜닝을 가능하게 하여, 비용을 절감하며 다양한 작업에서 성능을 향상시킵니다. 또한, 전체 경로를 사용하는 방법보다 우수한 일반화 능력을 제공하여 새로운 작업에서도 성능을 보장합니다.

2. **전반적인 요약**:

이 논문은 LLM 에이전트를 전문가 경로의 중요한 단계만을 사용하여 효율적으로 미세 조정하는 방법인 ATLAS를 제안합니다. ATLAS는 데이터 사용을 30%로 줄이면서도 성능을 유지하거나 개선할 수 있으며, 특히 새로운 환경에서도 일반화 성능이 뛰어납니다. 이는 적은 자원으로도 효과적인 에이전트를 훈련할 수 있게 함으로써 AI의 발전을 도울 수 있습니다.