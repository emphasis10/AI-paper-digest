# DiM: Diffusion Mamba for Efficient High-Resolution Image Synthesis
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.14224.pdf](https://arxiv.org/pdf/2405.14224.pdf)

### 1. 섹션별 요약

#### 소개 (Introduction)
- **개요**: 이 논문은 효율적인 고해상도 이미지 생성을 위해 Mamba와 확산 모델을 결합한 Diffusion Mamba(DiM) 모델을 제안합니다. 
- **주요 기여**: Mamba는 State Space Models(SSM)을 기반으로 한 시퀀스 모델이며, 효율적이고 고성능을 자랑합니다. DiM은 복잡도가 선형적으로 증가하여 고해상도 이미지 생성에 적합합니다.

#### 관련 연구 (Related Work)
- **기존 모델**: 전통적으로 U-Net과 Transformer 기반의 확산 모델이 사용되었으며, 각기 장단점이 존재합니다. 특히 Transformer는 확장성이 훌륭하지만 계산 비용이 큽니다.
- **SSM과 Mamba**: SSM은 순차적 입력 신호를 인코딩하고 디코딩하는 데 사용됩니다. Mamba는 이러한 SSM을 개선한 버전으로 효율성을 크게 높였습니다.

#### 방법론 (Method)
- **DiM 아키텍처**: DiM은 Mamba를 2D 이미지 생성에 맞도록 여러 가지 디자인을 도입합니다. 예를 들어, 다중 방향 주사, 패딩 토큰, 경량 지역적 특징 강화 등이 포함됩니다.
- **효율적 학습 전략**: DiM은 저해상도 이미지에서 사전 훈련 후 고해상도 이미지로 고도화하는 "약한-강한" 훈련 전략을 도입합니다. 또한 추가 학습 없이 고해상도로 업샘플링하는 방법도 탐구합니다.

#### 실험 (Experiments)
- **설정 및 데이터셋**: CIFAR-10과 ImageNet 데이터셋에서 실험을 수행하며, 각 데이터셋에 맞춘 설정으로 모델의 성능을 평가했습니다. 
- **효율성 분석**: DiM은 고해상도 이미지 생성에서 Transformer보다 효율적입니다. 예를 들어, 1024×1024 이상의 해상도에서 Transformer보다 빠릅니다.

#### 결론 (Conclusion)
- **결론**: DiM은 효율적인 고해상도 이미지 생성을 위해 설계된 Mamba 기반의 확산 모델로, 다중 주사 패턴과 패딩 토큰 같은 여러 혁신적 요소를 도입했습니다. 실험 결과는 DiM이 Transformer 기반 모델과 비교하여 경쟁력 있는 성능을 보임을 나타냅니다.

### 전체 요약

이 논문은 고해상도 이미지 생성을 효율적으로 수행하기 위해 Mamba와 확산 모델을 결합한 Diffusion Mamba(DiM)를 제안합니다. 기존의 U-Net과 Transformer 기반 모델은 각각 장단점이 있으나, DiM은 State Space Model(SSM)의 일종인 Mamba의 효율성을 활용합니다.

DiM의 주요 혁신점은 다음과 같습니다:
1. **다중 방향 주사**: 2D 이미지에서 Mamba의 사용을 용이하게 하여 효율성을 높입니다.
2. **패딩 토큰**: 각 행과 열의 끝에 학습 가능한 패딩 토큰을 추가하여 시공간 연속성을 보장합니다.
3. **경량 지역적 특징 강화**: 네트워크의 시작과 끝에 경량의 3x3 깊이 별 컨볼루션 레이어를 추가하여 지역적 구조를 강화합니다.

DiM은 저해상도 이미지에서 사전 훈련한 후 고해상도 이미지로 고도화하는 "약한-강한" 훈련 전략을 도입하고, 추가 학습 없이 고해상도로 업샘플링하는 방법도 탐구합니다. 이러한 전략은 고해상도 이미지 생성을 위한 비용을 크게 절감합니다.

실험을 통해 CIFAR-10과 ImageNet 데이터셋에서 DiM의 효율성과 성능을 입증했으며, DiM이 Transformer 기반 모델보다 더 빠르게 고해상도 이미지를 생성할 수 있음을 보여줍니다.

결론적으로, DiM은 고해상도 이미지 생성을 위한 효율적이고 효과적인 솔루션을 제공합니다. DiM의 혁신적인 디자인과 훈련 전략은 향후 AI와 머신 러닝 분야에서 중요한 기여를 할 것으로 기대됩니다.