# Speech-MASSIVE: A Multilingual Speech Dataset for SLU and Beyond
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.03900.pdf](https://arxiv.org/pdf/2408.03900.pdf)

### 1. 섹션별 주요 내용 요약 및 설명

#### Abstract 요약
이 논문은 Speech-MASSIVE라는 다국어 음성 데이터셋을 소개합니다. 이 데이터셋은 MASSIVE 텍스트 코퍼스에 대한 음성 버전으로 12개 언어를 포함하고 있습니다. 이 데이터셋은 다국어 음성 이해(SLU) 모델의 성능을 평가할 목적으로 개발되었으며, 음성 인식(ASR), 언어 식별(LID), 음성 번역(ST) 등 다양한 작업에 활용될 수 있습니다. 이 논문에서는 여러 학습 시나리오(제로 샷, 몇 샷, 전체 미세 조정)에 걸쳐 SLU 베이스라인을 설립하고 이를 공개합니다.

#### Introduction 요약
다국어 음성 코퍼스는 주로 자동 음성 인식(ASR)과 음성 번역(ST)에 집중되어 있으나, 음성 언어 이해(SLU) 데이터셋은 많지 않습니다. MASSIVE 텍스트 데이터셋을 기반으로 하여 SLU 데이터셋을 확장한 Speech-MASSIVE는 12개 언어에 대해 의도 예측 및 슬롯 채우기 작업을 지원합니다.이 데이터셋은 다양한 다국어 및 다작업 연구의 벤치마크로 사용할 수 있습니다.

#### Data Collection and Validation Process 요약
Speech-MASSIVE 데이터셋은 원어민을 통해 수집한 음성 데이터를 포함합니다. 주요 데이터 수집은 Prolific이라는 크라우드소싱 플랫폼을 통해 이뤄졌으며, 이 중 일부는 데이터 정확성을 확보하기 위해 검증되었습니다. 녹음 참가자는 원본 문장을 정확하고 자연스럽게 읽도록 지침을 받았으며, 검증 단계에서는 녹음된 음성을 듣고 유효성을 확인했습니다.

#### Overall Statistics 요약
이 데이터셋은 12개 언어로 구성되어 있으며, 언어별로 다양한 의도와 슬롯 유형을 포함한 대화 데이터를 제공합니다. 데이터 수집과 검증 과정을 통해 총 데이터의 품질을 높였습니다.

#### ASR Assessment 요약
ASR 평가를 통해 다양한 언어에 대한 음성 인식 성능을 측정했습니다. Whisper 모델을 사용하여 데이터셋의 모든 샘플에 대해 언어 식별(LID)과 음성 번역(ST) 성능도 평가했습니다. 이 평가를 통해 각 언어의 인식 품질을 확인하고, 데이터셋의 다국어 음성 인식 작업에 대한 유용성을 입증했습니다.

#### SLU Baselines and Beyond 요약
여러 학습 조건에서 다양한 SLU 모델을 평가하여 기본 베이스라인을 구축했습니다. 여기에는 제로 샷, 몇 샷, 전체 미세 조정과 같은 다양한 시나리오가 포함됩니다. 또한 음성 번역과 언어 식별 작업을 추가 평가하여 Speech-MASSIVE 데이터셋의 다목적 활용 가능성을 입증했습니다.

#### Conclusion 요약
이 연구는 12개 언어에 대한 SLU 데이터셋인 Speech-MASSIVE를 소개하고, 다양한 학습 시나리오에서 SLU 모델의 성능을 평가했습니다. 이 데이터셋은 다양한 음성 작업에 대한 벤치마크로서 잠재력을 지니고 있으며, 향후 연구 방향으로는 제로 샷 및 몇 샷 학습 성능 탐구와 다중 작업 음성 시스템의 경계 확장이 있습니다.

### 2. 전체 요약
이 논문은 다국어 음성 언어 이해(SLU) 데이터셋인 Speech-MASSIVE를 소개하고, 이를 통해 다양한 언어와 작업 시나리오에서 SLU 모델의 성능을 평가합니다. 이 데이터셋은 12개 언어를 포함하며, MASSIVE 텍스트 데이터셋의 음성 버전으로 의도 예측과 슬롯 채우기 작업을 지원합니다. Prolific 플랫폼을 통해 원어민을 고용하여 데이터 수집 및 검증을 거쳤고, 이를 통해 데이터의 품질을 높였습니다. 다양한 평가 시나리오에서 Whisper 모델을 사용하여 음성 인식(ASR), 언어 식별(LID), 음성 번역(ST) 작업을 실험하였으며, 이를 통해 SLU 모델의 성능을 입증하였습니다.

이 데이터셋은 각 언어에 대해 다양한 의도와 슬롯 유형을 포함한 대화 데이터를 제공하며, 음성 인식 품질 평가를 통해 다국어 음성 인식 작업의 유용성을 입증합니다. 향후 연구 방향으로는 제로 샷 및 몇 샷 학습 성능을 탐구하고 다중 작업 음성 시스템의 경계를 확장하는 것을 목표로 합니다.

## Similar Papers
- [SpeechVerse: A Large-scale Generalizable Audio Language Model](2405.08295.md)
- [mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus](2406.08707.md)
- [Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment](2404.12318.md)
- [Audio Dialogues: Dialogues dataset for audio and music understanding](2404.07616.md)
- [Investigating Decoder-only Large Language Models for Speech-to-text Translation](2407.03169.md)
- [In-Context Example Selection via Similarity Search Improves Low-Resource Machine Translation](2408.00397.md)
- [How multilingual is Multilingual BERT?](1906.01502.md)
- [RegMix: Data Mixture as Regression for Language Model Pre-training](2407.01492.md)
- [FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs](2407.04051.md)
