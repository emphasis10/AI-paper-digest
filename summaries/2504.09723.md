# AgentA/B: Automated and Scalable Web A/BTesting with Interactive LLM Agents
## TL;DR
## Summary
- [https://arxiv.org/pdf/2504.09723.pdf](https://arxiv.org/pdf/2504.09723.pdf)

1. 각 섹션 요약:

- **서론**: 이 논문은 웹 인터페이스 디자인 평가를 위한 LLM(대형 언어 모델)에 기반을 둔 AgentA/B 시스템을 소개합니다. 전통적인 A/B 테스트의 한계를 극복하고자, 대규모의 LLM 에이전트를 사용하여 실시간 웹에서 상호작용하는 행위를 자동화합니다. 이를 통해 사용자 행동 패턴을 현실적으로 모방하고, A/B 테스트 시 실제 사람과 유사한 피드백을 제공합니다.

- **관련 연구**: 기존의 A/B 테스트의 제약과 자동화된 실험 워크플로우, 다양한 도메인에서 LLM 기반 에이전트 시뮬레이션, 웹 환경에서 인터랙티브 에이전트와 같은 관련된 연구들을 검토합니다.

- **연구 문제 및 제너레이션**: 이 연구는 전통적 A/B 테스트 참여자의 제약을 지적하며, LLM 에이전트가 다양한 인격을 모사하고 실시간 웹 페이지와 상호작용할 수 있도록 하는 시스템 아키텍처를 제안합니다. 초기 테스트에서는 Amazon.com을 대상으로, 가상 고객으로 구성된 1,000명의 LLM 에이전트가 사용되었습니다.

- **구현 및 평가**: AgentA/B 시스템은 대규모 LLM 에이전트를 사용하여 실제 웹 사이트와의 인터랙션에서 A/B 테스트 조건을 자동으로 생성합니다. Amazon을 사용한 사례 연구는 시스템이 자동화된 대규모 웹 A/B 테스트를 수행하는 데 있어 매우 유망한 결과를 보여줍니다.

- **결론**: AgentA/B 시스템은 LLM 기반의 에이전트를 활용한 웹 인터페이스의 대규모 A/B 테스트 시뮬레이션을 가능하게 합니다. 평가 결과, LLM 에이전트는 현실적이고 목표 지향적인 행동을 보이며, 인터페이스 변화에 민감하게 반응합니다. 이것은 초기 UX 평가의 범위를 확장하고, 전통적인 A/B 테스트를 보완하는 새로운 에이전트 기반 파일럿 단계를 도입합니다.

2. 전체 요약:

AgentA/B 시스템은 LLM 기반 에이전트를 사용하여 웹 인터페이스 디자인의 A/B 테스트를 자동화하고 대규모로 실행하는 새로운 방식을 제안합니다. 이는 전통적인 방법의 한계를 극복하며, UX 평가의 초기에 보다 유용한 피드백을 제공합니다. 이 시스템은 다양한 도메인에서 에이전트의 역할을 확대하여 웹 디자인의 효율성을 높이고, 초기 디자인 프로세스를 가속화하며, 미래에는 다양한 도메인의 시뮬레이션으로 확장될 수 있습니다.