# Improved Distribution Matching Distillation for Fast Image Synthesis
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.14867.pdf](https://arxiv.org/pdf/2405.14867.pdf)

### 논문 요약 및 분석

#### **1. 서론**
최근 디퓨전 모델은 시각적 생성 작업에서 전례 없는 품질을 달성했습니다. 그러나 이러한 모델의 샘플링 절차는 수십 번의 반복적인 노이즈 제거 단계가 필요하여 고해상도 텍스트-이미지 합성이 느리고 비용이 많이 듭니다. 이를 해결하기 위해 많은 디스틸레이션 방법이 개발되어 교사 디퓨전 모델을 효율적인 몇 단계의 학생 생성기로 변환하고 있습니다.

#### **2. 관련 연구**
디퓨전 모델의 가속화 기법은 디스틸레이션을 통해 샘플링 과정을 빠르게 만드는 데 중점을 둡니다. 이들은 일반적으로 교사 모델의 샘플링 과정을 적은 샘플링 단계로 근사하도록 학생 생성기를 훈련시킵니다. 예를 들어, Luhman et al.과 같은 연구들이 있습니다. 기존 방법들은 많은 노이즈-이미지 페어를 생성해야 했으나, 새로운 방법들은 이러한 데이터셋 생성의 필요성을 제거했습니다.

#### **3. 배경: 디퓨전과 분포 매칭 디스틸레이션(DMD)**
디퓨전 모델은 반복적인 노이즈 제거를 통해 이미지를 생성합니다. 이 과정에서 샘플에 점진적으로 노이즈를 추가하여 신호를 왜곡시킨 후, 이 과정을 되돌려 원래의 이미지를 복원합니다. DMD는 이러한 디퓨전 모델의 출력을 학생 모델로 디스틸레이션하여, 원래 모델의 샘플링 경로를 따르기보다 분포를 매칭하도록 합니다. 그러나 DMD는 안정적인 훈련을 위해 많은 노이즈-이미지 페어가 필요했으며, 이는 비용이 많이 들고 교사 모델의 성능에 상한을 두게 됩니다.

#### **4. 개선된 분포 매칭 디스틸레이션**
1. **회귀 손실 제거** - 우선 회귀 손실 없이도 안정적인 훈련을 보장하는 방안을 제안했습니다. 이를 통해 비용이 많이 드는 데이터셋 생성의 필요성을 없앴습니다.
2. **GAN 손실 도입** - 또한, GAN 목표를 통합하여 실제 이미지와 학생 생성기에서 생성된 이미지를 구별하도록 디스크리미네이터를 훈련시켰습니다. 이는 학생 모델이 실제 데이터를 훈련 데이터로 사용하게 하여 품질을 향상시켰습니다.
3. **다단계 생성기** - 다단계 샘플링을 지원하는 새로운 훈련 절차를 도입하여, 훈련과 추론 간의 입력 불일치를 해소했습니다.

#### **5. 실험 결과**
제안된 DMD2는 ImageNet과 COCO에서의 클래스 조건부 이미지 생성 및 텍스트-이미지 생성 성능을 평가했습니다. 기존 기법에 비해 우수한 성능을 보였으며, 교사 모델을 초과하는 성능을 보였습니다. 예를 들어, ImageNet-64x64에서는 FID 점수가 1.28로, COCO 2014에서는 8.35를 기록했습니다.

#### **6. 한계점**
이 방법의 한계점으로는 여전히 고해상도 이미지 생성에서 다단계 생성기의 복잡성 및 제한된 모델 용량이 있습니다. 이는 훈련 시간이 길고, 더 많은 계산 자원이 필요하게 합니다.

#### **7. 넓은 영향**
이 기법은 텍스트-이미지 합성, 고해상도 이미지 생성 등 다양한 시각적 생성 작업에 널리 사용될 수 있으며, 이를 통해 많은 비용과 시간을 절감할 수 있습니다. 또한, 더 현실적이고 높은 품질의 이미지를 생성할 수 있습니다.

### 전체 요약
논문에서는 기존 디퓨전 모델의 한계를 극복하는 DMD2 기법을 제안했습니다. 회귀 손실을 제거하고 GAN 손실을 도입하여 훈련의 안정성과 품질을 향상시켰습니다. 다단계 샘플링을 지원하며, 이를 통해 ImageNet과 COCO 데이터셋에서 교사 모델 이상의 성능을 기록했습니다. 그러나 여전히 높은 계산 자원이 필요하며, 고해상도 이미지 생성에는 제한이 있습니다. 이러한 기법은 텍스트-이미지 합성 등 다양한 시각적 생성 작업에 큰 영향을 미칠 수 있습니다.

## Similar Papers
- [Editable Image Elements for Controllable Synthesis](2404.16029.md)
- [Improving GFlowNets for Text-to-Image Diffusion Alignment](2406.00633.md)
- [Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation](2406.06525.md)
- [Consistency Flow Matching: Defining Straight Flows with Velocity Consistency](2407.02398.md)
- [DITTO-2: Distilled Diffusion Inference-Time T-Optimization for Music Generation](2405.20289.md)
- [Aligning Diffusion Models with Noise-Conditioned Perception](2406.17636.md)
- [RL for Consistency Models: Faster Reward Guided Text-to-Image Generation](2404.03673.md)
- [TurboEdit: Text-Based Image Editing Using Few-Step Diffusion Models](2408.00735.md)
- [Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models](2404.07724.md)
