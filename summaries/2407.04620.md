# Learning to (Learn at Test Time): RNNs with Expressive Hidden States
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.04620.pdf](https://arxiv.org/pdf/2407.04620.pdf)

### 요약문:

1. **Introduction (소개)**:
   논문은 LSTM(장단기 메모리) 네트워크가 Transformer보다 시간적으로 확장하기 어렵다는 기존의 연구결과를 재평가합니다. Mamba라는 최신 RNN을 사용하여 길이가 긴 문맥에서도 효과적으로 작동할 수 있는지 테스트하였으며, Transformer와 유사한 성능을 보이지만 문맥이 길어질수록 예측력이 떨어지는 문제를 발견했습니다. RNN의 복잡도는 선형이지만, 긴 문맥에서 문맥 정보를 충분히 활용하지 못하는 한계를 지적합니다.

2. **TTT Layers (테스트 시간 훈련 레이어)**:
   새로운 시퀀스 모델링 레이어를 제안합니다. TTT 레이어는 히든 스테이트를 모델로 하며, 업데이트 규칙은 자기 지도 학습(self-supervised learning)을 따릅니다. 이 레이어는 테스트 시퀀스를 훈련하는 과정과 동일하게 동작하며 TTT-Linear와 TTT-MLP라는 두 가지 구현을 통해 Transformer와 Mamba보다 우수한 성능을 보였습니다.

3. **Hardware Efficiency (하드웨어 효율성)**:
   TTT 레이어의 하드웨어 효율성을 개선하기 위해 미니배치 TTT와 듀얼 폼을 제안합니다. 이 기술들은 GPU와 TPU의 성능을 극대화하여 계산 시간을 줄이는 데 도움을 줍니다. TTT-Linear는 이미 8k 문맥에서 Transformer보다 빠르게 동작할 수 있으며, Mamba와 유사한 속도를 보입니다.

4. **Self-supervised Task (자기 지도 학습 과제)**:
   자기 지도 학습 과제를 외부 루프 내에서 학습하여 최적의 성능을 끌어내려고 합니다. 이를 위해 다양한 뷰를 통해 학습하는 여러 가지 자기 지도 학습 과제를 제안합니다. 이 뷰들은 트레이닝 뷰, 레이블 뷰, 테스트 뷰로 나뉘며, 각각의 뷰를 통해 모델의 성능을 향상시킬 수 있습니다.

5. **Open Problems (열린 문제들)**:
   논문은 TTT 레이어의 제한된 학문적 자원으로 인해 아직 해결되지 않은 여러 가지 문제들을 제기하며, 학계와 연구 커뮤니티의 참여가 필요함을 강조합니다.

### 논문의 주요 공헌과 혁신적인 부분 (Main Contribution and Innovative Part)
- **TTT 레이어 제안**: TTT 레이어는 테스트 시퀀스를 학습하는 새로운 시퀀스 모델링 레이어로 히든 스테이트를 모델로 하고, 업데이트 규칙을 자기 지도 학습으로 삼습니다. 이 새로운 관점은 미래 연구에 새로운 방향성을 제시합니다.
- **성능 우수성**: TTT-Linear는 125M에서 1.3B 파라미터 범위에서 Transformer와 Mamba보다 우수한 성능을 보입니다.
- **하드웨어 효율성 개선**: 미니배치 TTT와 듀얼 폼을 통해 하드웨어 효율성을 크게 개선하여 TTT-Linear를 대형 언어 모델(LLM)의 실용적인 구성 요소로 만듭니다.

### 전체 요약 (Overall Summary)
이 논문은 AI와 머신러닝의 시퀀스 모델링 분야에서 중요한 발전을 이루었습니다. TTT(테스트 시간 훈련) 레이어는 텍스트 예측을 위해 새로운 히든 스테이트 모형과 자기 지도 학습 규칙을 활용하여 기존 RNN과 Transformer 모델보다 우수한 성능을 보였습니다. 또한, 미니배치 TTT와 듀얼 폼을 통해 하드웨어 효율성을 극대화시켜 실용성을 높였습니다. 이 연구는 AI의 학습 과정에 새로운 접근 방식을 도입하여 향후 연구에 중요한 기여를 할 것으로 기대됩니다.