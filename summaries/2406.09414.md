# Depth Anything V2
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.09414.pdf](https://arxiv.org/pdf/2406.09414.pdf)

### 요약: Depth Anything V2 논문

#### 1. 섹션별 요약

##### Introduction
- **배경**
  - Monocular Depth Estimation (MDE)은 3D 재구성, 내비게이션, 자율 주행 등 다양한 응용에서 기본적 역할을 함.
  - 최근에는 AI 생성 콘텐츠, 이미지, 비디오, 3D 장면 등에의 응용이 늘어남.
- **기존 연구**
  - Discriminative 모델과 Generative 모델로 구분됨.
  - Discriminative 모델(예: Depth Anything)과 Generative 모델(예: Marigold)의 비교.
- **목표**
  - 복잡한 장면에서의 견고한 예측.
  - 투명 객체, 반사 표면 등을 포함한 세부 정보 고려.
  - 다양한 모델 스케일과 추론 효율성을 제공.
  - 다운스트림 작업으로의 일반화 가능성.

##### Revisiting the Labeled Data Design of Depth Anything V1
- **기존 연구 비판**
  - MiDaS, Depth Anything V1 등은 많은 라벨링된 이미지를 학습에 사용하지만, 이는 진정으로 유리한지 재검토 필요.
- **문제점**
  - 실제 라벨링된 이미지의 잠재적 문제와 노이즈.
  
##### Challenges in Using Synthetic Data
- **질문과 답변**
  - Q1: Coarse depth가 실제로 필요한가? 
    - A1: 그렇지 않다. 효율적인 Discriminative 모델들도 세부 정보를 생성할 수 있다.
  - Q2: 그렇다면 왜 기존 연구들은 여전히 실제 이미지를 사용하는가?
    - A2: Synthetic 이미지들이 가지고 있는 한계 때문.
  - Q3: Synthetic 이미지를 어떻게 활용하면 좋은가?
    - A3: 가장 강력한 모델을 사용하여 대규모 Pseudo-labeled 이미지를 생성하고, 이를 통해 학습.

##### Key Role of Large-Scale Unlabeled Real Images
- **중요성**
  - Synthetic 이미지의 한계 극복을 위해 대규모 Unlabeled 실제 이미지를 활용.
  - Domain gap을 줄이고 다양한 장면을 커버.
  - 작은 모델들이 가장 강력한 모델의 고품질 예측을 모방할 수 있도록 도움.

##### Depth Anything V2: Overall Framework
- **구성**
  - 고품질 Synthetic 이미지로 신뢰할 수 있는 Teacher 모델 학습.
  - 대규모 Unlabeled 실제 이미지에 Pseudo depth 라벨 생성.
  - 학생 모델을 Pseudo-labeled 실제 이미지로 최종 학습.

##### Depth Anything V2: Details
- **세부사항**
  - 5개의 정밀한 Synthetic 데이터셋과 8개의 대규모 Pseudo-labeled 실제 데이터셋 사용.
  - 두 가지 손실 항을 사용하여 Optimization 진행.
  - 노이즈가 있는 Pseudo 라벨을 무시하는 전략 활용.

##### Conclusion
- **결론**
  - Depth Anything V2는 더 강력한 단일 뷰 깊이 추정 모델을 제공.
  - 다양한 크기의 모델을 지원하고, 다운스트림 작업으로 쉽게 전이 가능.
  - 다양한 고해상도 이미지로 구성된 평가 기준(DR-2K)을 구축.

### 2. 전체 요약

논문 "Depth Anything V2"는 단일 뷰 깊이 추정을 위해 더 강력한 기초 모델을 제안합니다. 이 모델은 복잡한 장면에서 견고하고 세밀한 깊이 예측을 제공하며, 다양한 크기의 모델을 지원합니다. 또한, 광범위한 응용을 위해 쉽게 조정할 수 있습니다. 기존 평가 기준의 한계를 극복하기 위해, 다각적인 고해상도 이미지를 포함한 새로운 평가 기준 DA-2K를 도입하였습니다. 이 모델은 고품질의 Synthetic 데이터와 대규모 Unlabeled 실제 데이터의 Pseudo 라벨을 이용하여 학습됩니다.

## Similar Papers
- [Learning Temporally Consistent Video Depth from Video Diffusion Priors](2406.01493.md)
- [Magic-Boost: Boost 3D Generation with Mutli-View Conditioned Diffusion](2404.06429.md)
- [SF-V: Single Forward Video Generation Model](2406.04324.md)
- [Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond](2405.03520.md)
- [CLAY: A Controllable Large-scale Generative Model for Creating High-quality 3D Assets](2406.13897.md)
- [Zero-shot Image Editing with Reference Imitation](2406.07547.md)
- [UniFL: Improve Stable Diffusion via Unified Feedback Learning](2404.05595.md)
- [4K4DGen: Panoramic 4D Generation at 4K Resolution](2406.13527.md)
- [Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation](2406.12849.md)
