# SoundCTM: Uniting Score-based and Consistency Models for Text-to-Sound Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.18503.pdf](https://arxiv.org/pdf/2405.18503.pdf)

### 1. 소개
**Sound Consistency Trajectory Models (SoundCTM)**은 고품질 1단계 및 다단계 생성 간 유연한 전환을 제공하여 텍스트에서 소리로 변환하는 모델입니다. 기존 CTM(Consistency Trajectory Models)의 제한점을 극복하기 위해 새로운 도메인 무관 피처 거리를 사용하고, 분류기 없는 유도 조건을 적용하여 소리 생성의 속도와 품질을 개선했습니다.

### 2. 사전 지식
**확산 모델 (Diffusion Models)**은 데이터 분포를 나타내는 확률 흐름 방정식을 사용하여 소리 생성을 수행합니다. 여기서 데이터 변수는 확률적 과정에 의해 역방향으로 생성됩니다.

### 3. CTM의 제한점
CTM은 고품질 생성 성능을 위해 추가적인 사전 학습된 피처 추출기와 적대적 손실에 의존하지만, 이는 훈련 비용이 높고 다른 도메인에서는 사용하기 어렵습니다. 또한 메모리 소비가 높습니다.

### 4. SoundCTM
SoundCTM은 CTM의 훈련 프레임워크를 재구성하여 훈련 비용을 줄이고 유연한 샘플링 기능을 제공합니다. 
- **교사 네트워크를 피처 추출기로 사용**: CTM 손실을 줄이기 위해 교사 네트워크를 사용하여 피처 거리를 측정합니다. 이를 통해 메모리 소비를 줄이고 성능을 개선합니다.
- **분류기 없는 유도 조건 처리**: 학생 모델 훈련 시 분류기 없는 유도 경로를 증류하여 성능을 최적화합니다.

### 5. 훈련 없는 제어 가능 생성
SoundCTM은 추가적인 훈련 없이도 제어 가능한 소리 생성을 제공합니다. 이는 최근 성공을 거둔 DITTO와 유사하게 초기 노이즈 최적화를 통해 이루어집니다.

### 6. 실험
실험 결과, SoundCTM은 1단계 생성에서 SOTA (State-Of-The-Art) 성능을 보여주며, 다단계 샘플링에서도 다른 T2S 모델을 능가합니다. 또한, 실시간 생성이 가능하며 도메인에 구애받지 않는 새로운 프레임워크를 제공합니다.

### 7. 결론
SoundCTM은 빠르고 유연하며 고품질의 소리 생성을 가능하게 하여 소리 제작 워크플로우의 효율성을 크게 향상시킬 수 있습니다. 이는 라이브 공연, 전시회 및 비디오 게임에서 실시간 동적 소리 생성의 길을 열어줍니다.

## 전체 요약
이 논문은 **Sound Consistency Trajectory Models (SoundCTM)**을 제안하여 텍스트에서 소리로 변환하는 모델의 성능을 크게 향상시켰습니다. 기존의 CTM의 한계를 극복하고자 교사 네트워크를 사용한 피처 거리 측정, 분류기 없는 유도 조건 처리 등을 도입하여 메모리 소비를 줄이고 훈련 비용을 낮췄습니다. 실험 결과, SoundCTM은 1단계 및 다단계 생성 모두에서 높은 성능을 보여주었으며, 추가적인 훈련 없이도 제어 가능한 소리 생성을 제공했습니다. 이를 통해 소리 제작 워크플로우의 효율성을 크게 향상시키고, 실시간 동적 소리 생성의 가능성을 열어주었습니다.

## Similar Papers
- [Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation](2405.14598.md)
- [DITTO-2: Distilled Diffusion Inference-Time T-Optimization for Music Generation](2405.20289.md)
- [MotionClone: Training-Free Motion Cloning for Controllable Video Generation](2406.05338.md)
- [Autoregressive Speech Synthesis without Vector Quantization](2407.08551.md)
- [FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized Sounds](2407.01494.md)
- [LiveSpeech: Low-Latency Zero-shot Text-to-Speech via Autoregressive Modeling of Audio Discrete Codes](2406.02897.md)
- [Invertible Consistency Distillation for Text-Guided Image Editing in Around 7 Steps](2406.14539.md)
- [Naturalistic Music Decoding from EEG Data via Latent Diffusion Models](2405.09062.md)
- [MusiConGen: Rhythm and Chord Control for Transformer-Based Text-to-Music Generation](2407.15060.md)
