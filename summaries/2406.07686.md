# AV-DiT: Efficient Audio-Visual Diffusion Transformer for Joint Audio and Video Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.07686.pdf](https://arxiv.org/pdf/2406.07686.pdf)

### 1. 섹션별 요약

#### Introduction
이 논문은 AV-DiT(오디오-비주얼 확산 변환기)라는 새로운 멀티모달 생성 모델을 제안합니다. 이 모델은 기존에 이미지 생성에 사용되던 DiT(backbone)을 오디오와 비디오 생성으로 확장하기 위해 설계되었습니다. 독특한 점은 이미지 데이터로만 사전 학습된 DiT를 얼려둔 채로, 새로운 어댑터 계층만을 학습한다는 것입니다. 이 방법을 통해 학습 파라미터 수를 크게 줄이면서도 성능을 극대화할 수 있습니다.

#### Related Work
이 논문은 기존의 디퓨전 모델 및 멀티모달 생성 모델들에 대해 논의합니다. 기존의 디퓨전 모델은 주로 단일 모달리티(이미지, 비디오, 오디오)의 생성에 초점을 맞추고 있습니다. 멀티모달 생성에 대해 최근 연구들은 주로 서로 다른 모달리티의 일관성을 유지하는 방법을 탐구하고 있습니다. AV-DiT는 이미 학습된 DiT를 사용하여 오디오와 비디오를 동시에 생성하는 첫 시도입니다.

#### Method
AV-DiT는 이미지 전용 사전 학습된 DiT 백본을 활용하여 오디오와 비디오를 생성합니다. 이 모델은 비디오 생성을 위해 시간적 일관성을 도입하고, 오디오 생성을 위해 도메인 차이를 완화하며, 오디오와 비디오의 상호작용을 통해 멀티모달 정렬을 수행합니다. 이러한 과정은 시간 어댑터와 LoRA(저랭크 어댑터) 계층을 사용하여 이루어집니다. 

#### Experimental Setup
AV-DiT 모델의 성능을 검증하기 위해 AIST++와 Landscape 데이터셋을 사용하였습니다. 실험 설정에는 학습률, 옵티마이저, 배치 크기 등이 포함됩니다.

#### Comparison with SOTA Methods
AV-DiT는 AIST++와 Landscape 데이터셋에서 기존의 최신 기술들을 상회하는 성능을 보였습니다. 특히, 적은 수의 학습 가능한 파라미터를 사용하면서도 더 나은 오디오 및 비디오 품질을 제공합니다.

#### Ablation Study
다양한 어댑터 계층과 자기 주의, 교차 주의 계층의 영향을 테스트하였습니다. 실험 결과, 특정 어댑터 계층을 제거하면 성능이 크게 저하됨을 확인할 수 있었습니다. AV-DiT는 자체 주의 메커니즘을 사용하는 것이 더 효율적임이 나타났습니다.

#### Conclusion
AV-DiT는 오디오와 비디오를 동시에 생성하는 첫 멀티모달 디퓨전 변환기 구조입니다. 이 모델은 이미지 데이터로만 사전 학습된 DiT 백본과 최소한의 추가 학습 계층을 사용하여 효율적으로 높은 품질의 오디오와 비디오를 생성할 수 있습니다. 향후 연구 방향으로는 클래스 조건부 및 텍스트 조건부 오디오와 비디오 생성에 대한 추가 연구가 필요합니다.

### 2. 전체 요약

이 논문에서는 첫 번째 멀티모달 디퓨전 변환기 구조인 AV-DiT를 제안합니다. 이 모델은 이미지 데이터로 사전 학습된 DiT 백본을 얼려둔 채, 오디오와 비디오를 동시에 생성하는 방법을 연구합니다. 핵심 기여는 다음과 같습니다: 

1. 사전 학습된 DiT를 사용하여 적은 수의 학습 가능한 파라미터로 높은 품질의 오디오와 비디오를 생성합니다.
2. 시간적 일관성과 도메인 차이 완화, 오디오-비디오 상호작용을 위한 데이터 적응 계층을 도입하여 멀티모달 생성을 효율적으로 수행합니다.
3. AIST++와 Landscape 데이터셋에서 실험한 결과, 기존의 최신 기술들을 상회하는 성능을 보였습니다.

이 모델은 교육, 엔터테인먼트, 접근성 향상 등 다양한 분야에서 사용될 수 있지만, 합성 미디어의 잠재적인 악용 가능성 또한 존재합니다. 