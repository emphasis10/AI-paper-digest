# Step Back to Leap Forward: Self-Backtracking for Boosting Reasoning of Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.04404.pdf](https://arxiv.org/pdf/2502.04404.pdf)

### 1. 각 섹션의 중요한 내용 요약

#### 1.1 서론
이 논문은 대형 언어 모델(LLM)의 사고 방식을 개선하기 위한 새로운 방법인 **Self-Backtracking** 기법을 제안합니다. 이 방법은 LLM이 과거의 잘못된 예측을 학습하고, 초기 예측 경로가 비효율적일 때 되돌아가서 대안을 탐색할 수 있게 합니다. 이를 통해 LLM의 복잡한 추론 작업에서 성능을 향상시킬 수 있습니다.

#### 1.2 관련 작업
기존의 연구들은 주로 LLM이 이전 실수를 학습하고 이를 수정하는 능력에 집중했습니다. 많은 연구들이 외부 검증자를 통해 LLM의 추론 경로를 평가하고, 이를 이용해 강화 학습을 통해 모델을 개선하려고 했습니다. 그러나 자기 돌아보기(Self-Backtracking) 기법은 내부적으로 학습하며, 비교적 간단한 방법으로도 자기 개선 능력을 가지게 합니다.

#### 1.3 방법론
**Self-Backtracking** 방법론은 LLM이 언제, 어디서 돌아가야 하는지를 학습하게 합니다. 학습 기간 동안 초기 예측이 비효율적일 때 알 수 있도록 훈련되고, 테스트 동안에는 이전 상태로 돌아가 다양한 경로를 탐색합니다.

#### 1.4 실험 결과
Countdown 작업에서 실험한 결과, Self-Backtracking 기법이 기존 방법에 비해 추론 성능을 40% 이상 향상시켰습니다. 이 성능 개선은 전체적인 추론 효율성에도 기여하였습니다.

#### 1.5 결론
이 연구는 LLM이 추론 문제를 해결하는 데 있어 자기 돌아보기 기법을 내부화함으로써, 비효율적인 과도한 사고를 줄이고, 전반적인 성능을 향상시킨다는 것을 보여줍니다. 본 연구의 접근 방식은 수학적 문제 해결 등 다양한 AI 응용 분야에서 효과를 발휘할 가능성이 높습니다.

### 2. 종합 요약
이 논문은 LLM의 추론 능력을 향상시키기 위한 Self-Backtracking 기법을 제안하고, 이 기법이 기존 방법에 비해 성능을 크게 개선함을 실험적으로 입증했습니다. LLM이 자기 학습을 통해 과거의 잘못을 수정하고 더 나은 추론 경로를 탐색하는 방법을 제시함으로써, AI의 사고 능력을 한 단계 끌어올릴 기회를 제공합니다. 이를 통해 AI의 다양한 분야에서의 활용 가능성을 더욱 넓힐 수 있을 것으로 기대됩니다.