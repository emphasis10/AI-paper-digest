# Retrieval-Augmented Decision Transformer: External Memory for In-context RL
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.07071.pdf](https://arxiv.org/pdf/2410.07071.pdf)

1. 각 섹션 요약 및 주요 기여와 혁신 부분:
   - **서론 (Introduction)**
     이 연구는 '맥락 내 학습(In-Context Learning, ICL)'의 개념에 대해 소개합니다. 이는 모델이 극소수의 예시로 새로운 작업을 학습할 수 있는 능력입니다. 특히 강화 학습(RL) 분야에서는 이전 맥락을 관찰하여 새로운 작업을 배울 수 있는 에이전트를 만드는 것이 목표입니다. 기존 방법은 전체 에피소드를 맥락에 포함시킵니다. 그러나 이 방법은 긴 에피소드가 있는 복잡한 환경에서 어려움을 겪습니다.

   - **RA-DT (Retrieval-Augmented Decision Transformer) 소개**
     RA-DT는 외부 메모리를 사용하여 과거의 경험을 저장한 후, 현재 상황에 맞는 하위 궤적만 추출할 수 있도록 설계되었습니다. 이는 복잡한 환경의 긴 에피소드를 다루는 데 유리합니다. RA-DT는 그리드 월드(grid-world) 및 로보틱스 시뮬레이션에서 기존 방법보다 더 나은 성능을 보였으며, 맥락 길이의 일부만 사용합니다.

   - **조건부 전략 (Conditioning Strategies)**
     RL의 조건부 전략 적용은 ICL 능력을 향상시키기 위해 필수적입니다. 다양한 조건부 전략에 대한 체계적인 연구가 미래에 필요합니다.

   - **결론 (Conclusion)**
     RA-DT는 ICL의 한계를 극복하고 복잡한 환경에서의 평균 성능을 높이는 데 기여합니다. 공개한 데이터셋은 새로운 연구를 촉진하기 위해 도입되었습니다.

2. 전반적 요약:
   이 논문은 강화 학습에서 맥락 내 학습(ICL)을 향상시키기 위한 새로운 방법인 RA-DT(Retrieval-Augmented Decision Transformer)를 제안합니다. RA-DT는 외부 메모리를 사용하여 효율적으로 과거의 경험을 저장하고, 현재 상황에 관련된 정보만을 검색합니다. 이는 그리드 월드 및 복잡한 로보틱스 환경에서 기존 방법보다 뛰어난 성과를 보였습니다. 이 연구는 ICL의 한계를 다루고, 앞으로의 연구 방향을 제시하며, 이를 뒷받침하는 데이터를 공개하여 후속 연구를 촉진하고자 합니다.