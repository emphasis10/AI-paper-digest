# Chain-of-Tools: Utilizing Massive Unseen Tools in the CoT Reasoning of Frozen Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2503.16779.pdf](https://arxiv.org/pdf/2503.16779.pdf)

### 1. 각 섹션 요약 및 주요 공헌:
- **소개 (Introduction):**
  이 연구는 Chain-of-Tools (CoTools)라는 새로운 도구 학습 방법을 소개합니다. 이는 미리 훈련된 대형 언어 모델(LLM)의 강력한 의미적 표현 능력을 활용하여 도구 호출을 통해 대규모의 유연한 도구 풀을 사용하는 방법을 제안합니다. 이 방식은 특히 보지 못한 새로운 도구들을 효과적으로 사용할 수 있도록 설계되었습니다.

- **관련 작업 (Related Work):**
  도구 학습(툴 러닝)은 LLM의 응용 범위를 확장하기 위한 연구 분야입니다. 기존 연구들은 도구 호출 데이터를 생성하거나, 특정 필드에서의 사용을 검증하는 다양한 방법을 포함합니다.

- **기술 방법 (Methodology):**
  CoTools는 숨겨진 상태를 사용하여 매번 새로운 토큰 생성 시 필요한 도구를 판단하고 선택합니다. 이 방법은 도구 설명으로부터 도구 벡터를 계산하여 유연성을 높였습니다. 또한, LLM은 학습되지 않으므로 CoTools의 추론 능력은 손상되지 않습니다.

- **데이터셋 및 실험 (Datasets and Experiments):**
  SimpleToolQuestions라는 새로운 데이터셋을 제작하여 대규모의 보지 못한 도구 시나리오에서 성능을 평가했습니다. GSM8K-XL, FuncQA, KAMEL, STQuestions과 같은 다양한 벤치마크에서 실험하였으며 CoTools의 성능이 우수함을 확인하였습니다.

- **결과 및 토의 (Results and Discussion):**
  CoTools는 수치 기반 추론과 지식 기반 질문 응답에서 기존 방법보다 뛰어난 성능을 보입니다. 또한, 모델 해석성을 높이기 위해 숨겨진 상태의 중요한 차원을 발견했습니다.

- **결론 및 제한점 (Conclusion and Limitations):**
  CoTools는 LLM의 기본 능력을 유지하면서 도구를 활용하여 답변을 생성하는 과정을 포함한 새로운 방법입니다. 그러나 실시간 활용 및 대규모 도구 세트에 대한 실험은 아직 제한이 많습니다.

### 2. 전체 요약:
이 연구는 CoTools라는 새로운 도구 학습 방법을 도입하여 대형 언어 모델(LLM)의 활용도를 높이고, 학습하지 않은 대규모 도구를 효과적으로 사용할 수 있는 가능성을 시연합니다. SimpleToolQuestions와 같은 데이터셋을 통해 CoTools의 성능을 입증했으며, 기존 벤치마크들에서 뛰어난 성과를 보였습니다. 이 방식은 보지 못한 도구를 유연하게 활용할 수 있으며, 숨겨진 상태의 중요한 차원을 통해 모델 해석성을 개선합니다. 하지만 대규모 실시간 도구 세트에 대한 연구는 아직 초기 단계에 있습니다.