# Towards Self-Improvement of LLMs via MCTS: Leveraging Stepwise Knowledge with Curriculum Preference Learning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.06508.pdf](https://arxiv.org/pdf/2410.06508.pdf)

1. 각 섹션 요약 및 논문의 주요 기여 및 혁신 부분 설명:

- **소개 (Introduction):**
    - 최근 연구에 따르면 대규모 언어 모델(LLM)은 자연 언어 처리 작업에서 뛰어난 능력을 보입니다. 그러나 수학 문제 해결과 같은 복잡한 추론과 계획이 필요한 작업에서는 한계가 있습니다.
  
- **알파LLM-CPL (AlphaLLM-CPL):**
    - 제안된 방법론은 MCTS(몬테카를로 트리 탐색)로부터 행동 증류를 통해 LLM이 스스로 개선할 수 있도록 설계된 새로운 쌍 기반 학습 프레임워크입니다. 이 접근법은 두 가지 주요 구성 요소로 이루어져 있습니다: 경로 쌍 추출과 커리큘럼 선호 학습. 실험 결과, 이러한 방법들이 LLM의 추론 능력을 크게 향상시킨 것으로 드러났습니다.

- **실험 (Experiments):**
    - 제안된 방법이 어떻게 수학적 추론 작업에서 이전의 MCTS 행동 증류 방법보다 뛰어난 성과를 보이는지를 보여줍니다. 특히, LLaMA-2와 같은 모델에서의 성능 향상이 두드러졌습니다.

- **결론 (Conclusion):**
    - ALPHALLM-CPL의 주요 혁신은 중간 노드에서 경로 쌍을 구성하고, 이들을 활용하여 추론 능력을 강화하는 것입니다. 이와 같은 접근법은 기존의 MCTS 기반 학습 방법보다 명확한 이점을 제공합니다.

2. 전체 요약:

- 이 논문은 AI 및 머신러닝의 발전을 위한 새로운 방법론인 ALPHALLM-CPL을 제안하고 있습니다. MCTS 기반의 행동 증류를 통해, LLM이 스스로의 추론 능력을 개선할 수 있도록 돕는 쌍 기반 학습 프레임워크를 도입하였습니다. 경로 쌍 추출 및 커리큘럼 선호 학습을 통해 학습 과정에서 더 중요한 요소를 우선시하여 성능을 극대화합니다. 실험을 통해 이 방법론이 수학적 추론에서 기존 방법보다 우수한 성과를 보여주었으며, 이는 LLM이 복잡한 문제 해결에 보다 효과적으로 접근할 수 있음을 시사합니다. 이 연구는 AI가 스스로 학습 능력을 강화할 수 있는 새로운 방향성을 제시한다는 점에서 가치가 있습니다.