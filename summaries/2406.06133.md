# ExtraNeRF: Visibility-Aware View Extrapolation of Neural Radiance Fields with Diffusion Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.06133.pdf](https://arxiv.org/pdf/2406.06133.pdf)

#### 1. 서론 (Introduction)
이 논문은 Neural Radiance Field (NeRF) 기술의 한계를 넘어 더욱 확장된 뷰를 생성할 수 있는 ExtraNeRF라는 새로운 방법을 제안합니다. 기존 NeRF는 관찰되지 않은 영역에 대한 시각적 재구성을 효과적으로 처리하지 못하는 한계가 있습니다. 이 논문에서는 확산 모델을 이용해, 관찰되지 않은 영역을 재구성하고, 다양한 시점의 이미지를 통해 더욱 높은 품질의 뷰를 제공하고자 합니다.

#### 2. 관련 연구 (Related Work)
기존의 뷰 합성 기술들은 주로 이미지 기반 렌더링에 의존하였으며, 최신 기술들은 심층 신경망을 통해 이를 개선해 왔습니다. NeRF 기술은 그 단순성과 뛰어난 성능으로 주목받았지만, 관찰되지 않은 영역을 재구성하는 데 있어서는 여전히 한계가 있었습니다. 확산 모델은 이러한 문제를 해결하는 데 중요한 역할을 합니다.

#### 3. 기초 (Preliminaries)
NeRF는 3D 공간의 연속 함수를 신경망으로 매개변수화하여 장면을 표현합니다. 이를 통해 각 픽셀에 대해 광선 경로를 캐스트하고, 샘플링한 3D 점의 방사율과 밀도를 집계하여 이미지를 렌더링합니다. 확산 모델은 노이즈가 있는 입력 이미지를 기반으로 그 노이즈를 예측하고 제거하여 점차적인 이미지 복원을 수행합니다.

#### 4. 방법 (Method)
ExtraNeRF는 세 단계로 구성됩니다:
1. **BaseNeRF 훈련**: Sparse한 입력 이미지 세트를 사용하여 NeRF를 훈련합니다.
2. **확산 기반 Inpainting**: 관찰되지 않은 영역을 확산 모델을 이용해 복원하고, 이를 NeRF에 통합합니다.
3. **확산 기반 Enhancement**: Inpainting 결과를 더욱 선명하고, 색상 일관성을 개선하기 위해 최종 확산 모델로 처리합니다.

#### 5. 실험 (Experiments)
ExtraNeRF의 성능을 LLFF와 Tanks & Temples 데이터셋을 이용해 평가하였습니다. 실험 결과 ExtraNeRF는 기존의 방법들에 비해 더 높은 품질의 뷰 확장 결과를 나타냈습니다.

#### 6. 결론 (Conclusion)
ExtraNeRF는 확산 모델을 활용하여 NeRF의 기존 한계를 넘어선 고품질의 시각적 재구성을 가능하게 합니다. 이는 소수의 입력 이미지로부터 고해상도의 뷰 확장이 필요한 다양한 애플리케이션에 적용될 수 있습니다.

### 전체 요약

ExtraNeRF는 NeRF의 한계를 넘어, 소수의 입력 이미지로부터 고품질의 뷰 확장을 가능하게 하는 혁신적인 방법을 제안하고 있습니다. 이를 위해 확산 모델을 활용하여 관찰되지 않은 영역을 효과적으로 복원하고, NeRF와의 결합을 통해 장면을 더욱 선명하고 일관되게 재구성합니다. 실험 결과, ExtraNeRF는 기존의 방법들에 비해 우수한 성능을 보여주었으며, 이는 다양한 실제 애플리케이션에 기여할 수 있습니다.