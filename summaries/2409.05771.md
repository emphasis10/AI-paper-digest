# Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.05771.pdf](https://arxiv.org/pdf/2409.05771.pdf)

### 1. 각 섹션 요약

**1. Introduction**
소개: 
이 연구는 대형 언어 모델(LLM, Large Language Models)의 중간 은닉 상태(intermediate hidden states)가 자연언어 자극에 대한 인간 뇌의 반응을 예측할 수 있다는 증거를 제시합니다. 중간층이 최종 출력층보다 이 예측 작업에서 더 뛰어난 이유를 설명하며, LLM이 훈련 과정에서 어떻게 두 단계의 추상화를 수행하는지 보여줍니다. 이 연구의 결과는 LLM과 인간 뇌 간의 유사성이 추상적, 구성적(compositional) 특성에 기인한다는 것을 시사합니다.

**2. Methods**
방법론:
- **뇌-모델 유사성:** 사람의 뇌 활성화 데이터를 사용하여 LLM 표현(representation)과 뇌 활동 간의 선형(mapping) 예측 성능을 측정합니다.
- **표현의 차원성 측정:** ID와 d를 사용하여 LLM의 레이어별 복잡성을 측정합니다.
- **예측 오류 측정:** TunedLens 방법을 사용하여 각 레이어에서의 다음 토큰 예측 오류(서프라이즈)를 계산합니다.

**3. Brain-Model Similarity**
뇌-모델 유사성:
훈련된 LLM의 중간 레이어가 뇌 활동을 예측하는 데 가장 효과적인 이유를 탐구합니다. fMRI 데이터를 사용하여 LLM 레이어의 표현력(encoding performance)을 평가합니다. 중간층이 뇌 활동을 잘 예측하는 이유는 추상화 단계 때문임을 발견했습니다.

**4. Dimensionality of Neural Manifolds**
신경 매니폴드의 차원성:
LLM의 각 레이어별 표현의 본질적인 차원(intrinsic dimensionality, Id)을 측정합니다. 분석 결과, Id가 LLM 레이어의 표현력과 밀접한 연관이 있음을 발견했습니다. 훈련이 진행됨에 따라 LLM의 각 레이어에서 Id가 증가하며, 이는 레이어별로 서로 다른 기능을 수행함을 나타냅니다.

**5. Measuring Layerwise Surprisal**
레이어별 서프라이즈 측정:
TunedLens을 사용하여 각 레이어가 다음 토큰을 얼마나 잘 예측하는지 평가합니다. 예측 성능이 뛰어난 레이어에서는 서프라이즈가 낮게 나타나며, 이는 추상화 단계를 거친 후 예측 단계로서 전환이 이루어짐을 시사합니다.

**6. Results**
결과:
훈련된 LLM의 중간 레이어가 뇌 활동을 예측하는 데 가장 효율적이라는 기존 연구 결과를 재확인했습니다. 레이어 깊이에 따른 표현 차원성과 서프라이즈의 변화를 분석하여 추상화 단계와 예측 단계의 존재를 증명했습니다.

**7. Discussion**
논의:
LLM의 중간 레이어가 뇌 활동을 예측하는 데 가장 뛰어난 이유를 설명합니다. 추상화 및 예측 단계의 존재를 통해 뇌-모델 유사성이 단순한 예측 성능만으로 이루어지지 않음을 제시합니다. 더 많은 모델을 테스트하여 이러한 결론을 일반화할 필요가 있음을 언급합니다.

## 2. 종합 요약

이 논문은 대형 언어 모델(LLM)이 인간의 뇌 활동을 어떻게 예측하는지를 탐구합니다. 연구는 LLM이 두 단계의 추상화 과정(초기 추상화 및 후속 예측)을 통해 중간 레이어에서 가장 높은 뇌-모델 유사성을 나타낸다는 새로운 증거를 제공합니다. 중간 은닉 상태가 자연언어 자극에 대한 인간의 뇌 반응을 잘 예측하는 이유는 LLM이 학습 과정에서 추상화 단계를 압축하여 표현의 본질적인 차원성을 높이기 때문임을 발견했습니다. 이러한 발견은 LLM과 인간 뇌가 복잡한 언어를 처리하는 방법에 대한 새로운 이해를 제공합니다. 연구는 또한 더 많은 모델을 테스트하여 결론의 보편성을 높일 필요성을 지적합니다.