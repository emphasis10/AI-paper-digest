# ClinicalBench: Can LLMs Beat Traditional ML Models in Clinical Prediction?
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.06469.pdf](https://arxiv.org/pdf/2411.06469.pdf)

1. 논문의 각 섹션 요약:

- **소개 (Introduction):** 이 논문은 대형 언어 모델(LLM)이 임상 시스템에서 도큐멘트 분류, 보고 생성 및 정보 추출과 같은 다양한 의료 텍스트 처리 작업에 뛰어난 능력을 가지고 있음을 강조합니다. 그러나 실제 임상 예측 작업에서는 여전히 전통적인 머신러닝(ML) 모델이 주로 사용되고 있습니다.

- **ClinicalBench: LLM 및 전통 ML 모델 벤치마킹 (ClinicalBench):** LLM과 여러 전통적인 ML 모델의 성능을 비교하여 LLM을 실제 임상 예측에 채택할 수 있는지 탐구합니다. 이 연구는 Length-of-Stay Prediction, Mortality Prediction, Readmission Prediction이라는 세 가지 일반적인 임상 예측 작업을 다루고, MIMIC-III 및 MIMIC-IV라는 두 개의 데이터베이스를 사용합니다.

- **LLM의 직접적 프롬프트 방식 효과 (Direct Prompting):** 대형 언어 모델을 직접적으로 프롬프트하여 전통적인 머신러닝 모델을 능가할 수 있는지를 조사합니다. 결과적으로 전통적인 ML 모델들이 일반 LLM 및 의료 LLM을 임상 예측 성능에서 여전히 상회함을 보여줍니다.

- **프롬프트 엔지니어링 (Prompt Engineering):** 다양한 프롬프트 기법이 LLM의 성능에 미치는 영향을 연구합니다. 그러나 전반적으로 프롬프트 엔지니어링은 성능을 향상시키는 데 제한적인 영향을 미치며, 전통적인 ML 모델을 능가하지 못합니다.

- **LLM의 파인 튜닝 (Fine-tuning):** LLM을 특정 임상 예측 작업에 맞추기 위해 파인 튜닝하는 것이 성능을 향상시킬 수 있는지를 살펴봅니다. 특히 Length-of-Stay Prediction과 Mortality Prediction에서는 일부 성능 향상이 있었으나, 전통적인 ML 모델을 능가하지 못했습니다.

- **결론 (Conclusion):** LLM는 다양한 파라미터 스케일, 다양한 프롬프트 또는 파인 튜닝 전략에도 불구하고 임상 예측에서 전통적인 머신러닝 모델을 능가하지 못하며, 복잡한 시나리오에서 실제 임상 추론과 의사결정에서의 잠재적 한계를 드러냈습니다.

2. 전체 요약:

이 논문은 LLM이 전통적인 ML 모델과 비교하여 임상 예측 작업에서 제안할 만한 가치가 있는지를 평가하기 위해 ClinicalBench라는 새로운 벤치마크를 구축했습니다. LLM은 의료 텍스트 처리와 관련된 작업에서 뛰어난 성능을 보이지만, 실제 임상 예측에서는 여전히 전통적인 ML 모델이 더욱 향상된 성능을 제공합니다. 특히 다양한 프롬프트 엔지니어링 및 파인 튜닝 전략이 적용된 경우에도 LLM은 전통적인 ML 모델에 비해 성능이 뒤떨어졌습니다. 따라서, LLM의 실제 임상 적용에 신중함을 기할 필요가 있음을 강조합니다.