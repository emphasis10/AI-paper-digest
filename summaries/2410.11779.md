# MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.11779.pdf](https://arxiv.org/pdf/2410.11779.pdf)

### 1. 각 섹션 요약

#### 서론
서론에서는 최근 다중모달 대형 언어 모델(Multimodal Large Language Models, MLLMs)이 급속도로 발전하면서 인공지능 일반(AI) 달성을 위한 잠재적 경로를 제시하고 있지만, 실제 사용에서는 허상 문제로 인해 개발이 저해되고 있다는 점을 지적합니다. MLLMs는 존재하지 않는 객체에 대한 진술을 생성하거나 특정 가시적 객체를 언급하지 않음으로써 오류를 발생시킬 수 있으며, 이는 의료 영상 분석, 자율주행, 인간-컴퓨터 상호작용 시스템 등 고위험 분야에서 심각한 위험을 초래할 수 있습니다.

#### MLLMs의 허상 문제와 DeCo 소개
MLLMs는 최종 출력에서 객체를 잘못 생성하지만, 실제로는 이전 레이어에서 시각적 객체를 인식할 수 있습니다. 이러한 문제를 해결하기 위해 동적 교정 디코딩(DeCo) 방법을 제안하여 MLLMs의 허상 문제를 완화합니다. 이 모델은 사전 지식을 통합하여 마지막 레이어의 출력을 조정하여 허상을 줄이고 실험적 결과는 다양한 벤치마크에서 큰 자료로 허상을 감소시키는 것을 보여줍니다.

#### DeCo의 주요 기여 및 혁신
DeCo의 주요 기여는 MLLMs 내에서 허상의 내부 메커니즘을 탐색하는 것입니다. 선행 레이어는 실제 객체 토큰에 대해 더 높은 신뢰도를 보여주며, 이를 통해 최종 출력의 로짓을 교정합니다. DeCo는 교육이 필요 없는 방법으로서, 다양한 디코딩 전략과 결합할 수 있습니다.

#### 실험 및 결과
DeCo는 실험에서 이미지 캡셔닝 데이터 셋에서 평균 10.8%의 허상 억제율을 달성하며, POPE 및 MME 등 여러 시각적 질문 응답 데이터 세트에서 비교일체를 능가합니다. 장점으로는 기본 디코딩 프로세스 대비 약 1.2배의 지연 증가 정도이며, 이는 이전 baseline보다 훨씬 빠릅니다.

#### 결론 및 중요성
이 논문에서는 MLLMs의 허상 생성 원인을 분석하고, 이를 완화하기 위한 동적 교정 디코딩 접근법을 제안합니다. 이는 시각적 정보가 있는 실제 객체를 보다 정확하게 인식하고 허상 생성을 줄이며, 다양한 분야에서 MLLMs의 신뢰도와 활용성을 향상할 수 있는 잠재력을 가지고 있음을 보여줍니다.

### 2. 전체적인 요약
이 논문은 다중모달 대형 언어 모델(MLLMs)의 허상 문제를 해결하는 데 중점을 둡니다. 저자는 이 모델들이 실제 객체를 초기에 인식할 수 있으나, 최종 출력에서는 오류가 발생한다는 점을 발견했습니다. 이를 개선하기 위해 동적 교정 디코딩 방법(DeCo)을 소개하여 허상을 줄이고 정확성을 높이는 방안을 제안합니다. 실험을 통해 다양한 벤치마크에서 DeCo의 효과를 입증했으며, 이는 다양한 고위험 분야에서 AI의 신뢰성을 높이는 데 기여할 수 있습니다. 이 논문은 MLLMs의 허상 문제에 대한 중요한 통찰을 제공하며, 향후 연구 및 실무에서의 AI 활용에 있어 중요한 기초 자료가 될 것입니다.