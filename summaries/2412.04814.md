# LiFT: Leveraging Human Feedback for Text-to-Video Model Alignment
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.04814.pdf](https://arxiv.org/pdf/2412.04814.pdf)

### 1. 섹션별 요약

#### 1. 개요 (Introduction)
이 논문은 텍스트 기반 비디오 생성(T2V) 모델의 정확성을 높이기 위해 인적 피드백을 활용하는 LIFT라는 새로운 미세조정 방법을 제안합니다. 이 방법을 통해 인간의 기대치에 더 잘 맞는 비디오를 생성할 수 있게 됩니다.

#### 2. 관련 연구 (Related Work)
현재 T2V 모델의 한계점을 보완하기 위해 다양한 접근법이 연구되었습니다. 그러나 대부분의 연구는 인간의 주관적인 피드백을 충분히 활용하지 못했습니다. 이 논문은 이에 대해 새로운 접근 방식을 제시합니다.

#### 3. 방법론 (Methodology)
LIFT 방법론은 세 단계로 구성됩니다: 인간 피드백 수집, 보상 함수 학습, 그리고 T2V 모델의 조정입니다. 특히, 인간의 피드백을 세 가지 주요 차원(의미 일관성, 움직임 부드러움, 비디오 충실도)으로 카테고리화하여 데이터세트를 구축하고 이를 통해 보상 모델을 학습하게 됩니다.

#### 4. 실험 결과 (Experimental Results)
LIFT를 통해 조정한 모델은 기존에 비해 모든 평가 기준에서 성능이 향상되었습니다. 특히, 인간의 피드백을 학습에 활용함으로써 비디오 생성의 일관성과 부드러움이 크게 개선되었습니다.

#### 5. 결론 (Conclusion)
LIFT는 인간의 피드백을 효과적으로 활용하여 T2V 모델을 미세 조정하는 파이프라인을 제공하며, 이를 통해 모델의 정열도와 품질을 높이는 데 기여할 수 있음을 보여줍니다.

### 2. 전체 요약
이 논문은 텍스트 기반 비디오 생성 모델의 성능을 개선하기 위해 인간 피드백을 활용하는 새로운 방법론인 LIFT를 제시합니다. 주요 기여는 피드백 기반 보상 모델을 통해 비디오 생성의 정밀성을 높였다는 점입니다. 특히 LIFT는 의미 일관성, 움직임 부드러움, 비디오 충실도라는 세 가지 핵심 요소를 중심으로 인간 피드백을 수집하고 이를 학습 모델에 반영함으로써, 전체적인 비디오 품질을 향상시키는 데 성공했습니다.