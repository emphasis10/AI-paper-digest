# Multimodal Large Language Models with Fusion Low Rank Adaptation for Device Directed Speech Detection
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.09617.pdf](https://arxiv.org/pdf/2406.09617.pdf)

### 1. 각 섹션의 요약

#### 서론 (Introduction)
이 논문은 음성 어시스턴트(Voice Assistant)의 성능 향상을 위해, 텍스트 데이터에만 사전 학습된 LLM(대규모 언어 모델)에 오디오 및 비디오 데이터를 융합하는 방법을 다룹니다. 'Fusion Low Rank Adaptation(FLoRA)' 기법을 제안하여 텍스트 기반 LLM을 멀티모달 LLM으로 변환하며, 이를 통해 실제 환경에서 발생하는 잡음과 모호한 경계 문제를 해결하고자 합니다.

#### FLoRA 접근법 (Approach)
'Low Rank Adaptation' (LoRA) 기법을 확장하여 멀티모달 데이터를 수용할 수 있도록 했습니다. 오디오 및 비디오 데이터를 텍스트 임베딩 차원으로 매핑하는 작은 프리픽스 네트워크를 통해, 텍스트 기반 LLM에 새로운 모달리티를 추가합니다. 이를 통해 전체 모델 파라미터의 부분적인 튜닝만으로도 성능 향상을 이끌어낼 수 있습니다.

#### 모달리티별 어댑터 (Modality-specific Adapters)
FLoRA는 각 모달리티(오디오, 비디오, 텍스트)에 대해 별도의 어댑터를 훈련시킬 수 있는 유연성을 제공합니다. 이는 각 모달리티에 대해 독립적으로 학습될 수 있으며, 데이터가 없는 상황에서도 효과적으로 작동할 수 있는 환경을 만듭니다.

#### 어댑터 드롭아웃 (Adapter Dropout)
모달리티가 일부 누락된 데이터셋에서도 효과적으로 작동할 수 있도록 설계된 기법입니다. 데이터를 모두 포함하지 않는 상황에서도 그에 맞는 어댑터만 사용하여 모델을 훈련시키며, 테스트 시에도 동일한 방식으로 적용됩니다.

#### 실험 설정 (Experimental Setup)
DDSD(기기 지향 음성 탐지) 과제를 적용 대상으로 하여 훈련 및 테스트를 진행하였습니다. B2B-1, B2B-2, B2B-3과 같은 다양한 데이터셋을 사용하여, 각각의 데이터 특성에 맞춰 실험을 설계했습니다. 주요 평가 지표로는 EER(Equal Error Rate)와 FA@10(False Accept Rate at 10% False Reject Rate)을 사용했습니다.

#### 결과 및 논의 (Results and Discussion)
FLoRA는 전체 모델 파라미터의 1-5%만 튜닝하여도, 전체 파라미터를 튜닝한 것과 비슷한 성능을 보였습니다. 특히, 데이터가 일부 누락된 상황에서도 강한 성능을 보였으며 모델의 확장성 역시 유망함을 확인했습니다. B2B-3 데이터를 통해 모델 크기 증가에 따른 성능 변화를 실험한 결과, 모델 크기가 커질수록 성능이 향상됨을 보였습니다.

#### 결론 (Conclusion)
FLoRA는 텍스트 만을 학습한 LLM을 멀티모달 입력을 수용할 수 있도록 변환하는 효과적인 방법을 제시합니다. 적은 양의 파라미터만 업데이트하여도 높은 성능을 유지하며, 데이터가 누락된 상황에서도 강한 성능을 보입니다. 다양한 모델 크기에서 높은 확장성을 보이며, 실용적인 응용 가능성을 확인했습니다.

---

### 2. 전반적인 요약
이 논문은 멀티모달 LLM을 구현하기 위한 새로운 기법인 FLoRA를 제안합니다. FLoRA는 특정 모달리티에 특화된 작은 어댑터를 훈련시켜, 텍스트 기반 LLM을 멀티모달 학습에 적합하게 변환합니다. 이 기법은 전체 모델의 1-5%의 파라미터만 튜닝하여도 높은 성능을 유지할 수 있으며, 특히 데이터가 일부 누락된 상황에서도 효과적으로 작동합니다. 다양한 데이터셋과 모델 크기에 대한 실험을 통해, 이 접근 방식이 실용적이고 확장 가능한 솔루션임을 입증했습니다. 이를 통해 실제 환경에서의 음성 어시스턴트 성능을 크게 향상시킬 수 있는 가능성을 확인하였습니다.