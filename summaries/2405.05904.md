# Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.05904.pdf](https://arxiv.org/pdf/2405.05904.pdf)

### 1. 논문 각 섹션의 요약

#### 초록
이 연구는 대형 언어 모델(LLM)이 미세 조정(Fine-Tuning)을 통해 새로운 사실을 학습할 때, 기존에 습득한 지식과 신규 지식 간의 상호 작용을 분석합니다. 연구 결과, 모델은 새로운 사실을 습득하는 데 어려움을 겪으며, 이는 결국 헛소리(비사실적 응답)를 생성하는 경향을 증가시킵니다. 

#### 1. 서론
대형 언어 모델은 방대한 텍스트 코퍼스를 사전 학습함으로써 많은 사실 지식을 내재화합니다. 이 모델들을 사용자 친화적으로 만들기 위해 미세 조정이 필요합니다. 그러나 미세 조정 시 새로운 지식이 추가되면 모델이 헛소리할 가능성이 높아지며, 이는 모델의 성능에 나쁜 영향을 미칠 수 있습니다.

#### 2. 연구 방법
이 연구는 ENTITYQUESTIONS 데이터셋을 사용하여 다양한 비율의 새로운 지식 예제를 포함하는 미세 조정 데이터셋을 설계했습니다. 이를 통해 새로운 지식이 모델 성능에 미치는 영향을 분석했습니다.

#### 3. LLM의 지식 정량화
모델이 새로운 지식을 얼마나 잘 습득하는지 평가하기 위해 SliCK라는 측정 방법을 사용했습니다. 이를 통해 모델의 지식 상태를 네 가지 카테고리(매우 잘 앎, 어느 정도 앎, 거의 모름, 전혀 모름)로 분류했습니다.

#### 4. 연구 결과
모델은 새로운 지식을 습득하는 데 어려움을 겪으며, 이는 미세 조정의 초기 단계에서 더욱 두드러집니다. 또한 새로운 지식을 포함한 예제는 모델의 성능을 저하시킵니다. 제어 설정을 통해 새로운 지식이 모델이 헛소리할 가능성을 증가시키는 것이 확인되었습니다.

#### 5. 지식 유형의 가치와 영향
매우 잘 아는 예제만으로는 최상의 성능을 얻을 수 없으며, 어느 정도 아는 예제가 포함된 경우가 가장 좋은 성능을 보였습니다. 이는 모델이 기존의 지식을 효과적으로 사용하는 데 중요한 역할을 합니다.

#### 6. SliCK 카테고리 분석
지식 카테고리를 세분화한 것은 의미 있었으며, 특히 어느 정도 아는 예제가 모델의 성능에 중요한 영향을 미친다는 사실을 발견했습니다. 이 카테고리들은 향후 연구에도 유용한 분류 기준을 제공할 수 있습니다.

#### 7. 결론
새로운 지식을 습득하기 위한 미세 조정은 헛소리와 연관이 있으며, 모델이 주로 기존의 지식을 사용하는데 더 유용하다는 결론이 나왔습니다. 이는 새로운 지식이 포함된 예제가 모델의 성능을 저하시킬 수 있으며, 조정 데이터셋 구성이 중요함을 시사합니다.

### 2. 전체 요약
이 논문은 대형 언어 모델에서 미세 조정 시 새로운 지식을 추가하면 헛소리가 증가하는 문제를 연구합니다. 연구는 ENTITYQUESTIONS 데이터셋을 사용하여 모델이 새로운 지식을 얼마나 효율적으로 습득하는지 분석했으며, 그 과정에서 SliCK라는 새로운 평가 방법을 제안했습니다. 결과적으로, 모델은 새로운 지식을 습득하는 데 어려움을 겪었으며, 이는 헛소리 증가와 성능 저하와 연관이 있었습니다. 전체적으로, 미세 조정 데이터셋의 구성은 모델의 성능에 중요한 요소로 작용하며, 이는 모델을 최적화하는 과정에서 주의 깊게 고려해야 할 부분입니다.

논문의 주요 공헌은 SliCK 평가 방법과 미세 조정 데이터셋의 구성 방식이 모델의 성능과 헛소리에 미치는 영향을 체계적으로 분석했다는 점입니다. 이를 통해 AI와 머신러닝 연구자는 더 나은 모델 최적화 방법을 모색할 수 있을 것입니다.