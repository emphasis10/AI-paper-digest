# Long-context LLMs Struggle with Long In-context Learning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.02060.pdf](https://arxiv.org/pdf/2404.02060.pdf)

이 문서는 큰 규모의 언어 모델(Large Language Models, LLMs)이 긴 문자열을 다루는 능력과 관련된 연구를 다루고 있습니다. 주목할 점은 이러한 모델들이 32K 이상의 토큰을 넘는 긴 순서를 처리하는 데 상당한 진전을 보였음에도 불구하고, 그들의 성능 평가가 대부분 어려움과 실제 세계 시나리오에서의 미묘한 능력을 완전히 반영하지 못하는 지표들에 국한되었다는 점입니다. 이 연구는 극한-레이블 분류(extreme-label classification)를 집중적으로 다루는 특화된 벤치마크(LongICLBench)를 소개하여 이러한 한계를 넘어서려고 시도합니다.

### 1. 문서의 주요 내용 요약

#### 1.1 서론 및 연구 동기
- 이 연구는 LLMs가 긴 입력을 분석하고 광범위한 레이블 공간을 인식해서 정확한 예측을 하는 능력을 측정하기 위한 과제들을 도입합니다. 
- 연구팀은 다양한 입력 길이(2K부터 50K 토큰까지)와 레이블 범위(28에서 174 클래스까지)를 다루는 여섯 가지 데이터셋을 선별했습니다. 
- 이 연구의 핵심은 긴 문맥 이해 및 추론에 있어서 현재의 LLMs가 여전히 어려움을 겪고 있다는 것을 밝히고, 더 나은 미래의 긴 문맥 LLMs 평가를 위해 LongICLBench가 유용할 수 있다는 것을 제시하는 것입니다.

#### 1.2 관련 연구
- 기존의 LLMs는 많이 나왔으며, 이들 중 다수는 극한-레이블 분류와 같은 긴 문맥 과제들을 수행하기 위해 기억 증강 및 초과 기법을 도입하여 성능을 향상시키려고 했습니다.

#### 1.3 실험 설계 및 결과
- 다양한 문맥의 길이와 난이도 수준을 가진 여섯 가지 과제들을 포함하는 벤치마크, LongIC LBench를 사용하여 13개의 긴 문맥 LLMs의 성능을 평가했습니다.
- 대체로, Transformer 기반 모델들이 RNN 기반 모델들보다 모든 평가 데이터셋에서 일관되게 더 좋은 성능을 보였으며, 특히 GPT4-turbo와 같은 강력한 API 기반 모델들보다는 뒤처졌습니다.
- 가장 도전적인 데이터셋인 Discovery에서는 모든 모델들이 세밀한 레이블 유형들 사이의 차이를 구별하는데 실패하여 점수가 0에 도달했습니다.
- 일부 LLMs의 성능은 과제 복잡성에 따라 거의 선형적인 관계를 보여주어, ICL에 대한 성능과 과제의 복잡성 사이에 수학적인 관계가 있을 수 있음을 암시합니다.

### 2. 전체 요약

이 연구는 기존의 긴 문맥 언어 모델(LLMs)이 극한-레이블 분류 과제에 대해 긴 입력을 분석하고 이해하는 능력을 평가하는 새로운 벤치마크, LongICLBench를 소개합니다. 여러 난이도의 레이블 공간을 포함하는 여섯 가지 과제들로 구성된 이 벤치마크는 모델이 전체 입력을 이해하고 올바른 예측을 하는 것을 필요로 합니다. 실험 결과, Transformer 기반 모델들이 일관된 성능을 보였지만, 모든 모델은 가장 어려운 Discovery 데이터셋에서 실패했습니다. 이는 현재 LLMs가 긴 문맥 및 세밀한 레이블 공간을 이해하고 처리하는 데 있어서 여전히 한계가 있음을 시사합니다. 또한, 일부 모델들의 성능이 입증 길이에 대해 선형적인 경향을 보여주어, ICL에 대한 성능과 과제의 복잡성 사이에 가능한 수학적 관계를 시사했습니다. 이 연구는 긴 문맥 이해와 추론에 대한 LLMs의 능력을 더 깊게 탐구하고 향후 설계 개선을 위한 통찰력을 제공합니다.

## Similar Papers
- [In-Context Learning with Long-Context Models: An In-Depth Exploration](2405.00200.md)
- [GenAI Arena: An Open Evaluation Platform for Generative Models](2406.04485.md)
- [LongIns: A Challenging Long-context Instruction-based Exam for LLMs](2406.17588.md)
- [Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction](2404.12957.md)
- [Never Miss A Beat: An Efficient Recipe for Context Window Extension of Large Language Models with Consistent "Middle" Enhancement](2406.07138.md)
- [VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation](2406.15252.md)
- [XC-Cache: Cross-Attending to Cached Context for Efficient LLM Inference](2404.15420.md)
- [LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs](2406.15319.md)
- [LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](2403.12968.md)
