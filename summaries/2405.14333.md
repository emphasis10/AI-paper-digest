# DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.14333.pdf](https://arxiv.org/pdf/2405.14333.pdf)

## 1. 요약

### 1.1 서론 (Introduction)
이 논문은 자연어 수학 문제를 형식화하여 대규모 Lean 4 증명 데이터를 생성하는 방법을 제안합니다. 이를 통해 대형 언어 모델(LLM)의 자동 정리 증명(ATP) 성능을 대폭 향상시켰습니다. 이 방법론은 수학 대회 문제를 Lean 4 형태로 변환하고, 불필요한 데이터를 제거하며 반복적인 증명 생성 과정을 통해 800만 개의 증명 데이터를 생성했습니다. 이 연구는 특히 중등 및 대학 수준의 수학에 초점을 맞추고 있습니다.

### 1.2 배경 연구 (Background and Related Works)
자동 정리 증명(ATP)은 초기부터 인공지능 연구의 중요한 분야였습니다. 최근 딥 러닝 모델의 발전을 통해 신경망 모델과 검색 알고리즘을 결합한 새로운 접근 방식이 제안되었습니다. 이 방법들은 일정 부분 성과를 거두었지만, 굉장히 큰 검색 공간을 다루는 데 어려움이 있었습니다. 이에 반해 대형 언어 모델을 활용한 방식은 높은 성능을 보였지만, 여전히 계산 자원 소모가 컸습니다.

### 1.3 접근법 (Approach)
이 논문에서는 자연어 수학 문제를 형식화하는 방법론을 제안합니다. 이 방법은 자연어 문제를 형식적인 명제로 변환하고, 저질 데이터를 필터링하고, 반복적인 증명 생성을 통해 최종 데이터를 구축합니다. 형식화된 명제와 증명 쌍은 Lean 4 환경에서 정확성을 검증받고, 이를 통해 더욱 고품질의 증명 데이터를 생성하게 됩니다.

### 1.4 실험 (Experiments)
이 논문에서는 제안한 방법론의 유효성을 검증하기 위해 다양한 실험을 진행했습니다. MiniF2F와 FIMO 벤치마크를 사용하여 모델의 증명 성능을 평가하였으며, 그 결과 기존 GPT-4와 비교해 훨씬 높은 정확도를 보였습니다. MiniF2F 벤치마크에서는 기존의 방법들보다 높은 46.3%의 정확도를 기록했으며, FIMO 벤치마크에서도 GPT-4가 하나의 문제도 풀지 못한 반면, 제안된 모델은 여러 문제를 성공적으로 풀어냈습니다.

### 1.5 결론 (Conclusion)
이 논문은 대규모 합성 증명 데이터를 이용해 대형 언어 모델의 증명 능력을 크게 향상시켰습니다. 이를 통해 자동 정리 증명 및 형식 수학 추론 연구의 발전에 기여할 것을 목표로 하고 있습니다. 특히 중등 및 대학 수준의 수학 문제에 초점을 맞췄으며, 향후 다양한 수학 문제로 연구 범위를 확장할 계획입니다.

## 2. 전반적 요약 

이 논문은 대규모 대형 언어 모델의 활용을 통해 자동 정리 증명 능력을 빠르고 정확하게 향상시키는 방법을 제안합니다. 이를 위해 자연어 수학 문제를 대규모의 형식적 증명 데이터로 변환하는 방법론을 개발하고, 이를 반복적으로 학습하여 Lean 4 환경에서 높은 정확도의 증명 결과를 보여주었습니다. 이 연구는 자동 정리 증명과 형식 수학 추론에서 큰 진전을 이루었으며, 교육 및 연구 커뮤니티에 유용한 데이터와 모델을 제공하여 AI 및 수학 분야의 연구 발전에 적극적으로 기여할 수 있을 것으로 예상됩니다.