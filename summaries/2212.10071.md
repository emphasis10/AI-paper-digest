# Large Language Models Are Reasoning Teachers
## TL;DR
## Summary
- [https://arxiv.org/pdf/2212.10071.pdf](https://arxiv.org/pdf/2212.10071.pdf)

### 논문 요약

#### **1. 요약 (섹션별)**
#### **1.1 초록 (Abstract)**
최근의 연구들은 체인 오브 생각(Chain-of-Thought, CoT) 프롬프팅이 언어 모델이 복잡한 추론 작업을 단계별로 해결할 수 있게 한다고 합니다. 그러나 이러한 프롬프팅 방식은 매우 큰 모델(GPT-3 175B)에서만 효과가 있습니다. 본 논문은 대형 모델을 교사 모델로 사용하여 더 작은 모델에서 복잡한 추론을 가능하게 하고, 모델 크기 요구사항을 줄이는 방법(Fine-tune-CoT)을 제안합니다. 이 방법은 작은 모델에서도 뛰어난 성능을 발휘하며, 특히 다양한 추론 샘플을 활용하면 성능이 더욱 향상됩니다.

#### **1.2 서론 (Introduction)**
언어 모델은 다양한 작업에서 놀라운 성능을 보여 왔으나, 복잡한 추론 작업에서는 한계를 보였습니다. 체인 오브 생각(CoT) 프롬프팅은 언어 모델이 중간 추론 단계를 생성하게 하여 문제 해결 능력을 향상시키는 방법으로, 큰 모델에서 효과적입니다. 본 논문은 이를 작은 모델에도 적용할 수 있도록 교사 모델의 추론 샘플을 생성하여 작은 모델을 교육하는 Fine-tune-CoT 방법을 제안합니다.

#### **1.3 관련 연구 (Related Work)**
이전 연구들은 Downsstream Transfer (사전 훈련과미세 조정) 패러다임을 사용하여 언어 모델의 성능을 향상시켰으나, 복잡한 작업에서는 여전히 한계를 보였습니다. 체인 오브 생각 프롬프팅(CoT)은 중간 추론 단계를 생성하여 성능을 향상시키는 방법으로, 특히 큰 모델에서 효과적이라고 알려져 있습니다. 본 논문은 이를 작은 모델에도 적용하도록 Fine-tune-CoT 방법을 제안합니다.

#### **1.4 체인 오브 생각 미세 조정 (Methodology: Chain-of-Thought Fine-Tuning)**
Fine-tune-CoT는 교사 모델에서 추론 샘플을 생성하고 이를 작은 학생 모델에 적용하여 추론 능력을 향상시키는 방법입니다. 세 단계로 이루어집니다:
1. 큰 교사 모델을 사용하여 주어진 작업의 추론 설명을 생성합니다.
2. 생성된 샘플을 필터링하고 재포맷하여 학생 모델을 교육합니다.
3. 학생 모델에 추론 샘플을 사용하여 미세 조정합니다.

#### **1.5 실험 (Experiments)**
12개의 작업에서 Fine-tune-CoT를 평가한 결과, 작은 모델에서도 뛰어난 성능을 발휘하며, 다양한 추론을 통해 성능이 더욱 향상됨을 확인했습니다. 특히 SVAMP와 MultiArith 작업에서 성능이 크게 향상되었습니다.

#### **1.6 결과 (Results)**
Fine-tune-CoT는 작은 모델에서도 매우 큰 모델과 비교할 때 뛰어난 성능을 발휘합니다. 다양한 추론을 사용하면 성능이 더욱 향상됨을 확인했습니다. 예를 들어, 0.3B 모델은 6.7B 모델을 추론 성능에서 능가할 수 있었습니다.

#### **1.7 논의 및 결론 (Discussion and Conclusion)**
Fine-tune-CoT는 작은 모델에서도 복잡한 추론을 가능하게 하여, 실세계 적용에 적합한 모델을 학습할 수 있음을 확인했습니다. 다양한 추론을 통한 Fine-tune-CoT가 매우 효과적이며, 이것이 작은 모델의 추론 능력을 크게 향상시키는 방법임을 입증했습니다. 이는 대규모 모델의 크기와 비용 문제를 해결하는데 큰 도움을 줄 수 있습니다.

#### **2. 전체 요약**
본 논문은 대형 언어 모델의 체인 오브 생각(Chain-of-Thought, CoT) 프롬프팅 방법을 작은 모델에도 적용하여 복잡한 추론 작업을 수행할 수 있게 하는 Fine-tune-CoT 방법을 제안합니다. 이 방법은 교사 모델에서 생성된 추론 샘플을 사용하여 작은 모델을 교육함으로써, 작은 모델에서도 뛰어난 성능을 발휘하고 다양한 추론을 통해 성능이 더욱 향상됨을 입증했습니다. 이를 통해 대형 모델의 크기와 비용 문제를 해결할 수 있으며, 실세계 적용이 가능한 모델을 학습할 수 있는 가능성을 보여줍니다.

## Similar Papers
- [Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models](2405.20541.md)
- [Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought](2404.03414.md)
- [GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models](2407.02936.md)
- [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](2404.02575.md)
- [Cognitive Map for Language Models: Optimal Planning via Verbally Representing the World Model](2406.15275.md)
- [Active Prompting with Chain-of-Thought for Large Language Models](2302.12246.md)
- [DistiLLM: Towards Streamlined Distillation for Large Language Models](2402.03898.md)
- [Prover-Verifier Games improve legibility of LLM outputs](2407.13692.md)
- [Aligning Teacher with Student Preferences for Tailored Training Data Generation](2406.19227.md)
