# WebGames: Challenging General-Purpose Web-Browsing AI Agents
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.18356.pdf](https://arxiv.org/pdf/2502.18356.pdf)

I'm unable to provide the output in the format directly requested, however, here is the summarization of the major sections of the AI and Machine Learning paper in Korean along with an overall summary based on your instructions.

1. 각 섹션의 요약:

   - **서론**
     이 연구에서는 웹 상호작용을 테스트하기 위해 'WebGames'라는 새로운 벤치마크를 소개합니다. 이는 대규모 최신 AI 모델들이 다중 단계의 웹 작업을 효과적으로 수행할 수 있는지를 평가하는데 중점을 둡니다. 'WebGames'는 인간에게는 직관적으로 쉬운 도전 과제를 통해 AI 시스템의 한계를 테스트하는 것이 특징입니다.

   - **WebGames 벤치마크**
     이 벤치마크는 인간 중심의 디자인, AI 도전성, 경량 구현, 검증 가능한 완성도, 그리고 격리된 역량 테스트라는 다섯 가지 핵심 원칙에 따라 설계되었습니다. 평가 범주는 기본 브라우저 상호작용, 고급 입력 처리, 인지 및 기억 과제, 워크플로 자동화, 인터랙티브 엔터테인먼트 시스템 등으로 구분됩니다.

   - **에이전트 성능 분석**
     우리는 GPT-4o, Claude Computer-Use, Gemini-1.5-Pro, Qwen2-VL 등 다양한 모델의 성능을 인간과 비교합니다. 결과는 모든 모델이 인간 성능(95.7%)에 비해 상당히 뒤떨어져 있다는 것을 보여주며, AI 시스템이 인간처럼 웹 상호작용을 할 수 없다는 현저한 차이를 드러냈습니다.

   - **결론 및 미래 방향**
     현재 AI 시스템과 인간의 웹 상호 작용에서의 능력 차이를 줄이기 위해 다양한 수준의 난이도를 추가한 도전 과제, 협력을 요구하는 다중 에이전트 시나리오, 절차적 콘텐츠 생성과 같은 희소성에 대한 테스트를 추가할 예정입니다.

2. 전체 요약:

   이 논문은 웹 상호작용을 평가하기 위한 종합적이며 다양한 도전 과제로 구성된 'WebGames' 벤치마크를 소개합니다. 이는 AI와 인간 간의 현재 능력 차이를 구체적으로 드러내며, 향후 연구와 발전에서 중점을 두어야 할 분야를 제시하고 있습니다. 이 연구의 혁신적인 부분은 AI 모델의 현재 한계와 이를 극복하기 위한 명확한 벤치마크를 설정하고 있다는 점입니다.