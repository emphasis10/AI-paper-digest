# VideoHallucer: Evaluating Intrinsic and Extrinsic Hallucinations in Large Video-Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.16338.pdf](https://arxiv.org/pdf/2406.16338.pdf)

### 1. 섹션별 요약 (중요 내용)

**추상 (Abstract):**
이 연구는 AI와 머신러닝 모델이 비디오 이해에서 '환상(hallucination)' 문제를 어떻게 겪고 있는지에 대해 다룹니다. 'VideoHallucer'라는 새로운 평가 도구를 소개하여, 모델이 시각적 컨텍스트에서 벗어나서 생성하는 무관한 내용이나 비논리적인 내용을 탐지합니다. 이 평가 도구는 환상을 내재적 환상(intrinsic hallucination)과 외재적 환상(extrinsic hallucination)으로 나눕니다.

**도입부 (Introduction):**
MLLM(Multimodal Large Language Models)은 비디오 이해와 언어 생성에서 강력한 성능을 보여주었으나, 자주 시각적 입력에 따라 부정확하거나 근거 없는 응답을 생성하며 '환상' 문제를 겪습니다. 연구팀은 비디오와 언어 모델의 환상 문제를 식별하고 평가하기 위해 'VideoHallucer'라는 새로운 도구를 제안했습니다.

**관련 연구 (Related Work):**
기존 연구들에서는 주로 비디오 이해와 텍스트 생성의 일반적인 성능에 초점을 맞췄지만, 환상 문제에 대한 체계적인 연구는 부족합니다. 이 연구는 이 문제를 다루기 위해 비디오와 텍스트 간의 관계를 더 깊이 탐구합니다.

**VideoHallucer 평가 도구:**
'VideoHallucer'는 내재적 환상(예: 객체-관계 환상, 시간적 환상)과 외재적 환상(예: 구체적 사실 환상, 비사실적 환상)으로 나누어 환상을 평가합니다. 평가는 기본 질문과 환상된 질문의 쌍을 사용한 이원 영상 질의응답(binary VideoQA) 방식으로 진행됩니다.

**자기-PEP 프레임워크 (Self-PEP Framework):**
이 프레임워크는 모델이 자신의 예측을 설명하는 과정을 통해 스스로의 예측 정확도를 향상시키도록 합니다. 특히 외재적 사실 환상(extrinsic factual hallucination)을 다루는 데 효과적입니다.

**최종 결과 및 토론 (Conclusion and Discussion):**
연구는 12개의 대규모 비디오-언어 모델을 평가하여 대부분의 모델이 심각한 환상 문제를 겪고 있음을 확인했습니다. 데이터와 파라미터를 확장하면 시각적 단서나 반대 사실(countryside facts)을 인식하는 능력은 향상되지만, 외재적 사실 환상을 탐지하는 데에는 큰 도움이 되지 않습니다. 자기-PEP 프레임워크는 모델 성능을 평균적으로 5.38% 향상시켰습니다.

### 2. 전체 요약

이 논문은 비디오 이해와 텍스트 생성 과정에서 발생하는 '환상' 문제를 해결하기 위해 'VideoHallucer'라는 포괄적인 벤치마크 도구를 소개합니다. 이 벤치마크는 모델이 시각적 컨텍스트에서 벗어나서 생성하는 무관하거나 비논리적인 내용을 체계적으로 평가합니다. 연구는 12개의 대규모 비디오-언어 모델을 이 도구로 평가하여 대부분의 모델이 심각한 환상 문제를 겪고 있음을 확인했습니다. 연구팀은 'Self-PEP' 프레임워크를 통해 모델이 스스로의 예측을 설명하고 수정하면서 환상 문제를 줄이는 방법을 제안했습니다. 이 방법은 모델의 환상 저항 능력을 평균적으로 5.38% 향상시켰습니다.

이 벤치마크와 프레임워크는 비디오와 언어 모델의 정확성을 높이고, AI와 머신러닝의 발전에 큰 기여를 할 것으로 기대됩니다.