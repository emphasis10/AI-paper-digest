# Found in the Middle: Calibrating Positional Attention Bias Improves Long Context Utilization
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.16008.pdf](https://arxiv.org/pdf/2406.16008.pdf)

### 1. 각 섹션 요약

#### 서론 (Introduction)
이 논문은 대형 언어 모델(LLMs)이 긴 입력 컨텍스트에서 중간에 위치한 중요한 정보를 적절히 강조하지 못하는 문제를 다루고 있습니다. 이를 해결하기 위해 LLM의 고유한 주의 편중(attention bias)이 이 문제와 어떻게 연결되는지 설명하고, 이를 교정하기 위한 메커니즘(finding-in-the-middle)을 제안합니다.

#### 문헌 검토 (Literature Review)
연구자들은 기존의 연구들에서 LLM이 입력의 시작과 끝 부분에 더 높은 주의를 기울이는 U자형 주의 편중을 보인다는 것을 밝혔습니다. 이는 위치 편중이 모델의 컨텍스트 이용에 영향을 미친다는 것을 시사합니다. 기존의 RAG (Retrieval-Augmented Generation) 기법들이 이 문제를 어떻게 다루려는지 등에 대해서도 논의합니다.

#### 방법론 (Methodology)
연구진은 위치 편중을 교정하는 'found-in-the-middle' 메커니즘을 제안합니다. 구체적으로, 상대적인 입력 위치에 따른 주의 변화를 측정하여 이것이 성능에 미치는 영향을 분석한 후, 교정된 주의값을 이용하여 모델이 실제로 중요한 문서를 더 잘 찾을 수 있도록 합니다.

#### 실험 (Experiments)
실험에서는 주로 두 가지 데이터 셋인 NaturalQuestion과 SynthWiki에서 Vicuna와 Tulu 모델을 사용하여 교정된 주의 메커니즘의 성능을 평가합니다. 실험 결과, 교정된 주의 메커니즘이 기존의 RAG 기법들과 비교했을 때 더 높은 성능을 보여주었고, 특히 골드 문서가 중간에 위치할 때 성능 향상이 두드러졌습니다.

#### 결과 (Results)
교정된 주의 메커니즘을 적용하면 중간에 위치한 문서의 중요성을 더 잘 파악할 수 있어서 기존 방법들보다 성능이 향상되었습니다. 특히, 가장 어려운 상황에서도 6-15 포인트의 성능 향상이 관찰되었습니다.

#### 결론 (Conclusion)
이 연구는 LLM의 위치 편중 문제를 해결하기 위한 중요한 진전을 이루었으며, 이 교정 메커니즘이 다양한 모델과 태스크에서 성능을 향상시킬 수 있음을 보여주었습니다. 이러한 결과는 향후 연구 방향에 중요한 시사점을 제공합니다.

### 2. 전체 요약
이 논문은 대형 언어 모델(LLMs)이 긴 입력에서 중간 부분의 중요한 정보를 적절히 강조하지 못하는 문제를 다룹니다. 'lost-in-the-middle' 현상의 원인으로 모델의 위치 편중(U자형 주의 분포)을 제시하고, 이를 교정하기 위한 'found-in-the-middle' 메커니즘을 제안합니다. 이 메커니즘은 모델이 실제로 중요한 문서의 정보를 더 잘 파악할 수 있도록 주의를 교정합니다. 실험 결과, 교정된 메커니즘이 기존의 방법보다 뛰어난 성능을 보여, 특히 중간에 위치한 문서에서도 높은 성능을 유지할 수 있음을 확인했습니다.

이 연구는 향후 LLM의 위치 편중 문제를 해결하고 RAG 성능을 향상시키는 데 중요한 기여를 합니다.