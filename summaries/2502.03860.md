# BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.03860.pdf](https://arxiv.org/pdf/2502.03860.pdf)

1. **논문 각 섹션 요약**

   - **1. 소개**
     대형 언어 모델(LLM), 특히 OpenAI의 o1 모델이 복잡한 문제를 해결하는 데 있어 뛰어난 사고 능력을 보여줍니다. LongCoT(긴 사고 과정)는 LLM이 문제를 분석하고 계획하며 반성하고 필요시 돌아가는 과정을 통해 더 나은 결과를 이끌어내는 방식을 제공합니다. 이 논문에서는 기존 모델에서 지식 증류 없이 LongCoT 능력을 개발할 수 있는 새로운 접근 방식인 BOLT(Bootstrapping Long-CoT)를 제안합니다.

   - **2. 관련 연구**
     LongCoT 모델은 복잡한 문제를 해결할 때 유용한 사고 과정을 반영합니다. 그러나 기존 연구는 대부분 지식 증류에 의존하고 있습니다. 이는 특정 데이터에 국한되며, 그 일반화 가능성에 의문을 남깁니다. BOLT는 기존 모델들에 대한 의존성을 줄이는 방향으로 개발되었습니다.

   - **3. BOLT 방법론**
     BOLT는 세 가지 단계로 나뉩니다: 
     1) LongCoT 데이터 부트스트랩핑: ShortCoT 모델을 활용하여 LongCoT 데이터를 생성합니다. 
     2) LongCoT 감독형 미세 조정: ShortCoT 모델을 LongCoT 형식에 맞게 조정합니다.
     3) LongCoT 온라인 훈련: 모델의 LongCoT 능력을 추가로 개선합니다. 이 방법은 단 10개의 예시만으로도 충분히 효과적임을 입증하였습니다.

   - **4. 실험**
     여러 모델에 BOLT를 적용하여 다양한 평가 기준에서 성능을 비교하고, 각 단계를 통해 달성한 성과를 측정했습니다. Arena-Hard, MT-Bench, WildBench 등을 통해 모델의 다양한 과제 수행 능력을 확인했습니다.

   - **5. 결론**
     BOLT 방법론은 ShortCoT 모델에서 LongCoT 능력을 개발할 수 있는 효율적이고 비용 효과적인 경로를 제시합니다. 최소한의 인적 노력을 통해 복잡한 사고 능력을 확장시킬 수 있는 가능성을 보여주었습니다. 이는 LLM의 일반화된 사고 능력 개발에 기여할 것입니다.

   - **주요 기여 및 혁신**
     이 논문에서의 주요 기여는 기존 LongCoT 모델에 의존하지 않고도 고급 사고 능력을 개발할 수 있는 새로운 방법론(BOLT)을 제안한 것입니다. 이를 통해 BOLT는 인건비를 최소화하면서도 LLM의 사고 능력을 효과적으로 확장시킬 수 있는 기반을 마련했습니다.

2. **전반적인 요약**
   이 논문은 대형 언어 모델에서 긴 체인 사고(LongCoT) 능력을 개발하기 위한 새로운 접근 방식인 BOLT를 제안합니다. BOLT는 ShortCoT 모델을 기반으로 하여, 최소한의 인적 노력으로도 효과적으로 LongCoT 능력을 배양하는 방법을 설명합니다. 모델 실험을 통해 다양한 평가 기준에서의 성과를 기록하며, BOLT가 LLM의 복잡한 사고 과정을 개발하는 데 있어 혁신적이고 효과적인 방법임을 입증합니다. 이를 통해 AI의 발전에 기여할 수 있는 중요한 이정표가 될 것입니다.