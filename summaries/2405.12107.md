# Imp: Highly Capable Large Multimodal Models for Mobile Devices
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.12107.pdf](https://arxiv.org/pdf/2405.12107.pdf)

### 요약

이 논문은 "Imp: Highly Capable Large Multimodal Models for Mobile Devices"라는 제목으로, 리소스가 제한된 환경에서도 강력한 다중모달 모델을 개발하기 위한 연구를 다룹니다. Imp 모델은 특히 모바일 장치에서 효율적으로 작동할 수 있도록 설계되었습니다.

#### 1. 소개
- 대형 언어 모델(LLM)의 발전은 인공지능의 전반적인 풍경을 크게 변화시켰습니다.
- 최신 LLM은 여러 도메인과 작업에서 뛰어난 능력을 보여주고 있으며, 이를 기반으로 한 다중모달 모델(LMM)도 점차 중요해지고 있습니다.
- 그러나 이러한 모델은 일반적으로 파라미터가 많고 계산 집약적이기 때문에 리소스가 제한된 환경에서는 사용이 어렵습니다.
- 본 연구는 경량의 LMM을 개발하여 리소스 제약 환경에서도 강력한 성능을 발휘하도록 하는 것을 목표로 합니다.

#### 2. 관련 연구
- 기존의 연구는 대형 모델의 효율성을 개선하기 위한 다양한 접근법을 탐구했습니다.
- 경량 LLM과 LMM은 제한된 자원에서도 강력한 성능을 유지하기 위한 여러 시도를 포함합니다.

#### 3. 방법론
1. **모델 아키텍처**:
   - LLaVA-1.5 모델을 기반으로 하여 경량 LMM인 Imp 모델을 개발했습니다.
   - 모델은 사전 훈련된 비주얼 인코더, 언어 모델, 그리고 이들을 연결하는 멀티모달 커넥터로 구성됩니다.

2. **훈련 전략**:
   - 두 단계의 훈련 전략을 사용합니다: 멀티모달 정렬 사전 훈련과 멀티모달 지시 튜닝.
   - 첫 번째 단계에서는 비주얼 인코더와 언어 모델을 고정하고 멀티모달 커넥터만 훈련합니다.
   - 두 번째 단계에서는 언어 모델과 멀티모달 커넥터를 함께 최적화합니다.

3. **훈련 데이터**:
   - 다양한 학술 VQA 데이터셋과 GPT-생성 데이터셋을 사용하여 모델을 훈련했습니다.
   - OCR 및 차트 데이터를 추가하여 특정 작업에 대한 성능을 향상시켰습니다.

#### 4. 실험
- Imp 모델의 성능을 다양한 벤치마크에서 평가했습니다.
- Imp-3B 모델은 기존의 경량 LMM들보다 뛰어난 성능을 보였으며, 13B 크기의 모델보다도 우수한 성능을 발휘했습니다.
- 모바일 장치에서의 효율성을 위해 저비트 양자화와 해상도 감소 기술을 적용하여 Qualcomm Snapdragon 8Gen3 칩에서 약 13 토큰/초의 높은 추론 속도를 달성했습니다.

#### 5. 결론
- 본 연구는 경량 LMM의 설계 공간을 체계적으로 조사하여 효율적이고 강력한 모델을 개발하는 방법을 제안했습니다.
- Imp 모델은 다양한 경량 LLM을 기반으로 하여 2B에서 4B 규모의 모델을 제공하며, 모바일 장치에서도 높은 성능을 유지합니다.
- 향후 연구에서는 고품질 훈련 데이터를 추가하고, 지식 증류 및 인간 선호도 최적화와 같은 효과적인 훈련 전략을 도입하여 모델의 성능을 더욱 향상시킬 계획입니다.

### 전체 요약
이 논문은 리소스가 제한된 환경, 특히 모바일 장치에서 강력한 성능을 발휘할 수 있는 경량의 다중모달 모델을 개발하는 방법을 제안합니다. Imp 모델은 주로 두 가지 혁신적인 요소를 통해 높은 효율성을 달성합니다: 점진적인 재파라미터화 배치 정규화(PRepBN)와 단순화된 선형 주의(SLA) 모듈입니다. 다양한 실험을 통해 Imp 모델의 우수한 성능을 입증했으며, 모바일 장치에서의 효율성을 높이기 위해 저비트 양자화와 해상도 감소 기술을 적용했습니다. 이를 통해 Imp 모델은 다양한 작업에서 높은 성능을 유지하면서도 자원 제약 환경에서도 실용적으로 사용할 수 있음을 보여주었습니다.