# PaSS: Parallel Speculative Sampling
## TL;DR
## Summary
- [https://arxiv.org/pdf/2311.13581.pdf](https://arxiv.org/pdf/2311.13581.pdf)

### 섹션 요약

1. **서론 (Introduction)**
   이 논문은 대규모 언어 모델 (Large Language Model, LLM)의 매개변수 수를 수십억으로 확장함으로써 다양한 작업에서 놀라운 성능을 발휘하지만, 그럼에도 불구하고 메모리 접근이 병목 현상을 유발한다고 설명합니다. 전통적으로는 자동 회귀 방식으로 매번 토큰을 생성해야 하기에 기다림 시간이 오래 걸립니다. 이에 대한 해결책으로 제안된 방법이 '병렬 추측 샘플링(Parallel Speculative Sampling, PaSS)'입니다. 이는 추가 입력 토큰을 통해 한 번에 여러 토큰을 생성함으로써 속도를 30%까지 향상시킵니다.

2. **방법론 (Method)**
   - **추측 샘플링 (Speculative Sampling):** 이 접근법은 추측 샘플링을 사용하여 대규모 모델의 생성 속도를 높이는 방식입니다. 작은 모델이 잠재적인 토큰을 초안을 작성하고, 큰 모델이 이를 한 번에 평가하면서 시간이 절약됩니다.
   - **병렬 추측 샘플링 (Parallel Speculative Sampling):** 두 번째 모델 없이 대규모 모델에서 여러 토큰을 병렬 디코딩으로 생성하며, "Look-ahead Embeddings"를 사용하는 방식입니다. 적은 수의 새로운 가중치 훈련만 필요하여 메모리 부담도 적습니다.

3. **실험 (Experiments)**
   - 실험은 텍스트와 코드 완성을 대상으로 진행되었으며, Wikipedia와 The Stack 데이터셋을 사용했습니다. 병렬 추측 샘플링은 특정 상황에서 실행 시간을 최대 30%까지 줄일 수 있으며, 이는 기존의 자가 회귀 생성 방법보다 더 효율적임을 보였습니다.

4. **결론 (Conclusion)**
   이 연구는 '병렬 추측 샘플링'을 제안하며, 이를 통해 추가적인 작은 모델 없이도 최대 30%의 속도 향상과 손실 없는 토큰 생성을 가능케 합니다. 향후 연구에서는 Look-ahead 토큰을 이용한 병렬 생성 품질을 향상시키는 방안을 탐색할 계획입니다.

### 전체 요약
이 논문은 대규모 언어 모델의 비효율적인 메모리 접근 문제를 해결하기 위해 '병렬 추측 샘플링' 기법을 소개합니다. 이 방법은 두 번째 모델 없이도 대규모 모델에서 여러 토큰을 병렬로 생성하여 속도를 높이고, 메모리 과부하를 줄이는 혁신적인 방법입니다. 실험을 통해 최대 30%의 실행 속도 개선을 확인하였으며, 이는 언어 모델의 실용적 성능을 높이는 데 기여합니다. 향후 연구에서는 Look-ahead 토큰을 사용하여 생성 품질을 더욱 향상시키는 것을 목표로 하고 있습니다.