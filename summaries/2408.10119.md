# Factorized-Dreamer: Training A High-Quality Video Generator with Limited and Low-Quality Data
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.10119.pdf](https://arxiv.org/pdf/2408.10119.pdf)

### 각 섹션 요약

#### 1. 서론
비디오 생성은 현실 세계의 복잡하고 역동적인 시나리오를 텍스트 프롬프트, 레이블, 이미지 등으로 시뮬레이션하는 어려운 작업입니다. 기존의 방법들은 고품질(HQ) 비디오 데이터를 필요로 하지만, 본 연구에서는 공개된 제한된 저품질(LQ) 데이터를 사용한 HQ 비디오 생성이 가능함을 보였습니다. 

#### 2. 관련 연구
텍스트-이미지(T2I) 생성 및 텍스트-비디오(T2V) 생성 분야의 최신 연구들이 다루어졌습니다. 기존 방법들은 주로 GAN 기반이었으나, 최근에는 Diffusion 모델로 진화하며 더 나은 성능을 보이고 있습니다. 특히, Factorized-Dreamer는 T2I 모델과 TI2V 모델을 결합해 더 효율적인 비디오 생성을 시도합니다.

#### 3. 방법론
Factorized-Dreamer는 스페이스-타임 구조를 채택하여 T2I 및 T2V 생성을 각각 이미지 생성과 텍스트/이미지-비디오로 구분하여 진행합니다. 이 모델은 T2I 어댑터, 픽셀-어웨어 크로스 어텐션(PACA) 모듈, T5 텍스트 인코더, PredictNet 등을 포함합니다. 특히, 전자 권장변환기를 사용해 모션 이해를 돕고, PredictNet을 사용해 옵티컬 플로우를 감독하여 비디오 생성의 안정성과 품질을 보장합니다.

#### 4. 실험 결과
다양한 T2V 및 이미지-비디오(I2V) 생성 작업에서 Factorized-Dreamer의 성능이 평가되었습니다. UCF101 데이터셋에서의 평가와 공개된 EvalCrafter 벤치마크에서 뛰어난 시각 품질과 텍스트-비디오 일치도를 보였으며, 상용 모델과 비교해도 뒤지지 않는 성능을 확인했습니다. 또한, 사용자 연구와 다수의 소속 실험을 통해 모델의 유효성을 검증했습니다.

#### 5. 결론 및 한계
Factorized-Dreamer는 공개된 제한된 LQ 데이터만으로 HQ 비디오 생성을 가능하게 했으며, 몇 가지 중요한 디자인 결정을 통해 간단하고 쉽게 훈련할 수 있습니다. 그러나 긴 비디오나 일관된 모션 생성에는 여전히 한계가 있습니다. 이후 연구에서는 이러한 한계를 극복할 계획입니다.

### 전체 요약
본 논문에서는 공개된 제한된 저품질(LQ) 데이터셋만을 사용하여 고품질(HQ) 비디오를 생성하는 Factorized-Dreamer라는 새로운 프레임워크를 제안합니다. 이 방법은 기존의 대규모 고품질 비디오 데이터셋을 필요로 하는 연구들과는 달리, 텍스트와 이미지를 결합하여 생성을 시도하는 스페이스-타임 구조를 채택했습니다. 중요한 설계 요소로는 T2I 어댑터, 픽셀-어웨어 크로스 어텐션(PACA) 모듈, T5 텍스트 인코더 및 PredictNet 등이 있으며, 이 모두가 결합되어 비디오 생성의 품질과 안정성을 보장합니다. 실험 결과, Factorized-Dreamer는 시각 품질과 텍스트 일치도에서 실제 사용 가능한 성능을 보여 주었으며, 향후 연구에서는 긴 비디오 생성 및 모션 일관성 향상에 초점을 맞출 예정입니다.