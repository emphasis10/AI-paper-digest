# Moto: Latent Motion Token as the Bridging Language for Robot Manipulation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.04445.pdf](https://arxiv.org/pdf/2412.04445.pdf)

1. 각 섹션의 중요 내용을 요약하고 한국어로 제공하겠습니다.

- **서론**: 최근 자연어 처리 분야에서 텍스트 데이터를 통한 자동 회귀식 사전 훈련의 성공 사례가 많아지고 있습니다. 이를 본떠 비디오 데이터를 통해 로봇 학습을 개선할 수 있는지 탐구합니다. 주된 도전 과제는 비디오 데이터의 효과적인 표현 형식을 찾는 것입니다.

- **관련 연구**: 연구들은 주로 언어와 비전을 결합한 모델을 구축해 로봇 동작을 예측하게 하거나 큰 규모의 비디오 데이터를 활용하여 정책 모델을 제안합니다. 본 연구는 모토(Moto)를 통해 비디오 프리트레이닝 방식을 적용하여 로봇 조작을 향상시키고자 합니다.

- **모토(Moto)의 방법론**:
  - **개요**: 모토는 자동 회귀식 비디오 프리트레이닝을 통해 로봇 학습에서 운동 선행 지식을 터득하는데 목표를 둡니다. 모토는 라텐트 모션 토크나이저, 모토-GPT 사전 훈련 및 로봇 행동 정책을 위한 공동 미세 조정 단계를 포함합니다.
  - **모션 토크나이저**: 비연속적인 VQ-VAE 아키텍처를 이용해 비디오 프레임 간 격차를 압축하고, 이러한 모션 토큰을 통해 시퀀스를 구성하여 모션 경로를 표현합니다.
  - **공동 미세 조정**: 모토-GPT를 로봇 조작을 위한 목표로 조정하기 위해 행동 쿼리 토큰과 모션 토큰을 결합합니다. 이를 통해 비디오에서 배운 추상적인 의도를 실제 행동으로 전환합니다.

- **실험 세팅 및 실험 결과**:
  - 다양한 실험을 통해 Moto-GPT의 유용성 및 로봇 정책으로서의 효과성을 검증하였습니다. 특히, 운동 토큰이 포함된 모델이 더 우수한 성능을 보였습니다.

- **결론**: 종합적으로 Moto는 비디오 데이터를 통해 얻은 모션 선행 지식이 로봇 조작에 효율적으로 전이될 수 있음을 주장합니다. 이는 전반적인 로봇 학습 능력을 크게 향상시킬 수 있음을 시사합니다.

2. 전체 요약:
본 연구는 비디오 데이터에서 모션 선행 지식을 추출하여 로봇 조작을 향상시키는 방법론인 Moto를 제안합니다. 비디오 데이터를 기반으로 라텐트 모션 토큰을 생성하고 모토-GPT를 사전 훈련하여 추상적인 모션 지식을 실제 로봇 조작에 전이합니다. 이 연구는 로봇 학습의 새로운 가능성을 제시하며, 비디오의 상호작용이 풍부한 자료를 활용함으로써 로봇의 성능을 크게 개선할 수 있음을 증명합니다.