# A Careful Examination of Large Language Model Performance on Grade School Arithmetic
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.00332.pdf](https://arxiv.org/pdf/2405.00332.pdf)

이 연구 논문에서는 "Large Language Models (LLMs)"의 초등 수학 문제 해결 능력에 대한 성능을 평가합니다. 특히, 데이터셋 오염이 모델 성능에 미치는 영향을 조사하기 위해 "Grade School Math 1000 (GSM1k)"라는 새로운 벤치마크를 개발했습니다. GSM1k는 기존 GSM8k 벤치마크의 스타일과 복잡성을 모방하여 설계되었습니다. 이 연구는 모델들이 GSM8k의 문제들을 일부 기억함으로써 오버피팅되었다는 것을 제안합니다. 즉, 일부 LLM이 특정 벤치마크 데이터를 통해 '학습'한 것이 아니라 '암기'했을 가능성이 있습니다.

### 주요 내용 요약

1. **서론 및 배경**:
   - LLM의 추론 능력을 평가하는 것은 연구의 중요한 방향입니다. 이를 위해 GSM1k를 개발하여 데이터 오염과 모델의 오버피팅을 조사합니다.

2. **GSM1k 벤치마크 개발**:
   - GSM1k는 사람이 만든 문제로 구성되어 있으며, LLM이나 다른 합성 데이터 소스의 도움 없이 만들어졌습니다. 문제는 GSM8k와 유사한 난이도와 스타일을 가지며, 기존 벤치마크의 데이터 오염 문제를 최소화하기 위해 설계되었습니다.

3. **성능 평가 및 분석**:
   - 다양한 LLM에 대한 GSM1k의 성능을 평가한 결과, 특히 Mistral과 Phi 모델군에서 오버피팅의 증거가 발견되었습니다. 이는 이러한 모델들이 GSM8k에서 특정 문제들을 부분적으로 기억하고 있음을 시사합니다. 그러나 모든 '프론티어(frontier)' 모델들은 오버피팅의 징후가 거의 없었습니다.

### 혁신적인 부분
이 논문의 혁신성은 새로운 데이터셋(GSM1k)을 개발하여 LLM의 실제 추론 능력을 평가하고, 데이터 오염의 영향을 최소화하는 데 초점을 맞춘 것입니다. GSM1k는 LLM의 성능을 보다 정확하게 평가하고, 오버피팅을 줄이는 방법을 제공합니다.

이 논문은 LLM의 추론 능력을 평가하고 개선하는 데 중요한 기여를 하며, 향후 이러한 모델의 발전 방향에 영향을 줄 것입니다.

## Similar Papers
- [Large Language Monkeys: Scaling Inference Compute with Repeated Sampling](2407.21787.md)
- [On Leakage of Code Generation Evaluation Datasets](2407.07565.md)
- [LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report](2405.00732.md)
- [NATURAL PLAN: Benchmarking LLMs on Natural Language Planning](2406.04520.md)
- [Estimating the Hallucination Rate of Generative AI](2406.07457.md)
- [Improve Mathematical Reasoning in Language Models by Automated Process Supervision](2406.06592.md)
- [Evaluating the World Model Implicit in a Generative Model](2406.03689.md)
- [Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On](2407.08348.md)
- [QLoRA: Efficient Finetuning of Quantized LLMs](2305.14314.md)
