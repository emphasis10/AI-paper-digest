# To Believe or Not to Believe Your LLM
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.02543.pdf](https://arxiv.org/pdf/2406.02543.pdf)

#### 소개
이 논문은 대형 언어 모델(LLMs)에서 불확실성 정량화에 대해 다룹니다. 특히, 에피스테믹(지식 기반) 불확실성과 알레아토릭(무작위) 불확실성을 구별하여 모델의 응답 신뢰성을 평가합니다. 이 접근법은 모델이 제공하는 응답이 신뢰할 수 없을 때, 즉 에피스테믹 불확실성이 클 때를 식별하는 데 중점을 둡니다.

#### 관련 연구
기존 연구들은 주로 단일 정답이 존재하는 문제에서 불확실성을 평가하는 데 중점을 두었으나, 이 논문에서는 다중 응답이 가능한 상황에서도 에피스테믹 불확실성을 분리하는 방법을 제안합니다. 이를 통해 응답의 신뢰성을 더 잘 판단할 수 있게 됩니다.

#### 방법론
이 논문은 정보 이론적 메트릭을 사용하여 에피스테믹 불확실성을 정량화합니다. 이를 위해 반복적인 프롬프트 방법을 사용하여 모델의 응답 분포와 실제 분포 간의 차이를 측정합니다. 이 방법은 특히 다중 정답이 가능한 상황에서 유용하며, 기존의 단순한 로그 가능도 기반 방법보다 더 정확하게 에피스테믹 불확실성을 평가할 수 있습니다.

#### 실험
실험 결과, 제안된 방법이 퀴즈 데이터셋(TriviaQA, AmbigQA)에서 기존 방법들보다 높은 성능을 보였습니다. 특히, 혼합된 단일 레이블 및 다중 레이블 샘플이 있는 데이터셋에서 제안된 방법은 높은 재현율을 유지하면서도 낮은 오류율을 달성했습니다.

#### 결론
이 논문은 LLM의 응답 신뢰성을 평가하는 새로운 방법을 제안합니다. 제안된 방법은 에피스테믹 불확실성을 정량화하여 응답이 신뢰할 수 없는 경우를 더 잘 식별할 수 있게 합니다. 이는 LLM이 다중 응답 상황에서도 정확하게 작동할 수 있도록 도와줍니다.

### 전체 요약
이 논문은 대형 언어 모델에서 응답의 신뢰성을 평가하기 위해 에피스테믹 불확실성을 정량화하는 새로운 방법을 제안합니다. 반복적인 프롬프트 방법을 통해 모델의 응답 분포와 실제 분포 간의 차이를 측정하며, 이를 통해 다중 응답이 가능한 상황에서도 정확하게 에피스테믹 불확실성을 평가할 수 있습니다. 실험 결과, 제안된 방법이 기존 방법들보다 높은 성능을 보였으며, 이는 LLM의 응답 신뢰성을 향상시키는 데 기여할 수 있습니다.