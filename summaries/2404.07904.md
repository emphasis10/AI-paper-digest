# HGRN2: Gated Linear RNNs with State Expansion
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.07904.pdf](https://arxiv.org/pdf/2404.07904.pdf)

HGRN2 논문을 요약하면 다음과 같습니다:

### 1. 서론 및 배경
이 연구는 향상된 RNN 모델인 HGRN2를 소개하며, 이 모델은 이전 버전인 HGRN에 비해 상태 크기를 증대시키는 새로운 메커니즘을 도입합니다. 이러한 변화는 언어 모델링, 이미지 분류, 그리고 Long Range Arena 벤치마크에서의 성능 향상을 목표로 합니다.

### 2. 기술적 배경
HGRN 모델은 기본적으로 고정된 상태 크기를 가지며, 이를 통해 모든 역사적 정보를 인코딩합니다. 최신 연구는 이 고정 크기의 상태를 더욱 효율적으로 활용하고, 상태 크기를 증대시키기 위한 방법을 모색하고 있습니다. 이 연구에서는 선형 주의 메커니즘에서 영감을 받아 비매개변수 외적 곱 기반 상태 확장 메커니즘을 소개합니다.

### 3. HGRN2 방법론
HGRN2는 입력 게이트 메커니즘을 변경하여 상태 확장을 달성합니다. 이는 행렬 점곱을 사용하여 숨겨진 상태를 업데이트하는 방식으로, 상태 확장 비율을 조절할 수 있습니다. 이 구조는 하드웨어 효율적인 GLA 훈련 알고리즘을 사용하여 대규모 실험을 가능하게 합니다.

### 4. 실험 결과
HGRN2는 언어 모델링, 이미지 분류 및 Long Range Arena 벤치마크에서 HGRN1을 능가하는 성능을 보였습니다. 특히, 언어 모델링에서는 기존의 다른 3B 모델들과 비교해도 경쟁력 있는 성능을 보여주었으며, 훈련 토큰의 수가 적음에도 불구하고 우수한 결과를 얻었습니다.

### 5. 결론
HGRN2는 선형 주의와 비매개변수 외적 곱을 사용하여 상태 확장을 구현함으로써, 기존 HGRN1 대비 향상된 성능을 제공합니다. 이 모델은 다양한 벤치마크에서의 성능 향상을 통해 그 유효성이 입증되었습니다.