# AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.15028.pdf](https://arxiv.org/pdf/2405.15028.pdf)

### 1. 각 섹션의 요약 및 주요 기여 내용

#### Introduction
이 논문은 다중-벡터 임베딩(multi-vector embeddings)을 사용한 임의-세분화 랭킹(Any-Granularity Ranking, AGRAME)을 제안합니다. 일반적으로 단일-벡터 임베딩을 사용하면 하나의 벡터만으로 전체 쿼리 및 문서를 나타내는 반면, 다중-벡터 임베딩을 사용하면 토큰 수준에서 더 세밀한 상호작용을 캡처할 수 있습니다.

#### Motivating Experiment
기존 연구에서는 단일 수준에서 인코딩을 수행하고 다중-벡터 임베딩을 이용하여 다양한 세분화 수준에서 랭킹을 수행하는 AGRAME의 필요성을 설명합니다. 여러 실험을 통해 다중-벡터 접근법이 더 높은 세분화에서의 랭킹 성능을 향상시키는지 조사합니다.

#### Method
ColBERTv2라는 다중-벡터 모델을 기반으로 AGRAME을 구현합니다. MaxSim 연산을 통해 각 쿼리 토큰 벡터와 문서 토큰 벡터 간의 상호작용을 계산하여 더 정확한 랭킹 점수를 산출합니다.

#### ColBERTv2 Preliminaries
ColBERTv2는 토큰 수준의 밀집 임베딩을 사용하여 쿼리 및 문서를 인코딩합니다. 주요 차별점은 단일 벡터 임베딩 대신 여러 토큰 임베딩을 사용하여 더욱 세밀한 랭킹이 가능합니다.

#### AGRAME: Any-Granularity Ranking with Multi-Vector Embeddings
AGRaME은 다중-벡터 임베딩을 활용해 다양한 세분화 수준에서 랭킹할 수 있도록 하며, 단일 수준의 인코딩을 유지합니다. 이 접근법을 통해 더 세밀한 쿼리-문서 상호작용을 캡처할 수 있습니다.

#### Multi-Granular Contrastive Training
다중 수준 대조 학습을 도입하여 문장 수준의 랭킹 손실을 추가로 제공함으로써 단락 수준의 인코딩에서 문장 수준의 랭킹 성능을 향상시킵니다.

#### Experiments
다양한 오픈 도메인 질문 응답 데이터셋을 사용하여 AGRAME의 성능을 평가합니다. 실험 결과, AGRAME이 기존 방법들에 비해 더 우수한 성능을 보였습니다.

#### QuerySub-Retrieval Unit Ranking for Open-Domain QA
오픈 도메인 질문 응답에서 쿼리-하위-검색 단위 랭킹의 혜택을 보여줍니다. 문장 수준에서 랭킹 성능이 크게 향상되었습니다.

#### Sub-QuerySub-Retrieval Unit Ranking for Fine-Grained Attribution
미세하게 구분된 속성 매핑에 대한 세분화된 랭킹의 효과를 탐구합니다. 특히, AGRAME은 문장 내 각 주장의 정확한 출처를 찾는 데 강력한 성능을 보였습니다.

#### Sub-QueryRetrieval Unit Ranking for Citation Addition
생성된 텍스트에 원천 정보의 인용을 추가하기 위해 AGRAME을 사용합니다. 제안된 PROPCITE 접근법은 기존의 생성 모델보다 더 정확한 인용 추가를 가능하게 합니다.

#### Conclusion
AGRaME는 다중-벡터 임베딩을 활용하여 다양한 세분화 수준에서의 정확한 랭킹을 가능하게 하며, 특히 문장과 주제 수준에서 뛰어난 성능을 입증했습니다.

### 2. 전체 요약

이 논문에서는 AGRAME(부여된 명칭)이 어떻게 다중-벡터 임베딩을 활용하여 다양한 세분화 수준에서 랭킹을 수행할 수 있는지를 설명합니다. ColBERTv2를 기반으로 한 AGRAME 모델은 MaxSim 연산을 사용하여 각 토큰 수준에서의 상호작용을 계산합니다. 이를 통해 세밀한 쿼리-문서 상호작용을 캡처하고, 더 나아가 세밀한 랭킹 성능을 향상시킬 수 있습니다. 다중-수준 대조 학습을 통해 기존 단일 수준 인코딩보다 더 나은 성능을 보였으며, 특히 문장 및 주제 내 주장의 출처를 정확하게 찾는 데 강력한 성능을 입증했습니다. 주요 응용 사례로는 오픈 도메인 질문 응답 시스템 및 생성된 텍스트에 대한 인용 추가가 포함됩니다.