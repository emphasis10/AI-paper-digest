# MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.08407.pdf](https://arxiv.org/pdf/2406.08407.pdf)

### 논문 요약

#### 1. 서론
현대의 대규모 언어 모델(LLMs) 및 다중 모달 언어 모델(MLLMs)들은 인공지능의 잠재적 경로에 대한 논의를 촉발시키며 텍스트와 이미지 도메인에서 놀라운 능력을 보여주었습니다. 그러나 이 모델들이 실제 세계의 역학을 얼마나 잘 이해하는지에 대한 질문이 남아 있습니다.

#### 2. 관련 연구
기존의 비디오 이해 벤치마크들은 여러 한계가 있습니다. MMWorld는 다양한 학문 분야와 여러 측면의 추론을 요구하는 새로운 벤치마크를 제안합니다. 이 벤치마크는 7개의 주요 학문 영역과 69개의 하위 영역에서 1,910개의 비디오와 6,627개의 질문-응답 쌍을 포함합니다.

#### 3. 데이터셋 및 메소드
MMWorld에는 인간이 주석을 단 데이터셋과 단일 모달리티에서 MLLMs를 분석하기 위한 합성 데이터셋이 포함됩니다. 이 데이터셋은 다양한 학문 분야 및 여러 측면의 추론(예: 설명, 반사적 사고, 미래 예측 등)을 평가하기 위해 설계되었습니다.

#### 4. 평가 및 결과
주요 평가 결과에 따르면 GPT-4V가 최고 성능을 보였고, MMWorld 벤치마크에서 큰 도전을 받고 있습니다. 평균 정확도는 52.3%로 나타났으며, 이는 모델들이 여전히 개선의 여지가 많음을 시사합니다. MLLMs는 인간과 다른 능력을 가지고 있어, 인간이 어려움을 겪는 질문도 해결할 수 있는 반면, 인간이 쉽게 해결하는 질문에서 어려움을 겪기도 합니다.

#### 5. 결론
MMWorld 벤치마크는 다중 모달 언어 모델의 능력을 평가하기 위한 중요한 기준을 제시합니다. 이 벤치마크는 이러한 모델들이 복잡한 비디오 콘텐츠를 이해하고 해석하는 능력을 도전하며, 다양한 학문 분야와 여러 유형의 추론 질문을 포함합니다. 향후 연구는 모델의 성능을 더욱 향상시키는 방향으로 진행되어야 합니다.

---

### 전체 요약

MMWorld라는 새로운 벤치마크는 다중 모달 언어 모델(MLLMs)의 세계 모델링 능력을 평가하기 위해 설계되었습니다. 이 벤치마크는 다양한 학문 분야에서 약 1910개의 비디오와 6627개의 질문-응답 쌍을 포함합니다. MMWorld는 기존 비디오 이해 벤치마크와 달리 다학문 및 다측면 추론을 요구하며, 이를 통해 모델들이 실제 세계의 역학을 얼마나 잘 이해하는지 평가합니다. 주요 평가 결과에 따르면, 모델들은 여전히 여러 도전에 직면하고 있으며, 특히 MMWorld에서의 평가 성과는 아직 개선의 여지가 많습니다. 전반적으로 MMWorld는 다중 모달 언어 모델의 성능을 종합적으로 평가하기 위한 중요한 도구로 자리 잡을 수 있을 것입니다.