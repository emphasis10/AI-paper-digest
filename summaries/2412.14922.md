# RobustFT: Robust Supervised Fine-tuning for Large Language Models under Noisy Response
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.14922.pdf](https://arxiv.org/pdf/2412.14922.pdf)

**1. 각 섹션 요약 및 주요 공헌**

- **서론**  
  대규모 언어 모델(LLM)의 지도 학습(Fine-tuning)은 특정 도메인에 맞춰 모델 성능을 최적화하는 중요한 기술입니다. 지도 학습 데이터는 노이즈를 포함하고 있어, 이를 다루기 위한 강건한 프레임워크의 필요성이 강조됩니다.

- **문제 정의**  
  다운스트림 작업에서 올바르지 않은 레이블 데이터를 식별하는 메커니즘 개발이 목표입니다. 이는 데이터 노이즈를 줄여 모델의 성능을 개선하기 위한 것입니다.

- **방법론**  
  - **개요**: LLM의 강건한 성능을 유지하기 위해 노이즈 감지 및 제거 메커니즘을 포함한 시스템을 구축합니다.
  - **노이즈 감지**: 여러 LLM의 협력 학습을 통해 노이즈 데이터 샘플을 파악하여 더 강력한 감지 메커니즘을 구현합니다.
  - **데이터 제거**: 문맥 강화 추론과 불확실성에 기반한 데이터 선택을 통해 신뢰할 수 있는 레이블을 생성하여 데이터를 정제합니다.
  - **데이터 선택**: 엔트로피 기반 데이터 선택 메커니즘을 통해 고품질의 샘플만을 보존합니다.
  - **종합**: 이러한 데이터를 결합하여 강건한 데이터 세트를 구성합니다.

- **실험 및 분석**  
  성능 개선을 위한 다양한 데이터 세트와의 실험을 통해 ROBUSTFT의 탁월한 성능을 증명했습니다. 더욱이, 다양한 소음 수준에서 견고한 성능을 유지할 수 있도록 설계되었습니다.

- **결론**  
  ROBUSTFT 프레임워크는 다소 미지의 영역인 노이즈에 강한 감독적 미세 조정을 다루고 있습니다. 이는 실제 노이즈 상황과 잘 부합하며, 실질적인 적용 가능성을 입증합니다.

**2. 전체 요약**

이 논문은 대규모 언어 모델의 성능을 개선하기 위해 데이터를 소음으로부터 보호하는 방법론을 제안합니다. ROBUSTFT는 다수의 LLM을 이용해 데이터를 검토하고, 신뢰할 수 있는 데이터를 기반으로 잘못된 레이블을 시정합니다. 실험을 통해 다양한 데이터 셋에서 우수한 성능을 보여 강한 실용성을 갖춘 방법임을 입증하였습니다. 이 방법론은 특히 noisy label 학습에서 고성능을 보이며, 다양한 도메인과 작업에서의 광범위한 적용 가능성을 제공합니다.