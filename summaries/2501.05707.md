# Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.05707.pdf](https://arxiv.org/pdf/2501.05707.pdf)

### Section 별 요약 및 주요 기여

1. **서론**
   - 대형 언어 모델(LLM)은 놀라운 성능을 보여주었지만 학습 데이터에 제한이 있습니다. 자기 개선 기법을 통해 LLM이 자체 생성 데이터를 사용하는 방법이 연구되었습니다. 그러나 자기 개선을 반복할수록 성능 향상이 급감하는 한계가 있습니다. 이 논문에서는 LLM의 멀티에이전트 시스템을 활용해 이러한 한계를 극복하는 새로운 방법을 제안합니다.

2. **멀티에이전트 미세조정**
   - 멀티에이전트 토론 방법을 사용하여 모델을 미세 조정하는 데이터 세트를 생성하고 각 모델을 그 데이터 세트로 전문화합니다. 이 과정은 모델들이 서로 다른 기능을 갖도록 하고, 다양한 응답을 생성하도록 설계되어 지속적인 성능 향상을 가능하게 합니다.

3. **제안 방법의 분석**
   - 제안된 방법은 토론 에이전트와 생성 에이전트로 모델을 전문화함으로써 다양한 데이터 세트를 생성합니다. 이를 통해 각 모델이 다양한 역할을 가질 수 있도록 하여 성능을 향상시킵니다.

4. **정량적 결과**
   - 멀티에이전트 미세조정은 싱글에이전트 미세조정부다 더 뛰어난 성능을 보여주며 반복적인 미세조정을 통해 성능을 크게 향상시켰습니다. 이 방법은 모델이 최초 성능을 넘어 광범위한 문제 해결에 적용될 수 있음을 보여줍니다.

5. **결론 및 제한**
   - 멀티에이전트 미세조정은 참조 모델보다 비용이 높고 훈련과 추론 시간에 더 많은 자원이 필요합니다. 이러한 한계를 극복하기 위해 모델 간의 가중치를 공유하거나 단일 모델로 토론 절차를 증류하는 방법이 필요합니다.

### 전체 요약
이 논문은 대형 언어 모델의 성능을 한 단계 발전시키기 위해 멀티에이전트 시스템을 활용한 새로운 미세조정 기법을 소개합니다. 본 연구에서는 각 모델이 독립적으로 전문화를 이룰 수 있도록 멀티에이전트 토론을 활용하여 다양한 데이터를 기반으로 성능을 지속적으로 향상시켰습니다. 본 연구는 오픈소스 및 상용 모델에 적용 가능하며, 반복적인 미세조정을 통해 정확도와 다양성을 모두 향상시킵니다. 그러나 기존 방법 대비 높은 비용과 시간이 소요되는 점에서 제한이 있어 추가 연구가 필요합니다.