# CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.02193.pdf](https://arxiv.org/pdf/2408.02193.pdf)

### 요약

#### 1. 주요 섹션 요약

**서론**
이 논문에서는 대형 언어 모델(LLM)의 코드 생성 작업에서 성능 격차를 해소하기 위한 새로운 프레임워크인 CodeACT를 제안합니다. LLM은 코드 처리에 뛰어난 성능을 보이며, 상용 제품(예: GitHub Copilot)과 오픈 소스 대안(CodeLlama, DeepSeek-Coder 등)이 존재하지만 성능 격차가 존재합니다. 기존의 방법들은 방대한 양의 합성 데이터를 생성해 모델을 미세 조정하지만, 이는 비효율적입니다.

**기초**
데이터 품질이 양보다 중요하다는 최근 연구를 바탕으로, CodeACT는 Complexity and Diversity Aware Sampling(CDAS) 방법과 Dynamic Pack 패딩 전략을 도입하여 효율을 개선하려고 합니다.

**방법론**
1. **CDAS**: 코드 데이터를 선택할 때 복잡성과 다양성을 고려하여 중요한 데이터를 식별합니다. 외부 LLM 없이 기본 LLM을 활용하여 데이터를 선택합니다.
2. **Dynamic Pack**: 데이터의 길이를 기준으로 정렬하여 패딩 토큰을 최소화하고 자원 사용을 최적화합니다.

**실험**
세 가지 모델(DeepSeek-Coder-Base-6.7B, CodeLlama-Python-7B, CodeLlama-Python-13B)을 다양한 데이터 세트(OSS-Instruct, EVOL-Instruct)로 평가했습니다. CodeACT는 데이터의 40%만 사용하여 성능을 유지하거나 향상시키는 반면, 훈련 시간과 GPU 메모리 사용량을 크게 줄였습니다.

**결론**
CodeACT 프레임워크는 LLM의 성능과 훈련 효율성을 크게 향상시키며, 데이터 선택과 훈련 과정을 최적화하여 경쟁력 있는 오픈 소스 모델을 제공합니다. 향후 연구는 복잡한 코드 데이터의 정확성을 보장하는 메커니즘을 통합하는 것이 중요합니다.

#### 2. 전체 요약

이 논문은 대형 언어 모델(LLM)의 코드 생성 작업에서 성능을 향상시키고 훈련 효율성을 극대화하기 위한 두 가지 주요 방법론인 CDAS와 Dynamic Pack을 제안합니다. CDAS는 데이터의 복잡성과 다양성을 고려하여 중요한 데이터를 식별하고, Dynamic Pack은 패딩 토큰을 최소화하여 자원 사용을 최적화합니다. 실험 결과, CodeACT 프레임워크를 사용하여 데이터의 40%만으로 모델의 성능을 유지하거나 향상시키면서 훈련 시간과 메모리 사용량을 크게 줄일 수 있었습니다. 이 논문은 AI와 머신 러닝 연구에 중요한 기여를 하며, 향후 연구에서는 복잡한 코드 데이터의 정확성을 보장하는 추가 메커니즘이 필요합니다.

이 요약을 통해 AI 및 머신 러닝의 발전에 이바지하기를 기대합니다.