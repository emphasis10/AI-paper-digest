# CodeACT: Code Adaptive Compute-efficient Tuning Framework for Code LLMs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.02193.pdf](https://arxiv.org/pdf/2408.02193.pdf)

### 1번 질문에 대한 답변: 논문의 각 섹션 요약

**I. 서론 (Introduction)**
이 논문은 인공 지능 대형 언어 모델(LLMs)이 코드 관련 작업에서 엄청난 잠재력을 가지고 있지만, 오픈 소스 모델은 여전히 폐쇄 소스에 비해 성능가 오차가 있다는 점을 지적합니다. 기존 방법은 대량의 합성 데이터를 생성해 미세 조정하지만, 비효율적입니다. CodeACT라는 새로운 프레임워크를 소개하며, 복잡성과 다양성이 높은 데이터를 선별하여 고품질 데이터를 선택하고, 패딩 토큰을 최소화하는 전략을 사용해 효율성을 극대화합니다. 이러한 접근은 성능과 자원 사용을 동시에 향상시키며, 오픈 소스 LLM의 능력을 향상시킵니다.

**II. 배경 지식 (Preliminaries)**
데이터셋을 튜닝하기 위해 코드 및 입력 센서스와 해당 응답으로 구성된 데이터 세트를 사용하며, 복잡성 측정의 지표로 이용하는 퍼플렉시티에 대해 설명합니다.

**III. 접근법 (Approach)**
1. **복잡성과 다양성 인식 샘플링 (CDAS)**: 데이터를 선별할 때 펄펙시티와 같은 어려운 샘플을 최적화합니다.
2. **패딩 전략**: 기존 패딩 방법은 비효율적이므로 다이나믹 패딩 및 패킹 전략을 채택하여 효율성을 개선합니다.
3. **Code Adaptive Compute-efficient Tuning (CodeACT)**: 이 프레임워크는 CDAS를 이용해 다양성과 복잡성이 높은 코드를 선택하고, 동적 패킹 전략을 사용하여 효율성을 극대화함으로써 코드 생성을 위한 LLMS의 훈련을 최적화합니다.

**IV. 실험 설정 및 결과 (Experimental Setup and Results)**
CodeACT를 사용하여 코드 LLMs의 성능과 효율성을 향상시키며, 기존의 공백 코드를 사용한 모델보다 우수한 결과를 나타내고 시간이 절감됨을 입증했습니다.

**V. 결론 (Conclusion)**
CodeACT는 오픈 소스 LLMs 모델을 최적화함으로써 성능과 리소스 효율성을 증대시키고, 향후 연구에서는 코드의 정확성을 확인하고 강화하는 메커니즘을 통합해야 한다고 제시합니다.

### 2번 질문에 대한 전체 요약

논문은 CodeACT라는 프레임워크를 제안하며, 이는 코드 LLMs의 훈련 과정에서 데이터 품질과 리소스 효율성을 동시에 최적화하고자 합니다. CDAS와 동적 패킹 전략을 결합함으로써, CodeACT는 코드 처리 작업에서 오픈소스 모델의 성능과 훈련 효율성을 모두 향상시킵니다. 실험 결과, CodeACT는 데이터 사용을 줄이면서도 성능을 개선하며, 경쟁력 있는 오픈소스 모델로 거듭날 수 있음을 보여줍니다. 

이 프레임워크를 통해 AI 분야에서 자원 효율적인 방법으로 성능을 극대화할 수 있음을 강조합니다.