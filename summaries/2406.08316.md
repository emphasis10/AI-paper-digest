# Is Programming by Example solved by LLMs?
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.08316.pdf](https://arxiv.org/pdf/2406.08316.pdf)

### 1. 각 섹션 요약

#### Introduction
프로그래밍 바이 이그젬플(PBE)은 주어진 입력-출력 예시에서 알고리즘을 생성하는 시스템입니다. 이 논문은 PBE 문제를 해결하기 위해 대형 언어 모델(LLM)이 얼마나 효과적인지를 조사합니다. LLM을 세 가지 도메인(벡터의 알고리즘, 문자열 매크로 조작, LOGO 그래픽 프로그래밍)에 대해 실험하고 결과를 분석했습니다. 미리 훈련된 모델은 거의 효과적이지 않으며, 오직 미세 조정(tuning)을 통해서만 높은 성능을 보일 수 있습니다.

#### Methodology
기본 프롬프트를 통해 모델을 훈련시키는 가장 간단한 방법을 설명했습니다. 미세 조정을 통해 훈련된 모델은 기존 프롬프트 방식보다 더 높은 성능을 보입니다. 이를 위해 입력-출력 예제를 포함하는 작은 데이터 세트(Dseed)를 사용하여 프로그램 예제와 입력을 생성한 뒤, 프로그램 실행 결과를 통해 출력(Y)을 예측하여 큰 데이터 세트(Dtune)를 구성했습니다. 이는 모델이 여러 도메인에서 프로그래밍을 수행할 수 있도록 학습합니다.

#### Experiments
세 가지 도메인에서 LLM 접근 방식으로 PBE를 수행하였고 실험 결과를 분석했습니다:
1. 리스트 기능: 숫자 벡터를 변환하는 알고리즘을 발견합니다.
2. 텍스트 편집: 문자열 매크로 조작기를 사용하여 문서나 스프레드시트를 편집합니다.
3. LOGO/Turtle 그래픽: 주어진 이미지를 생성하는 프로그램을 합성합니다.

모델의 결과는 미세 조정된 모델이 기존 기법들보다 뛰어나다는 것을 보여주었으며, 새로운 도메인에 대한 적응력 역시 높음을 확인하였습니다.

#### Results
실험 결과는 미세 조정된 LLM이 여러 도메인에서 뛰어난 성능을 보인다는 것을 보여줍니다. 특히 더 복잡하고 익숙하지 않은 도메인에서도 높은 정확도를 보였습니다. 또한, 데이터 적응 방법을 통해 도메인 간 성능 격차를 줄일 수 있음을 발견하였습니다.

#### Discussion
LLM이 생성하는 프로그램의 성공 미비를 분석했습니다. 입력-출력 예제에 대해 높은 확률의 올바른 솔루션을 생성하는 경향이 있지만, 드문 오류나 분포 밖 예제에서의 성능 저하가 존재합니다. 따라서, LLM의 미세 조정 및 데이터 적응의 중요성을 강조했습니다.

#### Conclusion
LLM을 사용한 PBE는 특정 도메인 내에서 높은 성능을 보입니다. 하지만, 현실 세계의 복잡한 문제를 해결하기 위해서는 더 많은 연구와 최적화가 필요합니다. 이 연구는 LLM의 가능성을 보여주며, 확대된 문제 해결 도메인을 다룰 수 있는 잠재력을 가지고 있습니다.

### 2. 전체 요약
이 논문은 대형 언어 모델(LLM)이 주어진 입력-출력 예제에서 알고리즘을 생성하는 프로그래밍 바이 이그젬플(PBE) 문제를 해결하는 능력을 탐구합니다. 연구는 세 가지 도메인에서 실험되었으며, 벡터 알고리즘, 문자열 매크로, LOGO 그래픽 프로그램이 포함됩니다. 미세 조정된 모델은 기존의 방법을 능가하는 성과를 보였으며 새로운 도메인에 대한 적응력도 높은 것으로 나타났습니다. 그러나 현실의 복잡한 문제를 해결하기 위해서는 더 많은 연구가 필요합니다. 초기의 프롬프팅 방식보다 데이터 적응 및 미세 조정이 중요한 역할을 하며, LLM의 가능성과 한계를 모두 탐구합니다.

이 논문의 주요 기여는 LLM의 PBE 성능을 세 가지 다양한 도메인에서 평가하고, 미세 조정과 데이터 적응을 통해 성능을 크게 향상시킬 수 있음을 보여주었다는 점입니다. 이를 통해 복잡하고 다양한 문제 해결에 대한 가능성을 열어줍니다.

## Similar Papers
- [Case2Code: Learning Inductive Reasoning with Synthetic Data](2407.12504.md)
- [How Far Can Transformers Reason? The Locality Barrier and Inductive Scratchpad](2406.06467.md)
- [Invertible Consistency Distillation for Text-Guided Image Editing in Around 7 Steps](2406.14539.md)
- [Yuan 2.0-M32: Mixture of Experts with Attention Router](2405.17976.md)
- [Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities](2406.14562.md)
- [PERSONA: A Reproducible Testbed for Pluralistic Alignment](2407.17387.md)
- [BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions](2406.15877.md)
- [Evaluating the World Model Implicit in a Generative Model](2406.03689.md)
- [GLiNER multi-task: Generalist Lightweight Model for Various Information Extraction Tasks](2406.12925.md)
