# Enhancing CTC-based speech recognition with diverse modeling units
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.03274.pdf](https://arxiv.org/pdf/2406.03274.pdf)

### 1. 논문 요약

#### 제 1 장: 서론
최근에는 심층 학습 아키텍처인 Transformer의 발전으로 엔드 투 엔드(E2E) 자동 음성 인식 (ASR) 모델이 크게 향상되었습니다. 이 논문에서는 Phoneme 및 Grapheme 기반 모델의 장점을 통합하여 다양한 모델링 유닛을 함께 학습하는 새로운 전략을 제안합니다. 이러한 접근법은 모형 정확도를 크게 향상시키며, ASR 시스템 개발에서 이종 모델링 유닛의 최적 통합에 대한 새로운 통찰을 제공합니다.

#### 제 2 장: 방법론 
- **백본 모델**: 기본 모델은 conformer 기반의 인코더를 사용하여 오디오 피처를 고수준 표현으로 매핑합니다. 
- **음향 모델 결합**: 외부 phoneme 기반 음향 모델(AM)을 E2E 시스템에 통합하여 다중 패스 인식 동안 최상의 가설을 선택합니다.
- **다중 모델링 유닛 공동 학습**: CTC 손실을 추가하여 다양한 유닛(예: 문자, 음소)으로 모델을 학습시키는 방법을 제안합니다. 이를 통해 처음부터 최적의 가설을 찾고 마지막 단계의 인식 정확도를 높입니다.

#### 제 3 장: 실험
- **개요**: 12층 conformer 인코더와 6층 Transformer 디코더로 구성된 모델을 사용합니다.
- **LibriSpeech 데이터셋**: 기본 wordpiece CTC-AED 모델 외에 phoneme 및 character CTC 모델도 학습되었습니다. N-Best 가설을 re-scoring하여 WER(Word Error Rate)를 측정합니다.
- **AISHELL-2 데이터셋**: 중국어 데이터를 사용하여 logographic 표현 (Pinyin 및 Wubi)을 평가합니다. 해당 데이터셋에서도 유사한 향상을 확인했습니다.

#### 제 4 장: 결론
다양한 모델링 유닛을 학습 중에 결합하여 인식 정확도를 크게 향상시킬 수 있습니다. 특히 발음 정보를 효과적으로 통합하여 모델의 전체 성능을 향상시키는 방법에 대한 새로운 접근법을 제시합니다.

### 2. 주요 기여와 혁신적인 부분
이 논문은 다음과 같은 주요 기여와 혁신적인 부분을 포함합니다:
1. **공동 학습 전략 제안**: 다중 모델링 유닛(문자, 음소 등)을 결합하여 학습함으로써 객관적인 인식 정확도를 개선하였습니다.
2. **레이어 매칭 조사**: 적절한 레이어와 모델링 유닛 간의 매칭을 조사하여 최적의 학습 효율성을 달성하였습니다.
3. **AM 결합 작업 확장**: AM 결합 없이도 대체 유닛 기반 모델로 WER을 개선하였습니다.

### 3. 전체 요약
이 논문은 최근 E2E ASR 모델의 진보를 바탕으로 phoneme과 grapheme 기반 모델의 장점을 결합한 새로운 학습 전략을 제안합니다. 이를 통해 모델의 인식 정확도를 높이고, logographic 언어 (예: 중국어)에서도 유사한 개선을 보였습니다. 주로 다층 인코더와 디코더를 활용하여 발음 정보를 효과적으로 통합하여 다중 유닛 공동 학습을 통해 전반적인 성능 향상을 달성하였으며, 인식 과정의 효율성을 높이는데 기여하였습니다.