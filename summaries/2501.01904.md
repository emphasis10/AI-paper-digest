# Virgo: A Preliminary Exploration on Reproducing o1-like MLLM
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.01904.pdf](https://arxiv.org/pdf/2501.01904.pdf)

1. 각 섹션의 요약:

- **Introduction (소개)**:
  이 논문은 최근 주목받고 있는 '슬로우 싱킹' 논리 시스템을 연구합니다. 이 시스템은 대형 언어 모델(LLM)에 기반하여, 복잡한 문제를 해결할 때 논리적인 사고 시간을 확장하는 방식으로 성능을 향상시킵니다. 특히, 다중 모달 LLM(MLLM)에 이 기능을 어떻게 적용할지에 대한 도전과제를 제기하고 있습니다.

- **Method (방법론)**:
  MLLM을 슬로우 싱킹 능력을 갖추도록 하기 위해, 두 가지 방법을 탐구합니다. 첫째는 '텍스트 기반 롱 쓰롯 데이터'로 슬로우 싱킹 능력을 전이하는 것이며, 둘째는 기존 슬로우 싱킹 MLLM으로부터 다중 모달 롱 쓰롯 데이터를 증류하는 것입니다. 이 방법론에서는 Virgo라는 시스템을 구현하여 실험을 진행합니다.

- **Experiments (실험)**:
  Virgo는 수학, 과학, 코드, 퍼즐 등의 다양한 도메인에서 수집된 데이터를 사용하여 실험을 진행합니다. 실험 결과는 Virgo가 상업적 시스템과 비교할 때 경쟁력 있는 성능을 보였고, 가장 중요하게 텍스트 기반 논리 지시가 다중 모달 데이터보다 더 효과적임을 발견했습니다.

- **Conclusion (결론)**:
  이 연구는 MLLM을 간단하게 텍스트 기반의 롱 쓰롯 데이터로 훈련함으로써 슬로우 싱킹 능력을 크게 향상시킬 수 있음을 입증했습니다. 하지만 논문의 성취는 초기 단계에 불과하며, 더 발전된 다중 모달 슬로우 싱킹 시스템 개발을 위한 기초가 될 것입니다.

2. 전체적인 요약:

이 논문은 다중 모달의 복잡한 문제를 해결하기 위한 슬로우 싱킹 논리 시스템을 구현하려는 접근을 다루고 있습니다. 주요 질문은 두 가지입니다: 첫째, 텍스트 기반 롱 쓰롯 데이터로 다중 모드간의 슬로우 싱킹 능력이 전이될 수 있는가? 둘째, 슬로우 싱킹 능력이 시각적 논리 데이터와 비교할 때 어느 정도 성능을 발휘할 수 있는가? Virgo라는 시스템을 개발하여 실험을 통해 상업적 시스템과 유사한 성능을 달성했으며, 텍스트 기반의 접근 방식이 효과적임을 확인했습니다. 이 연구의 혁신적인 점은 MLLM의 언어 모델을 활용하여 모드 간, 또는 도메인 간의 슬로우 싱킹 능력을 전이할 수 있는 가능성을 발견한 것입니다.