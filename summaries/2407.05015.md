# How do you know that? Teaching Generative Language Models to Reference Answers to Biomedical Questions
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.05015.pdf](https://arxiv.org/pdf/2407.05015.pdf)

### 1. 각 섹션의 중요한 내용 요약 및 주된 기여와 혁신적 요소 설명

#### 소개 (Introduction)
이 논문은 대형 언어 모델(LLMs)이 사용자 질문에 대한 답변을 제공하는데 활용되면서도, 특히 바이오 메디컬과 같은 민감한 분야에서의 사실 정확성과 신뢰성 문제를 해결하고자 합니다. 논문은 PubMed에서 관련 초록을 검색하고 이를 기반으로 참조된 답변을 생성하는 바이오메디컬 RAG 시스템을 소개하며, 이 시스템은 23%의 향상된 성능을 보였습니다.

#### 관련 연구 (Related Work)
LLMs의 생성된 내용의 신뢰성 및 검증 가능성에 관한 다양한 연구를 검토하며, 특히 LLM이 내부적으로 학습한 정보와 외부에서 검색한 정보를 혼합하여 참조를 생성하는 방법에 주목합니다. 기존 연구들은 생성을 통해 제공되는 정보의 불확실성과 높은 오류율을 강조합니다.

#### 정보 검색 구성요소 (Information Retrieval Component)
이 시스템은 PubMed 데이터베이스를 활용한 기존의 BM25 기반의 문헌 검색과, 의미적 검색을 결합한 하이브리드 검색 시스템을 사용합니다. 이 하이브리드 검색 시스템은 정확도가 개선된 검색 결과를 제공합니다.

#### 생성 구성요소 (Generative Component)
생성 모델은 Mistral-7B을 사용하며, 사용자 질문과 관련된 PubMed 초록을 검색하고, 이를 기반으로 답변을 생성합니다. 모델은 GPT-4 Turbo와 비교 시 유사한 성능을 보입니다. 특히, 답변 내 각 주장에는 참조된 초록이 명시되어 있어 사용자들은 답변의 검증이 가능합니다.

#### 데이터셋 (Dataset)
모델을 튜닝하기 위해 PubMedQA 데이터셋을 사용하여  nine-thousand-seventy-five 개의 질문과 10 개의 관련 초록으로 구성된 커스텀 데이터셋을 생성했습니다. 답변 생성에는 향상된 지침 준수 능력을 갖춘 GPT-4 Turbo 모델을 사용하여 문제의 답변을 생성했습니다.

#### 모델 튜닝 (Fine-tuning the models)
모델 튜닝은 QLoRA 방법론을 사용해 수행했으며, fine-tuned 모델들은 GPT-4 Turbo와 비교할 수 있는 성능을 보였습니다. 두 모델 모두 32시간 안에 40GB NVIDIA GPU로 학습되었습니다.

#### 시스템 평가 (System Evaluation)
IR 구성요소와 생성 구성요소 모두 별도로 평가되었으며, 하이브리드 검색 시스템은 PubMed 검색엔진 대비 23% 향상된 성능을 보였습니다. 생성 모델의 경우, fine-tuned Mistral-7B 모델이 가장 높은 성능을 보였으며, GPT-4 Turbo와 비교하여 유사한 성능을 보였습니다.

#### 결론과 미래 작업 (Conclusions and Future Work)
본 논문은 바이오메디컬 도메인에서의 참조된 질의응답 시스템을 개발하여 정확하고 검증 가능한 답변을 생성하는 데 성공하였음을 설명합니다. 향후 연구에서는 자동 평가 방법을 통한 참조된 QA 품질 평가와 더 나아가 큰 샘플에서의 추가 품질 평가가 필요합니다.

### 2. 전체 요약
이 논문은 대형 언어 모델(LLMs)이 바이오메디컬 도메인에서 정확하고 검증 가능한 답변을 생성하기 위한 RAG 시스템을 제안합니다. 이 시스템은 PubMed 데이터베이스에서 관련 초록을 검색하여 모델의 생성 답변을 참조 가능한 형태로 출력합니다. 연구 결과, fine-tuned Mistral-7B 모델은 GPT-4 Turbo와 비교하여 유사한 성능을 보였으며, 검색엔진 성능 대비 23% 개선된 결과를 보였습니다. 향후 연구는 대규모 샘플을 활용한 자동화된 평가 방법을 통해 시스템의 효율성을 더욱 증진시키는 방향으로 진행될 것입니다.

## Similar Papers
- [Not All Language Model Features Are Linear](2405.14860.md)
- [Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting](2407.08223.md)
- [GLiNER multi-task: Generalist Lightweight Model for Various Information Extraction Tasks](2406.12925.md)
- [Pre-Trained Foundation Model representations to uncover Breathing patterns in Speech](2407.13035.md)
- [Exploring Advanced Large Language Models with LLMsuite](2407.12036.md)
- [MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases](2402.14905.md)
- [RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation](2408.02545.md)
- [Towards a Personal Health Large Language Model](2406.06474.md)
- [Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation](2406.13663.md)
