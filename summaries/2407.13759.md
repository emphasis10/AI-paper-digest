# Streetscapes: Large-scale Consistent Street View Generation Using Autoregressive Video Diffusion
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.13759.pdf](https://arxiv.org/pdf/2407.13759.pdf)

### 섹션별 요약

#### 1. 소개
본 논문에서는 도심 환경의 장거리, 3D 일관된 뷰를 생성하는 새로운 방법론인 "Streetscapes"를 제안합니다. 기존의 텍스트-비디오, 텍스트-3D 생성 방법은 단거리 또는 개별 객체 생성에 국한되었지만, 본 연구는 도시의 도로를 따라 이동하면서 일관된 시각적 품질을 유지하는 장거리 카메라 경로를 생성합니다. 이를 위해 오버헤드 장면 레이아웃(지도와 고도 지도)을 사용하여 생성 과정을 제어하고, 텍스트 입력을 통해 스타일(날씨와 시간대)을 지정할 수 있습니다.

#### 2. 관련 연구
기존의 많은 컴퓨터 그래픽스 연구는 주어진 환경 모델을 기반으로 효율적인 가시성 처리에 중점을 두었지만, 본 연구는 최신 신경망 생성 방법을 사용하여 도시 장면을 실시간으로 생성하는 데 중점을 둡니다. 특히, 3D와 비디오 생성을 위한 디퓨전 모델에 대한 최근 연구들이 본 논문의 기반이 됩니다.

#### 3. 세부 기술
##### 3.1 디퓨전 모델의 배경
디퓨전 모델은 무작위 노이즈 이미지를 순차적으로 복원하여 고품질의 이미지를 생성합니다. 이 과정에서 카메라 뷰를 고려한 레이아웃 정보를 입력 받아 장면 일관성을 유지합니다.

##### 3.2 레이아웃 기반 장면 생성
기존의 텍스트-이미지 디퓨전 모델을 두 개의 카메라 뷰로 확장하고 애니메이션 모듈을 도입하여 두 프레임씩 생성합니다.

##### 3.3 자율회귀적 시간 전이 방식
사전 학습된 두 프레임 생성 모델을 수정하여, 현재 프레임을 다음 카메라 뷰로 이동시키는 과정을 통해 일관된 장거리 비디오 시퀀스를 생성합니다.

#### 4. 실험 결과
본 논문에서는 실제 거리 이미지와 비교하여 높은 정확성을 유지하면서 장거리 시퀀스를 생성할 수 있음을 실험적으로 입증하였습니다. 짧은 거리 생성에서는 현재 저명한 방법들과 동일한 수준의 성능을 보이며, 장거리 생성에서는 일관성을 유지합니다. 또한, 텍스트 입력을 통해 다양한 스타일과 기후 조건을 반영한 시가지 뷰를 생성할 수 있습니다.

### 중요한 기여 및 혁신적인 부분
본 논문의 주요 기여는 다음과 같습니다:
1. **새로운 자율회귀적 시간 전이 방식**: 이는 장거리 시퀀스를 생성하면서도 시각적 일관성을 유지하게 합니다.
2. **오버헤드 장면 레이아웃을 활용한 생성 제어**: 이는 텍스트 입력을 통해 스타일과 기후 조건을 반영할 수 있게 합니다.
3. **실제 거리 데이터를 활용한 학습**: Google Street View에서 추출한 대규모 데이터셋을 활용하여 현실성을 높였습니다.

### 전체 요약
본 논문은 도시 환경에서 장거리, 일관성을 유지하는 3D 뷰를 생성하는 혁신적인 방법인 Streetscapes를 제안합니다. 이는 디퓨전 모델과 오버헤드 장면 레이아웃을 활용하여 고품질의 장거리 비디오 시퀀스를 생성할 수 있게 하며, 현실적인 데이터셋으로 학습하여 높은 정확도를 보장합니다. 텍스트 입력을 통해 다양한 스타일을 반영할 수 있어 실용적인 응용 가능성이 큽니다.

이번 논문의 기여는 AI 및 컴퓨터 그래픽스 분야의 발전에 큰 도움이 될 것입니다.

## Similar Papers
- [RELIC: Investigating Large Language Model Responses using Self-Consistency](2311.16842.md)
- [CamViG: Camera Aware Image-to-Video Generation with Multimodal Transformers](2405.13195.md)
- [Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization](2404.09956.md)
- [Vid3D: Synthesis of Dynamic 3D Scenes using 2D Video Diffusion](2406.11196.md)
- [Matting by Generation](2407.21017.md)
- [Controlling Space and Time with Diffusion Models](2407.07860.md)
- [Image Conductor: Precision Control for Interactive Video Synthesis](2406.15339.md)
- [LogoMotion: Visually Grounded Code Generation for Content-Aware Animation](2405.07065.md)
- [CamCo: Camera-Controllable 3D-Consistent Image-to-Video Generation](2406.02509.md)
