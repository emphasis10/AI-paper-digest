# DeepCritic: Deliberate Critique with Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2505.00662.pdf](https://arxiv.org/pdf/2505.00662.pdf)

### 1. 주요 내용 요약

1. **서론 (Introduction)**
    - 이 논문은 대형 언어 모델(LLM)의 난제 중 하나인 수학적 비판 능력 향상을 목표로 합니다. 기존의 LLM 비평가들은 피드백이 상형적이고 피상적이라 에러 판단의 정확도가 낮습니다. 이를 해결하기 위해, 이 논문은 두 단계의 프레임워크를 제안하였습니다. 첫 번째 단계에서는 LLM 비평 모델이 보다 깊고 다양한 시각에서의 비평을 생성할 수 있도록 4,500개의 비평 데이터를 생성하였고, 두 번째 단계에서는 강화 학습을 통해 모델의 비평 능력을 더욱 개선하였습니다.

2. **관련 연구 (Related Work)**
    - LLM 비평가의 비평 능력 개선이 중요성에 대해 다루며, 기존 연구에서는 LLM의 자기진화 및 자동 감독 방안으로 LLM을 비평가로 사용하는 방법이 제안되었습니다. 이 연구는 특히 수학적 비판 능력을 개선하여, 자동화된 스케일러블 감독을 가능하게 합니다.

3. **방법론 (Methodology) - 심층 비평 모델 개발**
    - 비평 모델의 첫 번째 단계에서는 Qwen2.5-72B-Instruct 모델을 사용해 비평 데이터를 생성하고, 수퍼바이즈드 파인튜닝(SFT)을 통해 초기 비평 모델을 개발합니다. 두 번째 단계에서는 RL(강화 학습)을 통해 비평 모델의 깊은 비평 능력을 향상시킵니다.

4. **실험 및 분석 (Experiments and Analysis)**
    - 다양한 에러 식별 벤치마크를 사용해 비평 및 판단 성능을 체계적으로 평가합니다. DeepCritic 모델은 기존 모델들보다 우수한 성능을 보여주며, 특히 비평 정밀도와 모델의 발전 가능성을 드러냈습니다.

5. **결론 (Conclusion)**
    - 연구의 중요한 기여는 LLM의 수학적 비평 능력을 두 단계의 학습 프로세스를 통해 획기적으로 향상시킴으로써, 자동화된 감독 및 지속적인 개선을 가능하게 한다는 점입니다. 이는 LLM의 자기개선과 자동화된 비평 프로세스에 대한 귀중한 통찰력을 제공합니다.

### 2. 논문의 전반적인 요약

이 논문은 대형 언어 모델(LLM)의 수학적 비평 능력을 향상시키기 위해, DeepCritic이라는 새로운 두 단계의 학습 프레임워크를 제안합니다. 첫째, LLM이 피드백을 보다 깊고 다양하게 제공할 수 있도록 심층 비평 데이터를 생성하여 수퍼바이즈드 파인튜닝을 수행합니다. 둘째, 강화 학습을 통해 이러한 비평 능력을 더욱 강화합니다. 연구의 실험 결과, 개발된 DeepCritic 모델은 기존의 다양한 비평 모델들에 비해 우수한 성능을 보여주었으며, 특히 정확하고 체계적인 피드백 제공으로 LLM 생성기를 개선할 수 있는 가능성을 입증하였습니다.