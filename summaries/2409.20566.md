# MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.20566.pdf](https://arxiv.org/pdf/2409.20566.pdf)

### 1. 섹션 요약

**Abstract**
이 논문에서는 MM1.5라는 새로운 멀티모달 대규모 언어 모델(MLLM) 가족을 소개합니다. 이 모델은 텍스트가 풍부한 이미지 이해, 시각적 참조 및 그라운딩, 다중 이미지 추론 능력을 향상시키기 위해 설계되었습니다. 그 동안의 훈련 과정에서 다양한 데이터 혼합의 영향을 체계적으로 탐구하며 고품질로 합성된 캡션과 OCR 데이터를 활용해 모델 성능을 개선했습니다.

**Introduction**
멀티모달 대규모 언어 모델(MLLM)은 최근 몇 년 동안 주요 연구 주제가 되었습니다. MM1의 성공을 기반으로, MM1.5는 핵심 기능 강화를 목표로 하며 특히 OCR을 사용해 고해상도의 이미지 이해 능력을 향상시켰습니다. 이 모델은 텍스트가 풍부한 이미지와 여러 이미지, 비디오 이해 등 다양한 데이터를 활용해 강력한 성능을 보여줍니다.

**Related Work**
이 섹션에서는 기존의 유사 연구들을 소개하고 MM1.5가 기존 모델들과 어떻게 차별화되는지 설명합니다. 예를 들어, LLaVA, InternVL2, Cambrian-1 등의 오픈 소스 모델들이 있으며, 이들의 성능과 비교해 MM1.5가 갖는 장점을 논의합니다.

**Methods**
MM1.5 모델은 세가지 단계의 훈련 과정을 거칩니다. 첫 번째는 대규모 저해상도 이미지 사전 훈련, 두 번째는 고해상도 지속 훈련, 마지막으로 감독된 미세 조정입니다. 각 단계에서는 특별히 텍스트가 풍부한 이미지 데이터를 활용해 성능을 최적화합니다.

**Experiments**
다양한 벤치마크 테스트를 통해 모델의 성능을 검증했습니다. 특히, OCR 성능, 텍스트-이미지 매칭, 다중 이미지 추론 등의 성능을 평가했으며 다른 최신 모델들에 비해 우수한 성능을 입증했습니다.

**Conclusion**
MM1.5는 기존 MM1 모델의 성공을 기반으로 하여 여러 개선점을 추가한 새로운 MLLM입니다. 이 모델은 특히 여러 이미지와 비디오 데이터를 동시에 처리할 수 있는 높은 이해 능력을 보입니다. 모델의 지속 훈련과 고해상도 이미지 처리, 데이터 혼합 최적화가 주된 개선점입니다.

### 2. 전체 요약
이 논문은 MM1이라는 모델의 성공을 기반으로, MM1.5라는 최신 멀티모달 대규모 언어 모델을 소개합니다. MM1.5는 텍스트-이미지 매칭, 다중 이미지 추론, 고해상도 이미지 이해 등에서 뛰어난 성능을 보입니다. 모델의 성능을 높이기 위해 지속 훈련과 고해상도 이미지 처리를 도입했으며, 특히 텍스트가 풍부한 이미지 데이터를 사용했습니다. 다양한 벤치마크 테스트 결과, 최신 모델들에 비해 우수한 성능을 입증했으며, 앞으로의 연구에 큰 도움이 될 것으로 기대됩니다.