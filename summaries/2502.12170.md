# MUDDFormer: Breaking Residual Bottlenecks in Transformers via Multiway Dynamic Dense Connections
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.12170.pdf](https://arxiv.org/pdf/2502.12170.pdf)

### 1. 논문 각 섹션 요약:

**서론**  
MUDDFormer는 초심플한 방법을 제안하여 잔차 연결의 한계를 해결하고, 트랜스포머 내 계층 간 정보 흐름을 강화합니다. 기존의 방법들이 정적이고 공유된 연결 가중치를 사용한 반면, MUDD는 각 시퀀스 위치와 분리된 입력 스트림에 따라 가중치를 동적으로 생성합니다. MUDDFormer는 다양한 모델 구조와 규모에서 기존 트랜스포머보다 뛰어난 성능을 보여줍니다.

**방법**  
트랜스포머 디코더에 여러 계층의 동적 밀집 연결을 통합하여 Cross-Layer Communication을 강화합니다. MUDD는 깊이-방향 다중 머리 주의와 유사하며, 잔차 스트림의 제한을 넘어 크로스 레이어 통신 대역폭을 확장합니다.

**실험 및 결과**  
MUDDFormer는 여러 테스트에서 기존의 트랜스포머를 뛰어넘는 성능을 보여줍니다. 단어 예측과 같은 미리 훈련된 언어 모델링에서 약 1.8배에서 2.4배의 계산 성능을 확인하였습니다. MUDDFormer는 더욱 적은 매개변수와 계산만으로 Pythia-12B와 유사한 성능을 보여줍니다.

**결론**  
MUDD 연결은 잔차 연결의 한계를 해결하며 차세대 기초 모델에 필수 구성 요소가 될 수 있습니다. 실험 결과에서 MUDDFormer는 언어와 비전 작업에서 트랜스포머의 기준을 크게 능가하며, emergent abilities의 향상에 기여했습니다.

### 2. 전체 요약:
이 논문은 잔차 연결의 문제를 해결하기 위해 MUltiway Dynamic Dense (MUDD) 연결 방식을 제안합니다. 이 방식은 정적 가중치 대신, 각 시퀀스 위치와 입력 스트림에 따라 동적으로 가중치를 생성하여, 크로스 레이어 정보 흐름을 크게 강화합니다. 다양한 실험을 통해 MUDDFormer는 기존 트랜스포머보다 뛰어난 성능을 보이며, 특히 단어 예측과 같은 작업에서 높은 성취를 나타냈습니다. MUDD 연결은 트랜스포머의 효율성을 높여 앞으로의 인공지능 연구와 발전에 기여할 가능성이 큽니다.