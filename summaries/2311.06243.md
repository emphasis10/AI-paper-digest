# Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization
## TL;DR
## Summary
- [https://arxiv.org/pdf/2311.06243.pdf](https://arxiv.org/pdf/2311.06243.pdf)

### 1. 섹션 요약

#### Abstract 및 Introduction
이 논문에서는 대규모 모델의 효율적다운스트림 타스크 적응을 위한 정교한 파인튜닝 패러다임, 즉 직교 파인튜닝(OFT)에 대해 연구합니다. 기존의 직교 행렬의 고차원성으로 인해 많은 수의 파라미터를 필요로 하는 문제를 해결하기 위해, 이 논문에서는 Cooley-Tukey의 빠른 푸리에 변환 알고리즘에서 영감을 받아 나비(fly) 구조를 이용해 효율적인 직교 파라미터화를 제안합니다. 이 방법은 OFT를 포함하여 더 일반화된 직교 파인튜닝 프레임워크를 형성하게 됩니다.

#### Orthogonal Finetuning (OFT)
OFT는 신경망의 같은 레이어의 모든 뉴런을 동일한 직교 행렬로 변환하여 뉴런 간의 쌍각(pairwise angle)을 보존하는 파인튜닝 방식입니다. 하지만 고차원 직교 행렬 때문에 파라미터 수가 많아지는 문제가 있습니다. 이를 해결하기 위해 블록 대각선 구조를 도입해 파라미터 수를 줄입니다. 이 방법은 구조적 특성을 유지하면서도 과적합을 방지해 주는 장점을 가지고 있습니다.

#### Orthogonal Butterfly (BOFT)
BOFT는 GOFT의 일반화된 프레임워크로, 여러 개의 희소 직교 행렬로 구성된 파라미터라이저를 통해 효율적인 파인튜닝을 가능하게 합니다. 이 방법은 모델 학습 중에 사용된 희소 행렬의 곱으로 표현되어 파라미터 수를 크게 줄이면서도 높은 성능을 유지할 수 있게 해줍니다. 또한, 이 방법은 파라미터 수를 최소화하는 새로운 방식으로 정보 전송 문제를 해결합니다.

#### 실험 및 결과
실험에서는 BOFT를 다양한 대형 언어 모델(DeBERTaV3, Llama-2), 비전(vision) 모델(DINOv2), 텍스트-이미지 생성 모델(Stable Diffusion)에 적용하였으며, 그 결과 기존 방법들보다 더 나은 성능을 보였습니다. 특히, GLUE 벤치마크와 VTAB-1K에서 상당한 성능 향상을 보여 주었으며, 실험 결과는 평균적으로 5회 실행한 결과를 나타내며 p < 0.05의 유의미한 테스트를 통과하였습니다.

#### 결론 및 한계
BOFT는 직교 네트워크를 구성하기 위한 다양한 요소들이 결합되어 효율적으로 학습할 수 있는 새로운 파인튜닝 방법을 제안합니다. BOFT의 주요 장점은 훈련 후 추가 추론 지연(latency) 없이 모델을 사용할 수 있다는 점입니다. 하지만 최종 직교 행렬이 여러 개의 직교 행렬의 곱으로 이루어져 있어 훈련 속도면에서 오버헤드가 발생할 수 있습니다. 이를 개선하는 것은 앞으로의 연구 과제로 남아 있습니다. 이 연구는 향후 네트워크 효율성에 대한 연구에서도 많은 영감을 줄 것으로 기대됩니다.

### 2. 전체 요약
이 논문은 대규모 AI 모델을 효율적으로 파인튜닝하기 위한 혁신적인 방법론, Orthogonal Butterfly (BOFT)를 제안합니다. BOFT는 Cooley-Tukey 빠른 푸리에 변환 알고리즘에서 영감을 받아 여러 개의 희소 직교 행렬을 사용하여 모델의 파라미터 수를 크게 줄이면서도 높은 성능을 유지할 수 있게 해줍니다. 이 방법론은 다양한 대형 언어 모델, 비전 모델, 텍스트-이미지 생성 모델에서 실험되었으며, 기존의 방법들보다 뛰어난 성능을 보여줍니다. 특유의 파라미터 효율성과 훈련 후 추가 추론 지연이 발생하지 않는 장점이 있으며, 앞으로의 연구에서도 다양한 응용 가능성을 시사합니다.

---

위와 같은 요약을 바탕으로 프레젠테이션을 진행할 수 있습니다. 논문에서 BOFT의 혁신성과 실험 결과를 강조하여 설명하면 좋은 발표가 될 것입니다.