# MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.01574.pdf](https://arxiv.org/pdf/2406.01574.pdf)

### 요약

#### 1. 요약 (섹션별)
##### Abstract
현대의 대규모 언어 모델들은 다양한 분야에서 언어 이해와 추론 능력을 확장하고 있지만, MMLU(Massive Multitask Language Understanding) 벤치마크에서의 성능이 점차 포화 상태에 도달하고 있습니다. 이를 해결하기 위해 MMLU-Pro라는 향상된 데이터셋이 소개되었습니다. MMLU-Pro는 더 도전적이고 추론 중심의 질문을 포함하며, 선택지를 네 개에서 열 개로 확장하여 모델의 능력 차이를 더 명확히 구별합니다. 실험 결과, MMLU-Pro는 모델의 정확도를 16%에서 33%까지 낮추며, 다양한 프롬프트 스타일에 대한 민감도를 줄여 더 큰 안정성을 보였습니다. 또한, Chain of Thought(CoT) 추론을 사용하는 모델이 더 나은 성능을 보여주었습니다.

##### Introduction
최근 몇 년간, 대규모 언어 모델(LLM)의 발전은 자연어 처리(NLP) 분야를 크게 변화시켰습니다. GPT-4, Gemini, Claude와 같은 최신 모델들은 다양한 작업에서 뛰어난 성능을 보여주고 있습니다. 이 연구의 주요 목표는 다양한 작업에서 상위 10% 수준의 성능을 달성하는 전문가 수준의 지능을 확보하는 것입니다.

##### The MMLU-Pro Benchmark
MMLU-Pro는 기존 MMLU보다 더 도전적이고 추론 중심의 질문을 포함하는 데이터셋입니다. 14개의 학문 분야에서 총 12,032개의 질문을 포함하며, 원본 MMLU 데이터셋에서 지나치게 쉬운 질문을 제거하고, 더 많은 STEM 기반 질문과 TheoremQA, SciBench의 질문을 추가했습니다. 선택지는 네 개에서 열 개로 확장되어 모델의 추론 능력을 더 정확히 평가할 수 있습니다.

##### Experimental Setup
MMLU-Pro는 다양한 언어 모델을 평가하기 위해 사용되었습니다. 실험에는 GPT-4, Claude-3, Llama-2 등의 모델이 포함되었으며, 5-shot Chain of Thought(CoT) 접근법을 사용해 모델의 성능을 측정했습니다.

##### Results and Analysis
MMLU-Pro는 기존 MMLU보다 훨씬 더 높은 난이도를 가지고 있습니다. GPT-4o는 MMLU에서 72.6%의 정확도를 보였지만, MMLU-Pro에서는 63.7%로 떨어졌습니다. CoT 접근법을 사용한 경우, 모델의 성능이 크게 향상되었으며, 이는 MMLU-Pro가 더 복잡한 추론을 요구함을 보여줍니다. 또한, MMLU-Pro는 프롬프트 스타일에 대한 민감도가 낮아 더 큰 안정성을 보여주었습니다.

##### Limitations
MMLU-Pro는 다중 선택 형식의 한계를 가지고 있으며, 개방형 답변 형식이 실제 세계 시나리오를 더 잘 반영할 수 있습니다. 또한, MMLU-Pro는 언어 모델만을 평가하며, 멀티모달 모델에 대한 평가는 포함되지 않습니다.

##### Conclusion
MMLU-Pro는 다중 작업 언어 이해 능력을 평가하기 위한 더 도전적인 벤치마크입니다. 더 복잡한 추론 중심의 과제를 포함함으로써, 모델의 성능을 더 정확히 구별할 수 있으며, AI 언어 모델의 능력을 향상시키는 데 중요한 역할을 할 것입니다.

#### 2. 전체 요약
이 논문은 기존 MMLU 벤치마크의 한계를 극복하기 위해 MMLU-Pro라는 새로운 벤치마크를 소개합니다. MMLU-Pro는 더 도전적이고 추론 중심의 질문을 포함하며, 선택지를 열 개로 확장하여 모델의 능력 차이를 명확히 구별합니다. 실험 결과, MMLU-Pro는 모델의 성능을 크게 낮추고, 다양한 프롬프트 스타일에 대한 민감도를 줄여 더 큰 안정성을 보여주었습니다. Chain of Thought(CoT) 추론을 사용하는 모델이 더 나은 성능을 보이며, 이는 MMLU-Pro가 더 복잡한 추론을 요구함을 나타냅니다. MMLU-Pro는 언어 모델의 다중 작업 언어 이해 능력을 평가하는 데 중요한 도구가 될 것입니다.