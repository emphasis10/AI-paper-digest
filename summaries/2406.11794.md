# DataComp-LM: In search of the next generation of training sets for language models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.11794.pdf](https://arxiv.org/pdf/2406.11794.pdf)

### 1. 각 섹션 요약 및 주요 내용 정리

#### Introduction (서론)
논문에서는 **DataComp for Language Models (DCLM)**라는 대규모 언어 모델의 데이터 큐레이션 벤치마크를 소개합니다. 이는 Common Crawl에서 추출한 240조 토큰과 다양한 데이터 큐레이션 전략을 포함합니다. 주로 데이터 필터링, 데이터 통합, 중복 제거 등의 기법이 강조됩니다.

#### Related Work (관련 연구)
데이터 큐레이션의 다양한 방법론과 기존 연구를 요약합니다. 웹 크롤링 데이터에서 불필요한 콘텐츠를 제거하고, 고품질 데이터를 필터링해 모델 성능을 향상하는 방법론을 다룹니다. 여러 공개 데이터셋과의 성능 비교가 제공됩니다.

#### Methodology (방법론)
DCLM 벤치마크를 위한 데이터셋 구성 및 데이터 큐레이션 전략을 설명합니다. 모델 기반 필터링을 통해 고품질의 데이터셋(DCLM-BASELINE)을 생성하여, 다양한 토큰 규모의 모델을 훈련합니다. 이 데이터셋으로 7B 파라미터 모델에서 64%의 5-shot MMLU 정확도를 달성했습니다.

#### Experiments and Results (실험 및 결과)
DCLM-BASELINE 데이터셋을 사용하여 훈련한 언어 모델의 성능을 다양한 벤치마크에서 평가합니다. 특히 MMLU와 53개의 자연어 이해 과제에서 이전의 최고 성능을 뛰어넘는 결과를 얻었습니다. 또한, 동일한 컴퓨팅 자원으로 더 나은 성능을 발휘한 점이 강조됩니다.

#### Discussion (토론)
데이터 셋 설계와 모델 성능 간의 관계를 논의합니다. 데이터 큐레이션의 중요성과 효율적인 데이터 셋 구축 전략이 강조됩니다. 구체적인 큐레이션 전략이 성능 향상에 미치는 영향을 다룹니다.

#### Conclusion (결론)
데이터 셋의 품질이 대규모 언어 모델의 성능에 결정적인 영향을 미친다는 것을 결론지으며, DCLM 벤치마크가 데이터 큐레이션 연구에 중요한 기여를 할 것으로 전망합니다. 추가적인 연구 방향도 제시됩니다.

### 주요 기여 및 혁신
논문은 DCLM 벤치마크를 통해 데이터 큐레이션의 중요성을 강조하며, 고품질의 데이터셋을 생성하기 위한 전략을 제시합니다. 특히 모델 기반 필터링 기법을 통해, 동일한 컴퓨팅 자원을 사용하면서도 성능을 극대화한 점이 혁신적입니다. 이를 통해, 대규모 언어 모델의 효율적이고 경제적인 훈련 방법을 제안합니다.

### 2. 전체 요약
이 논문에서는 DCLM(Datacom)의 벤치마크를 소개하여, 고품질 데이터 셋이 대규모 언어 모델의 성능에 미치는 중요한 영향을 다룹니다. Common Crawl에서 추출한 240조 토큰과 다양한 큐레이션 기법을 통해, 7B 파라미터 모델에서 64%의 5-shot MMLU 정확도를 달성합니다. 논문은 데이터 큐레이션 전략의 중요성을 강조하며, 새로운 데이터 셋 설계와 모델 훈련 방법론을 제시합니다. DCLM 벤치마크는 데이터 큐레이션 연구의 중요한 기초 자료로 활용될 수 있으며, 추가적인 연구 방향도 제시하고 있습니다.

## Similar Papers
- [MINT-1T: Scaling Open-Source Multimodal Data by 10x: A Multimodal Dataset with One Trillion Tokens](2406.11271.md)
- [Long Code Arena: a Set of Benchmarks for Long-Context Code Models](2406.11612.md)
- [Scaling Retrieval-Based Language Models with a Trillion-Token Datastore](2407.12854.md)
- [LongVideoBench: A Benchmark for Long-context Interleaved Video-Language Understanding](2407.15754.md)
- [Linearizing Large Language Models](2405.06640.md)
- [Large Scale Transfer Learning for Tabular Data via Language Modeling](2406.12031.md)
- [CLIP meets Model Zoo Experts: Pseudo-Supervision for Visual Enhancement](2310.14108.md)
- [Found in the Middle: Calibrating Positional Attention Bias Improves Long Context Utilization](2406.16008.md)
- [Stylebreeder: Exploring and Democratizing Artistic Styles through Text-to-Image Models](2406.14599.md)
