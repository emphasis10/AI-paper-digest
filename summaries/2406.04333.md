# BitsFusion: 1.99 bits Weight Quantization of Diffusion Model
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.04333.pdf](https://arxiv.org/pdf/2406.04333.pdf)

### 섹션별 요약

#### 1. 서론 (Introduction)
- **요약**: 최근 몇 년 동안 신경망 기반의 디퓨전 모델은 높은 품질의 이미지를 생성하는 데 성공을 거두었습니다. 그러나 이 모델은 매개변수가 많아 모델 크기가 큽니다. 이러한 문제를 해결하기 위해 새로운 가중치 양자화 방법을 제안합니다. 이 방법은 모델의 크기를 줄이는 동시에 성능을 유지하거나 향상시킵니다.

#### 2. 관련 작업 (Related Works)
- **요약**: 다른 연구들은 효율적인 아키텍처 설계 및 네트워크 가지치기를 사용하여 모델 크기 감소를 시도했지만, 많은 훈련 시간과 자원이 필요합니다. 양자화는 이러한 문제를 해결할 수 있는 유망한 방법으로 떠오르고 있습니다.

#### 3. 혼합 정밀도 양자화 전략 (Mixed Precision Quantization Strategy)
- **요약**: 모델의 각 층에 최적의 비트 수를 할당하여 전체 양자화 오류를 줄이는 전략을 개발했습니다. 이를 위해 모델의 각 층의 양자화 오류를 분석하고 민감도 속성을 정의했습니다. 그 결과, 각 층에 적절한 비트 수를 할당하여 매개변수 효율을 최적화했습니다.

#### 4. 극소 비트 디퓨전 모델 학습 (Training Extreme Low-bit Diffusion Model)
- **요약**: 최적의 비트 너비를 결정하고 나면, 일련의 기술을 사용하여 양자화된 모델을 학습시킵니다. 여기에는 시간 임베딩 사전 계산 및 캐싱, 대칭 가중치 분포 추가, 대체 최적화 등이 포함됩니다. 또한, 전체 정밀도 모델을 교사로 사용하여 양자화된 모델을 훈련시키는 개선된 훈련 파이프라인을 제안합니다.

#### 5. 주된 결과 (Main Results)
- **요약**: 제안한 1.99 비트 모델은 원래 모델을 뛰어넘는 성능을 보였습니다. 다양한 벤치마크 데이터셋과 사람 평가에서 높은 점수를 받으며 효과성을 입증했습니다. 또한, 다른 양자화 방법과 비교했을 때 더 높은 CLIP 점수를 달성했습니다.

#### 6. 결론 (Conclusion)
- **요약**: 제안한 양자화 방법은 모델 크기를 대폭 줄이면서도 성능을 유지하거나 향상시키는 것을 목표로 합니다. 앞으로 유사한 기술을 다른 복잡한 신경망에도 적용할 수 있을 것입니다.

### 전체 요약

이 논문은 디퓨전 모델의 효과적인 가중치 양자화 방법을 제안합니다. 이 방법은 모델의 크기를 1.99 비트로 줄이는 동시에 원래 모델보다 더 우수한 성능을 유지합니다. 특히:
- 각 층에 최적의 비트를 할당하는 혼합 정밀도 양자화 전략을 개발했습니다.
- 사전 계산, 대칭 가중치 분포 추가, 대체 최적화 등의 다양한 기술을 사용하여 모델을 초기화하고 학습시켰습니다.
- 실험 결과, 제안한 모델은 다양한 평가 지표에서 원래 모델을 뛰어넘는 성능을 보였습니다.

이 논문은 모델 크기를 줄이면서도 높은 성능을 유지하는 양자화 방법을 제시함으로써, 자원 제약이 있는 장치에서도 고품질의 모델을 사용할 수 있게 하는 데 기여합니다.