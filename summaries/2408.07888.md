# Fine-tuning Large Language Models with Human-inspired Learning Strategies in Medical Question Answering
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.07888.pdf](https://arxiv.org/pdf/2408.07888.pdf)

### 1. 섹션별 주요 내용 요약

**1. 도입 (Introduction)**
- **내용 요약**: 
    - 대형 언어 모델(LLM) 훈련에는 상당한 데이터 관련 비용이 필요합니다. 
    - 이를 효율적으로 사용하기 위한 인간 영감을 받은 학습 전략, 특히 커리큘럼 학습(curriculum learning)이 도입됩니다. 
    - 기존 연구에서는 일반 텍스트 이해에 대한 개선이 보고되었으나, 의료 분야의 질문 응답에 대한 적용은 부족했습니다. 본 연구는 이 갭을 메우기 위해 다양한 인간 영감을 받은 학습 전략을 평가했습니다.
- **주요 기여**: 
    - 다양한 크기와 아키텍처를 가진 네 가지 LLM을 이용해 인간 영감을 받은 학습 전략의 효과를 평가.
    - 머신 생성 라벨과 인간 생성 라벨을 비교하여, LLM 기반 질문 난이도 정의가 성능 개선에 더 효과적임을 발견.
  
**2. 관련 연구 (Related Work)**
- **내용 요약**: 
    - 데이터 효율적인 LLM 튜닝에서 데이터 선택과 정렬 방법이 중요합니다. 
    - 커리큘럼 학습은 주로 사용되었으며, 이는 일반 텍스트 이해 과제에서 성능을 개선하는 것으로 나타났습니다. 
    - 본 연구는 기존의 데이터를 순서를 정하는 전략에서 한 단계 발전하여 인간 영감을 받은 다양한 학습 전략을 소개합니다.
  
**3. 방법 (Methods)**
- **내용 요약**: 
    - 실험 설계: 데이터 정렬 전략과 다섯 가지 인간 영감을 받은 학습 전략이 제안되었고, 네 가지 LLM에 적용하여 총 24개의 모델을 평가했습니다.
    - 데이터셋: 세 가지 다양한 의료 데이터셋을 사용했으며, 모델 생성 데이터 라벨을 사용하여 세 가지 데이터 라벨링 시나리오를 구현했습니다.
    - 학습 전략: 블로킹 학습, 교차 학습, 커리큘럼 학습, 블록 커리큘럼 학습, 교차 커리큘럼 학습.

**4. 결과 및 논의 (Results and Discussion)**
- **내용 요약**: 
    - 인간 영감을 받은 학습 전략은 대체로 랜덤 셔플 대비 최대 2%의 정확도 향상을 보였습니다.
    - 데이터 라벨링 시나리오 간의 효과 차이가 컸으며, 특정 모델이나 데이터셋에 따라 최적의 전략이 달랐습니다.
    - LLM 기반 질문 난이도 정의가 인간 정의 난이도 대비 더 나은 성능을 보였습니다.
  
**5. 결론 (Conclusions)**
- **내용 요약**: 
    - 인간 영감을 받은 학습 전략은 LLM 튜닝에 있어 적당한 성능 향상을 제공하며 데이터 효율성을 높일 수 있습니다.
    - 그러나 특정 모델이나 데이터셋에 최적의 전략은 다를 수 있기에 일반화하는 데 주의가 필요합니다.
    - LLM 기반 난이도 측정이 비용 효율적인 대안이 될 수 있습니다.
  
**6. 한계 및 향후 연구 (Limitations and Future Work)**
- **내용 요약**: 
    - 종속 샘플로 인해 신뢰 구간 설정이 어려울 수 있습니다.
    - LLM 기반 난이도 측정 및 군집화 알고리즘 선택과 같은 변수는 결과 변화에 영향을 미칠 수 있습니다.
    - 제한된 질문 수량과 제한된 데이터셋은 커리큘럼 학습의 효과를 완전히 드러내기에는 부족했습니다.
    - 향후 연구는 더 넓은 범위의 질문과 대규모 LLM을 포함하여 전략의 일반화를 평가할 필요가 있습니다.

### 2. 전체 요약

이 연구는 대형 언어 모델(LLM)을 효율적으로 튜닝하기 위한 인간 영감을 받은 학습 전략, 특히 커리큘럼 학습(curriculum learning)의 효과를 평가합니다. 네 가지 다른 크기와 아키텍처의 LLM과 세 가지 의료 질문 응답 데이터셋을 사용하여, 다섯 가지 인간 영감을 받은 학습 전략을 도입하고 이들 전략이 데이터 효율성과 모델 성능에 미치는 영향을 분석했습니다. 연구 결과, LLM 기반 질문 난이도 정의가 인간 정의 난이도보다 더 나은 성능을 보였으며, 특정 모델이나 데이터셋에 따라 최적의 전략이 다를 수 있음을 발견했습니다. 이는 특정 상황에 맞춘 데이터 정렬 전략이 필요함을 시사하며, LLM 튜닝에서 데이터 효율성을 높이는 데 유용한 인사이트를 제공합니다. 앞으로는 더 다양한 질문과 대규모 LLM을 포함한 연구가 필요합니다.