# Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2506.01939.pdf](https://arxiv.org/pdf/2506.01939.pdf)

I'm now going to list the sections I found in the text for the most structured analysis possible. 

### 1. 소개
이 논문은 대형 언어 모델(LLM)의 추론 능력을 강화하기 위해 중요한 기술인 보상 검증 강화 학습(RLVR)을 분석합니다. 이 논문은 특히 LLM에서 고출력 엔트로피 토큰의 역할이 기존 연구에서 무시되고 있음을 지적합니다.

### 2. 사전 준비
이 섹션에서는 LLM의 추론 과정에서 고출력 엔트로피 토큰이 "분기점" 역할을 하여 다양한 추론 경로를 유도한다는 것을 보여줍니다. 따라서 중요한 분기점에서 고출력 엔트로피를 유지하는 것이 추론 성능에 유리합니다.

### 3. 체인 오브 띠잡(Chain-of-Thought)에서의 토큰 엔트로피 분석
이 논문은 기존 연구들이 여러 토큰의 엔트로피를 집합적으로 분석했다는 점에 주목하며, 체인 오브 띠잡 방식에서의 토큰 엔트로피를 개별적으로 분석합니다. 결과적으로, 대부분의 토큰은 낮은 엔트로피 값을 가지며, 극소수의 토큰만이 높은 엔트로피 값을 가짐을 보여줍니다.

### 4. RLVR가 모델의 엔트로피 패턴을 유지하고 강화함
이 섹션에서는 RLVR 훈련 동안 모델에서 높은 엔트로피 값을 갖고 있는 토큰들의 엔트로피가 더욱 증가한다고 설명합니다. 반면 낮은 엔트로피 값을 가진 토큰의 경우에는 비교적 변화가 적습니다.

### 5. 고출력 엔트로피 토큰의 중요성
이 섹션에서는 LLM의 RLVR에서 고출력 엔트로피 토큰이 어떻게 추론 능력에 기여하는지 실험적 증거를 통해 설명합니다. 고출력 엔트로피 토큰은 실제로 거의 모든 추론 성능 향상을 촉진하며, 그들의 중요성을 고려하지 않을 경우 모델의 성능 저하가 발생할 수 있음을 강조합니다.

### 6. 논의 및 결론
이 논문은 고출력 엔트로피 소수 토큰을 전략적으로 활용하여 LLM 추론 성능을 향상시킬 수 있는 RLVR 알고리즘을 제안하며, 기존의 RLVR 방식보다 효율적이고 집중된 전략 개발을 제안합니다.

---

### 전반적인 요약
이 논문은 LLM의 추론 성능을 높이기 위한 강화 학습 기법을 탐구하면서 고출력 엔트로피 토큰의 중요성을 강조합니다. 결론적으로 고출력 엔트로피를 가진 토큰들이 LLM의 추론 경로에서 중요한 분기점을 제공하며, 이러한 토큰들을 전략적으로 활용하는 것이 지속 가능한 성능 향상에 있어 필수적임을 제안합니다. 논문 전반에서 RLVR 모델이 이러한 엔트로피 토큰을 강조할 때 성능상의 두드러진 성과를 보였음을 지속적으로 확인합니다.