# Learning From Correctness Without Prompting Makes LLM Efficient Reasoner
## TL;DR
## Summary
- [https://arxiv.org/pdf/2403.19094.pdf](https://arxiv.org/pdf/2403.19094.pdf)

### 논문 요약

#### 1. 제목 및 요약
논문 제목은 "Learning from Correctness Without Prompting Makes LLM Efficient Reasoner"입니다. 요약에서는 대규모 언어 모델(LLM)이 다양한 과제에서 뛰어난 성과를 보였지만, 여전히 환각, 부정확한 추론 및 유해한 콘텐츠 생성 등의 한계를 가지고 있다고 언급합니다. 이를 해결하기 위해, 인간의 피드백이나 외부 도구 없이도 작동하는 내재적 자기 수정 추론 프레임워크(LECO)를 제시합니다.

#### 2. 도입
LLM은 다양한 자연어 처리 벤치마크에서 탁월한 성과를 보이고 있음에도 불구하고, 여전히 환각, 유해한 콘텐츠 생성, 규칙을 따르지 않는 등의 문제를 가지고 있습니다. 기존 접근법은 인간 피드백이나 외부 도구를 사용하지만 이는 비용이 많이 들고 근본적인 해결책이 아닙니다.

#### 3. 관련 연구
기존 연구는 피드백을 통한 학습에 중점을 두고 있으며, 이는 주로 인간 피드백이나 외부 도구에 의존합니다. 그러나 이러한 방법은 비용이 많이 들고 실시간 피드백 기능이 부족합니다. 최근 연구는 LLM이 자체적으로 오류를 수정할 수 있음을 입증했지만, 이는 여전히 사람의 개입이 필요합니다.

#### 4. 방법론
LECO는 각 추론 단계에 대한 신뢰도를 평가하는 새로운 방법을 제시합니다. 첫 번째 라운드에서 신뢰도가 가장 낮은 단계를 오류로 간주하고, 이후 올바른 단계를 누적하여 최종 정답에 도달합니다. 이 방법은 추가 토큰이나 외부 도구 없이 실행됩니다. 

구체적으로, 정답률 평가를 위해 평균 토큰 신뢰도, 단계 발산 점수, 단계 전이 확률을 종합적으로 고려합니다.

#### 5. 실험
실험 결과, 다양한 다단계 추론 과제에서 LECO가 GPT-3.5 및 GPT-4 모델의 추론 성능을 높이는 데 효과적임을 확인했습니다. 특히, 수학적 추론 과제에서는 LECO가 특히 큰 향상을 보였으며, 이는 올바른 단계에서 학습함으로써 오류를 줄이는 데 효과적임을 시사합니다.

#### 6. 결론 및 향후 연구
LECO는 인간의 피드백이나 외부 도구 없이도 LLM의 추론 성능을 향상시키는 새로운 방법을 제시합니다. 향후 연구에서는 LECO의 단계 신뢰도 알고리즘을 더 복잡한 추론 구조에 적용하는 것이 주요 목표가 될 것입니다.

### 전체 요약

이 논문은 대규모 언어 모델(LLM)의 추론 성능을 향상시키기 위해 내재적 자기 수정 추론 프레임워크(LECO)를 제안합니다. LECO는 인간 피드백이나 외부 도구 없이도 다단계 추론에서 효율적으로 작동하며, 각 단계의 신뢰도를 평가하여 올바른 단계를 누적하는 방식을 사용합니다. 실험 결과, 다양한 추론 과제에서 LECO가 GPT-3.5 및 GPT-4 모델의 성능을 크게 향상시키는 것으로 나타났습니다. 향후 연구에서는 LECO의 알고리즘을 더 복잡한 추론 구조에 적용하는 방향으로 진행될 것입니다.