# Are We Done with MMLU?
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.04127.pdf](https://arxiv.org/pdf/2406.04127.pdf)

### 1. 서론 (Introduction)
- **내용 요약**: 이 논문은 대규모 다중 작업 언어 이해(MMLU) 벤치마크의 오류를 체계적으로 분석하고, 이를 고치기 위한 새로운 하위 집합 데이터셋인 MMLU-Redux를 소개합니다.
- **주요 기여 및 혁신 부분**: 기존 MMLU 데이터셋의 오류와 문제점을 진단하고, 이를 개선한 새로운 데이터셋인 MMLU-Redux를 공개해 언어 모델(LLM)의 평가를 보다 신뢰성 있게 할 수 있게 합니다.

### 2. MMLU의 문제점 (What is wrong with MMLU?)
- **내용 요약**: MMLU 데이터셋은 다양한 주제를 다루고 있지만, 일관되지 않은 레이블링 및 모호한 질문이 포함된 경우가 많습니다. 이러한 문제는 모델의 성능 평가 결과를 신뢰하기 어렵게 만듭니다.
- **주요 기여 및 혁신 부분**: 데이터셋의 일관성을 유지하기 위해 필터링하여 MMLU-Redux를 구성하였고, 기존 데이터셋의 문제를 체계적으로 정리했습니다.

### 3. 오류 탐지 분류 (Error Detection Taxonomy)
- **내용 요약**: 이번 연구에서는 MMLU 데이터셋 내 오류를 유형별로 분류하고, 각 유형별 예시와 영향을 분석했습니다.
- **주요 기여 및 혁신 부분**: 오류 유형을 체계적으로 분류하고, 이러한 오류가 평가에 어떤 영향을 미치는지 체계적으로 분석함으로써 모델의 신뢰성을 높이는 방법을 제시합니다.

### 4. MMLU-Redux: 고쳐진 MMLU 하위 집합 (MMLU-Redux: A correct MMLU Subset)
- **내용 요약**: MMLU-Redux는 엄선된 3,000개의 질문으로 이루어져 있으며, 각 질문은 철저히 검토되어 정확성을 보장합니다.
- **주요 기여 및 혁신 부분**: MMLU-Redux 데이터셋을 공개하여 커뮤니티의 참여를 유도하고, 지속적으로 데이터셋의 품질을 높일 수 있게 합니다.

### 5. MMLU-Redux 분석 (Analysis of MMLU-Redux)
- **내용 요약**: MMLU-Redux를 이용해 다양한 LLM들의 성능을 재평가한 결과, 데이터셋의 품질이 모델 평가에 큰 영향을 미친다는 것을 확인했습니다.
- **주요 기여 및 혁신 부분**: 데이터셋의 오류를 자동으로 식별하는 방법을 제시하고, 이를 통해 LLM들의 평가 신뢰성을 높일 수 있는 가능성을 탐구했습니다.

### 6. 결론 (Conclusion)
- **내용 요약**: MMLU-Redux를 통해 데이터셋의 오류를 체계적으로 정리하고, 이를 기반으로 LLM 평가의 신뢰성을 높이는 방안을 제시했습니다.
- **주요 기여 및 혁신 부분**: MMLU-Redux 데이터셋을 공개하여 커뮤니티와 협력하여 데이터셋 품질을 지속적으로 향상시키고, 이를 통해 다음 세대의 언어 모델 평가를 보다 정확하게 수행할 수 있도록 합니다.

### 전체 요약
이 논문은 대규모 다중 작업 언어 이해(MMLU) 벤치마크의 오류를 체계적으로 분석하고, 이를 개선한 새로운 하위 집합 데이터셋인 MMLU-Redux를 소개합니다. 주된 기여는 기존 MMLU 데이터셋의 오류를 식별하고 고치는 과정에서 얻은 통찰을 기반으로, MMLU-Redux라는 개선된 데이터셋을 확보하여 언어 모델의 성능 평가의 신뢰성을 높인 것입니다. MMLU-Redux를 공개하여 커뮤니티와 협력하여 데이터셋 품질을 지속적으로 향상시킬 계획입니다. 이를 통해 다음 세대의 언어 모델 평가가 보다 정확하게 이루어질 수 있도록 기여하고 있습니다.