# ODGEN: Domain-specific Object Detection Data Generation with Diffusion Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.15199.pdf](https://arxiv.org/pdf/2405.15199.pdf)

#### 1. 도입부 (Introduction)
이 논문에서는 객체 탐지를 위한 데이터 생성의 새로운 방법으로 ODGEN을 소개합니다. 최근의 이미지 생성 모델은 텍스트 프롬프트를 기반으로 이미지를 생성할 수 있지만, 복잡한 장면에서 여러 개의 객체를 포함하는 이미지 생성에는 한계가 있습니다. ODGEN은 경계 상자(bounding boxes)와 텍스트 설명을 사용하여 고품질 이미지를 생성하며, 이는 객체 탐지 데이터셋을 풍부하게 하는 데 도움을 줍니다. ODGEN은 특히 특정 도메인에서의 복잡한 장면과 밀집된 객체를 다루는 데 강력한 성능을 보입니다.

#### 2. 관련 연구 (Related Works)
최근 몇 년간 확산 모델(diffusion models)은 이미지 생성에서 큰 진전을 이루었으며, 높은 충실도와 학습 안정성을 보여줍니다. ODGEN은 이러한 확산 모델을 기반으로 하여 레이아웃-투-이미지 생성(layout-to-image generation) 및 객체 탐지 데이터셋 생성을 위한 다양한 방법들을 결합합니다. 이 논문에서는 이러한 방법들과 ODGEN의 차별점을 설명하며, ODGEN이 어떻게 더 나은 성능을 발휘하는지 보여줍니다.

#### 3. 방법론 (Method)
ODGEN의 주요 구성 요소는 다음과 같습니다:
- **도메인별 확산 모델 미세조정(Domain-specific Diffusion Model Fine-tuning):** 사전 학습된 확산 모델을 도메인별 데이터셋에 맞춰 미세 조정합니다.
- **객체 단위 조건부 생성(Object-wise Conditioning):** 각 객체의 클래스 이름을 텍스트 임베딩으로 인코딩하고, 시각적 조건으로 합성된 객체 패치를 사용합니다.
- **데이터셋 합성 파이프라인(Dataset Synthesis Pipeline):** 경계 상자와 클래스 정보를 사용하여 이미지와 텍스트 리스트를 생성하고, 이를 기반으로 합성된 이미지를 만듭니다.

#### 4. 실험 (Experiments)
ODGEN의 성능을 평가하기 위해 7개의 도메인별 벤치마크에서 실험을 수행했습니다. ODGEN이 생성한 데이터로 훈련된 객체 탐지기는 기존 방법들에 비해 최대 25.3%의 mAP 향상을 보였으며, COCO-2014를 기반으로 한 일반 도메인에서도 최대 5.6%의 mAP 향상을 나타냈습니다. 또한, FID(Frechet Inception Distance) 측정에서 ODGEN이 가장 우수한 결과를 보였습니다.

#### 5. 결론 (Conclusion)
ODGEN은 경계 상자와 텍스트 설명을 기반으로 고품질의 합성 이미지를 생성하여 객체 탐지 데이터셋을 강화합니다. 이 방법은 특정 도메인뿐만 아니라 일반 도메인에서도 높은 성능을 보여주며, 합성 데이터가 객체 탐지 모델의 성능을 크게 향상시킴을 입증했습니다. ODGEN은 복잡한 장면과 밀집된 객체를 효과적으로 처리할 수 있는 강력한 도구로, 객체 탐지 작업에 유용한 합성 데이터를 제공할 수 있습니다.

---

### 전체 요약
ODGEN은 특정 도메인과 일반 도메인 모두에서 객체 탐지를 위한 고품질 데이터를 생성하는 혁신적인 방법을 제시합니다. 이 방법은 사전 학습된 확산 모델을 도메인별 데이터셋에 맞춰 미세 조정하고, 객체 단위 조건부 생성 방식을 사용하여 텍스트와 시각적 정보를 기반으로 이미지를 생성합니다. 실험 결과, ODGEN이 생성한 데이터로 훈련된 객체 탐지기는 기존 방법들보다 뛰어난 성능을 보였으며, 이는 객체 탐지 모델의 학습에 큰 도움을 줄 수 있음을 보여줍니다. ODGEN은 특히 복잡한 장면과 여러 객체가 포함된 이미지 생성에서 탁월한 성능을 발휘합니다.

## Similar Papers
- [Kaleido Diffusion: Improving Conditional Diffusion Models with Autoregressive Latent Modeling](2405.21048.md)
- [Make It Count: Text-to-Image Generation with an Accurate Number of Objects](2406.10210.md)
- [MotionClone: Training-Free Motion Cloning for Controllable Video Generation](2406.05338.md)
- [Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics](2408.04631.md)
- [Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding](2405.08748.md)
- [Vivid-ZOO: Multi-View Video Generation with Diffusion Model](2406.08659.md)
- [Semantica: An Adaptable Image-Conditioned Diffusion Model](2405.14857.md)
- [I4VGen: Image as Stepping Stone for Text-to-Video Generation](2406.02230.md)
- [Auto Cherry-Picker: Learning from High-quality Generative Data Driven by Language](2406.20085.md)
