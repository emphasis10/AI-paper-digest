# Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.03414.pdf](https://arxiv.org/pdf/2404.03414.pdf)

### 개요
이 논문에서는 기존의 대형 언어 모델(Language Model, LM)을 이용한 추론 작업을 개선하는 새로운 프레임워크, LM-Guided Chain-of-Thought(CoT)를 소개합니다. 이 방법은 경량 LM을 사용하여 입력 인스턴스에 대한 근거를 생성하고, 이 근거를 바탕으로 대형 LM이 작업 출력을 예측하도록 유도합니다. 주요 기여는 경량 LM만을 훈련시키는 비용 효율적인 방법을 통해, 향상된 추론 결과를 도출한다는 점입니다.

### 1. 도입
Chain-of-Thought(CoT) 프롬프팅은 LM의 내재된 추론 능력을 이끌어내는 방법으로 주목받고 있습니다. 이 연구에서는 경량 LM이 근거를 생성하고 대형 LM이 이를 기반으로 답변을 예측하는 LM-Guided CoT 방법을 제안합니다. 이 방법은 기존의 CoT 프롬프팅이 갖는 한계를 극복하고자 합니다.

### 2. 관련 연구
이전 연구들은 대형 LM에서 작은 LM으로 지식을 전달(distillation)하여 추론 능력을 향상시키는 방법을 탐구했습니다. 또한, 생성된 근거의 질을 평가하고 개선하는 다양한 접근법이 소개되었습니다.

### 3. LM-Guided Chain-of-Thought
이 프레임워크는 두 가지 LM을 사용합니다: 경량 모델은 최적의 근거를 생성하고, 대형 모델은 이 근거를 바탕으로 출력을 예측합니다.

#### 3.1. 근거 증류
경량 LM은 대형 LM으로부터 근거를 배우는 지식 증류 기법을 사용합니다. 이 과정은 경량 LM이 근거를 생성하는 능력을 향상시키기 위해 설계되었습니다.

#### 3.2. 근거 개선
생성된 근거의 품질을 측정하고 개선하기 위한 방법이 도입되었습니다. 여러 언어적 측면(사실성, 관련성, 논리성 등)을 고려하여 평가하고, 이를 바탕으로 강화 학습을 적용하여 근거의 질을 더욱 끌어올립니다.

### 4. 실험 및 결과
FLAN-T5 모델을 사용하여 HotpotQA와 2WikiMultiHopQA 벤치마크에서 실험을 수행했습니다. 결과적으로, LM-Guided CoT 프롬프팅은 기준 모델을 상회하는 성능을 보여주었습니다.

### 5. 결론
LM-Guided CoT는 기존의 CoT 프롬프팅을 두 단계로 분해하여 대형 및 경량 LM을 분리적으로 최적화함으로써, 추론 작업의 효율성과 효과를 증대시킵니다. 이 연구는 CoT 프롬프팅 패러다임 내의 도전을 해결하는 효과적이고 자원 효율적인 접근법을 제시합니다.