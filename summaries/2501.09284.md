# SEAL: Entangled White-box Watermarks on Low-Rank Adaptation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.09284.pdf](https://arxiv.org/pdf/2501.09284.pdf)

1. 섹션 요약

- **서론**: 이 섹션에서는 SEAL이라는 새로운 워터마킹 기법을 소개합니다. SEAL은 LoRA(Low-Rank Adaptation) 가중치에 특화된 방법으로, 모델 성능을 저하시키지 않으면서 소유권 검증을 강화하는 혁신적인 접근법입니다. 이 방법은 특수한 고정 행렬을 도입하여 트레이닝된 파라미터를 엮어내는 기법을 제안합니다.

- **관련 연구**: 여기서는 현재 주로 사용되는 PEFT(파라미터 효율 튜닝) 기법들과 DNN(Deep Neural Networks) 소유권 보호에 대한 다양한 기존 기법들을 비교 분석합니다. LoRA 기반의 다양한 튜닝 방법이 SEAL과 어떻게 차별화되는지를 설명하고 있습니다.

- **방법론**: SEAL은 비훈련 가능한 행렬 C를 사용하여 훈련 가능한 파라미터를 엮는 방법을 소개합니다. 이 기법은 물리 공간에서 보이지 않는 워터마크를 삽입하고, 인증 이벤트에서 사용자의 적합성을 확인하기 위해 몇 가지 수학적 변형을 사용합니다.

- **실험 및 결과**: 실험 결과에서는 SEAL의 높은 충실도와 다양한 공격에 대한 강한 내구성이 확인되었습니다. SEAL은 워터마크 제거, 모호화 및 중복 공격에 대하여 안정성을 유지하면서도 기존 LoRA 성능 수준과 동등하거나 이를 초과하는 성능을 보여주었습니다.

- **결론**: 이 연구는 SEAL이 LoRA의 가벼운 모델에서도 효과적임을 증명합니다. 또한, SEAL의 개념이 다른 PEFT 방법에도 확장될 수 있다는 점을 강조하며, 이를 활용한 광범위한 적용 가능성에 대해 논의합니다. 워터마킹이 오픈 소스 AI의 지식 재산 보호를 강화하면서도 협업을 촉진한다는 점을 언급합니다.

2. 전반적인 요약

SEAL은 LoRA 기반 모델의 소유권 보장을 강화하기 위해 설계된 혁신적인 워터마킹 기법으로, 비훈련 가능한 고정 행렬을 활용하여 훈련 가능한 파라미터를 복잡하게 엮습니다. 이를 통해 모델의 성능을 유지하면서도, 다양한 형태의 공격에 대한 내구성을 갖춘 워터마크를 구현합니다. SEAL은 단순하고 강력한 저작권 보호 기제를 제공하며, 향후 더 넓은 범위의 파라미터 효율 튜닝 방법에 적용될 수 있는 가능성을 제시합니다.