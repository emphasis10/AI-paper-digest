# Generative Inbetweening: Adapting Image-to-Video Models for Keyframe Interpolation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.15239.pdf](https://arxiv.org/pdf/2408.15239.pdf)

### 1. 논문의 각 섹션 요약 및 주요 기여와 혁신 부분

#### Introduction
이 논문에서는 두 개의 입력 키 프레임 사이에서 일관된 모션을 가진 비디오 시퀀스를 생성하는 방법을 제시합니다. 기존의 이미지-비디오 변환 모델을 가볍게 튜닝하여 키 프레임 보간에 적합하도록 하였습니다. 이는 한 장의 이미지로부터 시간 역방향으로 움직이는 비디오를 예측하도록 모델을 수정하는 것입니다. 이 과정을 통해 기존의 전방향 운동 예측을 하는 모델과 결합하여 두 개의 키 프레임에서 일관된 비디오를 생성할 수 있습니다. 이 방식은 기존의 방식보다 더 높은 품질의 비디오를 생성한다는 실험 결과를 보여줍니다.

#### Related Works
이 섹션에서는 기존의 비디오 생성과 관련된 연구들을 논의합니다. 특히, 대규모 이미지-비디오 모델, 확산 모델 및 프레임 보간 기법들을 다룹니다. 기존의 연구들은 주로 단일 입력 이미지에서 비디오를 생성하는데 집중하지만, 이 연구는 두 개의 키 프레임을 이용한 비디오 생성에 초점을 맞추고 있습니다.

#### Background
Stable Video Diffusion (SVD) 모델을 기반으로 한 이 연구는 확산 과정을 통해 높은 해상도의 비디오를 생성합니다. SVD 모델은 사전 학습된 오토인코더의 잠재 공간에서 작동하며, 시간 축 상의 자가 주의 메커니즘을 통해 프레임 간의 상호 작용을 학습합니다. 이는 일관된 움직임을 가진 비디오를 생성하는 데 중요한 역할을 합니다.

#### Method
- **모션-시간 연결 반전**: 자가 주의 맵을 180도 회전하여 키 프레임 사이의 역방향으로 움직이는 비디오를 생성합니다.
- **가벼운 역방향 모션 미세 조정**: 기존의 전방향 운동 통계를 활용하여 적은 데이터와 매개변수로 모델을 미세 조정합니다. 이를 통해 역방향 모션을 생성할 수 있습니다.
- **이중 방향 샘플링**: 두 개의 키 프레임에서 시작하는 전방향 및 역방향 모션 예측을 결합하여 일관된 비디오를 생성합니다.
- **실험**: 제안된 방법이 기존의 방식보다 더 높은 품질의 비디오를 생성한다는 것을 실험을 통해 입증합니다. 특히, Davis와 Pexels 데이터셋을 사용하여 성능을 평가합니다.

### 2. 전체 요약
이 논문은 기존의 이미지-비디오 변환 모델을 가볍게 튜닝하여 두 개의 입력 키 프레임 사이에 일관된 모션을 가진 비디오를 생성하는 새로운 방법을 제안합니다. 기존의 전방향 운동 예측 모델에 역방향 운동을 예측하는 가벼운 미세 조정을 추가하였으며, 이를 통해 두 개의 키 프레임에서 시작하여 일관된 비디오를 생성합니다. 실험 결과, 제안된 방법은 기존의 프레임 보간 및 확산 모델 기반 비디오 생성 방법보다 뛰어난 성능을 보였습니다.

-----

이 요약을 기반으로 프레젠테이션을 구성할 수 있으며, 자세한 정보는 각 섹션의 내용을 참고하면 됩니다.