# MuPT: A Generative Symbolic Music Pretrained Transformer
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.06393.pdf](https://arxiv.org/pdf/2404.06393.pdf)

이 논문은 대규모 언어 모델(Large Language Models, LLMs)을 음악 사전 훈련에 적용하는 방법에 대해 탐구합니다. 기존 음악 모델링에서 널리 사용되는 MIDI와 달리, LLMs는 ABC 악보 표기법과 더 양호한 호환성을 보이며 이를 통해 음악 작곡 성능을 향상시킵니다. ABC 악보 표기법을 사용함으로써, 다양한 음악 트랙 간의 일관성을 유지하면서, 더 높은 품질의 음악 구조를 생성할 수 있는 Synchronized Multi-Track ABC (SMT-ABC) 악보 표기법을 제안합니다. 이 논문은 최대 8192 토큰을 처리할 수 있는 모델 시리즈를 개발하고, 음악 데이터의 반복 훈련이 모델 성능에 미치는 영향을 탐구하는 Symbolic Music Scaling Law (SMS Law)을 도입하여 음악 생성 분야에서의 향후 연구 방향을 제시합니다.

### 1. 중요 내용 요약
#### 1.1 도입부 및 기여
- 대규모 언어 모델(Large Language Models, LLMs)의 발전과 멀티모달 영역으로의 확장을 배경으로, 이미지와 음성 처리에서의 성공에 이어 음악 분야에서도 새로운 접근 방식을 모색합니다.
- MIDI 대신 ABC 악보 표기법을 채택하여 음악 구조의 디지털 표현과 처리를 개선하고, 여러 트랙 간의 일관성 문제를 해결하기 위해 SMT-ABC 악보 표기법을 제안합니다.
- SMS Law를 통해 음악 데이터의 반복 학습이 모델의 성능 향상에 기여하는 방식을 탐구합니다.
- ABC 악보 표기법을 기반으로 한 상태 최고의 음악 생성 모델과 훈련 체크포인트를 공개함으로써, 연구 및 혁신을 촉진합니다.

#### 1.2 관련 연구
- 음악 사전 훈련 분야에서 자기 지도 학습이 주목받고 있으며, 조건부 및 비조건부 음악 생성을 위한 기존 모델들이 MIDI를 이용하였으나 장기적 음악 생성 및 음악성 제한에 도전합니다.
- ABC 악보 표기법을 통한 음악의 디지털 표현은 자연어 처리 기술을 활용하여 효율적으로 음악 생성 및 검색을 가능하게 합니다.

### 2. 종합 요약
이 논문은 ABC 악보 표기법에 적합한 대규모 언어 모델을 사용하여 음악 생성의 성능을 향상시키고, SMT-ABC 악보 표기법으로 여러 트랙에 걸쳐 음악 조각들의 일관성을 유지하는 새로운 접근 방식을 제안합니다. 특히, 음악 데이터의 반복 학습이 모델 성능에 미치는 영향을 탐구하는 SMS Law를 통해, 훈련 데이터 및 모델 크기 확장이 음악 생성 성능에 긍정적인 영향을 미치는 증거를 제시합니다. 이 연구는 음악 생성 분야의 연구 및 개발에 중요한 자원을 제공함으로써, 이 분야의 발전에 기여할 것으로 기대됩니다.