# Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.15999.pdf](https://arxiv.org/pdf/2410.15999.pdf)

### 섹션별 요약

1. **소개**
   이 논문은 대형 언어 모델(LLM)의 매개 변수와 문맥적 지식 간의 충돌 문제를 해결하는 방법을 제안합니다. LLM의 매개 변수에 저장된 지식은 종종 부정확하거나 최신 정보가 아니며, 이를 해결하기 위해 정보 검색이나 도구를 통해 외부 지식(문맥적 지식)을 추가하지만, 이 과정에서 지식 충돌이 발생할 수 있습니다.

2. **배경 및 문제 설정**
   개방형 질문-응답(ODQA) 작업에서 LLM의 동작을 조사하기 위해 이 연구는 모델의 매개 변수 지식과 문맥적 지식 간의 충돌을 다루고 있습니다. 모델이 발생하는 지식 충돌을 어떻게 탐지하고 조정할 수 있는지를 설명합니다.

3. **SPARE의 제안**
   Sparse Auto-Encoder(SAE)를 사용하여 LLM의 동작을 조정하는 SPARE라는 새로운 방법을 제안합니다. 이 방법은 사전훈련된 SAE를 활용하여 LLM의 내부 활성화를 편집하고, 모델의 지식 선택 방법을 효과적으로 제어할 수 있도록 합니다.

4. **실험 결과**
   개방형 질문-응답 작업에서 SPARE는 기존의 표현 공학 및 대비 디코딩 방법보다 10% 이상 정확도가 높았습니다. SAE를 활용하여 비교적 적은 수의 기능적 피처를 편집함으로써 효율적으로 지식 충돌을 관리할 수 있습니다.

5. **결론**
   SPARE는 지식 충돌을 관리하기 위한 효과적이고 효율적인 방법으로, inference 시간에 모델의 지식 선택 동작을 제어할 수 있는 가능성을 보여줍니다. 그러나 이 접근법은 사전훈련된 SAE에 의존하므로 모든 모델에 적용할 수 있는 것은 아니며, 보다 복잡한 문제에는 어떻게 적용될지 불분명합니다.

### 전체 요약

이 논문은 대형 언어 모델(LLM)의 매개 변수 지식과 문맥적 지식 사이의 충돌을 해결하기 위해 SPARE라는 새로운 방법론을 제안합니다. SPARE는 Sparse Auto-Encoder(SAE)를 사용하여 LLM의 내부 활성화를 조정함으로써 모델의 지식 선택 동작을 컨트롤합니다. 실험 결과는 SPARE가 기존 방법보다 높은 정확도로 지식을 선택할 수 있게 해주며, 이는 지식 충돌을 효율적으로 관리하는 데 유용할 것으로 보입니다. 그러나 이 방법은 사전훈련된 SAE에 의존하므로 다양한 모델에의 적용 가능성에는 제한이 있을 수 있습니다.