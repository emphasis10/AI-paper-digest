# Language Models Prefer What They Know: Relative Confidence Estimation via Confidence Preferences
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.01126.pdf](https://arxiv.org/pdf/2502.01126.pdf)

**1. 각 섹션의 중요한 내용 요약 (정리된 한국어)**

**1.1 서론**
이 논문에서는 언어 모델(LM)의 출력 확실성을 정확하게 평가하기 위한 방법의 필요성을 강조한다. 특히 언어 모델들은 여전히 오류를 범할 가능성이 있으며, 사용자들이 모델의 출력을 해석할 때 이 확실성 추정치가 중요하다. 기존의 절대적인 신뢰도 평가 방법에는 한계가 있어, 새로운 접근 방식인 상대적 신뢰도 추정이 제안된다.

**1.2 절대 신뢰도 추정**
기존의 절대 신뢰도 추정 방법에서 모델에게 개별 질문에 대한 자신감 점수를 직접 평가하도록 요청하면, 모델들이 너무 비슷한 점수를 부여하는 경향이 있다. 예를 들어, 많은 질문에 대해서 0.9라는 같은 점수를 부여하는 경우가 있었다.

**1.3 상대 신뢰도 추정**
상대 신뢰도 추정은 질문들을 서로 비교해서 신뢰도를 판단하도록 하는 방법이다. 즉, 모델에게 어떤 질문에 대해 더 자신 있는지를 물어 구체적인 신뢰 점수 대신 상대적인 신뢰도를 추정하는 방식이다. 이를 통해 모델의 신뢰도를 더 정확하게 표현할 수 있으며, 게임 순위 집계 방법을 활용하여 점수로 변환한다.

**1.4 실험 및 평가**
논문은 다섯 가지 최첨단 언어 모델에서 상대적인 신뢰도 추정의 효과를 실험했다. 이 과정에서 상대 신뢰도 추정이 절대 신뢰도 추정보다 더 신뢰성 있는 결과를 보여주었으며, AUC(면적 아래 곡선)에서도 상대 신뢰도 추정이 평균 3.5% 개선된 성과를 보였다.

**1.5 결론**
본 연구는 상대 신뢰도 추정 방법이 절대 신뢰도 추정보다 더 나은 신뢰성 점수를 제공하는 것을 입증하였다. 이러한 방법론적인 개선은 사용자가 모델의 출력을 이해하고 오류를 감지하며, 전문가에게 의뢰하는 데 도움이 될 것으로 기대된다.

---

**2. 전체적인 요약 (정리된 한국어)**

이 논문은 언어 모델의 출력 확실성을 평가하기 위한 새로운 방법론, 즉 상대적 신뢰도 추정 방법을 제안한다. 기존의 절대적인 신뢰도 평가 방법은 신뢰도가 값이 매우 비슷하게 나오거나 비효율적이어서 사용자에게 유용하지 않았다. 상대적 신뢰도 추정은 복수의 질문을 비교하여 이들에 대한 상대적인 신뢰도를 판단하는 방식으로, 이를 통해 신뢰성이 높아진다. 연구 결과는 이 접근 방식이 다섯 개의 최첨단 언어 모델에서 시스템의 신뢰도 평가에 있어 더 유용하며, 실질적으로 높은 성과를 보여주었다. 이러한 발전은 사용자가 모델의 출력을 바르게 해석하고 필요 시 더 나은 결정을 내리지도록 돕는 데 기여할 것이다.