# PAS: Data-Efficient Plug-and-Play Prompt Augmentation System
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.06027.pdf](https://arxiv.org/pdf/2407.06027.pdf)

### 요약: "PAS: Data-Efficient Plug-and-Play Prompt Augmentation System"

#### 1. 서론
최근 대형 언어 모델(LLMs)의 발전과 이를 위한 플러그 앤 플레이(PnP) AI 시스템에 대한 수요가 증가하고 있습니다. 그러나 사용자들이 프롬프트 작성에 어려움을 겪는 경우가 많아 이를 자동화하는 시스템이 필요합니다.

#### 2. 관련 연구
기존의 많은 자동 프롬프트 엔지니어링(APE) 모델이 존재하지만, 이들 대부분은 사용이 어렵거나 인간의 노동력을 많이 필요로 합니다. 본 논문에서 제안하는 PAS는 이러한 문제를 해결하고자 합니다.

#### 3. 방법론
PAS 시스템은 두 가지 주요 단계로 구성됩니다:
  - **프롬프트 선택**: 임베딩 모델을 사용하여 프롬프트 데이터를 추출하고, 이를 클러스터링하여 중복된 데이터를 제거합니다. 그런 다음 LLMs를 사용하여 고품질 프롬프트를 선택합니다.
  - **프롬프트 보완 생성**: 소수의 샘플을 제공하는 few-shot learning 기법을 활용해 새로운 프롬프트를 생성합니다.

#### 4. 실험 결과
PAS 모델은 이전의 SoTA 모델인 BPO와 비교하여 월등한 성능을 보였습니다:
  - 효율성: 단 9000개의 데이터 페어만으로도 LLMs를 효과적으로 미세 조정 가능.
  - 유연성: 모든 LLMs에 플러그 앤 플레이 방식으로 통합 가능.

#### 5. 결론
PAS는 뛰어난 성능, 효율성, 유연성을 통해 프롬프트 엔지니어링을 혁신적으로 개선하고 있으며, 다양한 LLMs에 적용할 수 있는 포괄적인 시스템입니다.

### 총괄 요약

PAS 시스템은 프롬프트 엔지니어링의 어려움을 해결하기 위해 개발된 데이터 효율적 플러그 앤 플레이 프롬프트 보완 시스템입니다. 본 논문은 PAS 시스템이 기존의 자동 프롬프트 엔지니어링 모델에 비해 다음과 같은 핵심적인 포인트에서 우수함을 입증하였습니다:

- **효율성**: 단 9000개의 데이터 포인트로도 높은 성능을 발휘
- **유연성**: 모든 LLMs에 통합 가능
- **사용자 친화성**: 인간 평가에서도 뛰어난 평가를 받음

이러한 혁신적인 접근은 AI의 상호작용을 향상시키는 데 큰 기여를 할 것으로 기대됩니다.

## Similar Papers
- [RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance](2405.14677.md)
- [Towards a Personal Health Large Language Model](2406.06474.md)
- [Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models](2406.04271.md)
- [Retrieved In-Context Principles from Previous Mistakes](2407.05682.md)
- [AI Hospital: Benchmarking Large Language Models in a Multi-agent Medical Interaction Simulator](2402.09742.md)
- [Clover: Regressive Lightweight Speculative Decoding with Sequential Knowledge](2405.00263.md)
- [A Comparative Study on Automatic Coding of Medical Letters with Explainability](2407.13638.md)
- [Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL](2406.08426.md)
- [MedFuzz: Exploring the Robustness of Large Language Models in Medical Question Answering](2406.06573.md)
