# Thinking Forward and Backward: Effective Backward Planning with Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.01790.pdf](https://arxiv.org/pdf/2411.01790.pdf)

### 1. 논문의 각 섹션 요약 및 주요 기여와 혁신 부분

**소개 (Introduction)**:
이 논문은 큰 언어 모델(LLMs)의 계획 및 추론 능력을 조사합니다. 종전의 연구는 주로 목표 지점에서부터 계획을 수립하는 전진 방향을 사용했지만, 역방향으로 계획을 수립하는 것이 더 쉬운 문제를 해결하기 위한 방식도 검토되었습니다. 특히, 문제점으로는 목표 지점 근처에 좁은 경로가 있을 경우 역방향 계획이 더 효율적이라는 점에 대해 설명합니다.

**계획 형식화 및 계획 도메인 (Formulation and Planning Domains)**:
계획 문제를 텍스트 기반으로 정의하고, 상태변화와 허용되는 최대 단계 등에 대해 설명합니다. 세 가지 서로 다른 계획 도메인(그래프 계획, 배열 변환, 블록 월드)을 고려했습니다.

**LLMs의 역방향 계획 한계 (LLMs Cannot Plan Backward As Effectively As Forward)**:
LLMs은 전향 계획에서 더 높은 성공률을 보이며, 역방향의 경우는 체계적인 편견으로 인해 성능이 떨어지는 것으로 나타났습니다. 이 편향은 주로 LLM의 전향 생성 방식과 훈련 데이터 세트의 편향에서 기인합니다.

**제안된 해결책: 문제를 뒤집어 후방 계획하기 (Proposed Solution: Plan Backward by Flipping the Problem)**:
원래 목표를 초기 상태로, 초기 상태를 목표로 뒤집은 후 플립된 문제의 전향 방향으로 계획을 수립하면 LLM의 편향을 피할 수 있습니다. 이 방법은 다양하고 더 많은 후보 계획을 생성할 수 있게 하여 여러 도메인에서 계획 성공률을 4-24% 향상시킵니다.

**실험 (Experiments with Flipping the Problem)**:
세 가지 계획 도메인에서 문제를 뒤집었을 때의 성능을 비교했습니다. 특히, 플립된 문제를 이용한 전향 플립 계획은 전향 방향만 고려했을 때보다 더 높은 계획 성공률을 보였습니다.

**결론 및 향후 과제 (Conclusion and Future Work)**:
향후 연구 방향은 LLM이 역방향으로 계획하는 능력을 제대로 학습하도록 하는 것입니다. 문제를 뒤집는 접근법이 다양한 판단 문제에서 사용할 수 있다는 점에서 확장 가능성이 있다고 봅니다.

### 2. 전반적인 요약
이 논문은 LLM을 활용하여 더 나은 계획 수립 방법을 찾고자 하는 연구입니다. 목표는 LLM이 역방향으로도 잘 계획할 수 있도록 하는 전략을 개발하는 것입니다. 제안된 방법은 문제를 뒤집어 전방향에서 계획을 세우는 것으로, 이를 통해 LLM의 편향을 완화하고 다양한 해결책을 제시할 수 있습니다. 실험 결과, 이러한 접근법이 여러 도메인에서 유의미하게 계획 성공률을 향상시킨다는 것을 입증했습니다.