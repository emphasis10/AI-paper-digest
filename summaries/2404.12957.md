# Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.12957.pdf](https://arxiv.org/pdf/2404.12957.pdf)

이 논문은 대규모 언어 모델(LLM)에서 잠재적 지식을 평가하는 새로운 접근 방법을 제안합니다. 이 방법은 인컨텍스트 학습(ICL)을 활용하여 LLM이 지식 베이스에 저장된 사실을 어느 정도 알고 있는지 추정합니다. 기존의 프롬프트 기반 방법과 비교하여, 이 새로운 지식 추정기는 더 신뢰성 있고 적용하기 쉬우며, LLM에 내재된 지식을 더 많이 끌어낼 수 있다고 합니다.

논문은 다음과 같은 네 가지 주요 기여를 합니다:
1. 신뢰할 수 있는 잠재 지식 추정기(LKE) 개발: 인컨텍스트 학습을 활용한 새로운 LKE를 제안합니다. 이는 프롬프트 기반의 기존 방법들이 가진 여러 신뢰성 문제를 피할 수 있습니다.
2. ICL을 사용한 지식 추정의 미묘함 탐구: 다양한 ICL 설계 선택이 지식 추정 성능에 미치는 영향을 조사합니다.
3. 이전 접근법과의 비교: IC-LKE가 다양한 오픈 소스 모델과 사실 관계 유형에서 인간 생성 또는 기계 생성 프롬프트를 사용하는 기존 지식 추정 방법보다 우수함을 실험적으로 입증합니다.
4. 다양한 오픈 소스 LLM의 잠재 지식 시스템 비교: 널리 사용되는 여러 LLM에 대한 지식 수준을 평가하고, 모델 가족과 모델 크기에 따른 차이를 비교 분석합니다.

이 연구는 LLM의 실제 지식 수준을 보다 정확하게 파악하고 평가하는 데 중요한 기여를 하며, LLM 설계자들에게 유용한 정보를 제공할 것으로 기대됩니다.

## Similar Papers
- [Investigating How Large Language Models Leverage Internal Knowledge to Perform Complex Reasoning](2406.19502.md)
- [LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report](2405.00732.md)
- [Designing a Dashboard for Transparency and Control of Conversational AI](2406.07882.md)
- [From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data](2406.19292.md)
- [Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws](2404.05405.md)
- [Finch: Prompt-guided Key-Value Cache Compression](2408.00167.md)
- [Time Sensitive Knowledge Editing through Efficient Finetuning](2406.04496.md)
- [Privacy Preserving Prompt Engineering: A Survey](2404.06001.md)
- [Breaking Boundaries: Investigating the Effects of Model Editing on Cross-linguistic Performance](2406.11139.md)
