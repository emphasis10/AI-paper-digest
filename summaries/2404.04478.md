# Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.04478.pdf](https://arxiv.org/pdf/2404.04478.pdf)

이 논문은 RWKV 아키텍처를 활용하여 이미지 생성 과제에 적용한 새로운 방법론인 Diffusion-RWKV를 소개합니다. 기존의 Transformer 모델은 자연어 처리(NLP) 및 컴퓨터 비전 분야에서 상당한 발전을 이끌었으나, 고해상도 이미지 생성과 같은 장문의 작업에서는 계산 복잡성으로 인해 제한적이었습니다. 이에 따라, RWKV 모델을 변형하여 이미지 생성에 적합하도록 한 Diffusion-RWKV를 제안합니다. 이 모델은 특히 고해상도 이미지 처리에 효과적이며, 계산 복잡성을 크게 줄여줍니다.

### 주요 내용 요약
1. **도입**
   - Transformer 모델은 NLP와 컴퓨터 비전 분야에서 큰 진전을 이루었지만, 고해상도 이미지 생성과 같은 장문의 작업을 처리하는 데 계산 복잡성이 높아 적용에 한계가 있었습니다. RWKV와 같은 새로운 모델들이 이러한 문제를 해결하기 위해 등장했습니다.

2. **방법론**
   - RWKV 모델을 기반으로 하는 Diffusion-RWKV는 이미지 생성을 위해 특별히 조정되었습니다. 이 모델은 이미지를 패치로 나누고 이를 시퀀스로 처리하여 고해상도 이미지 생성에 있어서 더 나은 성능과 효율성을 제공합니다.

3. **실험**
   - Diffusion-RWKV는 CIFAR-10, CelebA, ImageNet-1K 데이터셋을 사용하여 테스트되었습니다. 이 모델은 다양한 해상도에서 이미지를 생성할 수 있으며, 기존 CNN 및 Transformer 기반 모델과 비교했을 때 FID 및 IS 지표에서 비슷하거나 더 나은 성능을 보여줍니다. 특히, 계산 복잡성이 크게 감소했음에도 불구하고 성능 저하가 없는 것이 확인되었습니다.

4. **결론**
   - Diffusion-RWKV는 고해상도 이미지 생성과 같은 장문의 작업을 처리할 수 있는 효율적인 대안을 제시합니다. 이 모델은 Transformer의 계산 복잡성 문제를 해결하면서도 우수한 이미지 생성 능력을 유지합니다.

이 논문은 RWKV 아키텍처를 활용한 Diffusion 모델이 고해상도 이미지 생성과 같은 복잡한 작업에서도 뛰어난 성능을 보이며, Transformer의 계산 복잡성 문제를 해결할 수 있는 가능성을 보여줍니다.