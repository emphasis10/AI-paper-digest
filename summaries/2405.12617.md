# Quantifying Emergence in Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.12617.pdf](https://arxiv.org/pdf/2405.12617.pdf)

#### 1. 소개
대형 언어 모델(LLM)의 발현은 모델이 특정 크기에 도달했을 때 나타나는 "고급 지능" 현상으로, 추상적 개념 이해, 복잡한 언어 기술, 인간과의 자연스러운 상호작용, 지시사항 따르기 등을 포함합니다. 이 연구는 발현을 정량화하고 모델 내부 메커니즘을 이해하기 위한 새로운 방법을 제안합니다.

#### 2. 관련 연구
기존 연구들은 모델의 성능을 통해 발현을 측정하려 했으나, 이는 자원 소모적이며 내부 메커니즘을 설명하지 못했습니다. 최근 연구들은 발현이 모델 크기와 데이터 양에 따라 연속적으로 증가한다고 주장합니다.

#### 3. 방법론
이 논문에서는 변환기 블록을 마르코프 과정으로 모델링하여 정보 이론의 관점에서 발현의 강도를 정량화합니다. 이는 마이크로스코픽(개별 토큰)과 매크로스코픽(전체 시퀀스) 수준에서 엔트로피 감소를 비교하여 발현의 강도를 측정하는 방식입니다.

#### 4. 실험 설정
두 가지 시나리오에서 발현 강도를 측정했습니다:
1. 문맥 학습(ICL)에서 발현: 몇 가지 샷(샘플)을 통해 모델이 새로운 토큰을 예측하는 능력을 평가.
2. 자연어 문장에서 발현: 실제 자연어 질문/답변 데이터를 사용하여 발현 패턴을 분석.

#### 5. 주요 발견
1. **샷 증가에 따른 발현 증가**: 샷의 수가 증가할수록 발현 강도는 증가하지만, 일정 수준 이상에서는 포화 상태에 도달합니다.
2. **발현과 모델, 데이터셋, 작업, 프롬프트의 상관관계**: 모델 크기와 데이터셋의 다양성, 작업 유형, 프롬프트 형식에 따라 발현 강도가 달라짐을 확인.
3. **자연어 문장에서의 발현 증가**: 자연어 문장에서는 토큰 수가 증가할수록 발현 강도가 증가합니다.
4. **LLM과 인간이 생성한 텍스트의 발현 차이**: LLM이 생성한 텍스트는 인간이 생성한 텍스트보다 더 큰 발현 강도를 보이며, 이는 LLM이 가장 높은 확률의 토큰을 생성하기 때문입니다.

#### 6. 결론
이 연구는 LLM의 발현을 정량화하는 새로운 방법을 제안하고, 이를 통해 모델의 내부 메커니즘을 더 잘 이해할 수 있게 되었습니다. 또한, 발현 강도가 환각 현상과의 상관관계를 가질 수 있음을 발견하여, 향후 환각 탐지 및 완화에 대한 새로운 통찰을 제공합니다.

### 전체 요약
이 논문은 대형 언어 모델의 발현을 정량화하기 위한 새로운 방법을 제안합니다. 변환기 블록을 마르코프 과정으로 모델링하여 마이크로 및 매크로 수준의 엔트로피 감소를 비교함으로써 발현의 강도를 측정합니다. 실험 결과, 발현 강도는 샷의 수, 모델 크기, 데이터셋의 다양성, 작업 유형, 프롬프트 형식에 따라 달라지며, LLM이 생성한 텍스트는 인간이 생성한 텍스트보다 더 큰 발현 강도를 보였습니다. 이 연구는 LLM의 발현을 이해하고 환각 탐지 및 완화를 위한 새로운 방향을 제시합니다.