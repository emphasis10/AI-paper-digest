# WildVision: Evaluating Vision-Language Models in the Wild with Human Preferences
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.11069.pdf](https://arxiv.org/pdf/2406.11069.pdf)

### 섹션 요약

#### 서론
비전-언어 모델(VLMs)은 다양한 응용 분야에서 획기적인 성과를 보이고 있습니다. 현재 평가 방법론은 단순하며, 실용적인 한계가 있습니다. CLIP 모델과 같은 최신 기술을 통해 참조가 필요 없는 평가가 가능해졌으나, 여전히 인간의 선호도를 반영하는 데는 부족함이 있습니다. 이 논문에서는 WILDVISION-ARENA 및 WILDVISION-BENCH를 소개하며, 이는 VLMs의 실제 성능을 평가하는데 중요한 데이터와 인사이트를 제공합니다.

#### WILDVISION-ARENA
WILDVISION-ARENA는 챗봇 스타일의 플랫폼으로, VLMs를 비교 평가할 수 있게 합니다. 이 플랫폼은 엘로(Elo) 랭킹 시스템을 사용하여 20개 이상의 모델을 지원합니다. 20,000번 이상의 인간-인공지능 대화를 통해 8,000번 이상의 투표 및 피드백을 수집하였고, 이를 바탕으로 WILDVISION-BENCH를 구성하였습니다. 특히 GPT-4o 모델을 판사 모델로 사용하여, Claude-3-Sonnet 모델과 비교 평가합니다. 이를 통해 자동 평가와 인간 선호도의 유사성을 0.94 스피어만 상관관계로 확인하였습니다.

#### WILDVISION-BENCH
WILDVISION-BENCH는 빠르고 인간 선호도에 맞춘 평가를 제공합니다. 다양한 대화 데이터를 안전하고 다각도로 샘플링하여, 자동 평가 방법을 곁들인 토대를 마련하였습니다. GPT-4V 모델은 다른 모델에 비해 꾸준한 성능을 보였으나, 여전히 낮은 해상도 또는 OCR 기술의 한계로 인해 세부적인 시각적 인식을 어려워합니다. 또한, 설정된 안전성 문제와 잦은 환각(잘못된 정보 생성) 현상도 문제로 지적되었습니다.

#### 전반적인 분석
20,000번 이상의 다중 모드 대화와 8,000번 이상의 투표 데이터를 바탕으로 종합적인 분석을 수행하였습니다. 이를 통해, VLMs가 시각적 문맥 인식, 공간적 추론 및 상상, 전문 분야의 지식에서 개선되어야 한다는 것을 발견하였습니다. 또한, 현재 모델들은 환각 문제 및 안전성 우려가 있으며, 이는 실제 응용에서 중요한 고려사항입니다. 본 연구의 데이터와 분석 결과는 향후 VLMs 연구에 중요한 기여를 할 것입니다.

### 종합 요약

이 논문은 비전-언어 모델(VLMs)의 평가 방법론에 대한 한계를 극복하기 위해 WILDVISION-ARENA 및 WILDVISION-BENCH를 소개합니다. WILDVISION-ARENA는 챗봇 스타일의 플랫폼으로, 다양한 모델의 성능을 비교 평가할 수 있으며, 인간의 실제 대화 데이터를 기반으로 엘로 랭킹 시스템을 적용합니다. 이를 통해 실시간 성능 평가와 분석이 가능해졌습니다. 본 논문에서 제시된 WILDVISION-BENCH는 안전하고 다각적으로 샘플링된 데이터를 바탕으로, 빠르고 인간 선호도에 맞춘 평가를 제공합니다. 종합 분석 결과, 현재 VLMs는 시각적 문맥 인식과 공간적 추론, 전문 분야의 지식에서의 성능 개선이 필요하며, 환각 문제 및 안전성 우려가 중요한 과제로 남아있음을 확인하였습니다. 본 연구는 향후 VLMs 연구에 중요한 데이터와 분석 결과를 제공하여, 더욱 발전된 평가 방법론을 제안합니다.

## Similar Papers
- [WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild](2406.04770.md)
- [GenAI Arena: An Open Evaluation Platform for Generative Models](2406.04485.md)
- [MuirBench: A Comprehensive Benchmark for Robust Multi-image Understanding](2406.09411.md)
- [WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks, and Refusals of LLMs](2406.18495.md)
- [Commonsense-T2I Challenge: Can Text-to-Image Generation Models Understand Commonsense?](2406.07546.md)
- [LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model](2404.01331.md)
- [TC-Bench: Benchmarking Temporal Compositionality in Text-to-Video and Image-to-Video Generation](2406.08656.md)
- [Visual Haystacks: Answering Harder Questions About Sets of Images](2407.13766.md)
- [Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone](2404.14219.md)
