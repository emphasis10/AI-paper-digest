# GraPE: A Generate-Plan-Edit Framework for Compositional T2I Synthesis
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.06089.pdf](https://arxiv.org/pdf/2412.06089.pdf)

1. 섹션 요약:

- **Introduction**: 이 논문은 이미지 생성 및 편집을 위한 최신 기법들을 분석하며, 특히 복잡한 지시를 충실히 따르는 이미지 생성을 위한 새로운 접근법을 제시합니다. GraPE라는 프레임워크를 제안하여 기존의 이미지 생성 모델이 갖는 문제를 해결하려고 합니다.

- **Related Work**: 기존 기술의 문제점을 식별하고, 텍스트에서 이미지를 생성하는 과정에서 발생하는 각종 어려움과 그 한계를 논의합니다.

- **Method (GraPE Framework)**: GraPE는 'Generate-Plan-Edit'라는 세 단계로 구성되어 있습니다. 이 방법은 복잡한 명령어를 여러 단순한 작업으로 나누어 처리함으로써 이미지 생성의 정확성을 높입니다.

- **Image Generation**: 이 모델은 첫 번째 단계인 'Generate'에서 기존의 텍스트-이미지 변환 모델을 사용하여 초기 이미지를 생성합니다.

- **Multi-Modal Planner**: 두 번째 단계인 'Plan'에서는 다중 모달 플래너를 사용하여 초기 이미지에서 수정이 필요한 부분을 식별하고, 이를 순차적인 수정 계획으로 표현합니다.

- **Text Guided Image Editing**: 세 번째 단계인 'Edit'에서는 이를 통해 생성된 계획을 따라 이미지를 수정함으로써 최종 이미지를 완성합니다.

- **Experiments and Results**: 다양한 데이터 셋에 대한 실험을 통해 제안된 방법의 성능을 입증하고, 기존보다 최대 20점 이상의 성능 향상을 보여줍니다.

- **Discussion and Limitations**: 그래프가 가진 한계를 논의하고, 향후 연구 방향을 제시합니다.

2. 전체 요약:

이 논문은 이미지 생성 및 편집에서의 기존 문제점을 해결하기 위해, 'Generate-Plan-Edit'의 세 단계로 구성된 GraPE 프레임워크를 제안합니다. 이 프레임워크는 복잡한 명령을 단순한 작업으로 분해하여 처리함으로써, 텍스트-이미지 변환의 정확성을 높이고자 합니다. 다양한 실험을 통해 제안된 방법의 성능이 입증되었으며, 특히 기존 모델에 비해 최고 20점 이상의 성능 향상을 보였습니다. GraPE는 객체 중심의 수정 계획을 통해 모듈식으로 작동하며, 다양한 기존 생성 모델과 편집 모델에 적용할 수 있는 유연성을 제공합니다.