# DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.18860.pdf](https://arxiv.org/pdf/2410.18860.pdf)

이 논문은 대형 언어 모델(LLM)의 허상(hallucination)을 줄이기 위해 새로운 디코딩 방법인 DeCoRe(Decoding by Contrasting Retrieval Heads)를 제안하고 있습니다. 주요 목표는 콘트라스트 디코딩과 조건부 엔트로피를 활용해 허상 가능성을 줄이는 것입니다.

### 1. 섹션별 요약

#### 도입부
대형 언어 모델은 다양한 자연어 처리 작업에서 우수한 성능을 보여주지만, 신뢰성과 실행 가능성을 방해하는 '허상'을 생성하는 문제가 있습니다. 이 논문에서는 특정 주의 헤드(retrieval heads)가 문맥 정보를 추출하는 데 중요한 역할을 하며, 이를 마스킹할 경우 허상이 유도될 수 있음을 발견했습니다.

#### 방법론
DeCoRe는 마스킹된 모델과 본래 모델의 출력을 대조함으로써, 모델이 예상하는 다음 토큰의 분포를 향상시키는 방식을 취하고 있습니다. 특히, 조건부 엔트로피를 사용하여 모델의 불확실성을 측정하고, 토큰 선택의 가중치를 조정합니다.

#### 실험 결과
DeCoRe는 다양한 지표에서 전통적인 디코딩 전략보다 우월한 성능을 보여줬으며, 요약 및 질문 응답 작업에서 특히 탁월한 성능을 발휘했습니다. 이는 DeCoRe의 허상 감소 및 정보 충실성 개선 가능성을 뒷받침합니다.

#### 결론
이 연구는 DeCoRe가 다양한 작업에서 대형 언어 모델의 정확성을 개선하고 허상을 줄이는 데 효과적임을 입증했습니다. 하지만, 특정 과제에서는 여전히 기존의 방법이 더 나은 결과를 보일 수 있어 모든 환경에서 적용 가능하지는 않을 수 있습니다.

### 2. 전체 요약
이 논문은 AI와 머신 러닝 분야에서 DeCoRe라는 혁신적 접근 방식을 통해 모델의 신뢰성을 개선하려는 시도를 다룹니다. 구체적으로, 대조 디코딩과 조건부 엔트로피를 사용하여 모델의 정보 충실성을 높이고 허상을 줄이는데 초점을 맞추고 있습니다. 이러한 방법론은 특히 복잡한 추론이 요구되는 상황에서 우수한 성능을 발휘하며, 이는 AI의 실세계 적용을 확대하는 데 기여할 수 있습니다.