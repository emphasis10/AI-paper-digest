# SambaLingo: Teaching Large Language Models New Languages
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.05829.pdf](https://arxiv.org/pdf/2404.05829.pdf)

이 문서는 대규모 언어 모델을 새로운 언어로 어떻게 학습시킬 수 있는지에 대한 연구를 다룹니다. 이 과정에서 다양한 언어들(아랍어, 불가리아어, 헝가리어, 일본어, 러시아어, 세르비아어, 슬로베니아어, 태국어, 터키어)에 대해 연구를 진행하며, 7B와 70B라는 두 가지 서로 다른 파라미터 규모에서 이 모델들을 평가하고 비교합니다. 그 결과, 기존의 다양한 언어 모델들과 비교해 우수한 성능을 보였으며, 이를 위한 다양한 방법론, 실험들이 제시되었습니다.

**1. 소개**

이 연구는 대부분의 대규모 언어 모델들이 주로 몇몇 인기 있는 언어(영어, 중국어, 프랑스어, 아랍어 등)에 중심을 두고 있으나, 다양한 언어에 대한 접근성과 능력에 있어 여전히 큰 격차가 존재한다고 언급합니다. 이를 극복하기 위해 이미 훈련된 대규모 언어 모델을 새로운 언어로 지속적으로 훈련시키는 방법에 대해 연구가 이뤄져왔다고 설명합니다. 본 논문은 LLM을 새로운 언어로 조정하는 과정에 대한 포괄적인 조사를 제시하며, 이 과정에서 어휘 확장, 직접 선호 최적화, 저자원 언어에서의 인간 정렬 문제 등을 다룹니다. 

**2. 관련 작업**

이전 연구들이 LLM을 새로운 언어로 조정하는 방법론에 대해 탐색했음에도 불구하고, 특히 새로운 언어에서 모델을 정렬하는 데 있어 설계 선택에 대한 깊은 연구가 부족했다고 분석합니다. 이에 본 연구에서는 새로운 언어로 사전 훈련된 모델을 적응시키는 명확한 프로토콜을 제시하여, 기존 연구들이 다루지 않은 어휘 확장, 토큰화기 설계, 데이터와 평가 전략 등을 포함한 다양한 설계 요소에 대해 논의합니다.

**3. 적응 방법론**

9가지 타깃 언어에 대한 최첨단 성능을 달성하기 위해 대규모 언어 모델을 새로운 언어로 적응시키는 방법론을 소개합니다. 본 논문의 주요 연구 내용 및 기여에는 새로운 언어로의 연속적 사전훈련에 대한 모범 사례 제시, 타깃 언어 용어 확장을 통한 토큰화기 개선, 다양한 임베딩 초기화 방법의 영향력 분석, 기준 체크포인트의 영어 벤치마크 품질이 언어 적응 결과를 개선할 수 있음을 보여줍니다.

이 연구는 새로운 언어로 LLM을 적응시키는 과정에서 실용적이면서도 효과적인 접근 방식을 제시하며, 이를 통해 얻은 모델이 기존의 최신 모델들을 뛰어넘는 성능을 보였다는 점에서 의의가 있습니다. 또한, 연구자들이 향후 연구를 위해 코드와 체크포인트를 공개함으로써 이 분야의 발전을 촉진하고자 합니다.

## Similar Papers
- [SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages](2407.19672.md)
- [Decoding the Diversity: A Review of the Indic AI Research Landscape](2406.09559.md)
- [Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models](2402.14714.md)
- [SambaNova SN40L: Scaling the AI Memory Wall with Dataflow and Composition of Experts](2405.07518.md)
- [Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities](2407.07080.md)
- [LLM-jp: A Cross-organizational Project for the Research and Development of Fully Open Japanese LLMs](2407.03963.md)
- [HelpSteer2: Open-source dataset for training top-performing reward models](2406.08673.md)
- [In-Context Example Selection via Similarity Search Improves Low-Resource Machine Translation](2408.00397.md)
- [H2O-Danube3 Technical Report](2407.09276.md)
