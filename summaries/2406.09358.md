# Understanding Hallucinations in Diffusion Models through Mode Interpolation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.09358.pdf](https://arxiv.org/pdf/2406.09358.pdf)

### 1. 섹션별 요약
#### 1.1 서론

- **기본 개념**: 이 논문은 확산 모델(Diffusion Models)에서 발생하는 '환각(hallucinations)' 현상을 연구합니다. 이는 원래의 학습 데이터 분포에 존재하지 않는 샘플을 생성하는 현상입니다.
- **주요 관찰**: 확산 모델이 학습 데이터 분포의 서로 근접한 모드 간을 부드럽게 보간하여 원래 데이터셋에 존재하지 않는 샘플을 생성하게 되는 현상을 '모드 보간(mode interpolation)'이라고 정의합니다.

#### 1.2 1D 가우시안 설정

- **실험 개요**: 1D 가우시안 혼합물 데이터셋을 사용하여 모드 보간을 실험합니다.
- **결과**: 모델이 훈련 데이터 분포의 불연속적 손실 지형을 부드럽게 근사화하면서 발생하는 모드 보간 현상을 확인했습니다. 이로 인해 원래 학습 데이터에 존재하지 않는 합성 샘플이 생성됩니다.

#### 1.3 2D 가우시안 설정

- **실험 개요**: 25개의 가우시안 모드가 2차원 격자 형태로 배열된 데이터를 사용하여 실험.
- **결과**: 근접 모드 간의 보간이 발생하며, 이는 주어진 분포에서 확률이 거의 없는 샘플을 생성하게 됩니다. 모드는 인접한 모드 간의 보간이 발생함을 확인했습니다.

#### 1.4 모드 보간의 원인 분석

- **주요 요인**: 모델이 불연속적인 점프를 학습하기 어려워하는 점을 지적합니다. 이를 통해 신경망이 분명히 나뉘는 모드 간의 점프를 부드럽게 근사화하는 과정을 설명합니다.
- **실험 결과**: 실제 점수 함수가 날카로운 점프를 포함하더라도 모델이 이를 부드럽게 학습하여 모드 간 보간이 일어나는 것을 발견했습니다.

#### 1.5 환각의 탐지 및 완화

- **탐지 방법**: 샘플링 과정 중 끝 부분에서 높은 분산을 보이는 샘플을 통해 환각을 탐지. 분산 기반 필터링을 통해 높은 민감도와 특이도를 유지하면서 환각 샘플을 탐지할 수 있음을 보여줍니다.
- **완화 방법**: 환각 샘플을 사전 필터링하여 다음 세대의 모델 훈련에서 제거함으로써 환각 비율을 줄이고 모델의 모드 붕괴를 일부 방지할 수 있음을 증명했습니다.

### 2. 전체 요약
이 논문은 확산 모델에서 발생하는 환각 현상을 깊이 있게 분석합니다. 환각은 모델이 훈련 데이터 분포의 모드 간을 부드럽게 보간하여 발생합니다. 실험을 통해 이러한 보간 현상이 복잡한 구조의 데이터셋에서도 발생함을 확인했습니다. 또한, 환각 샘플을 식별하는 메트릭을 개발하여 높은 민감도와 특이도를 갖춘 방법으로 환각을 탐지하고 완화할 수 있음을 입증했습니다. 이로써 모델의 반복 훈련 과정에서 발생하는 문제를 줄이는 방안을 제시합니다. 이는 확산 모델의 안정성과 신뢰성을 향상시키는 데 중요한 기여를 합니다.

**핵심 기여**: 
- 환각 현상을 모드 보간을 통해 설명.
- 높은 분산을 보이는 샘플을 통해 환각을 탐지하고 완화하는 메트릭 제안.
- 반복 훈련 과정에서의 모델 붕괴 문제 해결방안 제시.

## Similar Papers
- [Diffusion Models Without Attention](2311.18257.md)
- [Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling](2401.16380.md)
- [Repulsive Score Distillation for Diverse Sampling of Diffusion Models](2406.16683.md)
- [An accurate detection is not all you need to combat label noise in web-noisy datasets](2407.05528.md)
- [Guiding a Diffusion Model with a Bad Version of Itself](2406.02507.md)
- [Generative Modeling with Phase Stochastic Bridges](2310.07805.md)
- [Semantic Entropy Probes: Robust and Cheap Hallucination Detection in LLMs](2406.15927.md)
- [The Remarkable Robustness of LLMs: Stages of Inference?](2406.19384.md)
- [Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention](2408.00760.md)
