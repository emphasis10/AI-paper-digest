# DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.11931.pdf](https://arxiv.org/pdf/2406.11931.pdf)

### 1. 각 섹션 요약

#### 1.1 서론 (Introduction)
이 논문에서는 오픈 소스 커뮤니티 내에서 코드 인텔리전스의 발전을 다루며, 특히 DeepSeek-Coder-V2 모델을 소개합니다. DeepSeek-Coder-V2는 GPT-4 Turbo, Claude 3 Opus 및 Gemini 1.5 Pro와 같은 최신 폐쇄형 모델과 성능을 경쟁할 수 있는 공개 소스 모델입니다. 이 모델은 추가적으로 6조 개의 토큰을 사용하여 사전 학습 되었으며, 코딩 및 수학적 추론 능력을 크게 향상시켰습니다.

#### 1.2 기여 (Contributions)
DeepSeek-Coder-V2의 주요 기여는 다음과 같습니다:
- 16B 및 236B 파라미터를 기반으로 한 DeepSeek-Coder-V2 소개
- 코딩 및 수학적 작업에서 최신 폐쇄형 모델과 경쟁할 수 있는 최초의 공개 소스 모델 개발
- 연구 및 상업적 용도로 자유롭게 사용할 수 있는 모델 공개.

#### 1.3 데이터 수집 (Data Collection)
모델 학습을 위한 데이터는 60% 소스 코드, 10% 수학 코퍼스 및 30% 자연 언어 코퍼스로 구성됩니다. 총 10.2조 개의 토큰이 포함되어 있으며, GitHub 및 CommonCrawl에서 수집된 다양한 프로그래밍 언어 관련 토큰이 포함되어 있습니다.

### 2. 보정 단계 (Alignment Phase)
그룹 상대 정책 최적화(GRPO) 알고리즘을 사용하여 인간의 선호도에 맞추어 모델의 행동을 조정합니다. 코딩 도메인에서 컴파일러 피드백과 테스트 케이스를 사용하여 선호도 데이터를 수집합니다. 이는 모델의 반응이 코딩 작업에서 최적의 정확성과 인간의 선호도를 만족하도록 합니다. 학습 과정에는 Fill-In-Middle(FIM) 접근법도 사용됩니다.

### 3. 평가 및 메트릭 (Evaluations and Metrics)
DeepSeek-Coder-V2는 다양한 벤치마크에서 탁월한 성능을 보여주며, 특히 코딩 작업에서 최신 폐쇄형 모델들과 비슷한 성능을 보입니다. HumanEval에서 90.2%, MBPP에서 76.2%, LiveCodeBench에서 43.4%의 점수를 기록했으며, SWEBench에서도 10% 이상의 점수를 기록한 최초의 공개 소스 모델입니다.

### 4. 결론 (Conclusion)
이 논문에서는 DeepSeek-Coder-V2를 소개하여 코드 인텔리전스 분야를 더욱 발전시키고, 현재의 최신 폐쇄형 모델과 비교해도 수준 높은 성능을 보여주는 모델임을 입증합니다. 향후에는 모델의 지시 사항 준수 능력을 더욱 향상시켜 복잡한 프로그래밍 시나리오를 처리하고 개발 과정에서의 생산성을 높이고자 합니다.

### 2. 전반적 요약 (Overall Summary)
DeepSeek-Coder-V2는 최신 폐쇄형 코드 모델과 비교해도 손색없는 성능을 보여주는 최초의 공개 소스 모델입니다. 이 모델은 추가 사전 학습을 통해 코딩 및 수학적 추론 능력을 크게 향상시켰으며, 다양한 프로그래밍 언어를 지원하고 최대 컨텍스트 길이를 128K 토큰까지 확장했습니다. 모든 연구 및 상업적 용도로 자유롭게 이용할 수 있도록 공개된 이 모델은 코드 인텔리전스의 발전에 중요한 기여를 하고 있습니다.