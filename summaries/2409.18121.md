# Robot See Robot Do: Imitating Articulated Object Manipulation with Monocular 4D Reconstruction
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.18121.pdf](https://arxiv.org/pdf/2409.18121.pdf)

### 중요 내용 요약

#### 1. Introduction (소개)
논문은 "Robot See Robot Do" (RSRD)라는 방법을 소개합니다. 이 방법은 사람의 단일 시각적 시범을 통해 로봇이 물체를 조작하도록 하는 방법입니다. RSRD는 두 단계로 나뉩니다:
1. "See" 단계: 멀티뷰 객체 스캔과 단일 시각적 입력 비디오에서 객체 모델을 생성하고 객체의 움직임을 그룹화합니다.
2. "Do" 단계: 동일한 객체가 작업 공간에 있음을 인식하고, 시범 비디오에서 복구된 3D 객체 궤적을 로봇의 엔드 이펙터 궤적으로 계획합니다.

#### 2. Related Work (관련 연구)
기존 연구들은 시점 이동, 로봇의 물체 조작 등을 다룹니다. 본 논문은 이러한 기존 연구를 바탕으로 하여 단일 시각적 시범을 통해 물체의 조작을 학습하는 더욱 일반적인 방법을 제안합니다.

#### 3. Problem Formulation and Assumptions (문제 형식화와 가정)
RSRD는 단일 시각적 시범과 고정된 멀티뷰 객체 스캔을 입력으로 사용하며, 객체의 구조적 정보는 필요하지 않습니다. 시범 비디오에서 객체의 3D 움직임을 복구합니다.

#### 4. Methodology (방법론)
논문은 "4D-Differentiable Part Models" (4D-DPM)을 사용하여 객체의 움직임을 복구합니다. 이 방법은 분석형-합성 접근 방식을 사용하며, 멀티뷰 고정 비디오를 3D Gaussian Splat으로 처리한 다음 DINO 피처 필드를 각 객체 부분에 내장합니다.

#### 5. Experiments and Results (실험 및 결과)
RSRD는 다양한 객체를 대상으로 실험하여 높은 성공률을 기록했습니다. 평균 87%의 성공률을 기록했으며, 전체적으로 60%의 성공률을 기록했습니다.

#### 6. Conclusion (결론)
RSRD는 단일 시각적 시범을 통해 로봇이 물체의 움직임을 학습하도록 하는 혁신적인 방법입니다. 이 방법은 라벨링된 데이터셋 없이도 다양한 객체를 추적하고 복제할 수 있습니다.

### 논문의 주요 기여와 혁신 부분
- **주요 기여**: 멀티뷰 객체 스캔과 단일 시각적 시범을 결합하여 객체의 3D 움직임을 복구하는 방법론을 제시합니다.
- **혁신 부분**: 라벨링된 데이터셋 없이도 객체의 움직임을 추적할 수 있는 4D-Differentiable Part Models (4D-DPM) 방법을 제안합니다.

### 전체 요약
이 논문은 로봇이 시각적 데이터를 통해 객체의 조작 방법을 학습하는 혁신적인 방법을 제안합니다. "Robot See Robot Do" (RSRD)라는 방법은 단일 시각적 시범과 고정된 멀티뷰 객체 스캔을 통해 객체의 3D 움직임을 복구하고 이것을 로봇으로 재현하는 두 단계로 구성되어 있습니다. 이 방법론은 라벨링된 데이터 없이도 다양한 객체를 효율적으로 추적하고 복제할 수 있다는 점에서 기여도가 높습니다. 이를 통해 로봇의 조작 능력을 크게 향상시킬 수 있습니다.