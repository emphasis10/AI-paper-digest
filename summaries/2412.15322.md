# Taming Multimodal Joint Training for High-Quality Video-to-Audio Synthesis
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.15322.pdf](https://arxiv.org/pdf/2412.15322.pdf)

**1. 논문 각 섹션 요약**

- **서론**
  이 연구에서는 비디오-오디오-텍스트 간의 멀티모달 통합 학습 패러다임을 제안합니다. 이로 인해 데이터 확장과 교차 모달 이해가 개선되어 오디오 품질과 의미적 정렬이 크게 향상됩니다.

- **관련 연구**
  오디오와 비디오 간의 의미 정렬을 개선하기 위해 오디오-시각 데이터 및 오디오-텍스트 데이터의 쌍을 기반으로 훈련합니다. 이는 비디오-텍스트 쌍에도 전이될 수 있는 의미적 이해도를 제공합니다.

- **MMAudio**
  - **설명**
    MMAudio는 비디오, 오디오, 텍스트 조건을 사용하는 멀티모달 트랜스포머 네트워크로 구성되어 있으며, 학습 시 결여된 모달리티는 마스킹 처리되어 하나의 통합된 시맨틱 공간을 가능하게 합니다.
  - **조건부 동기화 모듈**
    오디오와 비주얼 간의 정밀한 시간 조정을 위해 자가 지도된 오디오-비디오 비동기 감지기를 활용하여 높은 프레임 속도의 비주얼 피처를 사용한 동기화 모듈을 소개합니다.
  - **훈련 및 추론**
    다양한 데이터세트에서 훈련해 대규모 멀티모달 데이터를 사용할 수 있으며, 오디오의 질과 의미적 정렬을 향상시킵니다.

- **실험 결과**
  오디오 품질, 의미적 정렬과 시간 조정과 같은 평가 지표에서 시각-오디오 동기화를 위해 제안한 동기 모듈이 높은 성능을 보이며, 다른 기존 방법들보다 우수한 결과를 나타냅니다.

- **결론**
  MMAudio는 데이터 모드의 생성에 있어 의미적 정렬과 동기화의 새로운 기준을 세우며, 특히 비디오-오디오 생성에서 혁신적인 성능을 보여줍니다.

**2. 전체 요약**

이 논문은 비디오, 오디오, 텍스트 모달리티 간의 통합 학습을 통해 다양한 모달 데이터 간의 의미적 정렬과 동기화를 개선하는 새로운 방법론을 제안합니다. MMAudio는 조건부 동기화 모듈을 활용하여 높은 품질의 오디오 데이터 생성과 의미적 정렬을 통해 새로운 최첨단 성능을 보여주며, 대규모 데이터세트에서 훈련된 기술로서 비디오-오디오 변환에 적용할 수 있는 잠재력을 보여줍니다.