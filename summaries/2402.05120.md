# More Agents Is All You Need
## TL;DR
## Summary
- [https://arxiv.org/pdf/2402.05120.pdf](https://arxiv.org/pdf/2402.05120.pdf)

해당 논문은 대규모 언어 모델(LLMs)의 성능을 향상시키는 새로운 방법을 제시합니다. 이 연구는 간단한 샘플링과 투표 방법을 통해 에이전트(모델 인스턴스)의 수를 증가시키면 LLMs의 성능이 향상될 수 있음을 발견했습니다. 특히, 이 방법은 기존의 복잡한 방법들과 병행하여 사용될 때 더 큰 성능 향상을 이끌어낼 수 있으며, 과제의 난이도와 성능 향상 사이에는 상관관계가 존재합니다. 이 연구는 여러 가지 언어 모델과 다양한 데이터셋에서 실험을 수행하여 이러한 발견을 검증했습니다.

### 1. 소개
대규모 언어 모델(LLMs)은 언어 생성, 이해, 추론 등 다양한 응용 분야에서 뛰어난 능력을 보이지만, 복잡한 과제를 해결할 때 정확한 답변을 제공하는 데 어려움이 있습니다. 이를 해결하기 위해 본 연구는 샘플링과 투표 방법을 통해 에이전트의 수를 증가시키는 간단하지만 효과적인 방법을 제안합니다.

### 2. 관련 연구
기존 연구들은 여러 LLM 에이전트를 사용하여 성능을 향상시키는 방법에 중점을 두었습니다. 예를 들어, LLM-Debate와 CoT-SC 방법은 여러 에이전트의 협력을 통해 추론 성능을 개선하였습니다. 그러나 본 연구는 에이전트의 수를 단순히 증가시키는 것만으로도 성능이 향상될 수 있음을 발견하였습니다.

### 3. 방법
본 연구에서 제안하는 방법은 샘플링과 투표의 두 단계로 이루어집니다. 첫 번째 단계에서는 LLM에 과제 쿼리를 반복적으로 입력하여 여러 출력을 생성합니다. 그 다음, 다수결 투표를 통해 최종 결과를 결정합니다. 이 방법은 기존의 복잡한 방법들과 병행하여 사용할 수 있으며, 더 나은 성능을 달성할 수 있음을 실험을 통해 입증하였습니다.

### 4. 실험 설정 및 결과
다양한 언어 모델과 데이터셋을 사용한 실험을 통해, 에이전트의 수를 증가시킴으로써 얻을 수 있는 성능 향상의 일반성과 호환성을 검증하였습니다. 실험 결과, 본 연구에서 제안한 방법은 다양한 과제에서 LLM의 성능을 향상시킬 수 있음을 보여주었습니다. 또한, 과제의 난이도가 증가할수록 상대적인 성능 향상이 더욱 두드러지는 것을 확인할 수 있었습니다.

### 결론
본 연구는 에이전트의 수를 증가시키는 것만으로도 LLM의 성능을 향상시킬 수 있는 간단하면서도 효과적인 방법을 제시합니다. 이 방법은 기존의 복잡한 방법들과 함께 사용될 때 더욱 효과적이며, 과제의 난이도에 따른 성능 향상의 상관관계를 밝혀냈습니다. 이러한 발견은 앞으로 LLM을 활용한 다양한 응용 분야에서의 성능 향상에 기여할 것으로 기대됩니다.