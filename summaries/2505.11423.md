# When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2505.11423.pdf](https://arxiv.org/pdf/2505.11423.pdf)

1. 논문의 각 섹션 요약

- **서론**: 논문은 대규모 언어 모델(RLLMs)이 수학 문제 해결, 계획, 다단계 질문 응답 등 다양한 문제에서 놀라운 성공을 보였다고 설명합니다. 그러나 명시적 사고 추론이 명령 수행 정확도를 낮출 수 있다는 새로운 현상을 발견합니다.

- **관련 연구**: 현존하는 대형 언어 모델들이 명시적 사고 능력을 활용하는 사례를 설명합니다. 특히, 수학과 같은 복잡한 논리적 문제에서 효과적으로 활용되고 있지만, 명령 수행 같은 구조화된 작업에서는 그 영향이 미미하다고 지적합니다.

- **실험 및 결과**: 15개의 언어 모델을 사용해 두 가지 벤치마크(IFEval과 ComplexBench)에서 명시적 사고(코드를 생각한다는 의미로 CoT)를 적용했을 때 명령 수행 능력이 낮아지는 경향을 발견했다고 보고합니다. 이는 대규모 케이스 스터디와 주의 기반 분석을 통해 확인되었습니다.

- **분석**: 명시적 사고가 성능에 미치는 부정적 영향을 줄이기 위해 네 가지 방법을 제안하고 평가합니다: 콘텍스트 학습, 자기 반성, 자가 선택적 사고, 분류기 선택적 사고.

- **결론**: 명시적 사고를 활용한 명령 수행의 실패를 체계적으로 조사하고 이를 완화하기 위한 전략을 제시했습니다. 특히 분류기를 활용한 선택적 사고법이 가장 효과적이라는 결론을 내렸습니다.

2. 전체 요약

논문은 대규모 언어 모델들이 명시적 사고를 통해 다양한 복잡한 문제에서 우수한 성과를 낸다고 평가하면서도, 설명 논리(CoT)가 명령 수행에서는 의외로 성능 저하를 초래할 수 있음을 밝혔습니다. 이를 보완하기 위해 네 가지 전략을 제안하는데, 그중 분류기를 활용한 선택적 사고법이 가장 효과적이라는 결론을 도출했습니다. 이러한 연구는 AI 연구에 있어 명시적 사고와 실용적인 수행 간의 균형을 찾는 데 중요한 인사이트를 제공합니다.