# BOND: Aligning LLMs with Best-of-N Distillation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.14622.pdf](https://arxiv.org/pdf/2407.14622.pdf)

### 1. 각 섹션의 중요한 내용 요약 및 설명

#### 1. 서론 (Introduction)
현재 최첨단 대형 언어 모델(LLMs)은 보통 세 단계를 거쳐 훈련됩니다. 먼저 대규모 데이터셋에서 다음 단어 예측으로 사전 학습을 하며, 이후 지도 학습으로 미세 조정(SFT)을 하고, 마지막으로 인간 피드백을 기반으로 강화 학습(RLHF)을 통해 개선됩니다. 하지만 RLHF 알고리즘에는 잊혀지기(French, 1992) 및 보상 해킹과 같은 몇 가지 도전과제가 존재합니다. 이를 해결하기 위해서는 높은 보상과 낮은 KL(Kullback-Leibler) 발산을 동시에 달성해야 합니다.

#### 2. 문제 설정 (Problem Setup)
LLM은 입력을 바탕으로 연속적으로 토큰을 생성하는 정책을 정의합니다. 이미 지도 학습이 완료된 참조 정책을 기반으로 사람의 선호도에 맞추기 위해 보상 모델을 사용합니다. 대부분의 RL 알고리즘은 보상과 참조 정책 간의 KL 발산의 조합을 최대화하려고 합니다.

#### 3. BOND 접근 방식 (The BOND Approach)
BOND는 Best-of-N 샘플링 전략을 통해 우수한 성능을 제공하지만, 이를 적용하는 데 드는 계산 비용이 큽니다. BOND는 이러한 Best-of-N 샘플링을 정책에 직접 전달하여 단일 샘플로 높은 성능을 달성하려는 목표를 가지고 있습니다. 이를 위해 Jeffreys 발산이라는 결합 발산 지수를 사용해 정책을 분포에 근접시키려 합니다.

#### 4. BOND의 구현과 알고리즘 (BOND Challenges and Algorithms)
BOND를 구현하는 데는 세 가지 도전과제가 따릅니다: 보상 백분위수 추정, 적절한 발산 지수 선택, 샘플링 세대 수 하이퍼파라미터 설정입니다. 이를 해결하기 위해 Monte-Carlo 백분위수 추정 방법과 Jeffreys 발산을 사용합니다.

#### 5. J-BOND (J-BOND)
J-BOND는 Jeffreys 발산을 사용하여 RLHF 알고리즘의 실행 가능성과 효율성을 높입니다. 이는 Monte-Carlo 샘플링, 앞뒤 KL 발산 목표 결합, 지수 이동 평균 앵커를 결합해 성능을 강화합니다.

#### 6. 실험 (Experiments)
BOND와 J-BOND의 효과를 입증하기 위해 두 가지 실험을 수행했습니다. 첫 번째는 요약 작업(XSum)에서 BOND의 효과를 입증하는 것이고, 두 번째는 Gemma 모델에 J-BOND를 적용해 다른 RLHF 알고리즘보다 성능이 높음을 확인했습니다.

#### 7. 결론 (Conclusion)
BOND는 Best-of-N 샘플링을 정책에 반영하여 높은 성능을 유지하면서도 계산 복잡성을 줄이는 새로운 방법을 제안합니다. 이를 통해 AI 시스템의 정렬을 개선하고 더 안전하고 신뢰할 수 있게 만들 수 있기를 기대합니다.

---

### 2. 전체 요약

이 논문은 대형 언어 모델(LLM)의 성능과 품질을 높이기 위한 새로운 방법론인 BOND(Best-of-N Distillation)를 제안합니다. 현재 사용되는 Best-of-N 샘플링 전략은 우수한 성능을 제공하지만, 계산 비용이 매우 높다는 단점이 있습니다. 이를 해결하기 위해 BOND는 Best-of-N 샘플링을 단일 샘플로 구현하여 성능을 유지하면서도 계산 비용을 줄이는 접근 방식을 제시합니다.

논문은 주요 도전과제를 해결하기 위해 Monte-Carlo 백분위수 추정 및 Jeffreys 발산을 사용해 정책을 최적화하는 방법을 제안합니다. 이를 통해 강화 학습 기반의 인간 피드백(RLHF) 알고리즘의 효율성과 실용성을 높인 J-BOND 알고리즘이 개발되었습니다. J-BOND는 여러 실험을 통해 기존 RLHF 알고리즘보다 높은 성능을 입증하며, 특히 요약 작업과 Gemma 모델을 통해 그 효과를 뚜렷이 보여줍니다.

이 연구는 AI 시스템의 정렬 문제를 해결하여 더 안전하고 신뢰할 수 있는 모델을 구축하는데 기여할 수 있을 것입니다.