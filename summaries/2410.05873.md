# MEXA: Multilingual Evaluation of English-Centric LLMs via Cross-Lingual Alignment
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.05873.pdf](https://arxiv.org/pdf/2410.05873.pdf)

### 1. 각 섹션의 중요한 내용 요약:

#### 서론
이 문서는 대규모 언어 모델(LLM)의 다중언어 평가를 위해 MEXA라는 새로운 평가 방법을 소개합니다. MEXA는 영어를 중심으로 발전한 LLM의 중간 레이어에서 영어를 피벗 언어로 활용하여 다중언어 커버리지를 평가합니다. 이를 통해 다양한 언어의 모델 성능을 비교할 수 있으며, 이는 영어 성능을 기반으로 다른 언어들에 대한 성능을 예측하는 데 도움이 됩니다.

#### 주요 기여 및 혁신
MEXA는 주어진 데이터세트와 과제를 사용하여 LLM의 다중언어 성능을 신뢰성 있게 평가할 수 있는 메트릭을 제공합니다. 이 방법은 여러 모델들(Llama, Gemma, Mistral, OLMo 등)을 통해 다방면에서 검증되어 높은 피어슨 상관 계수를 보여줍니다. 이를 통해 영어 중심 LLM의 다중언어 확장 가능성을 탐색하는 데 큰 도움이 될 것입니다.

#### Methodology
MEXA는 비영어 문장과 대응하는 영어 문장의 임베딩 정렬을 통해 여러 언어 간의 이해 능력 전이를 추정합니다. FLORES-200과 성경을 이용하여 두 가지의 병렬 데이터세트를 사용하며, BeLeBeLe, m-MMLU, m-ARC와 같은 세 가지 다운스트림 과제를 통해 평가됩니다.

#### 한계점
MEXA는 영어 중심 LLM의 다중언어 성능을 대략적으로 추정하며, 모든 모델의 모든 과제를 대체할 수는 없다는 한계를 가지고 있습니다. 그러나 이는 더 다중언어적인 모델을 개발하는 데 근거 자료로 활용될 수 있습니다.

### 2. 전반적인 요약:
이 논문은 특정한 언어나 과제에 집중하기보다, 영어-중심 LLM이 어떻게 다양한 언어에서 퍼포먼스를 발휘할 수 있는지에 대한 다중언어적 잠재력을 탐구합니다. MEXA라는 방법론을 통해 영어를 매개로 한 언어 이해력 전이를 평가하여 다양한 언어 간 성능을 보다 효율적으로 평가할 수 있도록 지원합니다. 다중언어 성능 향상을 위한 피드백 루프를 제공함으로써, 이는 다양한 문화와 언어적 맥락을 고려한 새로운 LLM 개발의 기초를 제공할 수 있습니다.