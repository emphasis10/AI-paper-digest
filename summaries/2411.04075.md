# M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.04075.pdf](https://arxiv.org/pdf/2411.04075.pdf)

### 1. 각 섹션 요약

#### 서론 및 배경
이 논문은 AI 기반의 과학적 질문 응답 시스템의 평가를 위해 M3SCIQA라는 새로운 벤치마크를 소개하고 있습니다. 기존의 평가 시스템이 단일 문서 또는 텍스트 기반에 초점을 맞춘 것과 달리, M3SCIQA는 여러 문서를 포함한 멀티모달 정보를 필요로 하며, 이러한 복잡성을 해결하기 위해 설계되었습니다.

#### 주요 기여 및 혁신
논문은 다섯 가지 주요 기여로 구성됩니다:
- M3SCIQA라는 벤치마크를 도입하여 여러 과학 문서를 이해하는 멀티모달 추론 능력을 평가.
- 18가지 기본 모델을 대상으로 한 포괄적인 평가를 통해 모델과 인간 전문가 간의 성능 격차를 확인.
- 과학적 도표 정보 검색, 긴 문맥에서의 재랭킹(long-context re-ranking) 및 장거리 검색 과제를 분석하여 현행 모델의 한계를 파악.
- 참고 논문의 시각적 맥락 및 세부 사항을 포함하는 질문을 통해 복합적인 질문 응답 평가를 가능하게 함.

#### M3SCIQA 벤치마크
M3SCIQA는 과학 논문을 멀티모달 방식으로 이해하고 평가하기 위해 설계되었으며, 두 가지 중간 질문 유형을 포함하여 구성됩니다:
- **시각적 맥락 질문**: 논문의 도표나 표에서 파생되는 질문으로, 다른 문서에서의 답변을 찾도록 함.
- **참고 기반 질문**: 해당 시각적 맥락 질문과 관련된 다른 논문에서 특정 세부 사항을 찾도록 유도.

### 2. 전체 요약
논문은 M3SCIQA라는 새로운 벤치마크를 통해 복잡한 다중 문서와 멀티모달 정보를 평가할 수 있는 인공지능 모델의 능력을 시험하고 있습니다. 이 벤치마크는 인간 전문 지식과 비교하여 현행 AI 모델의 성능 한계를 평가하여, 미래 AI 기술 개선의 방향을 제시합니다. 

이번 연구는 다양한 모델의 한계를 분석하며 궁극적으로는 더욱 향상된 추론과 검색 기능을 통해 AI의 잠재력을 극대화하는 방법을 찾기 위해 기획되었습니다.