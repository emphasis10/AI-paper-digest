# Vision language models are blind
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.06581.pdf](https://arxiv.org/pdf/2407.06581.pdf)

### 1. 각 섹션 요약

#### 소개 (Introduction)
이 논문은 최신 시각 언어 모델(VLMs, Vision Language Models)들이 인간처럼 이미지를 인식하지 못한다는 문제를 다루고 있습니다. 특히, 단순한 2D 기하학적 형태를 인식하거나 교차점을 카운트하는 등의 기본적인 시각 작업에서 VLMs가 실패하는 점을 강조합니다. 인간은 쉽게 인식할 수 있는 시각적 패턴을 VLMs는 정확하게 처리하지 못하는데, 이는 마치 근시인 사람이 세부사항을 흐릿하게 보는 것과 비슷하다고 설명합니다.

#### 비전 언어 모델 (Vision Language Models)
논문에서는 GPT-4o, Gemini-1.5 Pro, Claude-3 Sonnet, Claude-3.5 Sonnet의 네 가지 최신 VLMs를 평가합니다. 이들 모델들은 다양한 시각적 벤치마크에서 높은 점수를 기록하고 있지만, 실제로 단순한 기하학적 모양을 인식하는 데 어려움을 겪는다고 지적합니다. 모델마다 응답 성능이 다르며, 동일한 API를 사용하는 경우라도 세부적인 튜닝에 따라 성능 차이가 있음을 발견했습니다.

#### BlindTest 벤치마크
논문은 BlindTest라는 새로운 벤치마크를 도입하여 모델들의 시각적 인식을 평가합니다. 이 벤치마크는 7개의 간단한 시각적 작업으로 구성되어 있으며, 기하학적 형태의 정의 및 교차점 수를 카운트하는 등의 활동을 포함합니다. 이 작업들은 인간에게는 매우 쉽지만, 모델들은 쉽게 실패하는 것으로 나타났습니다.

#### 실험 결과 (Results)
각 작업에서 VLMs는 일관되게 저조한 성능을 보였습니다:
- 선 교차점 카운트: 대부분의 모델이 교차점을 정확히 카운트하지 못함.
- 겹치는 원 인식: 두 원이 겹쳐져 있을 때 이를 정확히 인식하지 못함.
- 그리드 행과 열 카운트: 빈 그리드의 행과 열 수를 정확히 카운트하지 못함.
- 단색 경로 추적: 단일 색상의 경로를 정확히 추적하지 못함.

#### 관련 연구 (Related Work)
기존 연구는 주로 복잡한 시각적 데이터를 이용하였으나, 본 연구는 단순한 기하학적 형태를 이용하여 기본적인 시각 인식 능력을 평가했습니다. 기존 벤치마크와 달리, BlindTest는 최소한의 선험적 지식이나 복잡한 추론을 요구하지 않습니다. 이로 인해 VLMs가 인간처럼 이미지를 인식하지 못한다는 점이 명확히 드러났습니다.

### 2. 전체 요약
이 논문은 최신 시각 언어 모델(GPT-4o, Gemini-1.5 Pro, Claude-3 Sonnet, Claude-3.5 Sonnet)들이 단순한 2D 기하학적 형태를 인식하는 데 있어 여전히 많은 한계를 가지고 있음을 보여줍니다. BlindTest라는 새로운 벤치마크를 통해 VLMs의 기본 시각 인식 능력을 평가한 결과, 모델들이 겹치는 원, 교차하는 선, 그리드의 행과 열을 정확히 인식하지 못한다는 것을 발견했습니다. 이는 VLMs가 복잡한 시각적 데이터에서는 높은 성능을 보이지만, 기본적인 시각 과제에서는 인간과 같은 성능을 발휘하지 못함을 시사합니다. 이러한 결과는 VLMs의 지속적인 발전과 개선이 필요함을 강조합니다.

이 요약을 통해 발표 자료를 준비하는 데 필요한 핵심 내용을 확보할 수 있습니다.