# The FFT Strikes Back: An Efficient Alternative to Self-Attention
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.18394.pdf](https://arxiv.org/pdf/2502.18394.pdf)

### 1. 섹션별 주요 내용 요약

**1. 도입부**
이 논문은 기존의 자기 주의 메커니즘이 긴 시퀀스를 처리할 때 복잡성이 𝑂(𝑛^2)으로 증가하여 확장성이 부족하다는 문제를 다룬다. 이를 해결하기 위해 FFTNet이라는 적응형 스펙트럴 필터링 프레임워크를 제안하며, 이는 빠른 푸리에 변환(FFT)을 이용해 시퀀스 전체의 글로벌 토큰 결합을 𝑂(𝑛log𝑛) 시간 복잡도로 처리할 수 있다.

**2. 관련 연구**
기존의 자기 주의 방식들은 시퀀스 길이가 증가할수록 연산 및 메모리 비용이 크게 증가하기 때문에 비효율적이다. Fourier-based 접근 방식은 좀 더 효율적인 글로벌 토큰 결합을 이뤄낼 수 있으며, FFTNet은 이러한 기존 기법과는 다르게 학습 가능한 스펙트럴 필터를 도입해 더 높은 표현 능력을 제공한다.

**3. 적응형 스펙트럴 필터링 방법**
FFTNet은 시퀀스를 주파수 도메인에서 변환하여 글로벌 상호작용을 만들어낸다. 이 과정에서 학습 가능한 필터를 사용하여 특정 주파수 대역을 강조하거나 감소시키며, 주파수 도메인의 역변환을 통해 복잡성을 줄이면서 표현력을 유지한다.

**4. 실험 결과**
실험은 Long Range Arena(LRA) 벤치마크와 ImageNet 분류에 대해 진행되었다. FFTNet은 LRA의 대부분의 작업에서 기존의 Transformer와 FNet보다 뛰어난 성능을 보였으며, ImageNet 분류에서도 유사한 수준의 정확도를 유지하면서 복잡성이 줄었다.

**5. 결론**
FFTNet은 자기 주의의 복잡성을 낮추고 효율성을 높이며, 학습 가능한 스펙트럴 필터로 인해 복잡한 패턴을 포착할 수 있는 능력을 제공한다. 이는 적응형 학습 전략과 강력한 이론적 기반을 결합하여 규모가 큰 시퀀스 모델링에 효과적이다.

### 2. 논문 전체 요약
이 논문은 높은 복잡성 문제를 해결하기 위해 제안된 FFTNet의 구조와 장점을 자세히 설명하고 있다. FFTNet은 푸리에 변환을 사용해 시퀀스 데이터를 처리하며, 학습 가능한 스펙트럴 필터를 통해 글로벌 및 지역적인 맥락을 모든 주파수로 연결한다. 실험 결과는 FFTNet이 대부분의 벤치마크 작업에서 기존 Transformer보다 우수한 성능을 발휘함을 보여준다. 따라서, 이는 규모가 큰 시퀀스를 효과적으로 처리할 수 있는 새로운 대안으로 제시된다.