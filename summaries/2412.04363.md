# Challenges in Trustworthy Human Evaluation of Chatbots
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.04363.pdf](https://arxiv.org/pdf/2412.04363.pdf)

### 1. 섹션별 요약

**초록**
이 논문은 Chatbot Arena와 같은 사용자 기반 플랫폼에서 인간의 평가가 어떻게 불신을 초래할 수 있는지에 대해 설명합니다. 특히, 악의적이거나 무관심한 사용자로 인한 낮은 품질의 투표가 어떻게 순위를 왜곡시킬 수 있는지를 연구하고, 이러한 플랫폼에서 고품질의 인간 주석을 확보하는 열린 과제를 논의합니다.

**서론**
자유형식 텍스트 생성의 신뢰할 수 있는 평가가 NLP에서 오랜 과제로 자리잡고 있습니다. 인간 주석은 객관적인 정확성의 개념이 없는 개방형 텍스트 생성 작업에 특히 중요합니다. 따라서, Chatbot Arena와 WildVision Arena와 같은 플랫폼은 사용자 상호작용을 통해 방대한 데이터셋을 수집하고 있으며, 이러한 데이터는 NLP 평가 환경에서 신뢰할 수 있는 벤치마크로 자리하고 있습니다.

**배경과 연구 문제**
논문은 Chatbot Arena를 사례 연구로 채택하여, 결과물의 순위 변화를 초래할 수 있는 질 낮은 선호 판단의 세 가지 원천을 탐구합니다: 무관심한 사용자, 악의적 사용자, 그리고 모호한 질문에 따른 임의적인 투표입니다. 이러한 나쁜 질의 주석이 모델 랭킹에 미치는 영향을 연구하고 있습니다.

**존재하는 문제점**
예를 들어, 무관심한 사용자와 악의적 사용자로 인한 낮은 품질의 투표가 모델 랭킹에 미치는 영향을 분석합니다. 이러한 낮은 품질의 투표는 적은 비율로도 모델의 순위를 크게 변화시킬 수 있으며, 사후에 이를 감지하는 것이 어렵습니다.

**결론 및 향후 방향**
논문에서는 플랫폼의 신뢰성을 위한 더 강력한 보호장치의 필요성을 주장하며, 이러한 시스템에 대해 사용자의 경험과 품질 통제 간의 균형을 맞추기가 얼마나 어려운지를 설명합니다. 이를 통해 미래 연구가 높은 품질의 주석을 확보하기 위한 방법을 개발할 것을 권장합니다.

### 2. 전체 요약
논문은 Chatbot Arena 같은 개방형 커뮤니티 플랫폼에서 인간이 직접 생성 모델을 평가하는 것이 어떻게 악의적인 행위자나 무관심한 사용자의 저품질 평가로 인해 왜곡될 수 있는지를 분석합니다. 이를 해결하기 위해 플랫폼은 보다 강력한 인증 시스템과 사용자 경험 및 질 관리 간의 균형을 찾아야 한다고 제안합니다. 주로 악의적인 사용자 행위를 감지하고, 더 나은 품질의 인간 피드백을 수집하기 위해 추가 연구가 필요하다고 결론지었습니다.