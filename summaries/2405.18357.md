# Faithful Logical Reasoning via Symbolic Chain-of-Thought
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.18357.pdf](https://arxiv.org/pdf/2405.18357.pdf)

### 논문 요약

#### 1. 소개
인공지능의 논리적 추론 능력을 인간 수준으로 향상시키는 것은 인공지능 시스템의 문제 해결, 의사 결정, 비판적 사고 능력을 가능하게 하는 데 중요합니다. 최근 대형 언어 모델(LLM)은 의미 이해에서 뛰어난 능력을 보이며 AGI(Artificial General Intelligence) 실현에 대한 희망을 주고 있습니다. 하지만 논리적 추론 능력을 더욱 강화하는 것은 중요한 과제입니다.

#### 2. 관련 연구
기존 연구들은 LLM을 사용하여 논리적 추론을 시도했으나, 대부분은 외부의 전통적 논리 추론 시스템에 의존하였습니다. 이런 접근 방식은 LLM의 내재적인 논리 추론 능력을 강화하지 못하고, 유연성 및 정보 손실 문제를 초래합니다. 이를 해결하기 위해, CoT(Chain-of-Thought) 기법이 도입되어 LLM이 중간 단계를 고려하며 문제를 해결하도록 하여 신뢰성을 높였습니다. 그러나 이 역시 자연어 표현의 추상성으로 인해 논리적 추론에서 한계를 가집니다.

#### 3. SymbCoT의 제안
SymbCoT는 논리적 추론을 위해 완전히 LLM 기반의 프레임워크를 제안합니다. 이는 다음의 네 가지 주요 모듈로 구성됩니다:
1. **번역기(Translator)**: 자연어로 된 전제를 기호 형식으로 변환합니다.
2. **계획자(Planner)**: 문제를 작은 하위 문제로 분해하고, 전제와 질문을 연결하는 세부 계획을 수립합니다.
3. **해결사(Solver)**: 계획에 따라 논리적 규칙을 적용하여 문제를 해결합니다.
4. **검증기(Verifier)**: 번역 및 추론 과정의 정확성을 검증합니다.

#### 4. 실험
SymbCoT는 FOL(First-Order Logic) 및 제약 최적화(Constraint Optimization) 기법을 사용하여 5개의 논리적 추론 데이터셋에서 테스트되었습니다. 결과는 SymbCoT가 기존의 CoT 및 최첨단 방법을 능가하며, 특히 복잡한 논리 추론 작업에서 현저한 개선을 보였습니다. 이는 SymbCoT의 신뢰성 있는 추론 과정 및 정보 손실 문제 해결 능력 덕분입니다.

#### 5. 결론
이 연구는 SymbCoT 프레임워크를 통해 논리적 추론 능력을 향상시키는 방법을 제안합니다. 실험 결과, SymbCoT는 CoT보다 더 나은 성능을 보였으며, 향후 연구에서는 외부 솔버와의 통합을 통해 성능을 더욱 향상시킬 계획입니다.

### 전체 요약
이 논문은 논리적 추론을 강화하기 위해 SymbCoT라는 새로운 기법을 제안합니다. SymbCoT는 LLM을 활용하여 자연어 전제를 기호 형식으로 변환하고, 논리적 규칙을 적용해 문제를 해결하는 과정에서 계획 및 검증 단계를 추가합니다. 실험 결과, SymbCoT는 기존 방법보다 우수한 성능을 보이며, 특히 복잡한 논리 추론 작업에서 큰 개선을 보였습니다. 이 연구는 논리적 추론 능력을 강화하는 데 중요한 기여를 하며, 향후 외부 솔버와의 통합을 통해 더 나은 성능을 기대할 수 있습니다.

## Similar Papers
- [How Far Are We from Intelligent Visual Deductive Reasoning?](2403.04732.md)
- [LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency](2404.12872.md)
- [Large Language Models Are Reasoning Teachers](2212.10071.md)
- [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](2404.02575.md)
- [Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities](2406.14562.md)
- [Active Prompting with Chain-of-Thought for Large Language Models](2302.12246.md)
- [Retrieved In-Context Principles from Previous Mistakes](2407.05682.md)
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](2305.10601.md)
- [Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning](2406.09170.md)
