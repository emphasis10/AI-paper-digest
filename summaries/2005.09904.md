# BiQGEMM: Matrix Multiplication with Lookup Table For Binary-Coding-based Quantized DNNs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2005.09904.pdf](https://arxiv.org/pdf/2005.09904.pdf)

이 논문은 딥러닝 모델의 정확도를 유지하면서도 모델의 크기와 필요한 연산량을 줄이는 새로운 행렬 곱셈 방법인 BiQGEMM에 대해 다루고 있습니다. 특히, 이 방법은 퀀타이즈된 DNNs(Deep Neural Networks)에 특화되어 있으며, 여러 퀀타이즈된 가중치를 한 번의 명령어로 동시에 접근할 수 있게 함으로써 메모리 대역폭의 낭비를 줄이고, 계산 효율성을 높이는 것이 주요 기여입니다.

### 1. 서론 및 배경

- **서론**: DNNs의 매개변수 수가 급격히 증가함에 따라, 모델의 복잡도와 필요한 메모리 양도 증가하고 있습니다. 이러한 문제를 해결하기 위한 한 가지 방법으로 모델 압축 기술, 특히 퀀타이제이션이 제시되고 있습니다. 이 논문에서는 퀀타이즈된 DNNs를 위한 새로운 행렬 곱셈 방법, BiQGEMM을 제안하고 있습니다. 이 방법은 메모리 접근 효율성을 높이고, 필요한 계산량을 줄여 성능을 향상시킵니다.
- **배경**: 퀀타이제이션은 모델의 크기를 줄이고 계산을 단순화하기 위해 가중치와 활성화를 저비트로 표현하는 기술입니다. 특히, 바이너리 코딩 기반 퀀타이제이션이 주목받고 있으나, 기존의 CPU와 GPU는 이를 효과적으로 지원하지 못하는 문제가 있었습니다. BiQGEMM은 이러한 문제를 해결하고자 하는 방법으로, 퀀타이제이션으로 인해 발생하는 계산의 중복성을 제거하고, 룩업 테이블을 이용해 높은 성능을 달성합니다.

### 2. 방법론

- **동기 및 정의**: BiQGEMM은 퀀타이제이션된 가중치를 인덱스로 사용하여 미리 계산된 값을 룩업 테이블에서 가져오는 방식을 사용합니다. 이를 통해 대부분의 산술 연산을 테이블 조회로 대체하여 성능을 향상시킵니다.
- **알고리즘 설명**: 룩업 테이블의 생성과 사용 방법에 대해 자세히 설명하고 있습니다. 룩업 테이블을 통해 입력 벡터와 퀀타이제이션된 가중치 행렬의 곱셈을 효율적으로 수행하는 방법을 제시합니다.
- **복잡도 분석**: BiQGEMM의 시간 복잡도가 기존 GEMM 방식에 비해 어떻게 개선되는지 분석합니다. 특히, 출력 크기가 크고 배치 크기가 작을 때 BiQGEMM의 성능 이점이 크다는 것을 강조합니다.

### 3. 실험 결과

- **실험 설정**: 다양한 프로세서 아키텍처에서 BiQGEMM의 성능을 평가하기 위한 실험 설정을 설명합니다.
- **런타임 프로파일링**: BiQGEMM을 실행할 때 각 연산의 런타임 비율을 분석하여, 주요 연산이 룩업 테이블에서 값을 검색하는 것임을 보여줍니다.
- **다른 방법들과의 비교**: BiQGEMM이 기존의 GEMM 방식, 특히 퀀타이제이션된 가중치를 사용하는 경우에 비해 어떻게 성능이 개선되는지 비교합니다. 출력 크기가 크고 배치 크기가 작은 경우 BiQGEMM의 성능 이점이 더욱 두드러집니다.

### 4. 토론 및 결론

- **토론**: BiQGEMM이 특히 자연어 처리와 같은 DNNs에 적합하며, CNNs에는 적합하지 않을 수 있음을 논의합니다. 또한, BiQGEMM을 위한 새로운 하드웨어 설계의 필요성에 대해서도 언급합니다.
- **결론**: BiQGEMM은 퀀타이제이션된 DNNs를 위한 효율적인 행렬 곱셈 방법으로, 메모리 대역폭의 활용을 극대화하고 필요한 계산량을 줄여 성능을 향상시킵니다. 이러한 접근 방식은 DNNs의 효율성을 크게 개선할 수 있는 가능성을 제시합니다.