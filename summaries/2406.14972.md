# A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.14972.pdf](https://arxiv.org/pdf/2406.14972.pdf)

먼저, 논문의 각 섹션별로 요약을 제공한 후 전체 요약을 제공하겠습니다.

### 1. 각 섹션별 요약

#### 서론
RAG(Retrieval-Augmented Generation)은 정보 검색과 생성 과정을 결합한 혁신적인 접근법이며, 이를 통해 LLMs(Large Language Models)의 한계를 보완합니다. 특히, RAG는 신뢰도와 정확성에서 뛰어난 성능을 보이며, 최신 정보를 반영하여 보다 문맥적으로 적절한 응답을 생성합니다.

#### 배경
이 섹션에서는 LLM의 학습 과정, 즉 사전 학습, 명령 조정, 그리고 인간 선호에 맞춘 최종 조정 과정을 설명합니다. 사전 학습은 다음 단어 예측 작업을 통해 광범위한 텍스트 자료를 학습합니다. 명령 조정은 정확한 지시를 따르고 다양한 유형의 명령을 효과적으로 실행하도록 모델을 훈련합니다. 마지막으로, 인간 선호에 맞춘 조정은 모델이 인간과 보다 효과적으로 상호 작용하도록 하는 과정입니다.

#### 실험 및 결과
기본 모델이 명령 조정된 모델보다 RAG 작업에서 평균적으로 20% 더 뛰어난 성능을 나타냈습니다. 이는 명령 모델이 반드시 더 우수하다는 기존의 신념을 반박하는 결과입니다. 기본 모델이 응답을 정확하게 거부하는 비율(negative rejection rate)에서 더 좋은 성능을 보였습니다.

#### 논의
기본 모델과 명령 조정 모델의 성능 차이를 분석하며, 이는 다양한 요인들이 복합적으로 작용함을 밝혀냈습니다. 이 연구는 RAG 시스템의 평가지표와 사용자 제어 메커니즘의 필요성을 제기합니다.

#### 결론
기본 모델이 명령 조정된 모델보다 RAG에서 더 나은 성능을 보이는 것으로 결론지었습니다. 이는 RAG 파이프라인의 새로운 평가 방법론과 사용자가 이 트레이드오프를 보다 직접적이고 명확하게 관리할 수 있는 메커니즘의 필요성을 시사합니다.

### 2. 전체 요약
이 논문은 기본 모델과 명령 조정 모델의 RAG 시스템 내 성능의 차이를 체계적으로 조사합니다. 예기치 않게도, 기본 모델이 RAG 작업에서 명령 조정 모델보다 더 나은 성능을 보였습니다. 이는 기존의 명령 모델의 우수성에 대한 믿음을 도전하는 결과로, 다양한 응용 분야에서 보다 신뢰성 있고 효율적인 AI 시스템을 개발하기 위한 새로운 연구 방향을 제시합니다.

논문에서는 기본 모델이 명령 조정된 모델에 비해 더 높은 정확성과 신뢰성을 보임을 밝혀내었고, 이는 보다 넓은 논의를 필요로 합니다. 최종적으로, RAG 시스템의 평가 방법론과 사용자가 모델 성능을 제어할 수 있는 메커니즘이 필요합니다.

## Similar Papers
- [Searching for Best Practices in Retrieval-Augmented Generation](2407.01219.md)
- [Human-like Episodic Memory for Infinite Context LLMs](2407.09450.md)
- [LAB: Large-Scale Alignment for ChatBots](2403.01081.md)
- [Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction](2404.12957.md)
- [Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge](2407.19594.md)
- [Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting](2407.08223.md)
- [Learning to Refuse: Towards Mitigating Privacy Risks in LLMs](2407.10058.md)
- [Adaptive Retrieval-Augmented Generation for Conversational Systems](2407.21712.md)
- [HEMM: Holistic Evaluation of Multimodal Foundation Models](2407.03418.md)
