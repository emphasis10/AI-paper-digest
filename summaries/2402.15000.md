# Divide-or-Conquer? Which Part Should You Distill Your LLM?
## TL;DR
## Summary
- [https://arxiv.org/pdf/2402.15000.pdf](https://arxiv.org/pdf/2402.15000.pdf)

**1. 논문 각 섹션 요약**

**서론:**  
이 연구는 대형 언어 모델(LLM)의 높은 추론 비용을 줄이는 방안으로, 문제를 분해하여 작은 모델에 유추하는 방법을 제안합니다. 간단히 말해서, 문제 해결 능력을 분해하여 처리하기 쉬운 부분만을 작은 모델로 전달함으로써 비용 효율성을 높이려는 것입니다.

**문제 해결 방법:**  
논문은 문제 해결 과제를 분해와 해결 단계로 나누고, 이 두 가지 능력을 작은 모델에 추출하는 방법을 연구합니다. 이는 큰 모델을 사용하지 않고도, 쉽게 해석하고 학습할 수 있는 '문제 분해 능력'을 작은 모델에 이식하여 다양한 작업에 적용할 수 있도록 합니다.

**주요 기여점 및 혁신적인 부분:**  
1. 문제 분해 능력이 중요한 이유를 설명하고, 이를 문제 해결 능력과 분리할 수 있음을 입증했습니다.
2. 문제 해결보다는 문제 분해의 추출이 더 용이하며, 다른 작업에 대한 적용성을 높일 수 있음을 실험적으로 검증했습니다.
3. 정적인 분해 및 해결 프레임워크의 장점을 강조했습니다.

**결과:**  
실험 결과, 문제 해결과 분해를 분리하여 각 단계별로 활용할 때 성능이 향상되는 것을 확인했습니다. 이를 통해 추론 시 비용 절감의 가능성을 모색하고, 문제 해결의 유연성을 증대할 수 있음을 보여줍니다.

**2. 전체 요약**

이 논문은 대형 언어 모델의 문제 해결 능력을 보다 효율적인 방식으로 활용할 수 있는 방안을 제시합니다. 문제가 복잡하고 비용이 많이 소모되는 추론 과정을 분해하여, 독립적이고 효율적으로 작은 모델을 통해 실행할 수 있습니다. 주요 혁신은 문제 해결의 두 가지 주요 단계인 분해와 해결을 분리하여, 유연성을 증대시키면서도 적절한 성능을 유지하는 것입니다. 이를 통해 AI 시스템이 더 유연하고 비용 효율적인 방식으로 발전할 수 있는 길을 열어 줍니다.