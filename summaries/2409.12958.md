# MURI: High-Quality Instruction Tuning Datasets for Low-Resource Languages via Reverse Instructions
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.12958.pdf](https://arxiv.org/pdf/2409.12958.pdf)

### 1. 각 섹션별 요약

**Introduction (소개)**  
이 논문에서는 사용자의 의도를 기반으로 대형 언어 모델(LLM)을 개선하는 방법인 지시 미세조정(Instruction tuning)을 소개합니다. 지시 미세조정은 웹에서 자동으로 수집된 데이터를 통해 이루어지며, 다국어의 저자원이 부족한 언어에 대한 데이터셋을 생성하는 데 어려움이 있습니다. 본 논문에서는 'Multilingual Reverse Instructions (MURI)'라는 새로운 방법을 제안하여 인간 주석자 없이 저자원 언어에 대한 지시 미세조정 데이터셋 생성 방법을 설명합니다.

**Related Work (관련 연구)**  
지시 미세조정 데이터셋 생성 방법에는 인간 주석, 템플릿 NLP 작업, 합성 데이터 생성 등 세 가지 주요 접근법이 있습니다. 그러나 이러한 방법들은 저자원 언어에 대해서는 한계가 있습니다. 이 논문에서는 이러한 문제를 해결하기 위해 MURI를 제안하며, 기존 방법론들과 비교 설명합니다.

**Method (방법)**  
MURI는 기존 인간이 작성한 텍스트를 가져와 역지시(Reverse Instructions) 방법과 번역 파이프라인을 사용하여 지시와 출력을 생성합니다. 이를 통해 문화적 관련성과 다양성을 유지하면서 고품질의 데이터셋을 생성합니다. 본 연구에서는 TPU Research Cloud를 활용하여 대규모 모델을 학습시키고, 다양한 설정에서 모델의 성능을 평가했습니다.

**Evaluation (평가)**  
MURI-IT 데이터셋은 13개 언어의 원어민 평가자들에 의해 평가되었습니다. MURI-101 모델은 기존의 다국어 모델보다 높은 성능을 보였으며, 특히 저자원 언어에서 성능을 크게 개선했습니다. 이는 저자원 언어의 데이터셋 보완에 MURI-IT가 유용하다는 것을 입증합니다.

**Conclusion (결론)**  
MURI는 인간 주석자 없이 저자원 언어에 대한 고품질의 지시 미세조정 데이터셋을 생성하는 혁신적인 방법입니다. MURI를 사용한 데이터셋은 다양한 다국어 언어 모델의 성능을 크게 향상시키며, 이는 더 포괄적이고 언어적으로 다양한 언어 모델을 만들기 위한 중요한 단계입니다. 향후 연구에서 데이터 품질을 더욱 향상시키고, 고급 다국어 모델을 활용하여 성능을 추가로 개선할 계획입니다.

### 2. 전체 요약
이 논문은 저자원 언어에서의 지시 미세조정 데이터셋 생성의 어려움을 해결하기 위해 'Multilingual Reverse Instructions (MURI)'라는 새로운 방법을 제안합니다. MURI는 역지시와 번역 파이프라인을 사용하여 인간의 개입 없이 고품질의 지시-출력 쌍을 생성합니다. 본 연구는 TPU Research Cloud를 통해 모델을 학습 시켰으며, 다양한 다국어 언어 모델의 평가에서 MURI-101 모델이 기존의 모델들보다 뛰어난 성능을 보였습니다. 이는 특히 저자원 언어에서 큰 성능 개선을 보이며, 더 포괄적이고 언어적으로 다양한 언어 모델을 만들기 위한 중요한 진전을 의미합니다. 이 논문은 MURI가 다국어 언어 모델 개발에 있어서 중요한 기여를 하였으며, 향후 연구를 통해 데이터 품질을 더욱 향상시키고자 합니다.