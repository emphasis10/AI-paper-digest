# Automatic Creative Selection with Cross-Modal Matching
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.00029.pdf](https://arxiv.org/pdf/2405.00029.pdf)

이 연구 논문에서는 특정한 맥락에서 이미지를 텍스트와 매칭하는 새로운 접근 방법을 소개합니다. 구체적으로, 어플리케이션 이미지를 그 어플리케이션을 찾기 위해 사용할 수 있는 검색 문구와 매칭하는 것에 중점을 둡니다. 이를 위해 사전 훈련된 교차 모달 모델에 대한 새로운 미세 조정 방법을 제안하며, 이 방법은 검색 텍스트와 어플리케이션 이미지 데이터에 특화되어 있습니다.

### 주요 내용 요약

1. **서론 및 배경**:
   - 어플리케이션 개발자들은 다양한 이미지를 사용하여 특정 페이지를 꾸미고, 다양한 관심사를 가진 사람들을 유치합니다. 개발자들은 때때로 자신들의 어플리케이션을 광고하고, 이때 가장 관련성 높은 검색 문구를 제안합니다.

2. **메소드**:
   - 제안된 접근 방식은 특정 검색 문구에 가장 잘 매칭되는 이미지를 자동으로 선택하는 방법을 제공합니다. 이는 이진 분류 문제로 모델링되며, 교차 모달 인코더를 사용하여 관련성 점수를 예측합니다.

3. **결과**:
   - 이 접근 방식은 두 가지 기준 집합에 대해 각각 0.96과 0.95의 AUC를 달성하여, 현재 최고의 모델들을 8%-17% 앞서는 성능을 보였습니다.

4. **결론**:
   - 교차 모달 모델 프레임워크는 어플리케이션과 검색 문구 간의 이미지-텍스트 매칭 예측 정확도를 크게 향상시킵니다. 이 연구는 개발자들이 자신의 어플리케이션을 홍보하는 데 가장 적합한 이미지를 자동으로 선택하는 능력을 제공합니다.

### 혁신적인 부분
이 논문의 혁신적인 점은 특정 어플리케이션 이미지를 해당 어플리케이션을 검색할 때 사용할 수 있는 문구와 매칭시키기 위해 사전 훈련된 교차 모달 모델을 미세 조정하는 새로운 방법을 개발한 것입니다. 이 접근 방식은 어플리케이션 개발을 지원하고 마케팅 전략을 개선하는 데 큰 도움이 될 것입니다.

## Similar Papers
- [Evolutionary Optimization of Model Merging Recipes](2403.13187.md)
- [Xmodel-VLM: A Simple Baseline for Multimodal Vision Language Model](2405.09215.md)
- [On Speeding Up Language Model Evaluation](2407.06172.md)
- [EVF-SAM: Early Vision-Language Fusion for Text-Prompted Segment Anything Model](2406.20076.md)
- [MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens](2404.03413.md)
- [Measuring Psychological Depth in Language Models](2406.12680.md)
- [Piccolo2: General Text Embedding with Multi-task Hybrid Loss Training](2405.06932.md)
- [An Introduction to Vision-Language Modeling](2405.17247.md)
- [Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks](2406.12066.md)
