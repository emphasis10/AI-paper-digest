# EdgeFusion: On-Device Text-to-Image Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.11925.pdf](https://arxiv.org/pdf/2404.11925.pdf)


1. **요약**

- **Abstract와 Introduction**: 이 논문은 텍스트로부터 이미지를 생성하는 과정에서 겪는 높은 계산 부담을 해결하기 위한 연구입니다. 기존 접근법에서 벗어나, 더 적은 리소스를 요구하며 고품질의 이미지 텍스트 쌍을 사용하여, 라텐트 일관성 모델(LCM)에 적합한 고급 디스틸레이션 과정을 설계하여 2단계만에 사실적이고 텍스트와 일치하는 이미지를 생성할 수 있는 방법을 개발했습니다. 이 연구는 자원 제한적인 에지 디바이스에서 1초 미만의 지연 시간으로 사진과 같은 이미지를 생성하는 것을 목표로 합니다.

- **1절 Introduction**: 안정화 확산(Stable Diffusion, SD) 모델은 텍스트로부터 고품질의 이미지를 생성할 수 있는 강력한 도구로, 창의적 예술에서 실용적인 솔루션에 이르기까지 다양한 분야에 응용할 수 있습니다. 그러나, 큰 계산 및 메모리 요구사항으로 인해 자원이 제한된 디바이스에 배포하기 어렵습니다. 이를 해결하기 위해, 몇 단계 생성, AI 생성 데이터, 아키텍처 축소 등의 방법에 중점을 둔 연구가 진행되고 있습니다.

- **2절 Proposed approach**: 이 섹션에서는 LCM의 고급 디스틸레이션을 통한 생성 속도 가속화와 향상된 데이터 품질을 이용한 훈련 방법을 제시합니다. BK-SDM-Tiny라는 최적화된 모델 구조를 통해 계산 병목 현상을 해결하고, 실제 비전 V5.1과 같은 고급 교사 모델을 사용하여 성능을 향상시킵니다.

**2. 종합 요약**

이 논문에서 제시된 "EdgeFusion"은 기존의 안정화 확산 모델을 발전시키는 새로운 접근법입니다. 자원이 제한된 에지 디바이스 환경에서도 1초 미만으로 사실감 있는 텍스트 기반 이미지를 생성할 수 있게 최적화된 과정을 제안하고 있습니다. 새롭게 제시된 고급 디스틸레이션 과정과 고품질 데이터의 활용은 이 모델이 기존 모델들과 비교해 우월한 성능을 나타낼 수 있게 합니다. 이 연구는 AI 및 머신러닝 분야에서의 응용 가능성을 확장하며, 특히 이미지 생성과 관련된 태스크에서의 실용적인 진보를 제시합니다.