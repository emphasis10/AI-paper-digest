# Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.07080.pdf](https://arxiv.org/pdf/2407.07080.pdf)

### Section Summaries in Korean

#### Abstract
이 논문에서는 저자들이 새로운 히브리어 언어 모델인 DictaLM2.0과 DictaLM2.0-Instruct를 소개합니다. 이 모델들은 저자들이 히브리어와 영어 데이터 200억 개의 토큰을 사용하여 Mistral 모델을 기반으로 훈련되었습니다. 모델의 효율적 학습을 위해 히브리어 특화 토큰 확장과 임베딩 증류 기술을 사용하였습니다. 이 모델들은 질문 응답, 감정 분석, 번역, 요약과 같은 다양한 언어 처리 과제에서 최고 성능을 달성했습니다. 저자들은 이 접근 방식이 다른 비영어권 언어로 언어 모델을 적응시키는 데에도 유용할 것이라고 제안합니다.

#### Introduction
최근 언어 모델의 발전으로 인해 자연어 처리(NLP) 기술에서 큰 도약이 있었습니다. 그러나 히브리어와 같은 저자원 언어는 데이터 부족으로 인해 높은 성능을 발휘하기 어렵습니다. 저자들은 약 100억 개의 히브리어 및 영어 데이터 토큰을 사용하여 Mistral 모델을 기반으로 한 DictaLM2.0과 DictaLM2.0-Instruct 모델을 개발하였습니다. 이 모델은 히브리어에 특화된 토큰 확장 및 임베딩 증류 기술로 효율적인 학습과 적응을 달성했습니다. 또한 명령 데이터셋을 사용하여 세분화된 과제를 해결할 수 있도록 성능을 향상시켰습니다.

#### Related Work
저자들은 비영어권 언어로 기존 언어 모델을 적응시키려는 시도가 증가하고 있다고 언급합니다. 예를 들어, Chinese-LLaMA는 중국어에 맞게 LLaMA 모델을 확장하여 성능을 향상시켰습니다. 이 논문은 이러한 이전 연구를 바탕으로 히브리어를 포함한 저자원 언어로 언어 모델을 확장하는 방법론을 채택했습니다.

#### Pre-training Data & Training Methodology
훈련 데이터를 준비하는 과정에서 히브리어와 영어 데이터를 사용하여 모델을 훈련시켰습니다. 데이터 준비 후에는 옵티맘-Habana 코드베이스와 DeepSpeed Zero-2를 사용하여 연속 사전 훈련을 진행했습니다. 이 과정에서 각 문서가 자신만의 어텐션을 사용하도록 하는 문서 어텐션 인과 마스크를 적용했습니다. 최종적으로 선정된 체크포인트는 여러 평가를 통해 선택되었습니다.

#### Evaluation
모델 성능을 평가하기 위해 자동 평가와 인간 평가를 조합한 엄격한 평가 프레임워크를 개발했습니다. 질문 응답, 감정 분석, 번역, 요약 등 다양한 테스트를 통해 모델이 히브리어 언어 과제에서 최고 성능을 달성했음을 입증했습니다. 또한 히브리어 언어 모델 평가를 위한 새로운 벤치마크 세트도 소개하였습니다.

#### Conclusion
DictaLM2.0과 DictaLM2.0-Instruct는 히브리어 NLP 분야에서 중요한 진전을 이룬 모델입니다. 이 모델들은 다양한 언어 처리 과제에서 높은 성능을 발휘함으로써 히브리어와 같은 저자원 언어의 모델 학습 및 평가에 대한 새로운 길을 제시합니다. 또한 다른 비영어권 언어로 이러한 접근 방식을 적용할 수 있는 가능성을 제공합니다.

### Overall Summary in Korean

DictaLM2.0과 DictaLM2.0-Instruct 모델은 히브리어와 같은 저자원 언어를 위한 특화된 언어 모델로, 약 200억 개의 히브리어 및 영어 데이터 토큰을 사용하여 훈련되었습니다. 저자들은 효율적인 학습과 적응을 위해 히브리어 특화 토큰 확장과 임베딩 증류 기술을 사용했습니다. 이 모델들은 히브리어 문서에 대한 질문 응답, 감정 분석, 번역, 요약 등 다양한 과제에서 최고 성능을 발휘하며, 저자들은 이를 통해 비영어권 언어로 다른 언어 모델을 적응시키는 방법론도 제시했습니다. 또한 저자들은 히브리어 언어 모델 평가를 위한 새로운 벤치마크 세트를 개발하여 커뮤니티 내에서의 연구와 협력을 촉진하고자 합니다. 이러한 연구는 히브리어 NLP뿐만 아니라 다중 언어 NLP의 발전에도 크게 기여할 것으로 기대됩니다.