# Long-LRM: Long-sequence Large Reconstruction Model for Wide-coverage Gaussian Splats
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.12781.pdf](https://arxiv.org/pdf/2410.12781.pdf)

### 1. 서론
이 논문에서는 다수의 소스 이미지를 사용하여 대규모 장면을 신속하게 재구성할 수 있는 범용 3D 가우시안 재구성 모델인 Long-LRM을 소개합니다. 기존의 모델이 1~4개의 입력 이미지만 처리할 수 있었던 것과 달리, Long-LRM은 최대 32개의 이미지를 단일 피드포워드 단계에서 처리하여 전체 장면을 재구성합니다.

### 2. 관련 연구
기존의 3D 재구성 기술과 비교하여, Long-LRM은 상호 겹치는 시각적 프레임을 필요로 하지 않으며 보다 높은 해상도와 입력을 처리할 수 있습니다.

### 3. 방법론
#### 전체 아키텍처
Long-LRM은 Mamba2 블록과 트랜스포머 블록의 혼합 구조를 특징으로 하며, 효율적인 토큰 병합과 가우시안 프루닝 과정을 통해 품질과 효율성을 모두 확보합니다.

#### Mamba2 블록
Mamba2 블록은 가벼운 계산 복잡성을 가지고 장문의 연속적인 입력에도 효과적이며, 다시말해 보다 적은 자원으로 긴 문맥을 처리할 수 있습니다.

#### 토큰 병합 및 가우시안 프루닝
높은 해상도의 이미지를 처리하기 위해 토큰 병합과 가우시안 프루닝을 도입하여 효율성을 높입니다. 이러한 과정을 통해 처리량을 줄이고도 품질 손실 없이 처리 속도를 증가시킬 수 있었습니다.

#### 학습 목표
모델의 안정적인 학습을 위해 MSE 손실, 심층 손실, 깊이 정규화와 불투명도 정규화를 포함한 다양한 손실들로 학습이 이루어집니다.

### 4. 실험 및 결과
Long-LRM은 DL3DV 데이터 세트와 Tanks and Temples 데이터 세트에서 실험되었으며, 각 장면에서 32개의 입력 이미지를 활용하여 3D GS 대비 월등한 속도와 품질(최대 10배의 속도로)로 장면을 재구성하였습니다.

### 5. 결론
Long-LRM은 넓은 범위의 씬 레벨 재구성을 위한 최초의 피드포워드 GS 솔루션으로 빠르면서도 높은 품질의 렌더링을 가능하게 합니다.

### 문서 전체 요약
이 논문은 AI 분야에서 중요한 혁신을 제안하며, 3D 가우시안 스플래팅을 활용한 신속한 대규모 장면 재구성을 가능하게 합니다. Long-LRM은 Mamba2와 트랜스포머 블록의 조합을 통해 대량의 입력을 빠르게 처리할 수 있으며, 토큰 병합과 가우시안 프루닝을 통해 자원 효율성을 향상시킵니다. 이러한 혁신적 접근은 AI 기술의 발전뿐만 아니라, 3D 비전 애플리케이션의 실질적인 발전을 도모할 수 있습니다. 이 모델은 장시간의 처리 시간을 요구하던 기존 방법에 비해 현저하게 빠른 처리 속도를 자랑합니다. 

**주요 기여 및 혁신:**
Long-LRM은 기존에 여러 제약이 있던 상황에서 다수의 입력을 효과적으로 처리함으로써 대규모 장면 전반에 걸친 재구성을 실시간에 가깝게 실현합니다. 또한, 학습과정에서 데이터 세트를 효율적으로 활용하고 있음으로써 학습 안정성을 극대로 끌어올렸습니다. 

이는 AI와 머신러닝 분야에서 중요한 기술적 도약으로, 앞으로의 연구와 실제 응용에서 많은 가능성을 제공할 것입니다.