# Piccolo2: General Text Embedding with Multi-task Hybrid Loss Training
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.06932.pdf](https://arxiv.org/pdf/2405.06932.pdf)

### 주요 내용 요약

1. **서론 및 배경**:
   - 이 논문에서는 Piccolo2라는 텍스트 임베딩 모델을 소개합니다. Piccolo2는 다양한 다운스트림 작업에서 효율적인 멀티태스크 하이브리드 손실 학습 접근 방식을 활용하여 CMTEB 벤치마크에서 새로운 최첨단 성능을 달성합니다. Piccolo2는 텍스트 데이터를 효과적으로 활용하기 위해 임베딩 차원을 확장하고 MRL(Matryoshka Representation Learning) 훈련을 사용하여 더 유연한 벡터 차원을 지원합니다.

2. **방법론**:
   - Piccolo2는 텍스트 임베딩 모델의 훈련을 위해 멀티태스크 하이브리드 손실 학습 방법을 제안합니다. 이 방법은 서로 다른 다운스트림 작업에 대해 다양한 손실 함수를 사용하여 모델 성능을 최적화합니다. 또한, MRL 훈련을 통해 임베딩 모델이 차원 축소 후에도 유용한 임베딩을 유지할 수 있도록 합니다.

3. **실험**:
   - Piccolo2는 다양한 데이터셋을 사용하여 훈련되며, 데이터 합성 파이프라인과 하드 네거티브 마이닝 접근 방식을 사용하여 고품질 데이터를 지속적으로 보강합니다. 실험 결과, Piccolo2는 CMTEB 벤치마크에서 기존의 최첨단 모델들을 능가하며, 특히 분류, 클러스터링, STS 및 페어 분류 작업에서 우수한 성능을 보였습니다.

### 혁신적인 부분
Piccolo2의 혁신성은 멀티태스크 하이브리드 손실 학습 방법을 통해 다양한 다운스트림 작업에서 탁월한 성능을 달성하는 데 있습니다. 또한, MRL 훈련을 통해 유연한 임베딩 차원을 지원하며, 데이터 합성 파이프라인과 하드 네거티브 마이닝 접근 방식을 사용하여 고품질 데이터를 지속적으로 보강합니다. 이로 인해 Piccolo2는 텍스트 임베딩 모델의 새로운 표준을 세우고 있습니다.