# Loong: Generating Minute-level Long Videos with Autoregressive Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.02757.pdf](https://arxiv.org/pdf/2410.02757.pdf)

1. 각 섹션의 요약

- **서론**: 본 연구는 AI와 머신러닝 기반의 언어 모델을 이용한 긴 동영상 생성의 도전과 기술적 문제점에 대해 논의합니다. 특히, 자연어 처리에서 성공을 거둔 자가회귀 언어 모델(LLM)을 통해 긴 동영상을 생성하는 방법을 제안합니다.

- **관련 연구**: 기존 비디오 생성 기술은 다양하지만, 특히 Diffusion 기반과 언어 모델 기반이 많이 사용되고 있습니다. 그러나 LLM을 사용한 긴 동영상 생성의 연구는 미미하며, 이 논문은 이러한 가능성을 탐험하고자 합니다.

- **본론(Loong 모델 제안)**: Loong 모델은 자가회귀 LLM을 기반으로 하여 분산형 비디오 토큰을 생성하고 이를 통해 시간에 따라 긴 동영상을 제작할 수 있도록 합니다. 모델 훈련에 있어, 짧은 비디오에서 긴 비디오로의 점진적인 훈련 전략과 손실 재조정 기법을 도입하여 훈련의 비대칭성을 완화합니다. 특히, 초기 프레임에서는 손실 비중을 높여 모델이 더 복잡한 패턴을 학습할 수 있도록 설정했습니다.

- **추론 전략**: 추가적으로 토큰 재코딩 및 샘플링 전략을 통해 비디오의 길이를 늘리고 해상도를 개선합니다. 이를 통해 분산 오류 누적을 방지하고 긴 동영상 생성의 시각적 질을 유지합니다.

- **결론 및 논의**: Loong 모델은 전반적으로 긴 동영상을 생성하는 데 있어 일관성 있는 모습, 큰 모션 다이내믹, 자연스러운 장면 전환 등을 보장합니다. 이 모델은 비디오 생성뿐만 아니라 멀티모달 학습의 발전에도 기여할 수 있을 것으로 기대됩니다. 그러나 사회적으로 가짜 콘텐츠 생성 및 오도 정보 전달에 악용될 여지가 있으므로 주의가 필요합니다.

2. 전체 요약

Loong 모델은 자가회귀 언어 모델(LLM)을 기반으로 한 새로운 비디오 생성 기술을 제안합니다. 긴 동영상을 생성하기 위한 도전은 많았지만, Loong은 짧은 동영상에서 점차 길이를 늘려가며 생성하는 혁신적인 접근을 통해 이를 해결합니다. 특히 초기 프레임의 복잡한 패턴을 더 잘 학습하도록 손실 비중을 조정하며, 토큰 샘플링 전략을 통해 비디오의 연장과 해상도 개선을 도모합니다. 이 모델은 긴 동영상 생성뿐만 아니라 멀티모달 AI 기술의 발전에도 기여할 수 있는 잠재력을 가지고 있어, AI 분야의 새로운 기회를 열어줄 것입니다.