# Towards Diverse and Efficient Audio Captioning via Diffusion Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.09401.pdf](https://arxiv.org/pdf/2409.09401.pdf)

### 1. 섹션별 요약 및 주요 기여점 설명

#### I. Introduction
오디오 캡셔닝 (Audio Captioning)은 사운드 이벤트를 탐지하고 이를 자연어로 설명하는 작업입니다. 전통적인 AR 모델은 뛰어난 성능을 보였지만, 높은 데이터와 계산 자원을 필요로 하며, 생성 속도가 느리고 반복적인 문장을 생성하는 한계가 있습니다. 반면, 본 논문에서는 비자동 회귀(NAR) 모델인 확산 기반 오디오 캡셔닝(DAC)을 제안하여 이러한 문제를 해결하고자 합니다.

#### II. Diffusion-based Audio Captioning (DAC)
DAC는 확산 모델(DDPM)을 기반으로 하여 오디오 특징을 잡음 샘플링을 통해 반복적으로 변형시키는 과정을 포함합니다. DAC는 연속적인 텍스트 잠재 공간에서 작업하며, 오디오 특징은 미리 학습된 오디오 인코더를 통해 추출된 후 투영 모듈을 통해 특징 공간으로 변환됩니다. 그런 다음 디퓨저는 각 단계에서 노이즈를 예측하여 원래 텍스트로 디코딩합니다.

#### III. Experiments
DAC 모델은 Audiocaps 데이터셋에서 학습되었으며, BLEU, METEOR, CIDEr, SPICE 등의 다양한 평가 지표에서 기존 SOTA(SOTA, State of the Art) 모델들과 비교하여 우수한 성능을 보였습니다.

#### IV. Results and Analysis
DAC 모델은 생성 품질, 다양성 및 효율성 측면에서 다른 모델들에 비해 높은 성능을 보였으며, 특히 다양한 문장 생성 및 빠른 생성 속도를 자랑합니다. 이러한 성과는 오디오 특징과 텍스트 설명을 적절히 결합한 덕분입니다.

#### V. Conclusion
본 논문에서는 확산 기반 오디오 캡셔닝 모델 DAC를 제안하고, 이를 통해 다양한 오디오 캡셔닝 작업에서 SOTA 성능을 달성하였습니다. DAC는 특히 생성 속도와 다양성 측면에서 기존 AR 모델을 능가하며, 경량화된 디자인 덕분에 다양한 디바이스에 쉽게 배포할 수 있습니다. 이는 멀티모달 콘텐츠 생성의 새로운 가능성을 열어줄 것으로 기대됩니다.

### 2. 전체 요약

본 논문에서는 Diffusion-based Audio Captioning (DAC) 모델을 제안하여 오디오 캡셔닝 작업에서 높은 생성 품질, 다양성, 효율성을 달성했습니다. 전통적인 AR 모델의 한계를 극복하고 비자동 회귀(NAR) 구조를 활용한 DAC는 빠르고 다양한 텍스트 설명을 생성할 수 있습니다. 오디오 인코딩과 텍스트 디코딩 과정에서의 크로스 어텐션 메커니즘을 통해, DAC는 오디오와 텍스트 간의 심층적인 연관성을 유지하면서도 우수한 성능을 보였습니다. DAC의 경량화된 디자인은 다양한 디바이스에서 쉽게 활용될 수 있어 향후 멀티모달 콘텐츠 생성에 큰 기여를 할 것으로 기대됩니다.