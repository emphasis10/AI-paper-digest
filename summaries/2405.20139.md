# GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.20139.pdf](https://arxiv.org/pdf/2405.20139.pdf)

#### 1. 서론
대형 언어 모델(LLM)은 자연어 이해에서 우수한 성능을 보이며, 많은 NLP 작업에서 최신 기술을 제공하지만, 새로운 지식이나 도메인 지식에 쉽게 적응하지 못하고 헛소리를 생성하는 경향이 있습니다. 반면, 지식 그래프(KG)는 구조화된 형식으로 정보를 저장하고 업데이트가 용이하여 복잡한 상호작용을 캡처할 수 있습니다. LLM과 KG를 결합한 RAG(검색 증강 생성) 프레임워크는 LLM의 헛소리를 줄이고 질문에 대한 답변을 KG 정보에 근거하여 제공할 수 있습니다.

#### 2. 관련 연구
기존의 LLM 기반 검색 방법은 복잡한 그래프 정보를 처리하는 데 한계가 있으며, 여러 홉의 정보를 필요로 하는 질문에 대한 성능이 떨어집니다. GNN-RAG는 GNN의 강력한 그래프 표현 학습 능력을 활용하여 이러한 한계를 극복합니다.

#### 3. 문제 정의 및 배경
KGQA(지식 그래프 질문 답변)는 주어진 KG와 자연어 질문에 대해 올바른 답변을 추출하는 작업입니다. 이를 위해 질문에 특정한 하위 그래프를 검색하고, GNN과 LLM을 사용하여 올바른 답변을 도출합니다. GNN은 노드 분류 문제로 KGQA를 처리하며, LLM은 자연어로 변환된 KG 정보를 사용하여 질문에 답변합니다.

#### 4. GNN-RAG
GNN-RAG는 GNN과 LLM의 강점을 결합하여 KGQA 성능을 향상시킵니다. 먼저, GNN은 밀집된 KG 하위 그래프에서 질문에 대한 답변 후보를 검색합니다. 그런 다음, KG에서 질문 엔티티와 답변 후보를 연결하는 최단 경로를 추출하여 LLM의 추론 입력으로 사용합니다. 또한, 검색 증강 기법을 개발하여 GNN-RAG의 KGQA 성능을 더욱 향상시킵니다.

#### 5. 실험 설정
WebQuestionsSP와 Complex WebQuestions 1.1의 두 가지 널리 사용되는 KGQA 벤치마크를 사용하여 실험을 수행했습니다. 실험 결과는 GNN-RAG가 기존 방법을 능가하며 복잡한 질문에 대해 탁월한 성능을 보였음을 보여줍니다. 특히, GNN-RAG+RA는 RoG보다 최대 15.5% 높은 성능을 나타냅니다.

#### 6. 결과
GNN-RAG는 두 가지 KGQA 벤치마크에서 최첨단 성능을 달성하며, GNN과 LLM의 결합이 KGQA 성능을 크게 향상시킵니다. 특히, 복잡한 질문과 다중 엔티티 질문에서 우수한 성능을 보입니다.

#### 7. 결론
GNN-RAG는 LLM과 GNN의 결합을 통해 KGQA에서 최신 성능을 달성하는 새로운 방법을 소개합니다. 이 방법은 효율성과 신뢰성을 동시에 제공하며, 복잡한 질문에 대한 LLM의 추론 능력을 강화합니다.

### 전체 요약
이 논문은 GNN과 LLM을 결합한 GNN-RAG라는 새로운 방법을 소개합니다. GNN-RAG는 밀집된 KG 하위 그래프에서 GNN이 답변 후보를 검색하고, 이를 LLM이 자연어로 추론하여 최종 답변을 도출합니다. 이 방법은 기존의 LLM 기반 검색 방법보다 복잡한 질문에서 우수한 성능을 보이며, 두 가지 KGQA 벤치마크에서 최신 성능을 달성했습니다. GNN-RAG는 효율적이고 신뢰성 있는 KGQA를 가능하게 하며, 복잡한 질문에 대한 LLM의 추론 능력을 크게 향상시킵니다.

## Similar Papers
- [From Local to Global: A Graph RAG Approach to Query-Focused Summarization](2404.16130.md)
- [CRAG -- Comprehensive RAG Benchmark](2406.04744.md)
- [Searching for Best Practices in Retrieval-Augmented Generation](2407.01219.md)
- [Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction](2405.12656.md)
- [Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation](2402.18150.md)
- [Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching](2406.06326.md)
- [Context Embeddings for Efficient Answer Generation in RAG](2407.09252.md)
- [Understand What LLM Needs: Dual Preference Alignment for Retrieval-Augmented Generation](2406.18676.md)
- [MindSearch: Mimicking Human Minds Elicits Deep AI Searcher](2407.20183.md)
