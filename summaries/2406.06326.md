# Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.06326.pdf](https://arxiv.org/pdf/2406.06326.pdf)

### 섹션별 요약

#### 1. 서론 (Introduction)

이 논문은 최신 정보를 갱신하는 어려움을 겪는 대형 언어 모델(LLM)을 위한 새로운 학습 프레임워크인 SELF-TUNING을 소개합니다. SELF-TUNING은 LLM이 새로운 문서에서 지식을 획득하고 이를 자가 학습(self-teaching)을 통해 효과적으로 기억할 수 있도록 돕습니다. 이 기술은 암기, 이해, 자기반성(self-reflection)의 세 가지 핵심 측면에 중점을 둡니다.

#### 2. 관련 연구 (Related Work)

관련 연구로는 지속적인 지식 삽입, 검색 기반 생성(RAG), 및 지식 편집 방법론이 있습니다. 기존 접근 방식의 문제점을 지적하며, SELF-TUNING이 이 문제를 어떻게 해결하는지를 설명합니다. 지식 삽입의 어려움을 강조하여 새로운 접근 방식의 필요성을 설명합니다.

#### 3. 데이터셋 (Datasets)

SELF-TUNING의 성능을 평가하기 위해 Wiki-Newpages-2023-QA 데이터셋이 도입되었습니다. 이 데이터셋은 LLM의 지식 획득 능력을 평가하기 위해 암기, 추출, 추론의 세 가지 과제를 포함하고 있습니다.

#### 4. 방법론 (Method)

SELF-TUNING은 세 단계로 구성됩니다:
1. 문서와 QA 데이터를 사용하여 초기 학습을 진행하고,
2. 새로운 문서에서 스스로 지식을 획득하도록 유도하며,
3. 최종적으로 새로운 문서를 사용하여 추가 학습을 진행합니다.
이 방법론은 이해와 자기반성을 강조하는 자가 학습 전략을 포함합니다.

#### 5. 실험 (Experiments)

SELF-TUNING의 성능을 평가하기 위해 단일 도메인, 다중 도메인, 크로스 도메인 시나리오에서 평가를 진행했습니다. 결과적으로 SELF-TUNING은 PPL(Perplexity)을 크게 줄이고, EM(Exact Match)을 증가시키며, 지식 추출 및 보존 능력에서도 뛰어난 성과를 보였습니다.

#### 6. 결론 (Conclusion)

SELF-TUNING은 새로운 지식을 효과적으로 획득하고 기존 지식을 보존하는 데 뛰어난 성과를 보였으며, 이를 통해 LLM의 신뢰성과 실용성을 크게 향상시킬 수 있습니다. 앞으로는 다양한 모델과 도메인에서도 이 방법을 적용할 계획입니다.

### 전체 요약

이 논문은 최신 정보를 반영하는 LLM의 문제점을 해결하기 위해 SELF-TUNING이라는 새로운 학습 프레임워크를 도입합니다. SELF-TUNING은 자가 학습을 통해 문서에서 지식을 효과적으로 획득하고 이를 기억, 이해, 자기반성을 통해 강화하는 방법론입니다. 이 방법론을 평가하기 위해 새로 만든 Wiki-Newpages-2023-QA 데이터셋을 사용하여 단일 도메인, 다중 도메인, 크로스 도메인 시나리오에서 성능을 검증했습니다. 결과적으로 SELF-TUNING은 지식 암기, 추출, 추론에서 뛰어난 성과를 보였으며, 기존 지식도 효과적으로 보존하였습니다. 이러한 접근 방식은 LLM의 신뢰성을 높이고 실용성을 강화하는 데 매우 유용할 것입니다. 앞으로 다양한 모델과 도메인에 이 방법을 적용할 계획이 있습니다.