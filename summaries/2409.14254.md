# Instruction Following without Instruction Tuning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.14254.pdf](https://arxiv.org/pdf/2409.14254.pdf)

## 1. 각 섹션의 요약

### Abstract (초록)
이 연구에서는 명시적인 지시 튜닝(Instruction Tuning) 없이 모델이 어떻게 지시를 따를 수 있는지에 대해 조사합니다. 지시-응답 쌍 없이 응답만으로 훈련하거나, 매우 좁은 영역의 데이터로 훈련한 경우에도 모델이 넓은 영역의 지시를 따르는 행동을 보일 수 있음을 발견했습니다.

### Introduction (서론)
지시 튜닝은 널리 사용되는 방식으로, 다양한 응답 분포를 학습해서 지시에 맞는 응답을 생성합니다. 하지만 지시 튜닝 없이도 모델이 지시를 따르는 행동을 보일 수 있는 두 가지 방법을 발견했습니다:
1. 응답 튜닝(반드시 지시에 대응하지 않아도 됨)
2. 단일 작업 미세 조정 (좁은 영역의 데이터로 훈련).

### Related Work (관련 연구)
이전 연구는 모델의 지시-응답 쌍 훈련이 적은 데이터로도 효과적임을 보여주었습니다. 또한, 특정 작업에 대한 미세 조정이 넓은 지시를 따르는 행동을 유발할 수 있음을 시사.

### Experiment Setting (실험 설정)
모델은 대규모 텍스트 코퍼스를 사용해 사전 훈련됩니다. 이후 지시 튜닝은 모델의 매개변수를 미세 조정하여 지시에 따른 유용한 응답을 제공하도록 합니다. 실험은 Nvidia GPU 머신에서 수행되었고, 다양한 하이퍼파라미터가 사용되었습니다.

### Response Tuning Yields Instruction Following (응답 튜닝이 지시를 따르게 함)
응답 튜닝만으로도 지시를 따르는 행동을 관찰할 수 있었습니다. 이는 모델이 이미 지시-응답 관계를 어느 정도 학습했음을 시사합니다. 이러한 방법은 GPT-3.5-turbo 모델과 비교했을 때도 약 43%의 승률을 기록했습니다.

### The Response Ranking Capability (응답 평가 능력)
모델은 지시 없이도 적절한 응답을 높은 확률로 생성할 수 있습니다. 이는 사전 훈련된 모델이 이미 지시와 응답 간의 관계를 어느 정도 이해하고 있음을 보여줍니다.

### Single-Task Finetuning Yields Instruction Following (단일 작업 미세 조정이 지시를 따르게 함)
단일 작업에 대한 미세 조정도 지시를 따르는 행동을 유발합니다. 이는 모델이 특정 작업에 국한되지 않고 넓은 범위의 지시에 응답할 수 있음을 보여줍니다.

### A 3-Rule Adapter for Instruction Following (지시를 따르는 3단 규칙 어댑터)
세 가지 간단한 규칙으로 응답을 생성하도록 모델을 조정하는 방법을 제안합니다:
1. EOS(End Of Sequence) 토큰의 확률을 점진적으로 증가
2. 반복 패턴을 페널티 부여
3. 15개의 단어 확률을 균일하게 변경.

### Conclusion (결론)
명시적인 지시 튜닝 없이도 모델이 지시를 따르는 행동을 보일 수 있음을 발견했습니다. 이는 모델의 배포 시 넓은 범위의 테스트와 안전성 검증이 필요함을 의미합니다.

## 2. 전체 요약

이 연구는 명시적인 지시 튜닝 없이도 모델이 지시를 따르는 행동을 보일 수 있음을 밝혀냈습니다. 중요한 기여는 다음과 같습니다:
1. **응답 튜닝**: 지시 없이 응답만으로도 모델이 지시를 따를 수 있음을 보여줍니다.
2. **단일 작업 미세 조정**: 특정 도메인에서 훈련된 모델이 넓은 도메인의 지시를 따를 수 있음을 확인했습니다.
3. **간단한 규칙 어댑터**: 세 가지 규칙을 사용해 간단하게 지시를 따르는 모델을 구현할 수 있습니다.

이 결과는 미래의 AI 연구 및 응용 프로그램에서 모델이 보다 효과적으로 지시를 따르게 하는 방법을 제공하며, 모델 배포 시 넓은 범위의 테스트와 안전성 검증이 필요함을 제안합니다.