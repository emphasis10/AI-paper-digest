# In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.19094.pdf](https://arxiv.org/pdf/2404.19094.pdf)

### 1. 각 섹션의 주요 내용 요약

#### Abstract
이 연구는 Symbolic Regression(SR)에서 대형 언어 모델(LLMs)의 잠재력을 탐구합니다. In-Context Symbolic Regression(ICSR)를 소개하며, 이 방법은 LLM을 활용해 함수 형태를 반복적으로 개선하고, 외부 옵티마이저로 계수를 결정합니다. LLM이 수학적 능력을 활용하여 초기 후보 함수를 제안하고 오차를 기반으로 이를 개선합니다. 연구 결과, ICSR이 네 가지 대표적인 벤치마크에서 기존 SR 기법과 비교해 더 나은 성능을 보이며, 더 단순한 방정식을 만들어 냅니다.

#### Introduction
전통적인 SR 알고리즘은 주로 유전 프로그래밍(GP)에 의존하며, 이는 기본 수학 표현 블록을 진화적 생물학 전략을 통해 복잡한 공식으로 결합합니다. 최근 Transformer 모델의 성공으로 언어 처리와 컴퓨터 비전 분야뿐만 아니라 SR에서도 LLM의 가능성이 제기되었습니다. 이에 따라, 이 연구는 ICSR을 제안하며, 이는 사전 학습된 언어 모델을 활용하여 데이터에 맞는 새로운 방정식을 찾고 반복적으로 개선합니다.

#### Related Work
기존의 SR 방법은 주로 유전 프로그래밍에 의존하며, 최근에는 딥러닝 기법이 이를 보완하려는 시도가 있었습니다. Transformer 기반의 방법도 동원되었으나, ICSR은 기존 방식과 달리 기초 모델을 사용하여 수학적 지식을 활용합니다.

#### Methodology
ICSR은 LLM에 이전에 테스트된 방정식과 적합도 점수를 제공하여 새로운 후보를 생성하도록 유도합니다. 이는 컴퓨팅 자원이 소진되거나 수렴할 때까지 반복됩니다. 이를 통해 LLM의 사전 학습 모델 개선이 가능하며, 수식의 도메인과 해석을 자연 언어로 통합할 수 있습니다.

#### Experiments and Results
ICSR은 Nguyen, Constant, R, Keijzer 벤치마크에서 기존 SR 기법과 비교하여 더 나은 성능을 보였으며, 더 낮은 복잡성의 방정식을 생성했습니다. 이는 기존 데이터를 벗어난 일반화 성능을 얻는 데 유리합니다.

#### Conclusion and Future Work
ICSR은 LLM을 활용하여 SR 작업에서 높은 성과를 달성했으며, 자연 언어 인터페이스와 Tree 기반 탐색 알고리즘 결합 등의 향후 연구 방향을 제시합니다. 또한, 특별히 도메인 지식을 추가하지 않고도 LLM이 SR을 수행할 수 있는 능력을 증명하였습니다.

### 2. 전체 요약
이 연구는 대형 언어 모델(LLMs)을 활용한 In-Context Symbolic Regression(ICSR)을 소개합니다. 기존의 심볼릭 회귀(SR) 방법들과 달리, ICSR은 대형 언어 모델이 사전 훈련된 수학적 지식을 활용하여 초기 함수를 제안하고 반복적으로 개선합니다. 실험 결과, ICSR은 네 가지 벤치마크에서 기존 방법보다 우수한 성능을 보였으며, 더 단순하고 일반화 성능이 뛰어난 방정식을 생성했습니다. 이 연구는 ICSR이 LLM을 활용한 SR 작업에서의 가능성을 제시하며, 자연 언어 인터페이스와 다른 탐색 알고리즘의 결합 등을 통한 향후 연구 방향을 논의합니다.

## Similar Papers
- [VCR: Visual Caption Restoration](2406.06462.md)
- [Recursive Introspection: Teaching Language Model Agents How to Self-Improve](2407.18219.md)
- [Masked Attention is All You Need for Graphs](2402.10793.md)
- [Conformal Prediction via Regression-as-Classification](2404.08168.md)
- [Cost-Effective Hallucination Detection for LLMs](2407.21424.md)
- [HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors](2406.12459.md)
- [PINE: Efficient Norm-Bound Verification for Secret-Shared Vectors](2311.10237.md)
- [The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism](2407.10457.md)
- [AI-Assisted Generation of Difficult Math Questions](2407.21009.md)
