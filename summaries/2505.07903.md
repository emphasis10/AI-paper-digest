# SEM: Reinforcement Learning for Search-Efficient Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2505.07903.pdf](https://arxiv.org/pdf/2505.07903.pdf)

1. 각 섹션의 중요 내용 요약:

- **서론(Introduction)**:
  최근 대형 언어 모델(LLM)의 진보는 검색 엔진과 같은 외부 도구 사용의 필요성을 제기했습니다. 이 논문에서는 대형 언어 모델이 언제 검색을 사용하고 언제 내부 지식에 의존해야 할지를 구별하도록 훈련하는 새로운 강화 학습 프레임워크인 SEM을 소개합니다. SEM은 검색 과정을 최적화하여 불필요한 검색을 줄이고 필요한 경우 검색을 효과적으로 활용하는 것을 목표로 합니다.

- **방법(Method)**:
  SEM 프레임워크는 모델이 언제 검색 기능을 사용할 것인지를 결정하도록 그룹 상대 정책 최적화(GRPO) 방법을 사용합니다. 모델은 내부 지식만으로 충분한 경우 검색을 사용하지 않도록 훈련되며, 불확실한 경우에만 검색하여 필요한 정보를 얻고 답변의 정확도를 향상시킵니다.

- **실험 및 결과(Experiments and Results)**:
  SEM을 적용한 모델은 여러 데이터셋에서 테스트되었으며, 불필요한 검색 횟수를 줄이면서도 높은 정확도를 보이는 것으로 나타났습니다. 특히 SEM은 HotpotQA, MuSiQue, MMLU, GSM8k 등에서 두드러진 성능 향상을 보였습니다. 이는 SEM이 모델의 검색 의사 결정 능력을 향상시키며 내부 추론 능력을 강화한다는 것을 보여줍니다.

- **결론(Conclusion)**:
  SEM 프레임워크는 LLM의 검색 사용 방식을 효율적으로 개선하여 모델의 이유력과 자원 활용 효율성을 증대시킵니다. 이는 실세계 시나리오에서 LLM의 실용성을 높이고 향후 상호작용 및 맥락 인식 AI 시스템 개발의 기초가 됩니다.

2. 전체 요약:

이 논문은 대형 언어 모델이 검색 도구를 언제 사용할지를 결정하는 새로운 강화 학습 프레임워크인 SEM을 제안합니다. 연구는 검색 활용을 최적화하여 모델의 정확도와 효율성을 개선하였으며, 불필요한 검색을 줄이고 필요한 시점에 적절히 검색을 활용하도록 모델을 훈련합니다. 실험 결과, SEM 방법론은 다양한 베이스라인 모델들과 비교하여 우수한 성능을 보였으며, 이는 모델의 검색 결정 능력과 내부 추론 능력을 강화하는 데 기여합니다.