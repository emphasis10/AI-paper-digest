# Fast Inference from Transformers via Speculative Decoding
## TL;DR
## Summary
- [https://arxiv.org/pdf/2211.17192.pdf](https://arxiv.org/pdf/2211.17192.pdf)

이 연구 논문은 "Fast Inference from Transformers via Speculative Decoding"이라는 제목으로, 추론 속도를 향상시키기 위해 추측적 디코딩(speculative decoding)이라는 새로운 기술을 소개합니다. 이 기술은 Transformer 모델에서의 디코딩 과정을 가속화하는 방법으로, 여러 토큰을 병렬로 생성할 수 있게 함으로써 기존 방식보다 빠른 추론을 가능하게 합니다.

### 주요 내용 요약

1. **서론 및 배경**:
   - 대규모 자동회귀 모델, 특히 Transformer는 능력이 뛰어나지만, 큰 모델에서 단일 디코드 단계가 상당히 느린 문제가 있습니다. 이러한 문제를 해결하기 위해 추측적 디코딩 방법을 도입합니다.

2. **추측적 디코딩 개요**:
   - 추측적 디코딩은 효율적인 근사 모델을 사용하여 먼저 여러 완성 추측을 생성하고, 대상 모델을 사용하여 이 추측들을 병렬로 평가하여 가능한 한 많은 추측을 채택합니다.

3. **추측적 샘플링**:
   - 이 방법은 근사 모델에서 생성된 분포를 사용하여 토큰을 추측적으로 샘플링하고, 대상 모델에서 이를 검증합니다. 이 과정을 통해 실제 모델 출력과 동일한 분포를 유지하면서 디코딩 속도를 향상시킵니다.

4. **성능 평가 및 응용**:
   - T5-XXL 모델을 사용한 실험에서, 표준 T5X 구현과 비교하여 2배에서 3배의 속도 향상을 보였습니다. 이 방법은 실제 생산 환경에서 쉽게 적용할 수 있으며, 새로운 모델을 훈련할 필요가 없습니다.

### 혁신적인 부분
추측적 디코딩의 혁신성은 별도의 모델 아키텍처 변경, 훈련 절차 변경, 또는 모델 재훈련 없이 기존의 Transformer 모델에서 추론 속도를 향상시킬 수 있다는 점에 있습니다. 이는 병렬 처리를 통해 추론 작업을 가속화하고, 특히 메모리 대역폭이 병목 현상을 일으키는 상황에서 유용합니다.

이 연구는 Transformer 모델의 디코딩 속도를 현저히 향상시킬 수 있는 새로운 기술을 제시하며, 향후 자연어 처리뿐만 아니라 다른 많은 분야에서의 응용 가능성을 제공합니다.

## Similar Papers
- [Accelerating Large Language Model Decoding with Speculative Sampling](2302.01318.md)
- [EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees](2406.16858.md)
- [Distributed Speculative Inference of Large Language Models](2405.14105.md)
- [Accelerating LLM Inference with Staged Speculative Decoding](2308.04623.md)
- [SPEED: Speculative Pipelined Execution for Efficient Decoding](2310.12072.md)
- [Who Says Elephants Can't Run: Bringing Large Scale MoE Models into Cloud Scale Production](2211.10017.md)
- [Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding](2401.07851.md)
- [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](2101.03961.md)
- [Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting](2404.18911.md)
