# Conformer-Based Speech Recognition On Extreme Edge-Computing Devices
## TL;DR
## Summary
- [https://arxiv.org/pdf/2312.10359.pdf](https://arxiv.org/pdf/2312.10359.pdf)

### 1. 각 섹션의 중요 내용 요약

#### 초록 (Abstract)
이 논문은 Conformer 기반의 최신 스트리밍 자동 음성 인식 (ASR) 시스템을 자원 제한 환경인 스마트폰, 스마트 웨어러블 기기, 소형 가정 자동화 장치에서 구현하기 위한 다양한 모델 구조 조정 및 최적화 방법에 대해 소개합니다. 제안된 방법은 정확도를 저하시키지 않으면서, 소형 웨어러블에서 5.26배 빠른 실시간 음성 인식을 달성하며 에너지 소비를 최소화합니다. 이러한 방법은 다른 트랜스포머 기반 서버 없는 AI 응용 프로그램에도 널리 적용될 수 있습니다.

#### 1. 서론 (Introduction)
Conformer 기반의 엔드 투 엔드(End-to-End, E2E) ASR 시스템은 최근 상당한 발전을 이루었으며, 자원 제한 모바일 장치에서도 완전한 신경 음성 인식을 가능하게 했습니다. 이 시스템은 기존의 혼합 HMM 기반 ASR 시스템에 비해 단순화된 훈련 절차와 더 나은 단어 오류율(WER)을 제공합니다.
 
#### 2. 선행 연구 (Prior Work)
트랜스포머 아키텍처의 효율성을 개선하기 위한 연구는 상당한 관심을 받고 있습니다. 기존 연구들은 주로 모델 아키텍처 개선 및 하드웨어 구성에 중점을 두고 있습니다. 본 연구는 모델 재훈련 없이 추론 효율성을 향상시키는 후처리 기법에 주로 초점을 맞추고 있습니다.

#### 3. 백본 모델 (Backbone Model)
우리의 백본 모델은 Conformer 신경 아키텍처를 기반으로 하고 있으며, 이 모델은 다중 작업 학습 메커니즘을 통해 CTC 및 Attention 기반 인코더 디코더를 결합한 듀얼 디코더로 구성되어 있습니다.

#### 4. 제안된 최적화 (Proposed Optimizations)
- **깊이 분리형 합성곱 (Depthwise Separable Convolution)**: Conformer 인코더의 기존 바닐라 합성곱 계층을 깊이 분리형 합성곱으로 대체하여 계산 비용을 줄였습니다.
- **메모리 인식 그래프 실행 (Memory-aware Graph Execution)**: Apple Neural Engine(ANE)에 최적화된 트랜스포머를 구현하기 위해 ANE의 4차원 및 채널 우선 아키텍처에 맞추어 데이터 형식을 선택하고, 캐시 상주를 증가시키는 작업을 수행하였습니다.
- **층 정규화의 안정성 (Stability of Layer Normalization)**: 저정밀 하드웨어 환경에서 발생하는 수치적인 불안정을 해결하기 위해 Lp-노름을 안정화시키는 최적의 프리-정규화 방법을 도입하였습니다.

#### 5. 성능 및 품질 평가 (Performance and Quality)
- **실시간 인자 (RTF) 성능**: Apple Watch에서 5.26배 빠른 실시간 인식을 달성하여 성능 목표를 충족했습니다.
- **에너지 소비**: 하드웨어 가속기를 사용하여 에너지 소비를 한 단계 줄였습니다.
- **수치적 안정성 (Numeric Stability)**: 수치적 안정성을 개선하여, 저정밀 환경에서 발생할 수 있는 오버플로우 및 언더플로우 문제를 해결했습니다.
- **WER 비교**: FP16과 FP32 사이의 WER 차이는 미미하며, DWS와 바닐라 합성곱은 거의 동일한 정확도를 제공합니다.

#### 6. 결론 (Conclusions)
제안된 최적화 방법은 Conformer CTC ASR 모델이 모바일 폰 및 웨어러블 기기와 같은 자원 제한 장치에서 실행될 수 있도록 하며, 인식 정확도를 유지하면서 실시간보다 빠르게 동작하고 더 적은 에너지를 소비할 수 있도록 합니다. 이론적인 수치적 안정화 기술은 다양한 딥러닝 모델과 컴퓨팅 작업에 적용될 수 있습니다.



### 2. 전체 요약

이 논문은 자원 제한 환경에서 Conformer 기반의 최신 스트리밍 자동 음성 인식(ASR) 시스템을 구현하기 위한 다양한 최적화 방법을 제안합니다. 제안된 방법은 모델 구조 조정 및 수치적인 최적화를 통해 모바일 폰, 웨어러블 기기 및 소형 가정 자동화 장치에서 정확도를 저하시키지 않으면서 빠르고 효율적인 음성 인식을 가능하게 합니다. 이를 통해 Apple Watch에서 5.26배 빠른 실시간 인식을 달성하였으며, 에너지 소비도 한 단계 줄었습니다. 또한, 수치적 안정성을 높이는 최적의 프리-정규화 방법을 도입하여, 저정밀 하드웨어 환경에서 발생하는 오버플로우 및 언더플로우 문제를 해결했습니다. 이러한 최적화 방법은 다른 트랜스포머 기반 서버 없는 AI 응용 프로그램에도 널리 적용될 수 있습니다.

## Similar Papers
- [A Primer on the Inner Workings of Transformer-based Language Models](2405.00208.md)
- [Enhancing CTC-based speech recognition with diverse modeling units](2406.03274.md)
- [Scalify: scale propagation for efficient low-precision LLM training](2407.17353.md)
- [State Space Model for New-Generation Network Alternative to Transformers: A Survey](2404.09516.md)
- [Accelerating LLM Inference with Staged Speculative Decoding](2308.04623.md)
- [BitNet: Scaling 1-bit Transformers for Large Language Models](2310.11453.md)
- [Autoregressive Speech Synthesis without Vector Quantization](2407.08551.md)
- [VeRA: Vector-based Random Matrix Adaptation](2310.11454.md)
- [Talaria: Interactively Optimizing Machine Learning Models for Efficient Inference](2404.03085.md)
