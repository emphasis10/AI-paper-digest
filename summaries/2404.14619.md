# OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.14619.pdf](https://arxiv.org/pdf/2404.14619.pdf)

이 논문은 OpenELM이라는 새로운 언어 모델의 소개 및 평가에 대해 다룹니다. 주요 내용은 다음과 같습니다.

1. **서론 및 배경**: OpenELM은 공개적으로 사용 가능한 데이터셋에서 사전 훈련된 언어 모델로, 투명하고 재현 가능한 연구를 촉진하고자 하는 목적으로 개발되었습니다. 이 모델은 높은 정확도를 유지하면서도 사전 훈련에 필요한 토큰 수를 현저히 줄였습니다.

2. **OpenELM 구조**: OpenELM은 각 레이어에서 파라미터를 효율적으로 할당하는 레이어-와이즈 스케일링 전략을 사용합니다. 이 방법은 입력에 가까운 트랜스포머 레이어에서는 작은 잠재 차원을 사용하고 출력에 가까워질수록 레이어를 점진적으로 확장합니다.

3. **사전 훈련 및 평가**: OpenELM은 RefinedWeb, PILE, RedPajama, Dolma v1.6 등의 공개 데이터셋을 사용하여 사전 훈련됩니다. 평가는 여러 리더보드 작업과 표준 제로샷 작업을 통해 이루어집니다.

4. **성능**: OpenELM은 비슷한 크기의 기존 언어 모델보다 우수한 성능을 보여줍니다. 예를 들어, 1.1B 파라미터 모델은 OLMo보다 평균 정확도가 2.36% 높습니다.

5. **소스 코드 및 모델 가용성**: OpenELM의 전체 프레임워크, 훈련 로그, 여러 사전 훈련된 체크포인트, 훈련 구성 등이 공개되어 있으며, GitHub 및 HuggingFace를 통해 접근할 수 있습니다.

6. **결론**: OpenELM은 공개 연구 공동체를 강화하고 향후 연구 노력을 지원하기 위해 개발되었습니다. 이 모델은 공개적으로 접근 가능하고, 재현 가능한 고성능 언어 모델의 개발을 목표로 합니다.

이 논문은 언어 모델의 효율적인 파라미터 할당과 향상된 정확도를 실현하기 위한 새로운 접근 방식을 제시하며, 이는 투명하고 개방된 연구를 촉진하는 데 기여할 것입니다.

## Similar Papers
- [Item-Language Model for Conversational Recommendation](2406.02844.md)
- [CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster Pre-training on Web-scale Image-Text Data](2404.15653.md)
- [Pre-training Small Base LMs with Fewer Tokens](2404.08634.md)
- [ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models](2310.04564.md)
- [NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment](2405.01481.md)
- [MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series](2405.19327.md)
- [Finch: Prompt-guided Key-Value Cache Compression](2408.00167.md)
- [LLM in a flash: Efficient Large Language Model Inference with Limited Memory](2312.11514.md)
- [Bytes Are All You Need: Transformers Operating Directly On File Bytes](2306.00238.md)
