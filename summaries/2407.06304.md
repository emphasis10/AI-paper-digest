# VIMI: Grounding Video Generation through Multi-modal Instruction
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.06304.pdf](https://arxiv.org/pdf/2407.06304.pdf)

### 섹션별 요약 및 주요 기여사항

#### 1. 서론 (Introduction)
이 논문은 비디오 생성에서 텍스트와 비주얼 입력을 통합하는 멀티모달 프롬프트 데이터셋의 필요성을 강조합니다. 기존 모델들은 주로 텍스트 입력만 사용하여 훈련되었기 때문에 비주얼 그라운딩이 부족하여 다양한 멀티모달 통합에 한계가 있음을 지적합니다. 이를 해결하기 위해 저자들은 검색 방법을 사용하여 멀티모달 프롬프트 데이터셋을 구축하고, 이를 통해 다양한 비디오 생성 작업을 수행할 수 있는 두 단계의 훈련 전략을 제안합니다.

#### 2. 관련 연구 (Related Work)
관련 연구에서는 검색 보강 방법이 언어 모델뿐만 아니라 이미지 생성 모델에서도 유용하다는 것을 보여줍니다. 특히, 텍스트-이미지 생성에서 검색 방법을 사용하여 모델의 효율성을 높이는 다양한 연구를 소개합니다.

#### 3. 방법론 (Method)
저자들은 멀티모달 입력-비디오 데이터셋을 구축하기 위해 검색 방법을 사용하는 새로운 접근 방식을 제안합니다. 먼저, 웹 스케일 이미지-텍스트 쌍을 검색하여 멀티모달 문서를 입력과 결합해 새로운 멀티모달 입력을 형성합니다. 그런 다음, 이를 통해 멀티모달 조건부 비디오 생성 프레임워크를 훈련시킵니다. 또, 멀티모달 지시 튜닝을 통해 비디오 생성 모델을 더욱 정교화합니다.

#### 4. 실험 (Experiments)
실험 결과, 제안된 방법이 다양한 비디오 생성 작업에 효과적임을 보여줍니다. 제안된 모델은 UCF101 벤치마크에서 최첨단 성능을 달성하며, 특히 명령어 기반의 비디오 생성에서 높은 성능을 보입니다. 또한, 다른 기존 모델들과 비교했을 때 일관된 시각적 품질을 유지하면서 큰 움직임을 포함한 비디오를 생성할 수 있습니다.

#### 5. 결론 (Conclusion)
멀티모달 검색 보강과 지시 튜닝을 결합한 새로운 비디오 생성 방법은 다양한 입력을 통합하고 실제 맥락을 고려한 비디오를 생성하는 데 뛰어납니다. 이 접근 방식은 향후 연구에서 멀티모달 통합을 위해 새로운 방향을 제시할 것입니다.

### 전체 요약
이 논문은 비디오 생성에서 텍스트와 비주얼 입력을 통합하는 혁신적인 접근 방식을 제안합니다. 기존의 단일 텍스트 입력 기반 모델의 한계를 극복하기 위해, 저자들은 멀티모달 프롬프트 데이터셋을 구축하고 이를 통해 다양한 비디오 생성 작업을 수행할 수 있는 두 단계의 훈련 전략을 개발했습니다. 실험 결과, 제안된 모델은 다양한 멀티모달 입력을 효과적으로 처리하며, 높은 성능의 비디오를 생성할 수 있음을 보여주었습니다. 이 접근 방식은 향후 멀티모달 통합 연구에 중요한 기여를 할 것으로 기대됩니다.