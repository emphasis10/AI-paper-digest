# 3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.05132.pdf](https://arxiv.org/pdf/2406.05132.pdf)

### 1. 섹션별 요약

#### 서론
논문은 물리적 세계를 이해하고 상호작용하는 로봇 및 지능형 에이전트를 개발하는 데 필수적인 언어와 3D 인식을 통합하는 것이 중요하다고 설명합니다. 하지만, 대규모로 언어와 3D 장면 간의 밀접한 연계를 제공하는 데이터셋이 부족하여, 3D 환경에서의 대형 언어 모델(3D-LLMs) 적응이 초기 단계에 머물러 있다고 지적합니다. 이를 해결하기 위해 40,087개의 가정 장면과 620만 건의 밀접하게 연결된 장면-언어 지시를 포함하는 대규모 데이터셋인 3D-GRAND를 소개합니다.

#### 연구 동기 및 문제 제기
3D 환경에서의 LLM(3D-LLM)은 언어와 물리적 세계 간의 연결(grounding)이 부족하여 아직 초기 단계에 있습니다. 이러한 3D-LLMs의 발전을 위해 대규모 3D-텍스트 데이터셋의 중요성을 강조하며, 현재 있는 데이터셋의 한계를 지적하고 3D-LLM에서의 환각 문제를 해결하기 위한 새로운 벤치마크인 3D-POPE를 소개합니다.

#### 데이터셋 설명
3D-GRAND는 40,087개의 가정 장면과 620만 개의 밀접하게 연결된 장면-언어 지시로 구성된 대규모 데이터셋입니다. 이 데이터셋은 물체 참조, 장면 설명, 질의응답(QA) 등 다양한 언어 과제를 지원하며, 각 언어 주석은 고품질, 다양성, 자연스러움을 보장하기 위해 철저히 수집, 필터링 및 평가되었습니다. 이러한 특징은 3D-LMM의 발전을 촉진하는 데 중요한 자원으로 작용합니다.

#### 3D-POPE: 3D-LLM 환각 평가 벤치마크
3D-POPE는 3D-LLM에서의 환각을 체계적으로 평가하기 위한 포괄적인 표준 프로토콜을 제공합니다. 이는 모델이 특정 물체의 존재 여부를 파악하는 능력을 평가하며, 이를 통해 미래 모델 간의 공정한 비교가 가능하게 합니다.

#### 실험 결과 및 논의
실험 결과, 3D-GRAND로 훈련된 모델은 grounding 능력이 크게 향상되고 환각이 감소했으며, 특히 ScanRefer 및 3D-POPE 벤치마크에서 기존 모델보다 우수한 성능을 보였습니다. 데이터셋 확장이 3D-LLM 성능 향상에 미치는 영향을 강조하며, 대규모 합성 데이터로 훈련된 모델이 실세계 3D 스캔에서 잘 동작할 수 있음을 보여줍니다.

### 2. 전체 요약
이 논문은 언어와 3D 인식을 통합하여 물리적 세계를 이해하고 상호작용하는 로봇 및 지능형 에이전트 개발에 중요한 기초를 제공합니다. 이를 위해 40,087개의 가정 장면과 620만 개의 밀접하게 연결된 장면-언어 지시를 포함하는 대규모 데이터셋인 3D-GRAND와, 3D-LLM의 환각을 체계적으로 평가하기 위한 벤치마크인 3D-POPE를 소개합니다. 3D-GRAND는 물체 참조, 장면 설명, 질의응답 등 다양한 언어 과제를 지원하며, 실험 결과 3D-LLM의 성능을 크게 향상시키고 환각을 감소시키는 것으로 나타났습니다. 이 연구는 3D 환경에서의 LLM 발전에 중요한 기초 자료를 제공하며, 향후 연구와 혁신을 촉진할 것입니다.

## Similar Papers
- [On the Robustness of Language Guidance for Low-Level Vision Tasks: Findings from Depth Estimation](2404.08540.md)
- [ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos](2406.19392.md)
- [Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs](2406.16860.md)
- [Auto Cherry-Picker: Learning from High-quality Generative Data Driven by Language](2406.20085.md)
- [BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation](2405.09546.md)
- [RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots](2406.02523.md)
- [RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing](2404.19543.md)
- [ExoViP: Step-by-step Verification and Exploration with Exoskeleton Modules for Compositional Visual Reasoning](2408.02210.md)
- [VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks](2407.19795.md)
