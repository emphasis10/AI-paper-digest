# Controllable Human Image Generation with Personalized Multi-Garments
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.16801.pdf](https://arxiv.org/pdf/2411.16801.pdf)

### 1. 논문 주요 내용 요약
#### 1.1. 소개
BootComp는 텍스트-이미지 변환(T2I) 확산 모델을 기반으로 하여, 다양한 의상을 참고로 사용할 수 있는 제어 가능한 인간 이미지 생성 프레임워크입니다. 이 프레임워크는 인간 이미지를 입은 다양한 의상 이미지의 고품질 대규모 데이터 설정이 어려운 과제를 해결합니다. 이를 위해, 일관된 품질 관리를 통한 대규모 합성 데이터셋을 만들어 인간 이미지와 여러 의상 이미지를 조건으로 하는 확산 모델을 훈련시킵니다.

#### 1.2. 배경 및 방법
_DIFFUSION_MODEL_은 순방향 과정과 역방향 과정으로 구성된 생성 모델로, 순방향 과정에서 Gauss 잡음을 데이터에 점진적으로 추가하고, 역방향 과정에서 이를 제거하여 이미지를 생성합니다. 이러한 모델은 높은 해상도의 텍스트 조건부 이미지 생성을 가능하게 합니다.

#### 1.3. 결과 및 결론
BootComp는 다양한 조건에서 인간 이미지를 생성할 수 있음을 보여주며, 여러 의상 종류와 자세, 스타일 변환 등 다양한 적용사례에서 뛰어난 성능을 발휘합니다. 특히, 본 연구의 본질적인 기여는 고품질의 합성 데이터 생성 및 복합 모델을 훈련함으로써, 다중 참고 이미지 기반 패션 도메인 이미지 생성에서 새로운 가능성을 열었습니다.

### 2. 전체 요약
BootComp 논문은 AI와 기계 학습의 중요한 진전을 보여주며, 특히 텍스트-이미지 변환 모델의 실제 응용 가능성을 확대합니다. 이 연구는 데이터 수집의 어려움을 해결하기 위해 합성 데이터 생성 전략을 확립하여, 사용자가 다양한 조건에 맞게 인간 이미지를 생성할 수 있게 합니다. 이는 패션 및 기타 창의적인 도메인에서 혁신적인 적용 가능성을 보여줍니다.