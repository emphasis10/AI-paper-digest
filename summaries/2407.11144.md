# YouTube-SL-25: A Large-Scale, Open-Domain Multilingual Sign Language Parallel Corpus
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.11144.pdf](https://arxiv.org/pdf/2407.11144.pdf)

### 1. 각 섹션별 요약

**1. 서론 (Introduction)**

이 논문은 "YouTube-SL-25"라는 대규모 다국어 수화 비디오 코퍼스를 소개합니다. 이 코퍼스는 약 25개의 수화와 잘 맞춰진 자막이 포함된 YouTube 비디오로 구성되어 있으며, 주요 목적은 수화에서 해당 지역의 말소리 언어로의 번역을 돕는 것입니다. 연구자들은 YouTube에서 잠재적으로 관련성이 있는 비디오를 자동 분류기를 사용하여 식별하고, 4일 동안 비디오의 우선 순위를 매겨 수집했습니다. 이는 기존의 유럽수화 데이터셋과 비교해도 저자원의 수화를 포함한 다수의 수화를 다룬 첫 번째 대규모 데이터셋입니다.

**2. YouTube-SL-25 코퍼스 (The YouTube-SL-25 Corpus)**

YouTube-SL-25는 멀티링구얼 코퍼스로, 주로 번역 모델의 사전 학습을 위해 설계되었습니다. 수집 과정은 자동으로 비디오를 검색하고, 수작업으로 비디오의 우선 순위를 매겨 코퍼스를 생성합니다. 최종적으로, 각각의 수화를 포함한 3000명 이상의 고유한 수화 신호자들이 포함된 3207시간의 비디오가 수집되었습니다. 이 데이터셋은 기존의 가장 큰 규모인 JWSign보다도 많으며, 이는 대규모 다언어 수화 코퍼스의 새로운 기록을 세운 것입니다.

**3. 방법론 (Methodology)**

이 논문에서는 YouTube-ASL 데이터세트 기법을 확장하여 25개 이상의 수화 언어를 포함하고, 비디오 식별 태스크와 문장 수준 번역 태스크를 포함하는 멀티태스크 모델을 구축했습니다. Google의 T5 모델을 기반으로 하여 미디어파이프의 랜드마크 정보를 입력으로 받고, 번역 결과를 출력합니다. 4개의 수화 언어에 대해 벤치마크를 수행하였으며, 다국어 전이 학습이 고자원 수화뿐만 아니라 저자원 수화에도 긍정적인 영향을 미친다는 것을 입증했습니다.

**4. 결과 (Results)**

모델 비교 결과, 멀티링구얼 전이 학습이 성능 향상에 도움이 된다는 것을 발견했습니다. ASL, SGG, SSR, SLF 등 다양한 언어에서 조사되었으며, 다국어 출력을 예측하는 것보다 다국어 학습이 더 나은 성능을 보였습니다. 이 과정에서 제로샷 학습과 파인트윈 학습 모두에서 성과를 보였으며, 이는 다국어 학습의 중요성을 강조합니다.

**5. 결론 (Conclusion)**

수집된 YouTube-SL-25 코퍼스는 다국어, 오픈 도메인 수화 비디오를 포함하여 더 높은 자원과 낮은 자원의 수화 모두에 긍정적인 영향을 미쳤습니다. 이 연구는 특히 청각 장애인 커뮤니티를 위한 기술 포용성을 높이기 위한 기초를 마련할 것을 희망합니다. 윤리적 고려사항과 함께 데이터의 책임있는 사용을 강조하며, 미래 연구의 방향을 제시합니다.

### 2. 전체 요약

이 논문은 'YouTube-SL-25'라는 대규모 다국어 수화 비디오 데이터셋을 소개하고, 이를 기반으로 번역 모델을 학습시킨 결과를 제시합니다. 총 3207시간의 비디오와 25개 이상의 수화 언어를 포함하여, 수집 과정에서 자동 분류기와 수작업 조정을 통해 높은 품질의 데이터를 얻었습니다. T5 모델을 사용하여 다국어 전이 학습을 수행한 결과, 고자원과 저자원 수화 모두에서 성능이 향상되었음을 확인했습니다. 이는 수화 번역 기술의 발전에 기여하며, 청각 장애인 커뮤니티의 기술 포용성을 높이는 중요한 기반이 될 것입니다. 

이 연구는 특히 윤리적 측면을 고려하여 데이터의 책임 있는 사용을 강조하며, 멀티태스크 학습과 다국어 전이 학습의 중요성을 증명했습니다. 이는 향후 연구와 실질적인 응용에 있어 중요한 참조 자료가 될 것입니다.