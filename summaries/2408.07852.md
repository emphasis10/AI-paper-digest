# Training Language Models on the Knowledge Graph: Insights on Hallucinations and Their Detectability
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.07852.pdf](https://arxiv.org/pdf/2408.07852.pdf)

### 1. 요약과 설명: 각 섹션의 주요 내용
#### 1.1. Introduction (소개)
- **내용 요약**: 이 섹션에서는 대형 언어 모델(large language models, LMs)의 환각(hallucinations) 문제와 이를 해결하기 위해 지식 그래프(Knowledge Graph, KG)를 사용하는 방법을 소개합니다. 환각은 LM이 생성하는 사실이 훈련 데이터에 존재하지 않는 경우를 말합니다. KG는 훈련 데이터의 사실성을 완전히 통제할 수 있어, 이를 기반으로 LM의 환각을 정량적으로 측정할 수 있습니다.
- **혁신적 기여**: 대형 언어 모델의 환각 문제를 극복하기 위해 KG를 활용하는 새로운 방법을 제안합니다.

#### 1.2. Controlling What an LM Knows (LM이 아는 것을 통제하기)
- **내용 요약**: LM 훈련 시 모델이 접했던 정보를 정확히 아는 것이 중요합니다. 이를 위해 전적으로 통제된 KG를 사용하여 데이터를 분할하고, 다양한 KF셋(fully visible set, partially visible set, invisible set)을 설계합니다.
- **혁신적 기여**: 특정 KG 데이터를 사용하여 훈련 정보의 완전한 통제와 이에 따른 분석을 수행합니다.

#### 1.3. The Knowledge Graph Dataset (지식 그래프 데이터셋)
- **내용 요약**: 사용한 KG는 주어(Subject), 서술어(Predicate), 객체(Object)의 삼중항(triplet)으로 구성됩니다. 특별한 토큰을 추가해 삼중항을 형성하고, 이를 통해 LMs를 훈련시키고 평가합니다.
- **혁신적 기여**: 삼중항을 기반으로 한 데이터셋을 통해 훈련된 LM에서 환각률을 분석합니다.

#### 1.4. Training LMs on the Knowledge Graph (지식 그래프에서 LMs 훈련)
- **내용 요약**: 다양한 규모의 LMs를 KG 기반 데이터셋을 사용해 다중 에포크 동안 훈련합니다. 샘플링 온도를 조정해 LM의 다양한 성능을 평가합니다.
- **혁신적 기여**: 큰 모델이 더 적은 환각을 보이지만, 예산 최적화 크기보다 훨씬 큰 모델이 필요하다는 사실을 발견합니다.

#### 1.5. Hallucination Rate and How It Scales (환각률과 스케일링)
- **내용 요약**: LM의 크기와 훈련 길이에 따라 환각률이 감소하지만, 초기 훈련 데이터에 보지 못한 경우 환각률이 더 높아집니다.
- **혁신적 기여**: 훈련 데이터 크기가 증가할수록, 특정 LM 크기 및 훈련 길이에서 성능이 저하된다는 것을 발견합니다.

#### 1.6. Hallucination Detectability and How It Scales (환각 탐지 가능성과 스케일링)
- **내용 요약**: 큰 LM이 더 능력이 뛰어나지만, 탐지기가 이를 탐지하기 어려워집니다. 탐지기의 성능은 LM 크기와 훈련 길이에 따라 달라집니다.
- **혁신적 기여**: 탐지기의 성능이 LM 크기와 훈련 길이에 따라 어떻게 변하는지 정량적으로 분석합니다.

#### 1.7. Limitations (한계점)
- **내용 요약**: KG 데이터셋은 일반적인 LM 훈련 데이터와 다르며, 사용한 모델이 최신 SOTA LM보다 작습니다. 따라서 결과 해석에는 주의가 필요합니다.
- **혁신적 기여**: 본 연구의 한계를 명확히 하고, 일부 결론은 다른 유형의 환각에 적용되지 않을 수 있음을 설명합니다.

#### 1.8. Conclusion (결론)
- **내용 요약**: LM의 환각률과 스케일 간의 관계를 탐구했습니다. 고정된 데이터셋 크기에서 큰 모델이 더 적게 환각하지만, 훈련 데이터셋 크기 증가로 인한 환각률 증가와 이를 완화하기 위한 비용 증가 등을 발견했습니다.
- **혁신적 기여**: LM의 환각을 줄이기 위한 탐지기와 기타 중재 방법의 필요성을 제안합니다.

### 2. 전체 요약
본 논문은 대형 언어 모델(LMs)에서 발생하는 환각(hallucinations) 문제를 해결하기 위해 지식 그래프(Knowledge Graph, KG)를 활용하는 방법을 제안합니다. KG를 기반으로 하여 훈련 데이터의 사실성을 완전히 통제하고, 이를 통해 LMs의 환각률을 정량적으로 측정합니다. 다양한 규모의 LMs를 여러 에포크에 걸쳐 훈련하고, 샘플링 온도 조절 등 다양한 성능 평가 기법을 활용하여 환각률을 분석하였습니다. 

결과적으로, 큰 모델이 더 적은 환각을 보이지만, 최신 예산 최적화 모델보다 훨씬 큰 모델이 필요하다는 사실을 발견했습니다. 또한, 데이터셋 규모와 훈련 길이에 따라 성능이 저하될 수 있으며, 환각 탐지기의 성능은 LM의 크기와 훈련 길이에 따라 달라진다는 것을 확인했습니다. 이러한 연구는 LMs의 환각을 줄이기 위한 다양한 중재 방법과 탐지기의 필요성을 강조합니다.

이 연구는 사용된 방법론과 결과를 통해 AI와 머신러닝 분야에서 LM의 성능 개선을 위한 중요한 기초 자료를 제공할 것입니다.