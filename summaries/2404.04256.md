# Sigma : Siamese Mamba Network for Multi-Modal Semantic Segmentation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.04256.pdf](https://arxiv.org/pdf/2404.04256.pdf)

이 논문은 멀티 모달 의미론적 분할을 위한 새로운 네트워크인 Sigma, 즉 Siamese Mamba Network를 소개합니다. 이 연구는 특히 저조도나 과다 노출 환경과 같은 까다로운 조건에서 AI 에이전트의 인식 및 장면 이해를 향상시키는 것을 목표로 합니다. 전통적인 RGB 이미지 외에도 열, 깊이 등의 추가적인 모달리티를 활용하여 보다 견고하고 신뢰성 높은 분할을 달성하려고 합니다. 기존의 CNN이나 Vision Transformers 방식 대신, 이 모델은 Selective Structured State Space Model인 Mamba를 활용하여 선형 복잡도로 전역 수용 영역을 달성합니다. Siamese 인코더와 Mamba 융합 메커니즘을 사용하여 다양한 모달리티에서 중요 정보를 효과적으로 선택하고, 채널별 모델링 능력을 강화하기 위한 디코더를 개발합니다.

### 주요 기여점

- **다중 모달 의미론적 분할을 위한 State Space Models (특히 Mamba)의 첫 성공적인 적용**: 이는 다양한 모달리티에서 중요 정보를 효율적으로 추출하고 통합하는 새로운 방식입니다.
- **주의 기반 Mamba 융합 메커니즘 및 채널 인식 Mamba 디코더 도입**: 다양한 모달리티 간의 정보를 효과적으로 통합할 수 있는 구조를 제안합니다.
- **RGB-Thermal 및 RGB-Depth 도메인에서 우수한 정확도 및 효율성을 입증**: 이를 통해 Mamba의 다중 모달 학습에 대한 잠재력을 탐색하는 새로운 기준을 제시합니다.

이 연구는 멀티 모달 의미론적 분할을 위한 새로운 접근 방식을 제시하며, 다양한 환경에서 보다 정확한 인식 및 분석을 가능하게 하는 기술적 발전을 이끌어냅니다. Sigma 네트워크의 설계와 구현을 통해, AI 에이전트가 복잡한 시나리오에서도 효과적으로 작동할 수 있음을 보여주며, 향후 다양한 모달리티를 활용하는 연구에 중요한 기초를 마련합니다.

## Similar Papers
- [VSSD: Vision Mamba with Non-Causal State Space Duality](2407.18559.md)
- [xLSTM-UNet can be an Effective 2D & 3D Medical Image Segmentation Backbone with Vision-LSTM (ViL) better than its Mamba Counterpart](2407.01530.md)
- [MaGGIe: Masked Guided Gradual Human Instance Matting](2404.16035.md)
- [Transferable and Principled Efficiency for Open-Vocabulary Segmentation](2404.07448.md)
- [4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities](2406.09406.md)
- [BioMamba: A Pre-trained Biomedical Language Representation Model Leveraging Mamba](2408.02600.md)
- [SIGMA: Sinkhorn-Guided Masked Video Modeling](2407.15447.md)
- [DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception](2407.08303.md)
- [EVLM: An Efficient Vision-Language Model for Visual Understanding](2407.14177.md)
