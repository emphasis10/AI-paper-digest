# Accuracy is Not All You Need
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.09141.pdf](https://arxiv.org/pdf/2407.09141.pdf)

### 1. 각 섹션 요약

**서론**
이 논문에서는 대규모 언어 모델(LLM)의 압축 방법을 평가하는 새로운 지표를 제안합니다. 기존의 평가 지표인 정확도만으로는 모델의 성능 저하를 충분히 설명하지 못하기 때문에, 플립(flip)과 KL 다이버전스(KL-Divergence)라는 거리(metric)를 소개합니다.

**LLM 평가 지표**
LLM의 평가 지표를 능력 지표와 거리 지표로 나누어 설명합니다. 능력 지표로는 정확도와 퍼플렉서티(perplexity)가 있으며, 거리 지표로는 플립과 KL 다이버전스가 바람직하다고 설명합니다. 플립은 정답이 오답으로, 오답이 정답으로 변환되는 비율을 측정하며, KL 다이버전스는 모델 간 확률 분포의 차이를 측정합니다.

**실험**
다양한 LLM과 여러 양자화 기술을 사용한 실험 결과를 제시합니다. Llama2와 Yi 모델을 대상으로 Bitsandbytes, GPTQ, AWQ, Smoothquant 등의 양자화 기법을 사용했습니다. 여러 과제를 통해서 압축된 모델의 정확도와 플립 비율을 비교한 결과를 보여줍니다.

**결과**
모든 양자화 방식에서 정확도는 거의 변하지 않지만, GPTQ W8A16을 제외한 모든 방식에서 플립 비율이 높음을 확인했습니다. 이로 인해 정답에는 거의 변화가 없지만 모델의 행동 양상이 크게 달라진다는 것을 알 수 있습니다.

**한계**
모델의 성능 저하를 예측하는 것은 여전히 어려운 과제입니다. 플립 비율이 높다고 해서 모든 경우에 모델의 성능 저하로 이어지는 것은 아닙니다. 또한, 주관적인 평가가 포함되어 결과가 광범위하게 대표되지 않을 수 있습니다.

**관련 작업**
다른 연구들과 비교하여 플립 현상에 주목한 점에서 차별화됩니다. 기존 연구는 LLM의 평가에서 정확도에 치중했지만, 이 논문에서는 플립과 같은 새로운 지표의 필요성을 제시합니다.

**결론**
기존의 정확도 지표만으로는 모델의 성능 저하를 충분히 평가할 수 없으며, 플립과 KL 다이버전스와 같은 거리 지표가 필요하다고 결론짓습니다. 이 새로운 지표는 모델 최적화와 압축 기술을 더 잘 평가할 수 있도록 도와줄 것입니다.

### 2. 전체 요약

이 논문은 대규모 언어 모델(LLM)의 압축 기술을 평가하는 새로운 지표로 플립과 KL 다이버전스를 제안합니다. 기존의 정확도 지표는 모델의 성능 저하를 충분히 설명하지 못하므로, 새로운 거리 지표를 도입하여 모델 간의 실제 성능 차이를 더 정확히 평가하고자 합니다. 주요 실험 결과는 모든 양자화 방식에서 정확도는 거의 변하지 않지만, 플립 비율이 높아짐에 따라 모델의 행동 양상이 크게 달라진다는 점을 보여줍니다. 따라서, 이 논문은 모델 압축 기술을 평가하는 새로운 기준을 제시하며, 플립과 KL 다이버전스와 같은 거리 지표의 중요성을 강조하고 있습니다.