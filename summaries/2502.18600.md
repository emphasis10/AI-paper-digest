# Chain of Draft: Thinking Faster by Writing Less
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.18600.pdf](https://arxiv.org/pdf/2502.18600.pdf)

1. 섹션 요약 및 주요 기여

- **소개 및 관련 연구**: 이 논문은 대형 언어 모델(LLM)이 문제를 해결할 때 사용하는 효율적이고 최소한의 접근 방식인 'Chain of Draft (CoD)'를 제안합니다. 이는 인간의 사고 과정을 모방하였으며, 기존의 'Chain of Thought(CoT)'보다 더 적은 토큰을 사용하면서도 정확성을 유지하거나 향상합니다.

- **Chain of Draft 접근법**: CoD는 인간이 복잡한 문제를 해결할 때 필수적인 정보만을 기록하는 방식을 LLM에 적용한 것입니다. 이 방법은 계산 비용과 대기 시간을 줄이는 이점이 있습니다.

- **실험**: CoD의 효율성을 평가하기 위해 산술 추론, 상식 추론, 기호 추론 등의 다양한 벤치마크에서 실험을 진행하였습니다. 결과는 CoT에 비해 토큰 사용량이 현저히 낮고 정확성도 높은 것으로 나타났습니다.

- **한계 및 토론**: CoD는 푸드샷 예제가 없는 경우 성능이 떨어지며, 소규모 모델에서는 CoT보다 성능 차이가 더 크게 나타납니다. 이는 CoD 스타일의 데이터가 훈련 과정에 부족하기 때문으로 추정됩니다.

2. 전체 요약

이 논문은 대형 언어 모델의 추론 효율성을 높이기 위한 새로운 방법인 Chain of Draft(CoD)를 소개합니다. CoD는 인간의 사고방식을 모방하여 최소한의 정보를 사용해 문제를 해결하는 접근법으로, CoT에 비해 더 적은 계산 자원을 소비하면서도 높은 정확도를 유지합니다. 실험 결과, CoD는 다양한 추론 작업에서 탁월한 성능을 보였습니다. 그러나 푸드샷 예제가 없는 경우에는 성능이 떨어지며, 소규모 모델에서 CoT와의 성능 차이가 큽니다.