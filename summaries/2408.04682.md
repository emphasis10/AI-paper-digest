# ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.04682.pdf](https://arxiv.org/pdf/2408.04682.pdf)

### 1. 논문의 각 섹션 요약

#### Abstract (초록)
이 논문은 새로운 대화형 평가 벤치마크인 TOOLSANDBOX를 소개합니다. TOOLSANDBOX는 대형 언어 모델(LLM)이 실제 도구를 사용해 문제를 해결하는 능력을 평가합니다. 기존의 평가 방법이 단일 회차 사용자 프롬프트나 오프 정책 대화 경로를 기반으로 하는 반면, TOOLSANDBOX는 상태 기반 도구 실행, 암묵적인 상태 종속성, 사용자 시뮬레이터의 온 정책 대화 평가, 그리고 동적인 평가 전략을 포함합니다.

#### Introduction (소개)
LLM의 발전은 LLM이 자율 에이전트로서 실제 환경에서 도구를 사용하여 작업을 수행할 수 있는 새로운 기회를 열어줍니다. TOOLSANDBOX는 이러한 도구 사용 에이전트를 평가하기 위해 설계되었으며, 특히 복잡한 상태 종속성, 캐논화, 불충분한 정보 등의 문제에서 성능 격차가 발생함을 보여줍니다.

#### Main Contribution and Innovative Part (주요 기여 및 혁신 부분)
- **상태 기반 도구 실행**: TOOLSANDBOX는 복잡한 작업을 수행하는 데 필요한 상태 기반 도구 실행을 포함하여, 도구 간의 상태 종속성을 평가합니다.
- **동적 평가 전략**: 각 작업의 중간 및 최종 결과를 평가하는 동적 평가 전략을 도입하여, LLM의 도구 사용 능력에 대한 심도 있는 분석을 제공합니다.

#### Evaluation (평가)
TOOLSANDBOX는 공개 소스 모델과 독점 모델 간의 성능 격차를 보여줍니다. 예를 들어, 공개 소스 모델인 Hermes는 두 번째로 낮은 독점 모델인 Claude-3-Haiku보다 20포인트 이상 뒤처집니다. 성능 저하의 주요 원인으로는 복잡한 도구 호출 시퀀스와 사용자 요청을 처리하는 능력이 떨어지기 때문입니다.

#### Conclusion (결론)
TOOLSANDBOX는 LLM 도구 사용 능력을 평가하는 데 중점을 둔 평가 벤치마크로, 다양한 시나리오에서 높은 성능을 발휘하기 위한 도전 과제를 제공합니다. 이를 통해 LLM의 도구 사용 연구의 경계를 확장하는 데 기여할 것입니다.

### 2. 종합 요약

TOOLSANDBOX는 대형 언어 모델의 도구 사용 능력을 평가하기 위한 새로운 벤치마크로, 복잡한 상태 종속성, 캐논화, 불충분한 정보 처리 문제를 중심으로 평가합니다. 이 벤치마크는 상태 기반 도구 실행 및 동적 평가 전략을 통해 독점 모델과 공개 소스 모델 간의 성능 격차를 보여줍니다. TOOLSANDBOX는 LLM 도구 사용 연구의 경계를 확장하고, 다양한 시나리오에서 높은 성능을 발휘할 수 있도록 설계되었습니다.