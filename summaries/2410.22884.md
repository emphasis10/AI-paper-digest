# Stealing User Prompts from Mixture of Experts
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.22884.pdf](https://arxiv.org/pdf/2410.22884.pdf)

### 1. 각 섹션 요약

#### 소개
혼합 전문가 모델(MoE) 아키텍처는 점차 대형 언어 모델(LLM)의 계산적 요구를 처리하는 데 중요해졌습니다. MoE 아키텍처는 처리 작업을 여러 '전문가' 모듈로 분산시켜 필요한 전문가만 활성화하여 효율성을 높이고 더 큰 LLM 개발을 가능하게 합니다. 그러나 이는 새로운 취약점을 초래할 수 있습니다.

#### MoE Tiebreak 누출 공격
이 논문에서는 혼합 전문가 모델의 Expert-Choice-Routing 전략의 취약점을 소개하고 이에 대한 새로운 공격 방법을 제시합니다. 이 공격은 모델의 내부 구조적 결함을 이용해 사용자 입력을 도용하는 것으로, 자세한 내용은 그림을 통해 시각적으로 설명되어 있습니다.

#### 사용자 프라이버시 침해
이전 연구들은 LLM에서 사용자 프라이버시가 어떻게 침해될 수 있는지 조사했으나, 특히 모델의 내부 구조적 이유로 인한 취약성을 본격적으로 분석한 것은 없습니다. 이 연구는 배치 내 독립성을 미세하게 파괴하는 다양한 라우팅 전략들이 유사한 취약성을 나타낼 가능성이 있음을 시사합니다.

#### 결론
MoE 모델은 한 사용자의 데이터가 다른 사용자의 출력에 영향을 줄 수 있는 부작용 채널을 도입합니다. 이 누출은 작고 탐지하기 어렵지만, 공격을 통해 적절하게 Craft된 입력 배치를 사용하여 MoE 모델 내 전문가 버퍼를 조작하여 피해자의 프롬프트를 완전하게 유출시킬 수 있음을 보여줍니다.

### 2. 전체 요약
이 논문은 대형 언어 모델의 혼합 전문가(MoE) 아키텍처와 관련된 새로운 보안 취약점을 설명합니다. 특히 Expert-Choice-Routing 전략에서 나타나는 'MoE Tiebreak 누출' 공격을 통해 사용자 프롬프트를 완전하게 도용하는 방법을 밝혀냈습니다. 이 공격은 모델이 처리 중인 데이터 배치의 독립성을 악용하여 발생합니다. 연구는 이러한 취약점을 방지하기 위해 모델 설계 과정에서 보안적 측면의 고려가 필요함을 강조합니다. 이 논문은 이러한 MoE 모델의 잠재적인 취약성에 대한 경고와 함께, 보안 점검의 필요성을 재고하게 합니다.