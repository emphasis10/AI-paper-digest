# ShieldGemma: Generative AI Content Moderation Based on Gemma
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.21772.pdf](https://arxiv.org/pdf/2407.21772.pdf)

### Section Summaries

---

#### Introduction

**소개**

이 논문은 최신 대형 언어 모델(LLM)이 사람들의 안전하고 책임있는 상호작용을 보장하기 위한 강력한 메커니즘이 필요하다는 점을 강조합니다. 현재 LLM의 입력과 출력을 필터링하는 다양한 콘텐츠 관리 도구(예: LlamaGuard, WildGuard, AEGIS 등)가 있습니다. 그러나 이러한 도구는 해로운 유형 예측의 세분성과 다양한 크기의 모델 제공에 있어 제한이 있습니다. 이를 해결하기 위해 Gemma2 기반의 다양한 콘텐츠 관리 모델을 제안합니다. 이 논문에서는 2B에서 27B 매개변수에 이르는 다양한 모델을 통해 최적화된 성능을 보여줍니다.

---

#### Literature Review

**문헌 검토**

연구된 내용은 크게 두 가지로 나뉩니다:

1. **안전 콘텐츠 관리:** 인간이 생성한 콘텐츠를 필터링하는 데 중점을 두고 있으며, Perspective API와 같은 도구가 중요한 역할을 하고 있음을 보여줍니다. LLM 기반의 콘텐츠 관리 연구도 최근 많이 진행되었습니다.

2. **합성 데이터 생성:** 질 높은 데이터 세트를 생성하기 위해 합성 데이터 생성 기술을 사용하고 있으며, 이는 인간 주석의 필요성을 줄이는 데 도움이 됩니다. LLM의 지식을 활용하여 고품질의 합성 데이터를 생성할 수 있습니다.

---

#### Safety Policy

**안전 정책**

안전 정책은 AI 시스템의 개발과 배포에 있어 중요한 요소입니다. 특히 애매한 주관성을 줄이기 위해 안전 정책은 주석자들에게 일관된 기준을 제공합니다. 예를 들어, 사용자 입력에서 해로운 콘텐츠를 직접적으로 포함하거나 그런 콘텐츠를 생성하려는 요청을 금지하는 것을 중점적으로 다룹니다. 반면, 모델 출력에서 해로운 콘텐츠의 생성을 막는 데 주력합니다.

---

#### Content Safety Taxonomy

**콘텐츠 안전 분류**

6가지 해로운 유형에 대한 정의를 제공하며, 이는 성인용 콘텐츠, 혐오 발언, 위험 콘텐츠, 괴롭힘, 폭력, 외설 및 욕설을 포함합니다. 이러한 각 범주는 정책 도구에 세부적으로 정의되어 있으며, 이를 통해 사용자와 모델 출력 모두에서 안전한 콘텐츠를 유지하는 데 도움을 줍니다.

---

#### Synthetic Data Curation

**합성 데이터 큐레이션**

이 논문은 합성 데이터 생성 파이프라인을 설명하고, 이를 통해 다양한 방어 및 공정한 데이터 세트를 생성합니다. 이러한 데이터는 AI 시스템의 안전성 강화를 목적으로 합니다. 또한, AART 시스템을 통해 문제의 범위를 정의하고, 다양한 적대적인 프롬프트를 생성하여 데이터 세트를 큐레이션합니다.

---

#### Data Expansion

**데이터 확장**

데이터의 다양성과 난이도를 높이기 위해 합성 데이터를 반복적으로 생성하고, 비판적 LLM을 사용하여 새로운 데이터를 생성합니다. 이를 통해 총 20K 예제의 데이터를 확장할 수 있으며, 이러한 데이터는 사용자 입력과 모델 응답의 다양한 사용 사례에 적용됩니다.

---

#### Data Annotation

**데이터 주석**

3명의 주석자가 데이터를 평가하고, 다수의 투표에 따라 최종 레이블을 생성합니다. 특히 모델 응답의 경우, 사용자 입력을 배경으로 하여 정책 위반 여부를 평가합니다. 테스트 데이터는 2,671개의 정상 예제와 다양한 해로운 유형에 대한 적대적 예제를 포함합니다.

---

#### Fairness Expansion

**공정성 확장**

이 논문은 모델의 공정성을 높이기 위해 성별, 인종, 민족, 성적 지향, 종교와 같은 다양한 정체성 범주 확장을 사용합니다. 합성 데이터를 생성하여 원래 레이블을 바탕으로 새로운 데이터를 만들고, 이를 통해 공정성을 강화합니다.

---

### Overall Summary

**전체 요약**

이 논문에서는 Gemma2를 기반으로 한 광범위한 LLM 기반 콘텐츠 관리 모델을 제안하여, 다양한 안전 위험에 대한 예측 성능을 극대화하는 방법을 다룹니다. 문헌 검토, 안전 정책, 콘텐츠 안전 분류, 합성 데이터 생성, 데이터 주석, 공정성 확장 등 다양한 측면을 통해 현재 LLM의 한계를 극복하고자 합니다. 특히, 새롭고 적대적이며 다양한 데이터 세트를 생성하고, 이를 통해 더욱 안전하고 신뢰성 있는 사용자와 AI의 상호작용을 가능하게 합니다.

이 논문은 다양한 응용 사례에 최적화된 성능을 제공하며, 연구 커뮤니티에 큰 기여를 합니다. LLM의 안전성과 공정성을 강화하여 더 효과적인 콘텐츠 관리 솔루션을 만들기 위한 기초가 됩니다.

## Similar Papers
- [Adapting Safe-for-Work Classifier for Malaysian Language Text: Enhancing Alignment in LLM-Ops Framework](2407.20729.md)
- [Best Practices and Lessons Learned on Synthetic Data for Language Models](2404.07503.md)
- [Privacy Preserving Prompt Engineering: A Survey](2404.06001.md)
- [Gemma: Open Models Based on Gemini Research and Technology](2403.08295.md)
- [Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex Models](2406.15718.md)
- [The Art of Refusal: A Survey of Abstention in Large Language Models](2407.18418.md)
- [Gemma 2: Improving Open Language Models at a Practical Size](2408.00118.md)
- [Phi-3 Safety Post-Training: Aligning Language Models with a "Break-Fix" Cycle](2407.13833.md)
- [From Pixels to Prose: A Large Dataset of Dense Image Captions](2406.10328.md)
