# Learning from Massive Human Videos for Universal Humanoid Pose Control
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.14172.pdf](https://arxiv.org/pdf/2412.14172.pdf)

### 1. Sectional Summaries

#### 소개
이 논문은 인간 비디오를 활용하여 인간형 로봇의 학습을 확장하는 "Humanoid-X"라는 대규모 데이터셋을 소개합니다. Humanoid-X는 2000만 개 이상의 인간형 로봇 포즈와 이를 설명하는 텍스트 기반 모션 설명을 포함하고 있으며, 이러한 풍부한 데이터를 활용하여 인간형 로봇의 일반화 능력을 크게 향상시키고자 하는 목적을 가지고 있습니다. 이를 통해 인간형 로봇들은 텍스트 명령에 따라 다양한 상황에서 적응력 있고 믿을 수 있는 동작을 수행할 수 있습니다.

#### 관련 연구
기존의 연구들은 로봇 팔을 중심으로 한 조작에 초점이 맞춰져 있어, 인간형 로봇의 제어에는 제한적입니다. 특히, 대부분의 연구들은 강화학습 등 제한적인 방법을 통해 제한적인 동작들만 제어할 수 있었습니다. 이에 반해, 대규모 인간 비디오를 활용하여 보다 일반화된 인간형 로봇 자세 제어를 연구합니다.

#### Humanoid-X 데이터셋
Humanoid-X 데이터셋은 방대한 동영상을 통해 인간형 포즈 제어를 학습할 수 있는 데이터셋으로, 다양한 액션 카테고리를 포괄하는 163,800개의 움직임 샘플을 제공합니다. 이 데이터셋은 비디오 캡션 생성, 인간 모션의 모션 리타겟팅 등의 과정을 통해 구성됩니다.

#### UH-1 모델
UH-1 모델은 방대한 데이터에 텍스트 명령을 통해 인간형 로봇 동작을 실행하기 위한 강력한 확장 가능한 모델입니다. 이 모델은 텍스트 명령을 바탕으로 인간형 로봇의 동작을 자동 회귀 방식으로 해석하여 다양한 동작 토큰 시퀀스를 생성합니다.

#### 실험 결과
실험을 통해 UH-1 모델의 일반화 능력이 강화됨을 입증했습니다. 특히 텍스트 명령을 기반으로 하는 인간형 로봇자세 제어에서, UH-1 모델은 기존의 두단계 접근방법보다 더 정교하고 신뢰성 있는 결과를 보여주었습니다.

### 2. 종합 요약
이 논문은 "Humanoid-X"라는 대규모 데이터셋과 이를 활용한 "UH-1" 모델을 제시하여, 인간형 로봇이 다양한 문맥적 명령을 이해하고 실행할 수 있도록 하였습니다. 특히, 인간 비디오를 활용한 대규모 학습을 통해 인간형 로봇의 일반화를 향상시킴으로써, 더욱 실용적이고 적응력 있는 로봇 제어를 목표로 합니다.