# HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models in Resource-Constrained Environments
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.10945.pdf](https://arxiv.org/pdf/2408.10945.pdf)

### 1. 섹션별 요약 및 주요 기여 점

#### Introduction (소개)
소개 부분에서는 비전-언어 모델(VLM)의 출현과 고해상도 이미지 처리의 필요성을 설명합니다. 기존의 VLM은 저해상도 이미지를 사용하여 세부 시각 정보를 잃는 단점이 있습니다. 이를 해결하기 위해 고해상도 이미지의 동적 분할을 사용하는 새로운 VLM이 등장했습니다.

#### Related Work (관련 연구)
이 섹션에서는 고해상도 VLM 효율성을 높이기 위한 다양한 방법을 다룹니다. 기존 연구들은 주로 모델 경량화, 희소 주의 계산, 그리고 시각 토큰의 조기 삭제 기술을 사용합니다. 그러나 이들 방법은 모두 주요한 성능 손실을 초래하거나, 자원 제약을 충분히 해결하지 못합니다.

#### Methods (방법론)
여기서 HiRED(High-Resolution Early Dropping)의 설계와 작동 방식을 설명합니다. HiRED는 주목(attention) 지도 조기 삭제 프레임워크로, 적은 토큰 예산 내에서 가장 중요한 시각 토큰만 남기고 나머지는 삭제합니다. 이 과정은 자원 제약이 있는 환경에서 효율적인 추론을 가능케 합니다.

1. **주요 기여 요소**:
    - 고해상도 VLM을 위한 플러그 앤 플레이 방식의 토큰 삭제 프레임워크.
    - 초기 계층의 클래스 토큰 주목(attention) 지도를 사용하여 시각 콘텐츠 평가.
    - 최종 계층의 주목 지도를 이용한 중요한 시각 토큰의 선택.

#### Evaluation (평가)
HiRED의 성능을 다양한 벤치마크 테스크를 통해 평가합니다. HiRED는 20%의 토큰 budget으로 대부분의 시각 질문 응답 테스크에서 거의 동일한 정확도를 유지하고, 일부 테스크에서는 더 높은 정확도를 보여줍니다. GPU 메모리 사용량도 크게 줄어듭니다.

#### Conclusion (결론)
최종적으로, HiRED는 다양한 멀티모달 테스크에서 고해상도 VLM의 추론 효율성과 성능을 크게 개선했다고 결론짓습니다. HiRED는 자원 제약이 있는 환경에서도 높은 정확도와 성능을 유지할 수 있으며, 이는 미래의 VLM 연구에 중요한 통찰을 제공합니다.

### 2. 전체 요약
이 논문은 고해상도 비전-언어 모델(VLM)의 효율성을 높이는 HiRED(High-Resolution Early Dropping) 프레임워크를 제안하고 평가합니다. HiRED는 주목(attention) 지도 기반의 조기 시각 토큰 삭제 기법을 통해 자원 제약 환경에서 고해상도 이미지 처리를 효율적으로 할 수 있게 합니다. 주요 혁신은 초기 계층과 최종 계층의 클래스 토큰 주목 지도를 활용하여 가장 중요한 시각 토큰을 선택하고, 나머지를 삭제하는 것입니다. 실험 결과 HiRED는 추론 속도와 메모리 사용 효율성 측면에서 기존 방법보다 우수한 성능을 보였습니다. 이 연구는 고해상도 VLM의 실용성을 높이는 중요한 기여를 했으며, 특히 자원 제약 환경에서의 멀티모달 테스크에서 강력한 성능을 입증했습니다.