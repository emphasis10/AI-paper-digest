# Z1: Efficient Test-time Scaling with Code
## TL;DR
## Summary
- [https://arxiv.org/pdf/2504.00810.pdf](https://arxiv.org/pdf/2504.00810.pdf)

### 섹션 별 요약

#### 1. 소개 (Introduction)
이 논문은 큰 추론 모델(LLM)의 효율적인 테스트 시간 확장 방법을 제안합니다. 이 모델들은 복잡한 문제 해결에 강점을 보이지만, 긴 문맥과 많은 '생각 토큰'이 필요해 비효율적입니다.

#### 2. Z1: 코드 기반의 효율적인 테스트 시간 확장
우선, 코드와 관련된 문제를 다루는 데이터셋인 Z1-Code-Reasoning-107K를 만들었습니다. 이 데이터셋은 문제의 복잡성에 따라 '약한 추론'과 '강한 추론'을 조절하여 '생각 토큰' 사용을 줄이는 'Shifted Thinking Window'라는 새로운 접근 방식을 소개합니다. 이를 통해 Z1-7B 모델은 R1-Distill-Qwen-7B 모델과 비슷한 성능을 보이면서도 30% 정도의 '생각 토큰'만 사용합니다.

#### 3. 실험
Z1-7B 모델은 다양한 추론 작업에서 효율적인 테스트 시간 확장을 자랑하며, 특히 GPQA Diamond와 MATH500 같은 벤치마크에서 뛰어난 성능을 보여주었습니다. 데이터 세트의 길이가 모델의 추론 효율성을 크게 좌우한다는 것도 확인되었습니다.

#### 4. 결론 및 기여
이번 연구의 주요 기여는 효율적인 테스트 시간 확장 방법의 도입, Z1-7B 모델의 성능 비교, 'Shifted Thinking Window'의 제안, 그리고 코드 관련 데이터셋을 통한 추론 학습에 대한 이해의 확장입니다.

### 논문의 주요 기여와 혁신적 부분
이 논문에서 제안한 주요 기여는 다음과 같습니다:
- 'Shifted Thinking Window': 복잡성에 따른 생각 토큰 사용을 줄이는 새로운 방식
- 코드 관련 문제에서의 효율적인 테스트 시간 확장 방법 구현
- 긴 추론 출력을 통해 성능을 증가시킨다는 개념을 확립.

### 전체 요약
전체적으로 이 논문은 대형 추론 모델의 테스트 시간에서 효율성을 향상시킬 방법을 제안하고, 새로운 데이터셋과 방법론을 통해 이의 유용성을 증명하였습니다. 이번 연구는 추론 모델이 복잡한 문제를 보다 효율적으로 처리하게 하여 AI의 발전에 기여할 수 있는 방법을 제시하였습니다.