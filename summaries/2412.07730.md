# STIV: Scalable Text and Image Conditioned Video Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.07730.pdf](https://arxiv.org/pdf/2412.07730.pdf)

### 1. 각 섹션의 중요한 내용 요약

**초록 (Abstract)**

이 논문은 비디오 생성 분야의 발전을 탐구하며, 강력하고 확장 가능한 모델 구축을 위한 체계적 접근법을 제안합니다. STIV라는 방법을 소개하며, 이는 이미지와 텍스트 조건을 모두 활용하여 텍스트-비디오(T2V) 및 텍스트-이미지-비디오(TI2V) 생성 모두를 수행할 수 있도록 설계되었습니다.

**서론 (Introduction)**

비디오 생성은 크게 발전하였지만, 다양한 조건을 결합하는 방법에 대한 명확한 지침이 부족합니다. 이 논문은 STIV라는 간단하면서도 확장 가능한 모델을 개발하여 이러한 요구를 충족시키려 합니다.

**모델 아키텍처 (Model Architecture)**

STIV는 PixArt-α 기반으로 설계되었으며, 텍스트와 이미지 조건을 통합하는 데 사용되는 구조적 요소를 설명합니다. 대부분의 비디오 프레임을 처리하기 위해 공간적 및 시간적 주의 기법을 사용합니다.

**학습 전략 (Training Strategy)**

효율적인 학습을 위해 텍스트, 이미지 조건 모두를 활용하는 Joint Image-Text Classifier-Free Guidance(JIT-CFG)를 제안하며, 이미지 조건 드롭아웃을 통해 다양한 작업을 수행할 수 있도록 했습니다.

**실험 결과 (Experimental Results)**

STIV는 최신 모델들에 비해 뛰어난 성능을 보여주었습니다. 특히 VBench에서 T2V 및 I2V 작업 모두에서 최고 기록을 세웠으며, 다양한 비디오 생성 문제를 해결할 수 있는 유연성을 보였습니다.

### 2. 전체 요약

이 논문은 STIV라는 비디오 생성 모델을 소개하며, 텍스트와 이미지 조건을 모두 활용하여 여러 비디오 생성 작업을 수행할 수 있는 새로운 방법을 제안합니다. STIV는 효율적이고 안정적인 학습 기술을 통해 모델 크기를 확장할 수 있으며, 높은 해상도 및 긴 지속 시간의 비디오를 생성할 수 있도록 설계되었습니다. 실험 결과, STIV는 최신 기술들과 비교하여 우수한 성능을 입증하였고, 다양한 응용 가능성을 보여주었습니다.