# Compositional Text-to-Image Generation with Dense Blob Representations
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.08246.pdf](https://arxiv.org/pdf/2405.08246.pdf)

### 주요 내용 요약

1. **서론 및 배경**:
   - 이 논문은 복잡한 텍스트 프롬프트를 처리하는 데 어려움을 겪는 기존 텍스트-이미지 모델의 문제를 해결하기 위해 **BlobGEN**이라는 새로운 방법을 제안합니다. BlobGEN은 장면을 모듈화되고 인간이 이해할 수 있는 **Dense Blob Representations**로 분해하여 세밀한 제어가 가능한 텍스트-이미지 변환을 가능하게 합니다. 이 방법은 블랍(Blob) 표현을 사용하여 텍스트 프롬프트에서 시각적 원시 요소를 생성하고, 이를 통해 더 정확하고 일관된 이미지 생성을 달성합니다.

2. **방법론**:
   - **Dense Blob Representations**: 블랍 표현은 장면의 시각적 세부 사항을 포함하는 모듈화된 표현으로, 각 블랍은 객체의 위치, 크기, 방향 등을 나타내는 매개변수와 객체의 외관, 스타일, 시각적 속성을 설명하는 텍스트 설명으로 구성됩니다.
   - **Blob-Grounded Text-to-Image Diffusion Model**: BlobGEN은 기존의 확산 모델에 새로운 마스크드 크로스-어텐션 모듈을 추가하여 블랍 표현과 시각적 특징 간의 결합을 분리합니다. 이를 통해 각 블랍이 해당 지역의 시각적 특징만을 참조하도록 하여, 더 모듈화되고 독립적인 생성을 가능하게 합니다.
   - **In-Context Learning**: 대규모 언어 모델(LLMs)을 사용하여 텍스트 프롬프트에서 블랍 표현을 생성하는 새로운 학습 방법을 설계했습니다. 이를 통해 복잡한 합성 이미지 생성 작업에서 뛰어난 성능을 발휘할 수 있습니다.

3. **실험**:
   - **MS-COCO 데이터셋**에서 BlobGEN의 제로샷 생성 품질을 평가한 결과, 기존 모델보다 우수한 성능을 보였으며, 레이아웃-가이드 생성에서 더 높은 정확도와 일관성을 달성했습니다. 예를 들어, BlobGEN은 제로샷 FID 점수를 10.40에서 8.61로 개선하였으며, 레이아웃-가이드 생성에서 GLIGEN보다 더 나은 성능을 보여주었습니다.
   - **수치 및 공간 정확성**에서, BlobGEN은 NSR-1K 벤치마크에서 LayoutGPT보다 5.7% 및 1.4% 더 높은 정확도를 나타냈습니다.

### 혁신적인 부분
BlobGEN의 혁신성은 **Dense Blob Representations**를 도입하여 텍스트-이미지 변환의 세밀한 제어를 가능하게 하고, 새로운 마스크드 크로스-어텐션 모듈을 통해 블랍 표현과 시각적 특징 간의 결합을 분리하여 모듈화된 생성을 가능하게 한다는 점입니다. 또한, 대규모 언어 모델을 활용한 인-컨텍스트 학습을 통해 복잡한 합성 이미지 생성 작업에서 뛰어난 성능을 발휘할 수 있습니다. 이를 통해 BlobGEN은 텍스트 프롬프트를 기반으로 한 더 정확하고 일관된 이미지 생성을 가능하게 합니다.

## Similar Papers
- [MaPa: Text-driven Photorealistic Material Painting for 3D Shapes](2404.17569.md)
- [Kaleido Diffusion: Improving Conditional Diffusion Models with Autoregressive Latent Modeling](2405.21048.md)
- [CamCo: Camera-Controllable 3D-Consistent Image-to-Video Generation](2406.02509.md)
- [Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities](2406.14562.md)
- [StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation](2405.01434.md)
- [MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation](2404.05674.md)
- [DisCo-Diff: Enhancing Continuous Diffusion Models with Discrete Latents](2407.03300.md)
- [Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation](2406.06525.md)
- [Matryoshka Diffusion Models](2310.15111.md)
