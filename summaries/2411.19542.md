# A dynamic parallel method for performance optimization on hybrid CPUs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.19542.pdf](https://arxiv.org/pdf/2411.19542.pdf)

### 1. 섹션 요약

**소개:**
종합 CPU 회사들이 하이브리드 CPU 아키텍처를 채택하고 있는 이유와 그 과정에서 발생하는 문제들을 소개합니다. 특히, 하드웨어의 불균형적인 성능이 AI 모델, 특히 대규모 언어 모델(LLM)의 성능을 저하시킬 수 있음을 설명합니다. 이 문서는 이러한 문제를 해결하기 위해 CPU 코어 간의 작업 부하를 균형 있게 조정하는 새로운 동적 병렬 방법을 제안합니다.

**접근법:**
새로운 동적 병렬 방법을 상세히 설명하고, 특히 하이브리드 CPU의 다양한 코어 성능을 통해 부하를 동적으로 조절하는 방법에 대해 다룹니다. 두 가지 주요 구성 요소인 CPU 런타임과 스레드 스케줄러에 중점을 둡니다. CPU 런타임은 CPU 상태를 관리하며, 각 코어의 실행 시간을 기록하고 스레드 스케줄러가 동적 성능에 따라 커널 작업을 코어 별로 분할합니다.

**결과:**
테스트한 하드웨어와 실험 설정을 나열하고, INT8 및 INT4 같은 다양한 연산에서 성능 개선을 달성했다고 보고합니다. 특히 INT4에서는 메모리 대역폭의 90% 이상을 활용했음을 강조합니다. 동적 병렬 방법의 적용으로 이전에 비해 압도적인 성능 향상을 보였으며, 하이브리드 CPU가 더 효율적으로 협업할 수 있도록 설계되었습니다.

**요약 및 미래 작업:**
이 방법이 하이브리드 CPU에서 LLM 추론 성능을 어떻게 향상시켰는지 설명하고, 다음 목표로 AIPC의 프리필 시간 지연을 줄이는 것을 제시합니다. 또한 CPU의 새로운 추가 컴퓨팅 유닛들과의 작업 통합 가능성을 탐구합니다.

### 2. 전체 요약
이 논문은 하이브리드 CPU에서 LLM (대규모 언어 모델) 추론 성능을 개선하기 위해 새로운 동적 병렬 방법을 제안합니다. 이 방법은 CPU 성능에 따라 작업을 동적으로 배치하여 메모리 대역폭의 최대 90% 이상을 활용할 수 있습니다. 실험 결과, 이 접근법은 기존의 OpenMP 방법보다 최대 3.7배 향상된 속도를 보여주었으며, 향후 연구 방향으로 AIPC의 작업 통합 최적화가 제시되었습니다. 이 연구는 LLM과 같은 AI 모델에서 하이브리드 CPU의 성능을 최대한 활용하려는 시도를 통해 AI 분야에 큰 기여를 할 수 있을 것으로 예상됩니다.