# Nemotron-CrossThink: Scaling Self-Learning beyond Math Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2504.13941.pdf](https://arxiv.org/pdf/2504.13941.pdf)

1. 섹션 요약 및 주요 기여와 혁신적 부분 설명:

   - **도입부**: NEMOTRON-CROSSTHINK를 통해 다양한 도메인에서 수집한 데이터들을 RL(강화학습) 훈련에 통합하여 다양한 과제에서 일반화 능력을 개선하는 방법을 제안합니다. 이를 통해 다분야 데이터를 활용하여 LLM(대용량 언어 모델)의 추론 능력을 향상시킵니다.

   - **방법론**: NEMOTRON-CROSSTHINK는 다단계의 프로세스를 포함하며 이에 대한 설명은 데이터를 다양한 출처에서 수집하고, 템플릿을 적용하여 응답 공간을 제한하고, 검증 가능 보상이 어려운 샘플을 필터링하는 것을 포함합니다. 이후 데이터를 효율적으로 조합하고, RL을 사용하여 여러 도메인에서 추론 능력을 개선합니다.

   - **결과 및 토론**: NEMOTRON-CROSSTHINK를 통해 얻은 모델은 수학적 과제뿐 아니라 비수학적 과제에서도 기존 모델에 비해 높은 정확도를 보이며, 다이나믹한 응답 전략을 보여 인퍼런스 비용을 절감합니다.

   - **결론**: 이 연구의 주요 기여는 다중 도메인 데이터를 활용하여 RL 훈련을 강화하고, 산술적 및 비산술적 기준 모두에서 모델의 성능을 개선하는 NEMOTRON-CROSSTHINK라는 새로운 프레임워크를 제안한 것입니다.

2. 전체 요약:

   이 논문은 NEMOTRON-CROSSTHINK라는 시스템을 제안하여 다양한 도메인에서 수집한 데이터를 활용함으로써 대용량 언어 모델의 추론 능력을 강화합니다. 다양한 질문 형식과 도메인 데이터를 통합하여 RL을 통한 학습 효과를 개선하였으며, 여러 벤치마크에서 일반화 성능을 높였습니다. 중요한 것은 데이터의 양보다는 다양한 도메인에서 가져온 데이터의 조합이 더 폭넓은 추론 능력을 위한 열쇠라는 점을 제시합니다.