# MiniMax-01: Scaling Foundation Models with Lightning Attention
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.08313.pdf](https://arxiv.org/pdf/2501.08313.pdf)

1. 본 논문의 주요 내용과 혁신적인 부분을 각 섹션별로 요약한 것입니다.

   - 서론: 대형 언어 모델의 발전과 인간의 가치 및 의도와의 정렬 문제를 제시합니다. 이 논문은 인퍼런스 시간의 효율성과 고성능 정렬을 결합한 '스트림 어라인너(Stream Aligner)'라는 새로운 정렬 패러다임을 제안하였습니다. 이는 문장 수준의 동적 교정을 수행하여 인간의 선호도에 맞춘 출력을 보장합니다.

   - 스트림 어라인너 패러다임: 스트림 어라인너는 생성 파이프라인에 플러그앤플레이 모듈로 작동하며, 상위 모델이 생성한 문장을 교정하여 다음 생성에 지속적으로 피드백합니다. 이 과정은 응답이 완전할 때까지 반복되어 모든 문장이 인간의 선호와 일치하는 결과를 보장합니다.

   - 기술적 세부사항: 스트림 어라인너는 문장 수준의 선호 데이터셋으로 미세 조정되어 선호 및 비선호 응답 간의 잔차를 학습합니다.

   - 실험 결과: 세 가지 작업(유용성과 무해성 QA, 수학 문제, 요약 작업)에 대해 스트림 어라인너의 성능을 평가하였으며, 유의미한 개선을 보였습니다. 이는 특히 유용성 및 무해성에서 상당한 성능 향상을 보여주었습니다.

   - 비교 및 한계점: 다른 정렬 방법과의 비교 및 제안한 방법의 이점을 간략히 논의하였으며, 일정한 감독 하에서도 상위 모델의 성능을 향상시킬 수 있음을 설명하였습니다.

2. 전체 요약:
   
   본 논문은 스트림 어라인너라는 새로운 정렬 패러다임을 제시하였으며, 이는 대형 언어 모델이 인간의 가치와 선호에 맞추어 출력을 생성할 수 있도록 문장 수준에서 정렬을 개선할 수 있는 방법을 제공합니다. 이 방법은 문장별 수정 과정을 통해 모델의 추론 능력을 향상시킵니다. 실험 결과, 다양한 작업에서 상당한 성능 향상을 보였으며, 특히 상위 모델과의 결합에서 최소한의 추가 모델 사용으로도 유용성과 무해성을 크게 향상시켰음을 보여주었습니다. 또한, 제안된 방법이 추론 기반 태스크에 대한 효과성을 입증하면서 다른 정렬 방법과의 비교를 통해 차별점을 부각하였습니다.