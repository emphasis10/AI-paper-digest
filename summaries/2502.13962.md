# Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.13962.pdf](https://arxiv.org/pdf/2502.13962.pdf)

### 1. 섹션별 내용 요약

**서론**
이 논문은 언어 모델의 추론 시간 동안의 컴퓨팅 리소스를 확장하여 결정적 사고 벤치마크에서 뛰어난 성능을 보여주는 모델의 중요성을 설명합니다. 기존 연구에서는 모든 질문에 대해 답변을 제공한다고 가정하며 모델의 자신감이나 답변 제공의 적절성을 고려하지 않았습니다.

**방법론**
추론 시의 컴퓨팅 자원을 늘리는 것이 QA(질문 응답) 작업에서 모델의 성능에 미치는 영향을 분석하였습니다. 두 가지 요인은 컴퓨팅 예산과 자신감 임계값으로, 컴퓨팅 예산은 추론 시 사용하는 토큰의 개수로 측정됩니다.

**실험**
DeepSeek-R1-32B와 s1 모델의 추론 확장 기능을 평가하였으며, AIME24 데이터셋을 사용했습니다. 이 데이터셋은 더 큰 컴퓨팅 예산을 통해 성능을 상당히 향상시킬 수 있습니다.

**유틸리티**
모델의 응답 정확도와 제공을 측정하기 위해 '위험이 없는 응답'과 '위험이 있는 응답' 환경을 소개했습니다. 각 환경의 위험 수준에 따라 적절한 평가 방법을 제안합니다.

**관련 연구**
실패에 대한 패널티를 다루는 선택적 분류와 비용 민감 학습으로부터 영감을 얻어, 모델이 언제 답변을 거부해야 하는지 판단하는 방법을 연구했습니다.

**결론 및 한계**
현재 테스트-시간 스케일링 연구에서 보이지 않는 성능 영역을 강조합니다. 자신감 요구를 충족시키기 위해 효과적으로 테스트-시간 컴퓨팅을 할당하는 방향으로 연구가 집행되길 권장합니다.

### 2. 전체 요약
이 논문의 주요 기여도는 언어 모델의 추론 시간 동안의 컴퓨팅 확장을 통한 모델의 성능 향상입니다. 특히, 이러한 확장은 각 모델이 자신감 임계값에 따라 올바른 답변과 잘못된 답변을 구분하는 데 도움을 주며, 틀린 답변을 제공할 때의 패널티를 고려하여 평가 지표를 개선합니다. 이 연구는 고위험 환경에서 모델이 결정을 내릴 때 인간 전문가와의 협력을 개선하기 위해 선택적 QA 환경을 도입했습니다. 이는 추후 연구에서 비용-효율적인 자원 할당과 인간 전문가와의 협력 메커니즘으로 확장될 수 있습니다.