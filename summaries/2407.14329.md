# Efficient Audio Captioning with Encoder-Level Knowledge Distillation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.14329.pdf](https://arxiv.org/pdf/2407.14329.pdf)

### 1. 섹션 별 요약

#### Introduction
자동화된 오디오 캡셔닝(AAC; Automated Audio Captioning)은 오디오 입력에 대해 텍스트 설명을 생성하는 작업으로, 오디오와 텍스트 두 가지 모달리티를 연결하는 교차 모달리티 번역 작업입니다. 최근에는 모델의 정확성, 다양성, 일반화 능력에서 많은 성과를 이루어졌으며, 특히 DCASE 챌린지의 인기로 인해 여러 연구자들이 이 분야 발전에 기여하고 있습니다. 하지만 이러한 향상은 모델의 복잡성과 계산 비용 증가를 동반하게 되며, 리소스가 제한된 장치에서 모델을 배포하는 데 어려움이 있습니다.

#### Proposed Knowledge Distillation Framework
이 논문에서는 지식 증류(Knowledge Distillation; KD) 프레임워크를 제안합니다. 특히 인코더-디코더 AAC 모델에서 인코더로 지식을 증류하는 것이 디코더로 증류하는 것보다 효과적이라는 분석결과를 얻었습니다. 우리는 표준 MSE 손실과 대조 손실을 기반으로 두 가지 인코더 레벨 KD 방법을 조사했습니다. 대조 손실이 데이터가 부족한 상황에서도 MSE 손실보다 더 견고한 성능을 발휘한다는 결과를 얻었습니다.

#### Experiment Setup
실험을 위해 Clotho와 AudioCaps 데이터셋을 사용했습니다. AudioCaps는 50,000개 이상의 오디오-텍스트 쌍을 포함하는 가장 큰 사람 주석 데이터셋이며, Clotho는 약 6,000개의 오디오 클립을 포함하는 소규모 데이터셋입니다. 우리는 EfficientNet-B2로 학생 인코더를, 얕은 2-레이어 트랜스포머로 학생 디코더를 구성했습니다. 전체 모델은 25 에포크 동안 학습되었으며, 학습률은 5 에포크 동안 선형으로 증가한 후 지수적으로 감소하는 형태로 설정되었습니다.

#### Results
실험 결과, 대조 지식 증류 기법이 데이터가 부족한 상황에서도 우수한 성능을 발휘하며, 학생 모델이 쉽게 교사 모델의 성능에 근접할 수 있음을 확인했습니다. 특히, 오디오 전용 데이터를 훈련에 포함하면서 학생 모델의 성능이 더욱 향상되었습니다. 최종 결과에서 학생 모델은 파라미터 수가 교사 모델의 약 6%에 불과하면서도, 성능 측면에서 큰 차이가 없음을 알 수 있습니다.

#### Conclusion
이 논문에서는 대규모 교사 모델 기준으로 효율적인 학생 모델을 학습하기 위한 지식 증류 방법을 제안했습니다. 실험 결과, 대조 손실을 활용한 인코더-레벨 지식 증류 기법이 데이터가 부족한 상황에서도 강력한 성능을 발휘하며, 인코더의 효율성을 크게 향상 시킬 수 있음을 확인했습니다.

### 2. 전체 요약
이 논문은 자동화된 오디오 캡셔닝(AAC)의 모델 압축에 초점을 맞추고, 특히 인코더-디코더 프레임워크의 인코더 레벨에서 효과적인 지식 증류(KD) 방법을 제안합니다. 이를 통해 복잡성과 계산 비용을 줄이면서도 성능을 유지할 수 있는 효율적인 학생 모델을 달성하는 것이 주요 기여입니다. 대조 손실을 기반으로 한 KD 기법의 우수성을 입증했으며, 추가로 오디오 전용 데이터를 사용해 지식 증류를 강화했습니다. 최종 결과, 학생 모델은 교사 모델에 비해 훨씬 적은 파라미터 수로도 거의 동등한 성능을 발휘함을 보였습니다. 

이를 통해, 저자는 리소스가 제한된 환경에서도 AAC 모델이 효과적으로 사용될 수 있는 가능성을 열었으며, 이는 AI와 머신러닝 분야에 큰 혁신과 기여를 할 것으로 기대됩니다.

## Similar Papers
- [PicoAudio: Enabling Precise Timestamp and Frequency Controllability of Audio Events in Text-to-audio Generation](2407.02869.md)
- [Investigating Decoder-only Large Language Models for Speech-to-text Translation](2407.03169.md)
- [Multimodal Large Language Models with Fusion Low Rank Adaptation for Device Directed Speech Detection](2406.09617.md)
- [WavCraft: Audio Editing and Generation with Large Language Models](2403.09527.md)
- [SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound](2405.00233.md)
- [Interface Design for Self-Supervised Speech Models](2406.12209.md)
- [Language Model Can Listen While Speaking](2408.02622.md)
- [Audio Dialogues: Dialogues dataset for audio and music understanding](2404.07616.md)
- [VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text to Speech Synthesizers](2406.05370.md)
