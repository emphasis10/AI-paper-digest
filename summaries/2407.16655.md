# MovieDreamer: Hierarchical Generation for Coherent Long Visual Sequence
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.16655.pdf](https://arxiv.org/pdf/2407.16655.pdf)

### 섹션별 요약

**1. Introduction (소개)**

이 논문은 MovieDreamer라는 새로운 계층적 프레임워크를 제안하여, 오토레그레시브 모델과 확산 기반 렌더링을 결합하여 긴 동영상 콘텐츠 생성의 어려움을 해결했다. 기존의 영상 생성 모델들이 주로 짧은 영상의 시각적 품질 개선에 중점을 둔 반면, MovieDreamer는 복잡한 내러티브와 캐릭터 일관성을 유지하면서 고품질의 긴 동영상을 생성할 수 있도록 설계되었다. 이러한 접근 방식은 전통적인 영화 제작 방식을 모방한 것으로, 복잡한 이야기를 관리 가능한 장면으로 분할하여 처리한다. 

주요 기여는 다음과 같다:
- 긴 내러티브의 일관성과 짧은 시각적 충실도 간의 균형을 맞춘 영화 생성 계층적 프레임워크 도입
- 멀티모달 오토레그레시브 모델을 사용하여 시각적 토큰 시퀀스 생성
- 혁신적인 멀티모달 스크립트를 사용하여 장면의 풍부한 설명과 캐릭터의 정체성을 구조화
- 캐릭터의 정체성을 유지하면서 고품질의 세부 시각 연속성과 높은 충실도의 영상을 생성.

**2. Related Work (관련 연구)**

비디오 생성 모델의 발전은 주로 확산 모델과 오토레그레시브 방법을 통해 이루어졌다. 즉, 확산 모델은 시각적 렌더링에 강점을 가진 반면, 오토레그레시브 모델은 복잡한 추론과 긴 시퀀스 예측에 더 적합하다. 최근 연구들은 멀티모달 대형 언어 모델(VLM)이 비디오 콘텐츠 생성에서도 강력한 성능을 발휘할 수 있음을 보여주었다. 이러한 연구들은 특히 영화와 같은 긴 동영상의 내러티브 구조를 효과적으로 처리하는 데 유용하다.

**3. Method (방법론)**

MovieDreamer는 멀티모달 스크립트를 조건으로 가져와 오토레그레시브 방식으로 키프레임 토큰을 예측하고, 이를 기반으로 전체 길이의 비디오를 생성한다. 이 접근 방식은 제로샷과 퓨샷 시나리오를 모두 지원하며, 캐릭터의 정체성을 유지하는 데 중점을 둔다. 서술적 연속성을 유지하기 위해, 스크립트는 시각적 스타일과 장면을 세부적으로 설명하며, 캐릭터의 얼굴 임베딩을 포함한다. 또한, 예측된 시각적 토큰을 이미지 확산 디코더로 디코딩하여 비디오로 렌더링한다.

**4. Experiments (실험)**

다양한 영화 장르에서의 광범위한 실험을 통해, MovieDreamer의 생성 품질이 우수하다는 것을 입증했다. 실험 결과는 시각적 연속성과 캐릭터의 정체성 유지 측면에서 최신 기술을 능가하는 성능을 보여준다. 또한, 오버피팅 방지를 위한 데이터 증강, 공격적인 드롭아웃, 토큰 마스킹 등의 전략을 사용하여 모델의 일반화 성능을 향상시켰다.

**5. Conclusion (결론)**

MovieDreamer는 오토레그레시브 모델과 확산 방식을 결합하여 긴 동영상 콘텐츠 생성을 위한 새로운 가능성을 제시한다. 캐릭터 정체성을 유지하고, 긴 내러티브의 일관성을 유지하는 것이 주요 특징이다. 이러한 접근 방식은 앞으로의 자동화된 긴 동영상 제작에 중요한 기여를 할 것으로 기대된다.

### 종합 요약

이 논문은 오토레그레시브 모델과 확산 기반 렌더링을 결합한 MovieDreamer라는 새로운 계층적 프레임워크를 제안한다. 이 Framework는 긴 동영상 콘텐츠 생성 문제를 해결하는 데 중점을 두었으며, 특히 영화 제작 방식을 모방하여 복잡한 내러티브를 효율적으로 처리한다. MovieDreamer는 제로샷 및 퓨샷 시나리오를 지원하며, 캐릭터의 정체성을 유지하면서도 시각적 품질 높은 긴 동영상을 생성할 수 있다. 실험을 통해, 이 접근 방식이 최신 기술보다 뛰어난 성능을 보여줬다는 점을 입증하였다. 앞으로의 자동화된 긴 동영상 제작에 중요한 기여를 할 것으로 기대된다.