# MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.02813.pdf](https://arxiv.org/pdf/2409.02813.pdf)

### Summarized Content of Each Section

#### 1. 서론
최근 여러 모드(다양한 입력 모달리티)를 사용하는 대형 언어 모델(MLLM)의 발전은 텍스트와 시각 정보를 결합한 복잡한 추론 작업에서 뛰어난 성과를 보여주었습니다. 하지만 이러한 성과가 진정한 이해와 추론 능력을 반영하는지, 단순히 통계적 패턴과 숏컷을 이용하는 것인지는 의문이 제기되고 있습니다. 이를 해결하고자 MMMU-Pro라는 더욱 견고하고 도전적인 벤치마크를 도입했습니다. MMMU-Pro는 모델의 실제 다중 모달 이해와 추론 능력을 정확하게 평가하기 위해 설계되었습니다.

#### 2. MMMU-Pro: 개선된 버전의 벤치마크
기존의 MMMU 벤치마크는 대학 수준의 과목별 지식과 세심한 추론을 요구하는 데이터셋입니다. 그러나 텍스트만으로 답변할 수 있는 질문이 포함되어 있어 모델이 숏컷을 찾아내는 경우가 많았습니다. MMMU-Pro는 이를 해결하기 위해 세 가지 주요 단계를 도입했습니다. 첫째, 텍스트만으로 답변 가능한 질문을 제거하고, 둘째, 선택지를 증가시켜 단순 추측을 줄였으며, 셋째, 질문이 이미지에 포함된 비전 전용 입력 설정을 도입했습니다.

#### 3. 실험 세팅 및 결과
다양한 최첨단 다중 모달 모델을 기반으로 MMMU-Pro의 난이도를 평가했습니다. 실험 결과, 모든 모델이 기존 벤치마크 대비 저하된 성능을 보였으며, 선택지 수가 증가함에 따라 성능이 떨어졌습니다. 비전 전용 설정에서도 성능 저하가 관찰되어, 모델의 텍스트와 이미지 통합 능력을 더욱 엄격히 평가할 수 있음을 확인했습니다. OCR(광학 문자 인식) 프롬프트는 대부분의 모델에서 큰 영향을 미치지 못했으며, Chain of Thought(CoT) 추론은 성능을 향상시키는 경향이 있었지만, 모델마다 결과가 달랐습니다.

#### 5. 결론
MMMU-Pro는 기존 벤치마크에 비해 다중 모달 이해와 추론을 보다 엄격히 평가하는 도구입니다. 이를 통해 현재 최첨단 모델의 한계를 노출시키고, 미래 연구에 중요한 방향성을 제시합니다. 특히 비전 전용 입력과 텍스트-이미지 통합 능력을 향상시키는 것이 중요한 과제입니다.

### Overall Summary (원문 요약)

MMMU-Pro는 기존의 MMMU 벤치마크를 개선하여 모델의 진정한 다중 모달 이해와 추론 능력을 평가하도록 설계된 새로운 벤치마크입니다. 텍스트만으로 해결 가능한 문제를 제거하고, 선택지를 증가시켜 단순 추측을 방지하며, 질문이 이미지에 포함된 비전 전용 설정을 도입했습니다. 다양한 모델을 테스트한 결과, MMMU-Pro는 모델의 성능 저하를 유도하여 기존 성과가 숏컷이나 패턴을 이용한 것임을 확인할 수 있습니다. 이를 통해 다중 모달 AI의 한계를 극복하고, 미래 연구를 위한 중요한 방향을 제시합니다.