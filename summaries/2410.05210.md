# Preserving Multi-Modal Capabilities of Pre-trained VLMs for Improving Vision-Linguistic Compositionality
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.05210.pdf](https://arxiv.org/pdf/2410.05210.pdf)

1. 각 섹션 요약:

- **서론**:
  이 논문은 기존의 비전-언어 모델(VLM)의 한계를 극복하고, 조합적 이해력을 향상시키는 새로운 방법을 제안합니다. 제안된 방법은 Fine-grained Selective Calibrated CLIP (FSC-CLIP)으로, 전통적인 방식의 글로벌 하드 네거티브 손실이 초래하는 멀티모달 성능 저하를 방지하고자 합니다.

- **기여점**:
  FSC-CLIP은 로컬 하드 네거티브 손실과 선택적 교정 정규화를 조합하여, 세밀한 네거티브 감독을 통해 모델의 표현 무결성을 유지하며 조합적 이해를 증가시키고자 합니다. 이는 다양한 벤치마크를 통해 입증되었습니다.

- **관련 연구**:
  CLIP과 같은 대규모 이미지-텍스트 프리트레이닝 모델이 멀티모달 영역에서 혁신을 일으켰지만, 여전히 조합적 추론에서 어려움을 겪습니다. FSC-CLIP은 이러한 문제를 해결하기 위해 높은 성능을 유지하는 프리트레이닝 및 파인튜닝을 조합한 방식을 연구합니다.

- **분석**:
  FSC-CLIP의 개별 구성 요소는 다각적인 평가를 통해 분석되었으며, 현저한 조합적 성능과 멀티모달 성능을 유지하며, 특정 손실 구성 요소의 영향력을 검토했습니다. 이를 통해서 FSC-CLIP은 효과적으로 다양한 조합적 과제를 수행할 수 있음을 확인했습니다.

2. 전체 요약:

이 논문은 기존의 비전-언어 모델이 직면하고 있는 조합적 추론 문제를 해결하기 위해 설계된 Fine-grained Selective Calibrated CLIP (FSC-CLIP)을 소개합니다. 이 모델은 기존 모델이 글로벌 하드 네거티브 손실을 통해 초래했던 멀티모달 기능 손실 없이 조합적 이해를 개선하는 데 중점을 두고 있습니다. 이는 로컬 하드 네거티브 손실과 선택적 교정 정규화를 통해 이루어지며, 이러한 혁신적인 접근법은 다양한 실험을 통해 입증되었습니다. 결과적으로 FSC-CLIP은 조합적 태스크와 멀티모달 태스크에서 탁월한 성능을 보여줍니다.