# APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.18518.pdf](https://arxiv.org/pdf/2406.18518.pdf)

### 논문 요약

#### 1. 요약 (각 섹션별 주요 내용)
논문에서는 AI 및 머신 러닝의 발전을 위한 데이터셋 생성 도구인 APIGen을 소개합니다.

**1.1 서론**
기능 호출 에이전트는 대형 언어 모델(LLM)의 중요한 진보를 나타냅니다. 이러한 모델은 자연어 지시를 바탕으로 API 호출을 수행할 수 있습니다. 그러나, 훈련 데이터셋의 품질이 낮아 실제 응용에서 부정확하고 비효율적으로 작동하는 문제점이 있습니다. 이를 해결하기 위해 APIGen을 도입했습니다.

**1.2 APIGen 소개**
APIGen은 다양한 기능 호출 데이터셋을 생성하는 자동화된 파이프라인입니다. 다양한 스타일의 API 호출 데이터를 포함한 60,000개의 고품질 데이터를 생성할 수 있습니다. 각 데이터는 형식 검증, 실행 검증, 의미 검증의 3단계 검증 과정을 거칩니다. 이를 통해 데이터의 신뢰성과 정확성을 확보합니다.

**1.3 기여와 혁신점**
논문은 APIGen이 작은 모델(예: 1B 파라미터)을 사용하더라도 성능을 높일 수 있음을 보였습니다. 특히, 생성된 데이터의 높은 품질 덕분에 더 큰 모델과 비교해도 경쟁력 있는 성능을 달성할 수 있습니다. 24가지 큰 카테고리에서 3,673개의 실행 가능한 API를 수집하여 서식을 통합하고, 고유한 API 호출 시나리오에도 적응할 수 있게 합니다.

**1.4 실험 결과**
생성된 데이터셋은 Berkeley Function-Calling Benchmark에서 여러 GPT-4 모델을 능가하는 성능을 보여주었습니다. 또한 7B 모델도 상위 6위에 오르는 등 뛰어난 성능을 보였습니다. 작은 모델(1B 모델)도 GPT-3.5-Turbo와 비교해 더 나은 성능을 발휘했습니다.

**1.5 결론**
APIGen은 다양한 API 호출 데이터를 생성하여 기능 호출 에이전트 모델의 성능을 향상시킵니다. 현재는 REST API와 Python 함수에만 집중하지만, 추후 더 다양한 시나리오와 프로그래밍 언어를 지원할 계획입니다. APIGen은 작은 모델도 높은 성능을 발휘할 수 있게 함으로써 데이터 품질이 모델 크기만큼 중요하다는 점을 강조합니다.

#### 2. 전체 요약
논문은 APIGen이라는 자동 데이터 생성 파이프라인을 소개합니다. APIGen은 다양한 기능 호출 데이터셋을 생성하고, 각 데이터는 3단계 검증 과정을 통해 신뢰성을 확보합니다. 이를 통해 작은 모델도 높은 성능을 발휘할 수 있을 만큼 데이터 품질을 향상시켜, Berkeley Function-Calling Benchmark에서 여러 GPT-4 모델보다 뛰어난 성능을 보였습니다. 현재는 제한된 API와 언어에 집중하고 있지만, 추후 더 다양한 시나리오를 지원할 예정입니다. APIGen은 기능 호출 에이전트 모델의 연구 및 개발에 새로운 가능성을 제공합니다.

## Similar Papers
- [MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains](2407.18961.md)
- [ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools](2406.12793.md)
- [Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models](2405.20541.md)
- [Scaling Synthetic Data Creation with 1,000,000,000 Personas](2406.20094.md)
- [MindSearch: Mimicking Human Minds Elicits Deep AI Searcher](2407.20183.md)
- [Parrot: Multilingual Visual Instruction Tuning](2406.02539.md)
- [Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models](2406.13542.md)
- [Applying RLAIF for Code Generation with API-usage in Lightweight LLMs](2406.20060.md)
- [HARE: HumAn pRiors, a key to small language model Efficiency](2406.11410.md)
