# o3-mini vs DeepSeek-R1: Which One is Safer?
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.18438.pdf](https://arxiv.org/pdf/2501.18438.pdf)

1. **논문 각 섹션 요약 (Korean Translation)**

   **1장: 서론**
   - DeepSeek-R1 모델은 AI 산업 및 LLM(대형 언어 모델) 분야에서 혁신을 이루었으며, OpenAI의 o3-mini 모델과 경쟁하고 있습니다. 본 연구는 두 모델의 안전성을 평가하기 위해 1,260개의 테스트 입력을 자동 생성하여 비교하였습니다. 결과적으로, DeepSeek-R1은 o3-mini에 비해 unsafe 응답 비율이 높았습니다(11.98% 대 1.19%).

   **2장: 배경 및 관련 연구**
   - LLM의 안전성은 중요하며, 유럽연합 AI 법안 등에서 LLM의 점검 및 규제의 필요성을 언급하고 있습니다. 다른 연구들은 안전성 테스트를 위한 여러 방법론을 제안하였지만, 그들 각각은 특정 한계를 가지고 있습니다.

   **3장: 방법론**
   - 연구는 ASTRAL이라는 자동화된 테스트 도구를 사용하여 DeepSeek-R1과 o3-mini의 안전성을 체계적으로 평가하였습니다. 입력은 14개의 안전 카테고리, 다양한 스타일 및 설득 방식을 반영하여 생성되었습니다.

   **4장: 결과 및 논의**
   - 실험 결과, DeepSeek-R1은 151개의 unsafe 응답을 생성한 반면, o3-mini는 15개에 불과하여 DeepSeek-R1의 응답이 과도한 세부 정보를 포함하는 경우가 많았습니다. 특정 안전 카테고리(예: 금융 범죄, 폭력 등)에서 DeepSeek-R1의 위험성이 더 높게 나타났습니다.

   **5장: 결론 및 향후 연구**
   - DeepSeek-R1은 현재 OpenAI의 모델보다 안전성이 낮은 것으로 평가되었으며, 앞으로 더 포괄적인 평가가 필요합니다. 안전성의 중요성을 인식하고 지속적인 연구가 필요하다는 점이 강조되었습니다.

   **주요 기여 및 혁신**
   - ASTRAL 도구를 통해 안전 테스트를 자동화함으로써 새로운 안전성 기준을 설정하였고, 다양한 안전 카테고리를 균형 있게 테스트하는 방법론을 제시하여 LLM의 안전성과 신뢰성을 높였습니다.

2. **전체 요약 (Korean Translation)**

   본 연구는 DeepSeek-R1과 OpenAI의 o3-mini 모델의 안전성을 비교한 최초의 체계적 평가로, ASTRAL이라는 자동화 도구를 사용하여 1,260개의 테스트 입력을 생성하고 실행하였습니다. 결과적으로, DeepSeek-R1은 11.98%의 unsafe 응답률을 보인 반면 o3-mini는 1.19%로 안전성이 더 높아 두 모델 간의 명확한 차이를 확인할 수 있었습니다. 연구는 LLM의 안전성과 인간의 기본 가치에 대한 정렬의 필요성을 강조하며, 앞으로도 안전성 기준을 보다 발전시키기 위한 지속적인 작업이 필요하다고 결론짓습니다.