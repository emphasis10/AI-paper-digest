# Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.15998.pdf](https://arxiv.org/pdf/2408.15998.pdf)

### 논문 요약: "Eagle: A family of multimodal large language models (MLLMs) with a mixture of vision encoders"

### 섹션별 요약

**1. 서론**

- **내용 요약**: 대형 언어 모델(LLM)의 성공은 이 모델들이 실제 세계에서 시각적 인식을 하고 이해하며 추론할 수 있도록 하는 것에 큰 관심을 불러 일으켰다. 본 논문은 다양한 비전 인코더를 사용하여 이미지 정보를 일련의 시각적 토큰으로 변환하고, 이를 텍스트 임베딩에 추가하는 방식의 MLLM 설계를 제안한다.
- **주요 기여 및 혁신**: 단순한 채널 연결을 통해 여러 비전 인코더의 시각적 토큰을 결합하는 혁신적인 설계를 제안. 이를 통해 기존 복잡한 아키텍처나 전략보다 효율성과 성능을 동시에 달성.

**2. 관련 연구**

- **내용 요약**: 여러 비전 인코더를 사용하는 기존 연구는 많지만, 본 논문은 이러한 설정에서 몇 가지 흥미로운 새로운 발견을 제시. 비전 인코더를 MLLM 훈련 중에 잠금 해제를 하는 것이 중요하며, 일부 최신 융합 전략은 실질적인 이점을 보이지 않음.
- **주요 기여 및 혁신**: 비전 인코더를 동결하지 않고 활용함으로써 MLLM의 인식 성능이 향상됨을 발견.

**3. 비전 인코더**

- **내용 요약**: 다양한 비전 전문가를 포함하는 비전 인코더 수집. 예를 들어, CLIP, ConvNeXt, EVA-02, Pix2Struct, SAM, DINOv2 등이 있다. 이들은 각기 다른 입력 해상도와 체크포인트를 갖추고 있으며, 이를 통해 시각적 정보의 숫자가 1024개임을 보장.
- **주요 기여 및 혁신**: 다양한 비전 전문가를 통합하여 MLLM의 성능 향상을 도모.

**4. 융합 전략**

- **내용 요약**: 주요 융합 전략들에는 시퀀스 추가, 채널 연결, 미니-젬니, 변형 가능한 주의 등이 포함됨. 이러한 방법들을 통해 여러 비전 인코더들의 장점을 최대한 활용하고자 함.
- **주요 기여 및 혁신**: 채널 연결 방식이 성능과 처리 속도 측면에서 가장 우수함을 확인.

**5. 실험 및 결과**

- **내용 요약**: 세 가지 VQA(VizWiz, TextVQA, GQA) 벤치마크에서 Eagle 모델 시리즈가 우수한 성능을 발휘함. TextVQA에서는 고해상도 아키텍처와 다양한 비전 인코더의 통합 덕분에 경쟁 모델을 능가.
- **주요 기여 및 혁신**: 고해상도 아키텍처와 다양한 비전 인코더의 조합으로 성능 향상.

**6. 결론**

- **내용 요약**: 비전 인코더를 MLLM에 통합하는 설계 공간에 대한 심층 분석을 통해 몇 가지 유용한 기술을 발견함. 이를 통해 단순한 설계를 통한 비전 인코더 성능 향상 방법을 제안.
- **주요 기여 및 혁신**: 비전 인코더 설계에 대한 체계적인 연구를 통해 새로운 기초와 영감을 제공.

### 전체 요약

본 논문은 다양한 비전 인코더를 결합하여 멀티모달 대형 언어 모델(MLLM)의 성능을 극대화하는 방법을 제안합니다. 주요 기여는 단순한 채널 연결 방식으로 여러 비전 인코더의 시각적 토큰을 효과적으로 결합하여 효율성과 성능을 동시에 달성한 점입니다. 또한, 비전 인코더를 동결하지 않고 통합함으로써 MLLM의 인식 성능이 크게 개선됨을 발견했습니다. 이 논문에서 제시한 혁신적인 설계와 실험적 결과들은 MLLM의 미래 발전 방향에 중요한 기여를 할 것입니다.

이 요약을 바탕으로 프레젠테이션을 만들 때 각 섹션의 주요 내용과 논문의 핵심 기여를 중심으로 구성하면 효과적일 것입니다.