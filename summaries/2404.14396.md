# SEED-X: Multimodal Models with Unified Multi-granularity Comprehension and Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.14396.pdf](https://arxiv.org/pdf/2404.14396.pdf)

이 논문은 SEED-X라는 다기능 멀티모달 기반 모델을 소개합니다. 이 모델은 실세계 응용 프로그램에서 다양한 사용자 요구에 효과적으로 대응할 수 있도록 설계되었습니다. 주요 내용은 다음과 같습니다.

1. **서론**: 멀티모달 대형 언어 모델(MLLM)의 발전이 비약적으로 이루어졌지만, 실제 응용에 있어서 여전히 제한적입니다. 이 논문에서는 이러한 간극을 줄이기 위해 이미지의 다양한 크기와 비율을 이해하고, 다중 정밀도 이미지 생성을 가능하게 하는 SEED-X를 제안합니다.

2. **SEED-X 모델**: SEED-X는 이미지를 이해하고 생성하는 능력을 통합하여, 실세계 상황에서 다양한 형태의 멀티모달 도우미로 기능할 수 있습니다. 사용자의 입력 이미지를 기반으로 수정 제안을 제공하고 시각화를 보여줄 수 있습니다.

3. **시각 토큰화 및 디토큰화**: SEED-X는 비주얼 토큰화기를 사용하여 이미지를 이해하고 생성하는 과정을 통합합니다. 이 과정에서 고해상도 이미지를 세밀하게 조작하는 기능을 강화하였습니다.

4. **동적 해상도 이미지 인코딩**: 다양한 크기와 비율의 이미지를 처리할 수 있도록 설계되어, 입력 이미지를 그리드로 나누어 각 서브 이미지를 인코딩합니다. 이를 통해 모델은 훈련 중 경험하지 못한 이미지 해상도에도 대응할 수 있습니다.

5. **다기능 훈련 및 지시 조정**: SEED-X는 멀티모달 데이터를 사용하여 사전 훈련을 받고, 다양한 도메인에 걸친 인간의 지시에 맞춰 미세 조정을 수행합니다. 이를 통해 이미지 편집, 슬라이드 생성, 스토리텔링 등 특정 작업에 맞는 모델을 생성할 수 있습니다.

6. **실험 결과**: SEED-X는 공개 벤치마크에서 경쟁력 있는 성능을 보이며, 이미지 이해와 생성 작업에서 상태-오브-더-아트 성능을 달성합니다.

7. **결론**: SEED-X는 실세계 시나리오에서 다양한 멀티모달 AI 도우미로서 기능할 수 있는 능력을 갖추고 있으며, 앞으로 멀티모달 재단 모델의 가능성을 탐구하는 데 중요한 통찰을 제공할 것입니다.

이 모델은 특히 이미지와 텍스트를 포함한 복합적인 데이터를 이해하고 생성하는 능력을 갖춤으로써, AI 기술의 응용 범위를 크게 확장할 수 있을 것으로 기대됩니다.