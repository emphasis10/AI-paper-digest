# HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.19280.pdf](https://arxiv.org/pdf/2406.19280.pdf)

### 1. 각 섹션 요약

#### Introduction
논문은 멀티모달 대형 언어 모델(MLLMs)인 GPT-4V와 같이 발전하는 모델들이 의료 멀티모달 능력에서 여전히 한계를 겪는다고 언급합니다. 데이터 프라이버시 문제와 고 비용의 주석 작업으로 인해 의료 이미지-텍스트 데이터의 양과 질이 부족하다고 설명합니다. 이러한 문제를 해결하기 위해 PubMed의 대규모 익명화된 의료 이미지-텍스트 쌍을 활용하는 시도를 소개합니다. 하지만 기존 데이터의 노이즈 문제를 해결하기 위해 GPT-4V를 활용한 'unblinded' 방식으로 데이터 정제를 통해 PubMedVision이라는 새로운 데이터셋을 개발했습니다.

#### Medical Visual Alignment in MLLMs
이 섹션은 기존 의료 시각적 질문 응답(VQA) 데이터와 주류 데이터셋 간의 비교를 다룹니다. 기존 데이터셋(VQA-RAD, SLAKE, PathVQA)은 크기와 모달리티 면에서 한계가 있으며, 'blinded' LLMs를 사용해 생성된 VQA 데이터셋은 잘못된 해석과 정렬 문제를 야기합니다. 이와 달리 PubMedVision은 더 큰 규모와 높은 품질의 의료 VQA 데이터셋으로 설명됩니다.

#### PubMedVision Dataset Construction
PubMedVision은 1.3백만 개의 의료 VQA 샘플을 포함한 대규모 데이터셋입니다. 이는 GPT-4V를 통해 자운즈된 의료 이미지-텍스트 쌍에서 생성되었습니다. 실험 결과, PubMedVision은 MLLMs의 의료 멀티모달 능력을 크게 향상시키며, 특히 MMMU Health & Medicine 트랙에서 유의미한 개선을 보여줍니다.

#### Experiment Setup
실험 설정에서는 세 종류의 벤치마크(의료 VQA, 멀티모달 벤치마크, 전통적인 의료 이미지 과업)를 사용하여 PubMedVision이 MLLMs의 성능을 어떻게 향상시키는지 평가합니다. LLaVA-v1.5-LLaMA3-8B 모델을 기반으로 PubMedVision 데이터를 추가했을 때 성능이 크게 향상됨을 확인했습니다. PubMedVision을 사용한 HuatuoGPT-Vision 모델은 여러 의료 멀티모달 벤치마크에서 뛰어난 성능을 보였습니다.

### 2. 전체 요약
이 논문은 멀티모달 대형 언어 모델(MLLMs)의 의료 응용 한계를 극복하기 위해 새로운 데이터셋인 PubMedVision을 소개합니다. 기존 데이터셋의 노이즈 문제를 해결하기 위해 GPT-4V를 활용한 'unblinded' 데이터 정제 방법을 도입하였고, 이를 통해 1.3백만 개의 고품질 의료 VQA 샘플을 포함한 대규모 데이터셋을 개발했습니다. 실험 결과, PubMedVision은 MLLMs의 의료 멀티모달 능력을 크게 향상시키며, 다양한 벤치마크 테스트에서 뛰어난 성능을 보였습니다.

이 논문의 주요 기여와 혁신점은 고품질의 대규모 의료 멀티모달 데이터셋을 구축하고 이를 통해 MLLMs의 성능을 높이는 방법을 제시한 것입니다. 이를 통해 의료 분야에서 MLLMs의 활용 가능성을 크게 확장하였습니다.

## Similar Papers
- [AI Hospital: Benchmarking Large Language Models in a Multi-agent Medical Interaction Simulator](2402.09742.md)
- [CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis](2407.13301.md)
- [Capabilities of Gemini Models in Medicine](2404.18416.md)
- [GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI](2408.03361.md)
- [DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception](2407.08303.md)
- [Medical SAM 2: Segment medical images as video via Segment Anything Model 2](2408.00874.md)
- [SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers](2407.09413.md)
- [ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos](2406.19392.md)
- [MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular Annotations for Medicine](2408.02900.md)
