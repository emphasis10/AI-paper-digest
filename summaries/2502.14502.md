# How Much Knowledge Can You Pack into a LoRA Adapter without Harming LLM?
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.14502.pdf](https://arxiv.org/pdf/2502.14502.pdf)

### 주요 섹션 요약 및 논문 기여

1. **소개 (Introduction)**
   대형 언어 모델(LLM)은 사용자 질문에 대해 인간과 같은 응답을 생성할 수 있어 다양한 응용 분야에서 널리 사용되고 있습니다. 이 모델들은 사전 훈련 중에 대량의 지식을 축적하여 요약, 추론, 질문 응답 등 다양한 문제를 해결할 수 있습니다. 본 연구에서는 LoRA를 사용하여 모델의 사전 학습된 지식에 손상을 주지 않고 새로운 데이터를 통합하는 방법을 조사하고, 이로 인해 발생하는 성능 저하의 이유를 식별하며, 부정적 영향을 최소화할 전략을 탐구합니다.

2. **연구 설계 (Study Design)**
   연구 목표는 LoRA 어댑터를 통해 LLM에 새로운 지식을 통합하면서 그 일반 능력을 유지할 수 있는 범위를 조사하는 것입니다. 이를 위해 다양한 양의 새로운 지식을 모델에 통합하여 모델의 내재적 성능 저하와 외재적 성능 측정의 영향을 추적하는 실험을 수행했습니다.

3. **로우랭크 적응(LoRA)**
   LoRA는 모델의 각 층에 있는 트랜스포머 구조에 순위 분해 행렬을 주입하여 다양한 작업에서의 훈련 가능한 매개 변수 수를 크게 줄입니다. 이는 비용-효율적인 파인튜닝 방법으로, 일반적인 파인튜닝과 유사한 결과를 달성할 수 있습니다.

4. **결론 (Conclusions)**
   연구 결과는 새로운 데이터와 잘 알려진 데이터가 혼합된 경우 가장 많은 추가 지식 획득이 가능하지만, 이는 복잡하거나 미묘한 질문에 정확하게 답변할 모델의 능력을 손상시킨다는 trade-off가 있음을 보여줍니다. LoRA 어댑터로 미세 조정된 LLM이 불확실성을 표현하는 능력이 감소하여 특정 시나리오에서 통계적으로 과대 대표되는 응답을 선호하게 되는 것도 발견되었습니다.

### 전체 요약

이 논문은 대형 언어 모델(LLM)에 새로운 지식을 통합하는 방법을 연구하며, LoRA(로우랭크 적응)를 사용하여 모델의 성능을 손상시키지 않으면서 지식을 증가시킬 수 있는 방법을 탐구합니다. 특히, 새로운 지식의 통합이 모델 성능에 부정적인 영향을 미칠 수 있음을 발견하고, 이를 최소화할 전략을 개발하였습니다. 연구는 다양한 실험을 통해 새로운 지식이 기존의 잘 알려진 데이터와 혼합될 때 최대 효과를 발휘하며, 이러한 접근이 모델의 복잡한 질의를 처리하는 능력을 저하시킬 수 있음을 확인하였습니다. 모델은 새로운 지식 추가 후 불확실성 표현이 감소하는 경향이 있어 특정한 답변을 선호하게 되므로, 훈련 데이터의 구성과 설정 파라미터의 중요성이 강조되었습니다.