# SAME: Learning Generic Language-Guided Visual Navigation with State-Adaptive Mixture of Experts
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.05552.pdf](https://arxiv.org/pdf/2412.05552.pdf)

1. 섹션 요약
   - 도입: 이 논문은 자연어 명령을 이해하고 새로운 환경을 탐색하는 능력을 강조하며, 서로 다른 탐색 목표에 기반한 다양한 탐색 과제를 통합하려고 합니다. 기존의 연구들이 개별 과제에 특화되었다면, 본 연구는 언어 안내에 따른 시각 탐색이라는 더 넓은 개념 하에 이 문제들을 통일하려 하고 있습니다.
   
   - Mixture of Experts (MoE) 접근법: MoE 모델은 구체적인 전문가망 사용 및 내적 라우팅 메커니즘을 소개하며, 이를 통해 모델은 다중 작업 학습에서의 비효율성을 해결하고자 합니다. 특히 시각적 쿼리에 MoE를 적용하여 효과를 입증하고 있습니다.
   
   - 상태 적응형 전문가 선택 메커니즘(SAME): SAME는 언어 입력 및 동적 시각적 관찰을 결합하여 다양한 그레인러리티를 처리할 수 있도록 돕습니다. 이는 각기 다른 탐색 문제에 일반화된 접근법을 제공하며, 탁월한 성능을 보입니다.

2. 전체 요약
   paper의 주된 기여는 언어 안내에 따른 시각적 탐색 과제를 통합된 프레임워크로 통일한다는 데 있습니다. 기존의 개별 방법론 대신, 상태 적응형 전문가 조합(MoE)와 같은 혁신적인 접근을 통해 여러 탐색 과제를 동시에 처리할 수 있는 범용 에이전트를 제안합니다. 이로써 서로 다른 탐색 목표와 복잡성을 성공적으로 해결하며, 보다 일반화된 탐색 시스템 구축을 목표로 하고 있습니다.