# ConflictBank: A Benchmark for Evaluating the Influence of Knowledge Conflicts in LLM
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.12076.pdf](https://arxiv.org/pdf/2408.12076.pdf)

### 1. 각 섹션의 요약

**소개 (Introduction)**
이 논문에서는 대형 언어 모델(LLMs)이 언어를 이해하고 생성하며 추론하는 데 있어 뛰어난 성능을 보이지만, 지식 충돌로 인해 신뢰성과 신뢰도가 크게 영향을 받을 수 있음을 지적합니다. 기존 연구에서는 모델이 추론 중 새로운 정보를 검색할 때 발생하는 '검색된 지식의 충돌'과 훈련 데이터 내 불일치로 인해 발생하는 '내재된 지식의 충돌'로 나눕니다. 이러한 문제를 해결하기 위해, 저자들은 전체적인 지식 충돌을 분석할 수 있는 최초의 종합 벤치마크인 CONFLICTBANK를 소개합니다.

**관련 연구 (Related Work)**
지식 충돌은 크게 검색된 지식 충돌과 내재된 지식 충돌 두 가지로 나누어집니다. 검색된 충돌은 모델이 외부에서 검색된 정보와 충돌할 때 발생하며, 내재된 충돌은 모델 내부의 파라메트릭 지식 간의 충돌로 인해 발생합니다. 이전 연구는 주로 검색된 지식 충돌에 초점을 맞췄지만, 저자들은 두 가지 충돌 유형과 그 상호작용을 조사하는 데 중점을 둡니다.

**내재된 지식의 충돌 (Conflicts in Embedded Knowledge)**
저자들은 CONFLICTBANK를 사용하여 내부 지식 충돌이 모델 성능에 미치는 영향을 조사합니다. 실험 결과, 내재된 지식 충돌은 데이터 양에 따라 모델의 성능에 큰 영향을 미칩니다. 더 많은 충돌 데이터가 존재할수록 모델 성능이 더 저하됩니다. 그러나, 외부 증거를 사용하여 올바른 지식을 획득하면 이러한 내부 충돌의 부정적인 영향을 줄일 수 있습니다.

**결론 (Conclusion)**
이 논문에서는 단편적인 지식 충돌 연구의 한계를 극복하기 위해 CONFLICTBANK라는 종합적인 데이터셋을 개발했습니다. 553K QA 페어와 7백만 개의 지식 충돌 증거를 포함한 이 데이터셋은 LLM의 다양한 성능을 평가할 수 있도록 고안되었습니다. CONFLICTBANK를 사용한 실험을 통해, 저자들은 지식 충돌에서 LLM의 행동을 심층 분석하고 다양한 모델 크기와 충돌 유형에 대한 통찰을 제공했습니다.

### 2. 전체 요약

**전체 요약**
이 논문은 대형 언어 모델(LLMs)에서 발생할 수 있는 지식 충돌 문제를 해결하기 위한 종합적인 데이터셋인 CONFLICTBANK를 소개합니다. LLMs는 언어를 이해하고 생성하는 데 있어 뛰어난 성능을 보이지만, 내재된 지식과 새로 검색된 지식 간의 충돌로 인해 신뢰성이 떨어질 수 있습니다. 기존 연구는 주로 검색된 지식 충돌에 초점을 맞췄으나, 이 논문은 내재된 지식 충돌과 그 상호작용을 포함한 전반적인 지식 충돌을 분석합니다.
CONFLICTBANK는 553,117개의 QA 페어와 7,453,853개의 지식 충돌 증거를 포함하며, 이는 LLM의 다양한 성능을 평가하는 데 사용할 수 있습니다. 저자들은 이 데이터셋을 통해 LLM의 지식 충돌 시나리오에 대한 심층 실험을 수행하였고, 모델 크기, 충돌 원인, 충돌 유형 등에 대한 통찰을 제공하였습니다.