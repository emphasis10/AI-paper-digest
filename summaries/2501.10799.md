# Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.10799.pdf](https://arxiv.org/pdf/2501.10799.pdf)

1. 각 섹션의 주요 내용 요약:

   **서론:** 대형 언어 모델(LLM)이 논리적 이유 기반 과제에서 뛰어난 성과를 보이지만, 최종 정답의 정확성에 치중하는 기존 방법들은 중간 추론 과정의 일관성과 신뢰성을 보장하지 못하는 문제를 가집니다.

   **Step-KTO 제안:** Step-KTO는 과정 수준과 결과 수준의 피드백을 결합한 훈련 프레임워크로, 언어 모델이 신뢰할 수 있는 논리적 경로를 따르도록 유도합니다. 이는 중간 추론 단계와 최종 답변의 품질을 향상시킵니다.

   **실험 및 결과:** 복잡한 수학적 추론 벤치마크에 대해 수행한 실험에서 Step-KTO는 중간 추론 단계의 품질뿐만 아니라 최종 답변의 정확성을 지속적으로 개선하며, 보다 해석 가능하고 신뢰할 수 있는 추론 능력을 강화합니다.

   **결론:** Step-KTO는 모델의 전체 추론 경로를 개선하여 LLM의 신뢰성을 높이고, 보다 효과적인 추론을 위한 발판으로 자리잡을 가능성이 큽니다.

   **한계점:** 결과 수준 피드백이 부정확할 경우, 훈련 신호의 정밀도가 떨어질 수 있고, 초기 참 해답이 없는 상황에서는 정당한 중간 추론 경로를 정의하기 어렵다는 제한점이 있습니다.

2. 전체 요약:

   이 논문은 대형 언어 모델이 수학적 문제 해결에서 중간 추론 단계의 신뢰성 및 일관성을 보장하지 못하는 한계를 극복하기 위해 Step-KTO라는 새로운 훈련 방법을 제안합니다. Step-KTO는 과정 수준과 결과 수준의 이진 피드백을 결합하여 모델이 논리적으로 일관된 경로를 따르고 최종 답변의 정확성을 높이며, 실험을 통해 높은 성과를 보였습니다. 이러한 접근법은 추론 과정 전체에 걸쳐 신뢰할 수 있는 해결책을 제시함으로써, LLM의 해석 가능성과 신뢰성을 향상시킵니다.