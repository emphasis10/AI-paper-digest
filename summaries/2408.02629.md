# VidGen-1M: A Large-Scale Dataset for Text-to-video Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.02629.pdf](https://arxiv.org/pdf/2408.02629.pdf)

### 1. 섹션별 요약 및 주요 기여와 혁신 부분 설명

1. **서론 (Introduction)**
   - **요약**: 이 논문은 최신 텍스트-비디오 생성 기술이 직면한 문제들을 다루며, 특히 현재 데이터셋의 한계로 인해 훈련이 불안정하고 성능이 좋지 않음을 지적합니다. 이러한 문제를 해결하기 위해 VidGen-1M이라는 고품질 비디오-텍스트 데이터셋을 소개합니다.
   - **주요 기여**: 고품질의 비디오와 자세한 캡션, 뛰어난 시간적 일관성을 갖춘 데이터셋을 제공하여 텍스트-비디오 모델의 훈련 성능을 향상시킵니다.
   - **혁신 부분**: 기존 데이터셋의 문제점을 해결하기 위해 "coarse-to-fine" 데이터 선별 방법론을 도입했습니다.

2. **관련 연구 (Related Work)**
   - **요약**: 기존의 비디오-텍스트 데이터셋과 텍스트-비디오 생성 모델에 대한 논의를 다룹니다. 
   - **주요 기여**: 기존 데이터셋과의 비교를 통해 VidGen-1M의 장점을 부각시킵니다.
   - **혁신 부분**: 기존 데이터셋이 갖고 있는 저품질 비디오, 불충분한 캡션, 시간적 불일치 및 데이터 불균형 문제를 해결하는 방법을 제시했습니다.

3. **방법론 (Method)**
   - **요약**: VidGen-1M 데이터를 구축하는 과정을 상세히 설명합니다. 여기에는 3.8백만 개의 고해상도 비디오를 세분화하여 데이터 선별 과정을 거치는 내용이 포함됩니다.
   - **주요 기여**: 3단계 데이터 선별 과정(초기 선별, 캡션 생성 및 정교한 선별)을 통해 고품질 데이터를 생성합니다.
   - **혁신 부분**: 최첨단 비전-언어 모델(VILA)을 사용하여 고품질 캡션을 생성하고, 최신 언어 모델(LLAMA3.1)을 사용하여 데이터 오류를 식별하고 수정합니다.

4. **실험 (Experiments)**
   - **요약**: VidGen-1M을 사용하여 모델을 훈련한 후의 성능을 평가합니다. 다양한 질적 평가를 통해 데이터셋의 유효성을 검증합니다.
   - **주요 기여**: VidGen-1M을 사용한 모델이 기존 최고 성능의 텍스트-비디오 모델보다 더 나은 성능을 보였음을 입증합니다.
   - **혁신 부분**: 새로운 데이터셋을 통한 훈련으로 실험에서의 향상된 성능을 확보했습니다.

5. **결론 (Conclusion)**
   - **요약**: VidGen-1M의 장점과 효용성을 재확인하며, 이 데이터셋과 관련 코드, 훈련된 모델을 공개할 계획을 발표합니다.
   - **주요 기여**: 텍스트-비디오 생성 모델의 성능을 크게 향상시키는 데이터셋을 제공함으로써 연구 커뮤니티에 기여합니다.
   - **혁신 부분**: 고품질 데이터셋의 공개를 통해 더 나은 영상 생성 기술의 개발을 촉진하고자 합니다.

### 2. 전체 요약
VidGen-1M 논문은 텍스트-비디오 생성 모델의 훈련에 최적화된 고품질의 비디오-텍스트 데이터셋을 제안합니다. 서론에서 기존 데이터셋의 문제점을 지적하며, 새로운 데이터셋을 통해 이러한 문제를 해결하고자 합니다. 방법론 섹션에서는 3단계 데이터 선별 과정을 통해 고품질의 비디오와 자세한 캡션을 확보하는 방법을 자세히 설명합니다. 실험 결과 섹션에서는 VidGen-1M을 사용한 모델이 기존 모델보다 우수한 성능을 보였음을 입증하며, 결론에서는 데이터셋과 관련 도구를 공개하여 연구 커뮤니티에 기여할 계획을 밝혔습니다. VidGen-1M은 텍스트와 비디오의 높은 일치성과 시간적 일관성을 강조하여, 텍스트-비디오 모델의 성능 향상에 크게 기여할 수 있습니다.

## Similar Papers
- [MiraData: A Large-Scale Video Dataset with Long Durations and Structured Captions](2407.06358.md)
- [ShareGPT4Video: Improving Video Understanding and Generation with Better Captions](2406.04325.md)
- [Diffree: Text-Guided Shape Free Object Inpainting with Diffusion Model](2407.16982.md)
- [EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture](2405.18991.md)
- [Lighting Every Darkness with 3DGS: Fast Training and Real-Time Rendering for HDR View Synthesis](2406.06216.md)
- [Tora: Trajectory-oriented Diffusion Transformer for Video Generation](2407.21705.md)
- [PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning](2404.16994.md)
- [Matryoshka Multimodal Models](2405.17430.md)
- [Video Diffusion Alignment via Reward Gradients](2407.08737.md)
