# LongWriter: Unleashing 10,000+ Word Generation from Long Context LLMs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.07055.pdf](https://arxiv.org/pdf/2408.07055.pdf)

## Section Summaries in Korean:

### 1. Abstract (초록)
현재의 긴 문맥 대형 언어 모델(LLMs)은 최대 10만 개의 토큰을 처리할 수 있지만, 2000 단어를 초과하는 출력을 생성하는 데 어려움을 겪습니다. 본 연구에서는 이 문제를 해결하기 위해 AgentWrite라는 에이전트 기반 파이프라인을 소개했습니다. AgentWrite는 초장문의 생성 작업을 여러 하위 작업으로 분해하여 일관된 출력을 생성할 수 있게 합니다. 이를 통해 LongWriter-6k 데이터세트를 구축하고, 기존 모델의 출력 길이를 성공적으로 확장했습니다. 또한, 초장문 생성 능력을 평가하기 위한 LongBench-Write 벤치마크를 개발했습니다.

### 2. Introduction (서론)
긴 문맥 LLMs는 입력의 길이를 확장할 수 있지만, 출력의 길이는 2000 단어로 제한됩니다. 이를 해결하기 위해 본 연구에서는 최대 출력 길이를 제한하는 주요 요인이 SFT 데이터셋의 특성임을 밝혀냈습니다. 또한, AgentWrite라는 새로운 파이프라인을 소개하여, 사용자의 입력에 따라 구조화된 작문 계획을 세우고, 각 단락별로 내용을 생성하는 방식으로 장문의 출력을 가능하게 했습니다.

### 3. Finding the Cause of the Bounded Generation Length Limit (출력 길이 제한 원인 탐구)
출력 길이가 제한된 주요 원인은 SFT 데이터셋의 최대 출력 길이에 있습니다. 시험을 통해 모델의 출력 길이가 SFT 데이터의 최대 출력 길이에 비례하여 증가한다는 것을 확인했습니다. 이를 통해 현재 모델이 2000 단어로 제한되는 이유를 설명했습니다.

### 4. LongWriter: Teaching Models to Generate Ultra-Long Output (LongWriter: 초장문 생성 방법)
AgentWrite를 활용하여 LLM에게 초장문 출력을 학습시키는 방안을 연구했습니다. 이를 위해 6000개의 장문 출력을 요구하는 사용자 명령어를 수집하고, AgentWrite를 통해 응답을 생성했습니다. 이 데이터세트는 LongWriter-6k로 명명되었으며, 이를 통해 10,000 단어 이상의 출력을 제공하는 모델을 성공적으로 훈련했습니다.

### 5. Related Work (관련 연구)
긴 문맥 LLM과 관련한 기존 연구를 검토했습니다. 특히, 컨텍스트 윈도우를 확장하는 방법과 LLM을 사용자 명령어에 맞게 정렬하는 방법에 주목했습니다. 본 연구는 LLM이 초장문을 생성할 수 있도록 정렬하는 문제를 중점적으로 다룹니다.

### 6. Conclusion (결론)
현재 LLM의 출력 길이를 초과하기 위해 LongWriter-6k와 AgentWrite를 활용하여 10,000 단어 이상의 출력을 가능하게 한 성과를 제시합니다. 향후 연구로는 AgentWrite를 확장하여 더 긴 출력을 생성하고, 품질을 높이며, 추론 효율성을 개선하는 방안을 제안했습니다.

## Overall Summary in Korean:

본 연구는 긴 문맥 대형 언어 모델(LLMs)의 출력 길이를 확장하기 위한 새로운 접근법을 제시합니다. 주요 기여는 다음과 같습니다:
1. 출력 길이 제한 분석: 현재 모델의 최대 출력 길이가 SFT 데이터의 최대 출력 길이에 비례함을 발견했습니다.
2. AgentWrite: 에이전트 기반 파이프라인으로 초장문 출력을 가능하게 했습니다.
3. LongWriter-6k 데이터세트: 초장문 출력을 위해 6000개의 장문 예제를 수집하여 모델 학습에 활용했습니다.
4. LongBench-Write 벤치마크: 초장문 생성 능력을 평가하기 위한 벤치마크를 구축했습니다.

본 연구의 혁신적인 부분은 AgentWrite를 통해 기존 모델의 출력 길이를 10,000 단어 이상으로 확장하며도 품질을 유지하는 점입니다. 또한, 이를 위해 새로운 데이터세트 및 평가 체계를 개발한 점에서도 큰 기여를 했습니다.

이를 바탕으로, AI의 장문 생성 능력을 더욱 발전시킬 수 있으며, 향후 더 긴 출력을 생성하고 품질을 높이는 방향으로 연구를 확장할 계획입니다.