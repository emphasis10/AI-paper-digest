# ContextCite: Attributing Model Generation to Context
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.00729.pdf](https://arxiv.org/pdf/2409.00729.pdf)

### 1. 각 섹션 요약

#### **1. 서론**
저자들은 문맥에서 제공된 정보를 사용하여 언어 모델이 반응을 생성하는 방법과 특정 진술이 문맥에서 실제로 근거가 있는지 또는 오해나 날조된 것인지 추론하는 방법에 대해 논의합니다. 이를 위해 문맥 귀속(context attribution) 문제를 제기하고, CONTEXTCITE라는 방법을 소개합니다. CONTEXTCITE는 기존 언어 모델 위에 적용 가능하며, 문맥 기반 반응 검증, 응답 품질 향상, 데이터 오염 공격 탐지 등에 활용될 수 있습니다.

#### **2. 문제 정의**
문맥 귀속의 목표는 생성된 응답을 특정 문맥 부분으로 소급하는 것입니다. 저자들은 언어 모델이 주어진 질문(Query)에 대해 문맥(Context)을 어떻게 활용하는지 설명하면서, 귀속 방법이 각 문맥 소스의 중요도를 어떻게 평가하는지 설명합니다. 특히, 문맥을 구성하는 여러 문장(또는 단어) 단위로 내용을 나누고, 각 단위가 응답에 얼마나 중요한지를 평가하는 방법론을 제안합니다.

#### **3. CONTEXTCITE 방법론**
CONTEXTCITE의 핵심은 선형 대리 모델을 학습하는 것입니다. 이 모델은 문맥의 특정 부분이 응답 생성에 얼마나 기여했는지를 예측합니다. 대리 모델은 문맥 내 여러 부분을 제거한 후 해당 응답 확률을 비교하여 학습됩니다. 이 과정에서 LASSO(Least Absolute Shrinkage and Selection Operator)와 같은 기법을 활용하여 모델의 희소성을 유지합니다.

#### **4. CONTEXTCITE 평가**
CONTEXTCITE의 효과를 평가하기 위해 다양한 데이터셋 및 모델을 활용한 실험을 수행했습니다. 여기에는 질문 응답 데이터셋(TyDi QA, Hotpot QA) 및 뉴스 기사 데이터셋(CNN DailyMail)이 포함됩니다. 주요 평가 지표는 Top-k Log-Probability Drop과 선형 데이터 모델링 점수(LDS)입니다. 실험 결과, CONTEXTCITE는 기존 방법들보다 높은 정확성을 보였습니다.

#### **5. CONTEXTCITE 응용**
저자들은 CONTEXTCITE의 세 가지 주요 응용을 제안합니다:
1. **생성된 진술 검증 돕기**: 문맥 귀속 결과를 사용해 생성된 진술의 정확성을 검증합니다.
2. **응답 품질 개선**: 관련 있는 정보만을 선택하여 문맥을 간추림으로써 응답의 품질을 향상시킵니다.
3. **문맥 중독 공격 탐지**: 악의적으로 수정된 문맥(데이터 오염)을 탐지하는 데 CONTEXTCITE를 활용합니다.

#### **결론**
저자들은 문맥 귀속이라는 새로운 문제를 제기하고, 이를 해결하기 위해 CONTEXTCITE 방법을 소개했습니다. 특기할만한 기여 사항으로는 문맥을 통한 진술 검증, 응답 품질 개선, 공격 탐지 등이 있습니다.

### 2. 전체 요약
이 논문에서는 언어 모델의 반응 생성 시 문맥의 특정 부분이 반응에 어떻게 기여하는지를 추적하는 문제, 즉 문맥 귀속 문제를 제기합니다. 이를 위해 CONTEXTCITE라는 새로운 방법론을 제시하며, 이는 언어 모델의 응답 검증, 품질 향상, 데이터 오염 공격 탐지에 적용될 수 있습니다. CONTEXTCITE는 선형 대리 모델을 학습하여 문맥의 각 부분이 응답 생성에 얼마나 기여했는지를 평가합니다. 다양한 데이터셋을 통해 실험한 결과, CONTEXTCITE는 기존 방법들보다 높은 정확성을 보였으며, 여러 실제 응용 시나리오에서 유용성이 확인되었습니다.

이 논문의 주요 혁신점은 문맥 귀속을 통한 생성된 언어 모델의 진술 검증, 응답 품질 향상 및 데이터 오염 공격 탐지입니다.