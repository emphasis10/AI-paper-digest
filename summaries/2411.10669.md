# Awaker2.5-VL: Stably Scaling MLLMs with Parameter-Efficient Mixture of Experts
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.10669.pdf](https://arxiv.org/pdf/2411.10669.pdf)

논문은 다양한 시각 및 언어 과제를 동시에 처리하기 위한 대규모 다중 모드 언어 모델인 Awaker2.5-VL을 소개합니다. 이 모델은 다중 과제의 충돌 문제를 해결하기 위해 다수의 전문가 구조를 도입하였습니다.

### 각 섹션의 요약

1. **서론**
   - 다중 모드 대형 언어 모델(MLLM)은 최근 급격한 발전을 이루고 있습니다. 그러나 다중 과제에서의 데이터의 불일치로 인해 '다중 과제 충돌' 문제가 발생해, 성능이 저하되는 장애가 존재합니다. 이를 해결하기 위해 Awaker2.5-VL 모델이 도입되었습니다.

2. **관련 연구**
   - 다중 모드 대규모 언어 모델의 발전과 전문가 혼합 (MoE) 기술에 대해 탐구합니다. MoE 모델은 다양한 과제에 특화된 전문가를 통해 모델의 성능을 향상시킵니다.

3. **방법론**
   - Awaker2.5-VL 모델은 MoEL 구조를 이용해 다수의 전문가와 게이트 네트워크를 포함합니다. 이를 통해 각 과제별 전문가가 활성화되도록 합니다. 또한, MoE 구조를 기본 모델에 결합하여 성능을 유지하면서 훈련 비용을 줄이고자 했습니다.

4. **실험 및 결과**
   - 다양한 벤치마크 테스트에서 Awaker2.5-VL은 최신의 다른 모델들을 능가하여 최고의 성능을 보여주었습니다. 특히, MME-RealWorld와 MMBench 벤치마크에서 높은 점수를 기록했습니다.

5. **결론 및 향후 연구**
   - Awaker2.5-VL은 MoE 구조를 통해 다중 과제 문제를 해결하며, 여러 최신 기준에서 경쟁력을 입증했습니다. 앞으로는 텍스트 프롬포트를 더 잘 표현하는 방법을 모색하고, ViT에 MoE 모델 적용을 계획하고 있습니다.

### 전체 요약

Awaker2.5-VL 논문은 다중 모드 대규모 언어 모델이 다양한 시각과 언어 과제를 동시에 수행할 수 있도록 설계되었습니다. 특히, 다중 과제에서의 데이터 불일치를 전문가 혼합 구조를 통해 해결하여, 성능 저하 문제를 효과적으로 극복하였습니다. 여러 벤치마크에서 뛰어난 성능을 보이며, AI와 머신러닝 분야의 발전에 기여할 것으로 기대됩니다.