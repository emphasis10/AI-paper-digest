# Stream of Search (SoS): Learning to Search in Language
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.03683.pdf](https://arxiv.org/pdf/2404.03683.pdf)

이 연구 논문은 언어 모델이 실수에서 배우고, 다양한 검색 전략을 사용하여 문제를 해결하는 방법을 탐구합니다. 특히, 이 논문은 "Stream of Search (SoS)"라는 새로운 프레임워크를 소개하며, 이를 통해 언어 모델이 언어로 검색과 백트래킹을 표현하고, 이를 바탕으로 문제를 해결하는 방법을 배울 수 있음을 보여줍니다.

### 소개
언어 모델은 대개 문제 해결의 최종 결과만 학습하며, 그 과정에서의 실수나 회복 과정을 배우지 못합니다. 이 연구에서는 실수를 포함한 검색 과정을 학습함으로써 언어 모델이 더 복잡한 의사결정과 추론 과정을 배울 수 있음을 제안합니다.

### 관련 연구
기존 연구들은 언어 모델을 검색 및 계획 시스템의 일부로 통합하는 방법을 탐구했습니다. 이 연구들은 언어 모델이 후보 작업을 생성하고 평가하는 데 도움을 주지만, 모델 자체의 추론 능력을 향상시키지는 못했습니다. 본 연구는 언어 모델이 독립적으로 검색 과정을 수행할 수 있도록 합니다.

### 검색을 위한 언어
이 연구는 검색 과정의 다양한 구성 요소를 통일된 언어로 표현합니다. 이를 통해 다양한 검색 전략을 동일한 형식으로 데이터셋에 포함시켜 언어 모델을 훈련시킬 수 있습니다.

### 문제 설정
이 연구는 "Countdown" 게임을 사용하여 언어 모델이 어떻게 검색 전략을 학습하고 문제를 해결할 수 있는지를 보여줍니다. 이 게임은 높은 분기 계수와 조합 탐색 공간으로 인해 복잡한 검색 문제를 제시합니다.

### 부적합한 검색 전략에서 학습하기
실제와 부적합한 검색 경로에서 학습한 모델이 단순히 최적 경로만을 학습한 모델보다 더 나은 성능을 보임을 발견했습니다. 이는 모델이 검색 과정과 백트래킹 과정에서 유용한 정보를 얻을 수 있음을 시사합니다.

### 검색 개선 정책
모델이 올바른 정답을 찾아내고 더 효율적으로 검색 전략을 사용하도록 하는 두 가지 정책 개선 방법(STaR과 APA)을 탐구합니다. 이러한 방법은 모델이 기존에 해결하지 못했던 문제를 해결하고, 새로운 검색 전략을 발견하는 데 도움을 줍니다.

### 결론
이 연구는 언어 모델이 검색과 백트래킹을 통해 문제를 해결하는 방법을 배울 수 있음을 보여줍니다. 이는 언어 모델이 복잡한 문제 해결 과정에서 더 나은 성능을 발휘할 수 있도록 하는 중요한 단계입니다.

## Similar Papers
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](2305.10601.md)
- [Advancing LLM Reasoning Generalists with Preference Trees](2404.02078.md)
- [Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning](2407.18248.md)
- [Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](2403.09629.md)
- [BlenderAlchemy: Editing 3D Graphics with Vision-Language Models](2404.17672.md)
- [Transformers meet Neural Algorithmic Reasoners](2406.09308.md)
- [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](2305.18290.md)
- [Let's Think Dot by Dot: Hidden Computation in Transformer Language Models](2404.15758.md)
- [Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](2408.03314.md)
