# Large Language Monkeys: Scaling Inference Compute with Repeated Sampling
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.21787.pdf](https://arxiv.org/pdf/2407.21787.pdf)

### 요약

#### 1. 각 섹션의 주요 내용 요약

**1. 서론**
대형 언어 모델(LLM)은 최근 몇 년 동안 코딩, 수학, 기타 추론 작업에서의 성과가 크게 향상되었습니다. 이 논문에서는 여러 샘플을 생성하는 방식으로 추론 컴퓨팅의 축을 확장하여 성능을 향상시키는 방법을 탐구합니다.

**2. 본론**
- *반복 샘플링의 중요성*: 반복 샘플링을 통해 다양한 작업과 모델에서 큰 성능 향상을 이룰 수 있음을 입증했습니다. 예를 들어, SWE-벤치 라이트 데이터셋에서 DeepSeek-V2-Coder-Instruct 모델을 사용하여 250번의 시도로 문제 해결률을 56%로 높였습니다.
- *모델 간 일관성*: 반복 샘플링은 여러 모델 크기, 계열, 학습 후 수준에 걸쳐 일관된 커버리지 증가를 보였습니다. 작은 모델일수록 반복 샘플링 적용 시 커버리지 증가가 두드러졌습니다.
- *비용 효율성*: 반복 샘플링을 통해 성능을 강화하는 것이 더 큰 모델을 사용하는 것보다 비용 효율적일 수 있음을 입증했습니다. 여러 번 샘플링하는 것이 더 저렴하고 더 많은 문제를 해결할 수 있습니다.

**3. 결과와 논의**
반복 샘플링을 통해 다양한 모델과 작업에서 엄청난 성능 향상을 달성할 수 있으며, 이 방법이 더 약한 모델을 증폭시켜 더 강력한 모델의 단일 시도를 능가할 수 있음을 보였습니다. 특히 SWE-벤치 라이트 데이터셋에서 250번의 시도로 문제 해결률을 56%로 높여 단일 시도의 최신 기술을 능가할 수 있었습니다.

**4. 결론**
반복 샘플링을 통한 추론 컴퓨팅 확장이 다양한 작업과 모델에서 성능을 극대화할 수 있는 강력한 방법임을 확인했습니다. 특히 자동 검증 도구를 이용할 수 없는 작업에서 모델 기반 검증 방법을 개발하는 것이 중요합니다.

#### 2. 전체 요약

이 논문은 대형 언어 모델(LLM)의 추론 성능 향상을 위해 반복 샘플링을 이용하는 방법을 탐구합니다. 반복 샘플링은 여러 작업과 모델에서 커버리지를 크게 증가시키는 효과적인 방법임을 입증하였으며, 더 약한 모델을 여러 번 샘플링하면 더 강력한 모델의 단일 시도보다 나은 성과를 낼 수 있습니다. 특히, 소프트웨어 엔지니어링 벤치마크(SWE-벤치 라이트)와 같은 실제 문제들에서 250번의 시도로 56%의 문제를 해결함으로써 단일 시도의 최고 성능을 능가했습니다.

이 연구의 주요 기여는 반복 샘플링을 통해 추론 컴퓨팅 축을 확장함으로써 성능과 비용 효율성을 모두 극대화할 수 있는 방법을 제시했다는 점입니다. 이를 통해 각종 작업에서 AI 모델의 성능을 높이는 혁신적인 방법론을 제공하였습니다.

## Similar Papers
- [Small Language Models Need Strong Verifiers to Self-Correct Reasoning](2404.17140.md)
- [Why Has Predicting Downstream Capabilities of Frontier AI Models with Scale Remained Elusive?](2406.04391.md)
- [A Careful Examination of Large Language Model Performance on Grade School Arithmetic](2405.00332.md)
- [Iterative Reasoning Preference Optimization](2404.19733.md)
- [DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging](2407.01470.md)
- [Many-Shot In-Context Learning in Multimodal Foundation Models](2405.09798.md)
- [Self-Play Preference Optimization for Language Model Alignment](2405.00675.md)
- [Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](2408.03314.md)
- [ReFT: Representation Finetuning for Language Models](2404.03592.md)
