# MiraData: A Large-Scale Video Dataset with Long Durations and Structured Captions
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.06358.pdf](https://arxiv.org/pdf/2407.06358.pdf)

### 섹션 요약 및 분석

#### 1. Introduction
최근 인공지능(AI) 및 생성 콘텐츠(AIGC) 분야에서의 발전으로 영상 생성, 이미지 생성, 자연어 처리 등이 빠르게 진화하고 있습니다. 이 중에서도 Sora라는 텍스트에서 영상을 생성하는 모델이 주목받고 있습니다. Sora는 특히 고품질의 긴 영상과 강한 움직임, 3D 일관성, 실제 세계의 물리 규칙 준수 등에 탁월합니다. 그러나 기존의 공개된 영상 데이터셋은 주로 짧은 클립과 간략한 캡션으로 구성되어 있어 Sora와 같은 모델을 학습하는 데 충분하지 않습니다. 이를 해결하기 위해, 본 연구에서는 긴 영상과 상세한 캡션을 포함한 고품질 데이터셋인 MiraData를 제안합니다.

#### 2. Background
비디오 생성은 초기 GAN 기반 모델에서 시작하여 최근의 확산 모델 기반 방법으로 발전했습니다. 이러한 확산 모델은 생성된 비디오의 시각적 품질과 다양성 면에서 상당한 진전을 이루었지만, 높은 계산 비용이 따릅니다. 기존의 방법들은 주로 짧은 길이의 비디오 생성에 중점을 두었지만, Sora의 성공은 긴 비디오 생성의 잠재력을 보여주었습니다. 하지만, 기존 데이터셋의 짧은 길이와 약한 움직임 강도, 부정확한 캡션 등의 한계가 있습니다.

#### 3. MiraData Dataset
MiraData는 긴 지속시간과 구조화된 상세 캡션을 특징으로 하는 대규모 텍스트-비디오 데이터셋입니다. 데이터 수집, 비디오 분할 및 병합, 선택, 캡션 작성의 5단계 과정을 통해 데이터셋을 구성했습니다. 다양한 비디오 콘텐츠를 포함하며, 시각적 품질과 움직임 강도가 높은 비디오를 선별하여 데이터셋에 포함했습니다. 캡션은 GPT-4V를 사용해 생성한 후, 상세한 구조화된 설명을 추가해 정확성을 높였습니다.

#### 4. MiraBench Benchmark
MiraBench는 긴 비디오 생성 모델의 평가를 위한 벤치마크로, 150개의 평가 프롬프트와 17개의 메트릭을 포함합니다. 이 벤치마크는 시간적 일관성, 움직임 강도, 3D 일관성, 시각적 품질, 텍스트-비디오 정렬 및 분포 유사성을 평가합니다.

#### 5. MiraDiT Model
MiraData의 효율성을 검증하기 위해, Diffusion Transformer 기반의 MiraDiT 모델을 설계했습니다. 이 모델은 공간적-시간적 자기 주의 메커니즘과 FPS 조건 기반의 모듈화를 통해 긴 비디오 생성 중 계산 부담을 줄였습니다. 또한, 다양한 해상도와 길이의 비디오 생성을 지원하여 다양한 시나리오에서의 성능을 평가할 수 있도록 했습니다.

#### 6. Experimental Results
MiraDiT 모델을 MiraData와 기존 데이터셋(WebVid-10M)으로 각각 학습시켜 MiraBench에서 평가했습니다. 실험 결과, MiraData는 특히 움직임 강도 면에서 기존 데이터셋보다 우수한 성능을 보였습니다. 이는 긴 영상을 생성하는 데 매우 효과적임을 나타냅니다.

#### 7. 결론 및 논의
본 연구에서는 긴 비디오 생성을 위한 고품질 데이터셋 MiraData와 이를 평가하기 위한 벤치마크 MiraBench를 제안했습니다. 이를 통해 기존의 한계를 극복하고 보다 현실적이고 일관성 있는 긴 영상을 생성할 수 있는 가능성을 검증했습니다.

---

### 전체 요약
본 논문은 긴 비디오 생성을 위한 고품질 데이터셋인 MiraData와 이를 평가하는 벤치마크 MiraBench를 소개합니다. Sora와 같은 고품질의 긴 비디오를 생성하는 모델을 학습하기 위해 필요한 데이터셋의 한계를 극복하고자, 긴 지속시간과 강한 움직임, 상세한 캡션을 가진 비디오를 수집하고 구조화하였습니다. MiraData의 효과성을 입증하기 위해 Diffusion Transformer 기반의 MiraDiT 모델을 설계하였으며, 실험 결과 긴 비디오 생성에서 뛰어난 성과를 보였습니다. 이 연구는 AI 기반 비디오 생성의 발전에 크게 기여할 것으로 기대됩니다.

## Similar Papers
- [FreeLong: Training-Free Long Video Generation with SpectralBlend Temporal Attention](2407.19918.md)
- [Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots](2405.07990.md)
- [OpenVid-1M: A Large-Scale High-Quality Dataset for Text-to-video Generation](2407.02371.md)
- [SF-V: Single Forward Video Generation Model](2406.04324.md)
- [MovieDreamer: Hierarchical Generation for Coherent Long Visual Sequence](2407.16655.md)
- [What Matters in Detecting AI-Generated Videos like Sora?](2406.19568.md)
- [Cinemo: Consistent and Controllable Image Animation with Motion Diffusion Models](2407.15642.md)
- [Image Conductor: Precision Control for Interactive Video Synthesis](2406.15339.md)
- [ExVideo: Extending Video Diffusion Models via Parameter-Efficient Post-Tuning](2406.14130.md)
