# REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.04759.pdf](https://arxiv.org/pdf/2412.04759.pdf)

죄송합니다. 다음의 주요 내용을 요약하였습니다.

1. **서론 및 배경**:
   논문은 디지털 및 현실 세계의 AI 에이전트가 새로운 환경에 신속하게 적응해야 하는 문제를 다룹니다. 현재의 에이전트 구조를 확장하는 것이 정말 효과적인 방법인지 의문을 제기하고, 간단한 'Retrieving and Playing (R&P)'라는 방법, 즉 주변 환경에서 가장 가까운 상태를 가져와 그에 맞는 행동을 수행하는 접근법을 검토합니다.

2. **REGENT의 소개**:
   'Retrieval-Augmented Agent' (REGENT)은 R&P의 강점에 기초해 설계되었습니다. 이 에이전트는 변환기(트랜스포머) 기반의 정책을 사전 훈련하고, 이 정책은 현재 상태뿐만 아니라 이전 보상, 행동 및 다양한 시연으로부터 획득한 데이터를 사용하여 특정된 행동을 제시합니다.

3. **실험적 평가**:
   REGENT는 고유한 환경에서 R&P보다 향상된 성능을 보여주며, 특히 보고된 모든 데이터와 비교했을 때 3배 적은 파라미터로 비슷하거나 더 나은 성능을 발휘하였습니다.

4. **결론 및 미래 작업**:
   REGENT는 미리 훈련된 환경과 상호작용 없이 제시된 몇 가지 사례로 직접 미지의 환경에 배치될 수 있는 기능을 가지고 있으며, 특히 주어진 데이터가 적은 상태에서의 적응력을 향상하는 데 주목할 만합니다.

**전반 요약**:
논문에서 제안된 REGENT 모델은 새로운 환경에 신속하게 적응하기 위해 검색 및 학습을 활용하여 훈련된 소형 트랜스포머 기반 정책을 이용한다는 것입니다. 새로운 환경에서의 데이터 효율적인 적응 능력을 보여주며, 다른 모델보다 적은 자원으로도 효과적인 성능을 발휘할 수 있다는 점에서 주목할 만합니다. REGENT는 특히 기존의 대규모 데이터와 높은 파라미터 수를 줄이고, 보다 빠른 적응을 추구하는 혁신적인 접근 방식을 제공합니다.