# Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.05719.pdf](https://arxiv.org/pdf/2404.05719.pdf)

이 논문은 모바일 사용자 인터페이스(UI) 화면을 이해하기 위해 특별히 설계된 새로운 다중 모달 큰 언어 모델(Multimodal Large Language Model, MLLM)인 Ferret-UI에 관한 것입니다. 기존의 일반 도메인 MLLM이 사용자 인터페이스 화면을 이해하고 상호 작용하는 데 한계가 있음을 지적하며, Ferret-UI는 이를 해결하기 위해 개발되었습니다. 특히, UI 화면은 일반적으로 더 긴 종횡비를 가지고 있고, 자연 이미지보다 더 작은 관심 객체(예: 아이콘, 텍스트)를 포함하는 경향이 있기 때문에, 이러한 특성을 고려하여 Ferret-UI는 세밀한 부분까지 확대하고 강화된 시각적 특성을 활용할 수 있도록 설계되었습니다.

### 주요 기여
- **모델 아키텍처 개선**: Ferret-UI는 기존 Ferret 모델을 기반으로 하여 UI 화면의 다양한 종횡비에 유연하게 적응할 수 있도록 'any resolution' 기능을 통합하였습니다. 이는 화면을 하위 이미지로 나누고 각각을 따로 인코딩하여 세부 사항을 확대하는 데 도움이 됩니다.
- **데이터 큐레이션**: 기본 UI 작업(아이콘 인식, 텍스트 찾기 등)부터 고급 작업(상세 설명, 기능 추론 등)에 이르기까지 다양한 세분화된 작업에 대한 훈련 샘플을 수집하여 모델의 추론 능력을 향상시킵니다.
- **벤치마크 설정**: 모델 평가를 위해 관련 작업을 모두 포함하는 포괄적인 벤치마크를 구축했습니다. Ferret-UI는 기초 UI 작업뿐만 아니라 GPT-4V를 모두 능가하는 성능을 보여줍니다.

### 혁신적인 부분
Ferret-UI의 가장 혁신적인 부분은 사용자 인터페이스 화면의 이해, 참조 및 추론 작업을 수행할 수 있는 최초의 UI 중심 MLLM이라는 점입니다. 'any resolution' 기능을 통해 화면의 다양한 종횡비와 더 작은 객체들을 더 잘 처리할 수 있으며, 이는 UI 화면 이해에 필수적인 세밀한 시각적 특성을 포착하는 데 도움이 됩니다.

### 전체 요약
Ferret-UI는 모바일 사용자 인터페이스 화면을 더 잘 이해하고 상호 작용할 수 있도록 설계된 새로운 다중 모달 큰 언어 모델입니다. 이 모델은 기존 모델들이 가진 한계를 극복하기 위해 'any resolution' 기능을 도입하여 화면의 세밀한 부분까지 확대할 수 있게 하고, 다양한 UI 작업에 대한 훈련을 통해 모델의 추론 능력을 강화했습니다. Ferret-UI는 벤치마크 테스트에서 우수한 성능을 보여주며, UI 화면 이해와 상호 작용을 위한 새로운 방법을 제시합니다.