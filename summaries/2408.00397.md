# In-Context Example Selection via Similarity Search Improves Low-Resource Machine Translation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.00397.pdf](https://arxiv.org/pdf/2408.00397.pdf)

### 1. 중요한 내용 요약 (섹션별)

#### 1. 소개 (Introduction)
이 논문은 대형 언어 모델(LLMs)을 사용하여 저자원 언어 기계 번역(MT) 성능을 개선하는 방법을 연구합니다. 특히, 현재의 연구들이 번역 예시를 무작위로 선택했지만, 이 논문에서는 문장 임베딩을 기반으로 유사한 예를 선택하는 것이 저자원 언어 번역 성능을 어떻게 향상시킨다는 점을 강조합니다.

#### 2. 배경 및 관련 연구 (Background and Related Work)
여기서는 In-Context Learning (ICL)의 중요성과 지난 연구들이 LLM 기반 기계 번역에 어떤 영향을 미쳤는지 설명합니다. 특히, 이전 연구들은 고자원 언어에 대해 많은 연구를 진행했지만, 저자원 언어에 대해서는 충분히 다루지 않았다는 점을 지적합니다.

#### 3. 실험 (Experiments)
유사성 검색을 통한 예시 선택 방법을 다양하게 실험합니다. 예를 들어, 영어에서 프랑스어, 독일어, 스와힐리어, 월로프어로 번역할 때 각각의 성능을 비교합니다. 결과적으로 유사성 검색을 통한 예시 선택이 동일 품질의 무작위 선택보다 저자원 언어 번역에 더 큰 향상을 가져온다는 결론을 도출합니다.

#### 4. 결론 (Conclusion)
논문은 문장 임베딩 기반의 유사성 검색을 이용한 예시 선택이 저자원 언어 번역에서 특히 유용하다는 것을 증명합니다. 또한, 기계 번역 평가에 있어서 기존의 평가 방법이 LLM 기반 시스템에 적합하지 않을 수 있음을 지적하고, 새로운 평가 기준인 laCOMET을 제안합니다.

### 2. 전체 요약

이 논문은 대형 언어 모델(LLMs)을 사용하여 저자원 언어 기계 번역(MT) 성능을 향상시키기 위한 새로운 방법을 제시합니다. 기존의 연구들이 번역 예시를 무작위로 선택한 반면, 이 논문은 문장 임베딩을 기반으로 유사한 예시를 선택하는 방법이 저자원 언어 번역 성능을 크게 향상시킨다는 점을 증명합니다. 이를 위해 다양한 언어에 대해 다수의 실험을 수행했으며, 고자원 언어와 저자원 언어 번역 성능의 차이를 체계적으로 분석했습니다. 그 결과, 저자원 언어에서는 유사성 검색을 통한 예시 선택이 더 효과적이라는 것을 발견했습니다. 또한, 평가 방법인 COMET의 한계를 지적하며, 언어 인식 능력을 강화한 laCOMET을 제안했습니다. 이 연구는 저자원 언어 번역에 있어 큰 기여를 하였으며, 향후 연구와 실제 적용에 중요한 시사점을 제공합니다.

## Similar Papers
- [mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus](2406.08707.md)
- [Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment](2404.12318.md)
- [SambaLingo: Teaching Large Language Models New Languages](2404.05829.md)
- [Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection](2407.11854.md)
- [LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages](2407.05975.md)
- [T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings](2406.19223.md)
- [A Survey on Retrieval-Augmented Text Generation for Large Language Models](2404.10981.md)
- [Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](2408.03314.md)
- [LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](2403.12968.md)
