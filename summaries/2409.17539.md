# Logic-of-Thought: Injecting Logic into Contexts for Full Reasoning in Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.17539.pdf](https://arxiv.org/pdf/2409.17539.pdf)

1. 각 섹션 요약

**서론**
최근 대형 언어 모델(LLM)은 다양한 자연어 처리(NLP) 작업에서 우수한 성능을 보였습니다. 하지만 수학 및 복잡한 논리 추론 작업에서는 한계가 명확합니다. 이를 개선하기 위해 체인 오브 쏘트(CoT)와 같은 프롬프트 방법이 개발되었고 논리적 추론 능력을 향상시키려는 노력이 진행되고 있습니다.

**기초 연구**
논리 추론 작업을 중심으로 논리 명제를 정의하고 있으며, 이러한 명제는 참, 거짓의 명확한 진릿값을 가진 선언문으로 설명됩니다. 또한 주요 논리 기호 및 연결자에 대한 정의도 명시되었습니다.

**방법론**
이 연구는 논리적 사고(LoT)를 도입하여 정보를 확장시키고 이를 기존 프롬프트에 추가하여 LLM의 논리적 추론 능력을 높이는 방법을 제시합니다. 이 방법은 기존의 체인 오브 쏘트(CoT)와 같은 프롬프트 기술에 쉽게 통합될 수 있습니다.

**실험**
LoT는 여러 데이터셋을 대상으로 다양한 프롬프트 기법과 결합하여 실험되었습니다. 실험 결과, LoT를 사용한 프롬프트는 대다수 경우에서 기존 방법보다 우수한 성능을 보였습니다.

**LoT와 SatLM의 비교 연구**
LoT는 SatLM보다 정확도가 높으며, 부정확한 논리 정보 추출로 인해 생기는 정보 손실 문제를 방지합니다. 이는 SatLM이 정보를 잘못 인식하여 오류가 발생될 수 있음을 보여줍니다.

**LoT와 ToT의 심층 분석**
LoT와 ToT의 결합은 탐구 범위를 넓히고 더 많은 성공적인 상태를 탐색함으로써 ToT의 효율성을 높이는 것으로 나타났습니다.

**결론**
LoT는 기존의 신경 기호적 방법에서 발생하는 정보 손실 문제를 해결하고, 다양한 프롬프트 방법의 성능을 크게 개선할 수 있음을 보여줍니다. 이는 기존 방식과 쉽게 통합되어 LLM의 논리적 추론 능력을 획기적으로 증강시킬 잠재력이 있습니다.

2. 종합 요약

이 논문은 Logic-of-Thought (LoT)라는 새로운 프롬프트 방법을 통해 대형 언어 모델(LLM)의 논리적 추론 능력을 증강시키는 방법을 제시합니다. 기존의 논리적 정보 손실 문제를 극복하고, LoT는 체인 오브 쏘트(CoT)와 같은 방법들에 쉽게 통합되어 다섯 개의 논리적 추론 과제에 대한 성능을 크게 개선합니다. 이러한 연구는 LLM이 논리적 표현 및 관계를 더 정확히 추출하고 사용하게 하며, 다양한 프롬프트 방법에 LoT를 결합함으로써 두드러진 성능 강화를 보여줍니다.