# AntiLeak-Bench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.13670.pdf](https://arxiv.org/pdf/2412.13670.pdf)

1. 논문 요약:

- **서론**: 이 논문은 대규모 언어 모델(LLMs)의 평가에서 데이터 오염 문제를 해결하기 위해 AntiLeak-Bench라는 프레임워크를 제안합니다. 기존의 방법은 새롭게 수집된 데이터를 통해 벤치마크를 업데이트하지만, 이 방법은 데이터 오염의 위험성을 완벽히 제거하지 못합니다. AntiLeak-Bench는 LLM의 학습 세트에 포함되지 않은 새 지식을 이용하여 오염이 없는 샘플을 자동으로 생성하는 워크플로우를 제공합니다.

- **본론**: AntiLeak-Bench의 주요 기여는 자동화된 시스템으로 벤치마크를 업데이트하여 인력 비용을 줄이면서 오염 없이 정확한 평가를 할 수 있다는 점입니다. 이 시스템은 다양한 다국어 샘플을 지원하고, 실제 데이터 소스를 기반으로 테스트 샘플을 생성합니다. 실험 결과, AntiLeak-Bench는 전통적인 샘플보다 더 도전적이며, 모델의 진정한 이해 및 추론 능력을 요구한다고 밝혔습니다.

- **결론**: AntiLeak-Bench는 데이터 오염을 방지하고 자원 소모를 줄이는 혁신적인 방법으로, 최신의 대규모 언어 모델에 대해 공정하고 정확한 평가가 가능하게 합니다. 이러한 방법은 데이터 오염을 방지하여 모델의 실제 능력을 평가하고 향후 LLMs의 발전에 중요한 시험대가 될 것임을 강조하고 있습니다.

2. 전체 요약:

이 논문은 대규모 언어 모델 평가의 신뢰성을 떨어뜨리는 데이터 오염 문제를 해결하기 위해 AntiLeak-Bench라는 자동 벤치마크 시스템을 제안합니다. 이 시스템은 LLM의 학습 세트에 없는 새로운 지식을 이용해 오염 없는 샘플을 자동으로 생성하고 업데이트하는 완전한 워크플로우를 제공하여 인력 비용을 크게 줄입니다. 실험적으로, AntiLeak-Bench는 기존에 사용되던 방법들 보다 더욱 공정하고 정확한 모델 평가가 가능하다는 점을 입증하였으며, 특히 다국어 평가와 실제 데이터에 기반한 테스트로 LLM의 진정한 능력을 평가함을 보였습니다. 이 시스템은 LLM을 평가하는 새로운 기준을 제시하며 향후 발전에 중요한 역할을 할 것으로 예상됩니다.