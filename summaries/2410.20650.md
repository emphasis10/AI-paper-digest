# NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.20650.pdf](https://arxiv.org/pdf/2410.20650.pdf)

### 각 섹션 요약 및 전체 요약

1. **논문의 주요 기여 및 혁신적인 부분 요약**

- **소개 (Introduction)**: 이 논문은 심층 신경망을 위한 새로운 메모리 효율적인 훈련 및 추론 방법인 NeuZip을 소개합니다. NeuZip은 부동 소수점 수의 엔트로피에 기반한 압축 기법으로, 성능을 유지하면서도 모델 크기를 줄임으로써 메모리 사용을 크게 감소시킵니다.

- **방법론 (Our Approach)**: 저자들은 부동 소수점의 지수 부분을 효율적으로 압축하여 메모리 사용을 줄이는 NeuZip 방식을 제안합니다. 특히 Asymmetric Numeral Systems(ANS)를 활용하여 효율적인 압축을 수행하며, 손실 없이 모든 매개변수를 훈련할 수 있도록 합니다.

- **손실 없는 NeuZip: 훈련을 위한 지수 압축(Lossless NeuZip: Compressing Exponents for Training)**: NeuZip은 신경망의 지수 비트를 손실 없이 압축하여 부동 소수점의 주요 정보 손실 없이 메모리 효율성을 높였습니다. 이것은 모델을 완전히 압축하지 않고도 메모리를 절약하도록 합니다.

- **손실 NeuZip: 멘티사를 줄인 추론(Lossy NeuZip: Additionally Truncating Mantissa for Inference)**: 추론 단계에서는, 멘티사의 상위 중요 비트만 저장하여 메모리 풋프린트를 더욱 줄이는 손실 변형을 제안합니다. 이는 메모리와 성능 간의 최적 절충을 보여줍니다.

- **실험 (Experiments)**: 여러 모델과 작업에서 NeuZip이 메모리 사용을 크게 줄이면서도 성능을 거의 유지함을 보여주는 실험이 수행되었습니다. 특히, Llama-3 8B 모델의 훈련 시 메모리 사용을 31GB에서 16GB 미만으로 줄임으로서 NeuZip의 효과를 입증했습니다.

---
2. **전체 요약**

이 논문은 NeuZip을 통해 신경망의 엔트로피 기반 압축을 이용한 메모리 효율적인 모델 훈련 및 추론 방법을 제시합니다. 주요 기여는 부동 소수점 수의 지수 비트를 허용 가능한 수준에서 압축하여 메모리 사용을 절감하여, 대형 모델의 훈련 및 추론에서의 메모리 병목현상을 극복하는 것입니다. 이를 통해, NeuZip은 성능 유지와 메모리 효율성 간의 최적의 균형을 유지하고, 특히 실용적인 대규모 인공지능 응용을 가능하게 합니다.