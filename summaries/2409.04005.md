# Qihoo-T2X: An Efficiency-Focused Diffusion Transformer via Proxy Tokens for Text-to-Any-Task
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.04005.pdf](https://arxiv.org/pdf/2409.04005.pdf)

### 1. 각 섹션 요약

#### Abstract (초록)
이 논문에서는 시각 정보의 희소성과 중복성 문제를 해결하기 위해 대리 토큰 주의 메커니즘을 활용한 효율적인 Diffusion Transformer 모델(PT-DiT)을 제안합니다. PT-DiT는 공간적 및 시간적 우선순위에 따라 대리 토큰을 무작위로 샘플링하고, 이들 간의 글로벌 상호작용을 통해 효율성을 극대화합니다. 또한, 윈도우 주의와 이동 윈도우 주의를 도입해 현지 세부사항의 모델링을 정교화합니다.

#### Introduction (소개)
최근 주요 Diffusion 모델들(Sora, Stable Diffusion 3 등)의 발전에도 불구하고, 기존의 전역 자가 주의 메커니즘은 시퀀스 길이에 따른 이차 계산 복잡성을 가지고 있어 실용적인 한계를 가지고 있습니다. 이 논문에서는 이러한 문제를 해결하기 위해 대리 토큰 주의를 사용하는 PT-DiT 모델을 제안하며, 이를 텍스트-이미지, 텍스트-비디오 및 텍스트-멀티뷰 생성에 적용합니다.

#### Literature Review (관련 연구)
기존 연구들은 Vision Transformer(ViT)와 U-Net 기반의 Diffusion Transformer 모델들이 뛰어난 이미지 생성 성능을 보였음을 입증하였으나, 높은 계산 복잡성 문제는 여전히 해결해야 할 과제로 남아 있습니다. PT-DiT는 이러한 문제를 해결하기 위해 프록시 토큰 주의 메커니즘을 사용합니다.

#### Methodology (방법론)
**Redundancy Analysis (중복성 분석)**:
기존의 자기 주의 메커니즘은 같은 윈도우 내의 토큰들 간 유사한 주의 맵을 가지며, 이는 계산 중복성을 야기합니다. PT-DiT는 이를 줄이기 위해 윈도우 내에서 샘플링된 대리 토큰만을 사용하여 자기 주의를 수행합니다.

**Architecture of PT-DiT (모델 구조)**:
PT-DiT는 대리 토큰을 활용하여 전역 자가 주의를 대체, 효율적으로 전역 시각 정보를 상호작용시키고, 윈도우 주의와 이동 윈도우 주의를 통해 현지 세부사항을 모델링합니다.

**Global Information Interaction Module (전역 정보 상호작용 모듈)**:
이 모듈은 대리 토큰을 통해 전역 정보를 효율적으로 상호작용시킵니다. 대리 토큰은 각 윈도우에서 무작위로 샘플링되며, 자기 주의와 교차 주의를 통해 현지 토큰에 글로벌 정보를 전파합니다.

**Texture Complement Module (텍스처 보완 모듈)**:
이 모듈은 윈도우 주의와 이동 윈도우 주의를 도입하여 현지의 세부 텍스처를 개선합니다. 이 과정에서 발생하는 계산 복잡성은 최소화됩니다.

#### Results (결과)
실험 결과, PT-DiT는 탁월한 성능을 발휘하며 계산 복잡성을 크게 줄였습니다. 이미지 생성에서 PT-DiT의 계산 복잡성은 동일한 파라미터 크기 기준으로 DiT의 52%, Pixart-α의 65%에 불과합니다. 비디오 생성에서도 CogVideoX 대비 77.2%, EasyAnimate 대비 85%의 복잡성만을 요구하여 뛰어난 효율성을 증명했습니다.

#### Conclusion (결론)
이 논문은 시각 정보의 희소성과 중복성을 해결하기 위해 대리 토큰 주의 메커니즘을 활용한 PT-DiT를 제안합니다. PT-DiT는 비디오와 이미지 생성 작업에서 높은 성능과 효율성을 보여줍니다. 이는 Diffusion Transformer 분야에 새로운 통찰을 제공할 것입니다.

### 2. 전체 요약

이 논문은 시각 정보의 희소성과 중복성 문제를 해결하기 위해 대리 토큰 주의 메커니즘을 도입한 Diffusion Transformer 모델(PT-DiT)을 제안합니다. PT-DiT는 무작위로 샘플링된 대리 토큰을 사용하여 계산 복잡성을 줄이고, 윈도우 주의와 이동 윈도우 주의를 추가해 현지 세부사항을 정교하게 모델링합니다. 실험 결과, PT-DiT는 이미지 및 비디오 생성 작업에서 기존 모델 대비 높은 효율성과 성능을 보여주었으며, 이는 Diffusion Transformer 모델의 새로운 방향성을 제시하는 중요한 기여를 합니다.