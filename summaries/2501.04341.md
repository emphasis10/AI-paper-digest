# Understanding Before Reasoning: Enhancing Chain-of-Thought with Iterative Summarization Pre-Prompting
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.04341.pdf](https://arxiv.org/pdf/2501.04341.pdf)

### 답변 1: 각 섹션 요약

1. **서론**
   - 논문은 대형 언어 모델(LLM)의 체인 오브 씽크(Chain of Thought, CoT) 방법을 활용하여 문제 해결 능력을 개선하는 것을 목표로 합니다. 주된 문제점은 CoT가 정보 수집과 추출에 대한 적절한 지원을 제공하지 못한다는 점입니다. 이를 해결하기 위해 반복 요약 프롬프트 기법(ISP2)을 제안합니다.

2. **관련 연구**
   - 기존 연구는 CoT 프롬프트 방법의 중요성을 강조하며, 이는 복잡한 문제를 해결하기 위한 논리적 사고 경로를 제공하는 역할을 합니다. 하지만 기존 방법은 아직 상위 정보 추출 하기에 미흡한 점이 있습니다.

3. **제안된 접근 방식**
   - ISP2 방법은 문제가 되는 정보를 반복적으로 요약하여 문제 해결 기반 정보를 내놓으려는 것입니다. 이 방법은 후보 정보의 적응적 추출, 정보 쌍의 신뢰도 평가, 지식 이해를 위한 반복적 요약을 포함합니다.

4. **실험 및 결과**
   - GPT 3.5 터보 및 LLaMA2와 같은 모델을 통해 실험하여 주요 데이터셋에서 7.1%에서 12.4%까지 성능이 개선되었음을 입증했습니다. 이는 ISP2가 문제를 이해하고 해결하는 효과적인 도구임을 나타냅니다.

5. **결론**
   - ISP2는 LLM의 사전 정보를 기반으로 한 이해 과정을 통해 더 깊은 문제 이해를 제공합니다. 이는 CoT 방법과 슈퍼프롬프트 방법(Self Consistency)의 합성으로 문제 해결 능력을 극대화합니다. 또한 다양한 데이터셋에서의 성능 향상을 지지하여 NLP 연구에 기여하고자 합니다.

### 답변 2: 전체 요약
이 논문은 대형 언어 모델의 논리적 추론 능력을 진보시키기 위해 반복 요약 프롬프트 기법(ISP2)을 제시합니다. CoT 방법론의 한계를 넘어서기 위해 개발된 이 접근 방식은 사전 프롬프트를 통해 문제 정보를 보다 체계적이고 철저히 요약하여, LLM이 보다 정확하고 일관된 결론에 도달할 수 있도록 합니다. 특히, 다양한 복잡한 문제를 해결하는 데 있어 ISP2는 체계적인 정보 추출과 신뢰도 평가를 통해 맞춤형 해결 방법을 제시하며 성능을 크게 향상시키는 것으로 나타났습니다.