# You See it, You Got it: Learning 3D Creation on Pose-Free Videos at Scale
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.06699.pdf](https://arxiv.org/pdf/2412.06699.pdf)

기존의 3D 생성 모델은 일반적으로 제한된 스케일의 3D '골드 라벨'이나 2D 확산 기본값에 의존하여 3D 콘텐츠 생성합니다. 그러나 이러한 접근 방식은 확장 가능한 학습 패러다임의 부재로 인해 성능이 제한됩니다. 본 연구에서는 대규모 인터넷 비디오를 학습한 비주얼 조건 다중 뷰 확산 모델인 See3D를 제안합니다. 이 모델은 대량의 비디오 데이터로부터 시각적 콘텐츠만 보고 3D 지식을 얻는 것을 목표로 합니다. 이를 위해, 데이터 커레이션 파이프라인을 개발하여 소스 비디오에서 다중 뷰 불일치 및 불충분한 관측치를 자동으로 필터링하며, 이것은 고품질의 다양하고 대규모의 다중 뷰 이미지 데이터세트를 형성합니다.

이 모델의 주된 기여 사항은 비디오 데이터의 이점을 활용하여 비용 및 포즈에 의존하지 않고도 3D 생성의 정확성과 확장성을 높였다는 점입니다. 이는 카메라 포즈 주석이 필요 없는 비주얼 조건을 도입하여, 모델이 다중 뷰 관찰의 일관성을 유지하는 동시에 일반적인 3D 사전 지식을 학습하게 합니다.

실험 결과는 다양한 단일 및 드문 뷰 재구성 벤치마크에서 See3D가 제안된 비주얼 조건을 토대로 하여 정밀한 3D 생성이 가능함을 보여주었습니다. 특히 3D 편집과 같은 이미지 조건 3D 생성 작업을 추가 조정 없이 수행할 수 있는 뛰어난 능력을 나타냈습니다.

결과적으로, 본 연구는 대규모 데이터세트를 통해 3D 생성의 상한을 넘어서기 위한 새로운 방향을 제시합니다. 이를 통해 강력한 폐쇄형 소스 3D 솔루션과의 파리티를 추구함으로써 3D 연구 커뮤니티의 관심을 대규모 포즈 없는 데이터로 끌어 모으고자 합니다.