# Activation Approximations Can Incur Safety Vulnerabilities Even in Aligned LLMs: Comprehensive Analysis and Defense
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.00840.pdf](https://arxiv.org/pdf/2502.00840.pdf)

1. **각 섹션의 주요 내용 요약**

   - **서론(Introduction)**:
     이 논문은 대형 언어 모델(LLM)의 활성화 근사화 기법이 모델의 안전성에 미치는 영향을 체계적으로 조사한다. LLM은 다양한 분야에서 놀라운 능력을 보였지만, 자원 제한 환경에서의 효율성을 위해 활성화 근사화가 필요하다. 이 논문은 이러한 근사화의 안전성 문제를 다룬 최초의 연구로, 여러 최신 기술과 그에 따른 안전성 구조를 평가한다.

   - **배경(Background)**:
     활성화 근사화 기법으로는 활성화 다항식화, 희소화, 양자화가 있다. 이 섹션에서는 각 기법의 기능과 안전성에 미치는 영향을 간략히 설명한다.

   - **안전성 평가(Safety Assessment)**:
     저자들은 여러 활성화 근사화 기법의 안전성을 평가하고, 그 결과를 바탕으로 안전성이 타격을 받는 주요 관찰사항을 제시한다. 특히, 첫 번째 레이어에서의 근사화가 가장 위험하다는 점을 강조한다.

   - **안전성 향상(Safety Enhancement)**:
     QuadA라는 새로운 안전성 강화 방법을 제안하여, 활성화 근사화가 이루어진 모델의 안전성을 회복할 수 있는 방안을 소개한다. QuadA는 최소한의 코드 변경으로 통합할 수 있는 방식으로 설계되었다.

   - **결론(Conclusion)**:
     이 연구는 활성화 근사화로 인해 생길 수 있는 안전성 저하의 심각성을 강조하고, 이를 방지하기 위한 QuadA 방법론의 필요성을 전달한다. 연구자들은 이 결과들이 LLM의 안전성을 높이는 데 기여하기를 바란다.

2. **전체 요약**:
   
   이 논문은 대형 언어 모델에서 활성화 근사화 기법이 안전성에 미치는 영향을 깊이 있게 분석하고, 이로 인해 발생하는 안전성 저하를 평가하고 해결 방법을 제안한다. 연구 결과에 따르면, 활성화 근사화는 모델의 안전성을 심각하게 저하시키며, 특히 초기 레이어에서 더 큰 영향을 끼친다. 이를 해결하기 위해 QuadA라는 새로운 안전성 강화 방법이 제안되었으며, 이는 LLM 개발자들이 기존 안전성 절차에 쉽게 통합할 수 있도록 설계되었다. 연구는 이 분야의 안전성 문제에 대한 인식을 높이고, 실질적인 배포 시 안전성을 강화하는 연구를 자극할 것으로 기대된다.