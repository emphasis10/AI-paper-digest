# Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.00205.pdf](https://arxiv.org/pdf/2408.00205.pdf)

### 1. 섹션별 요약 및 주 내용

#### 1.1. 서론 (Introduction)

**요약**
자동 음성 인식(ASR)은 많은 발전을 이루었지만, 사람이 이해하기에는 어려운 구어체 표현들이 많습니다. 이 문제를 해결하기 위해 문장 단위 음성 요약(Sen-SSum)을 제안합니다. Sen-SSum은 실시간 처리와 간결함을 결합하여 음성 문서의 문장별 요약을 제공합니다.

**주요 기여 및 혁신**
- **문장 단위 음성 요약 (Sen-SSum)** 개념 도입: ASR과 기존 음성 요약의 단점을 보완하여 실시간으로 간결한 요약 제공
- **두 가지 접근 방식 제안**: ASR과 텍스트 요약을 결합한 Cascade 모델과 하나의 모델로 요약을 생성하는 E2E 모델

#### 1.2. 관련 연구 (Related Work)

**요약**
텍스트 문장 요약은 많이 연구되었으나, 음성을 다룬 연구는 부족합니다. 본 연구는 Sen-SSum과 관련된 최초의 대규모 데이터셋을 소개하며 두 가지 접근 방식을 비교합니다.

**주요 기여 및 혁신**
- Sen-SSum 관련 연구 정리
- Mega-SSum과 CSJ-SSum 데이터셋 소개

#### 1.3. 데이터셋 (Datasets)

**요약**
Mega-SSum은 Gigaword 데이터셋에서 파생된 영어 데이터셋으로, 380만 개의 음성-문자-요약 삼중 데이터를 포함합니다. CSJ-SSum은 일본어 기반의 데이터셋으로 3만 8천 개의 실제 음성 데이터를 포함합니다.

**주요 기여**
- **대규모 데이터셋 제공**: 실제와 합성 음성을 포함한 다양한 트레이닝 데이터

#### 1.4. 방법론 (Method)

**요약**
학습 데이터 부족 문제를 해결하기 위해 Cascade 모델을 사용하여 의사 요약(pseudo-summaries)을 생성하고 이를 통해 E2E 모델을 훈련합니다. 또한 WavLM 등의 자가 지도 학습 모델을 활용하여 성능을 향상합니다.

**주요 기여 및 혁신**
- **지식 증류 (Knowledge Distillation)** 사용: Cascade 모델로부터 생성된 의사 요약을 통해 E2E 모델 성능 향상
- **자가 지도 학습 모델 통합**: WavLM을 활용하여 저자원 환경에서도 높은 성능 확보

#### 1.5. 실험 (Experiment)

**요약**
다양한 실험을 통해 Cascade 모델과 E2E 모델의 성능을 비교하고, 의사 요약과 실제 요약의 효과를 분석합니다. Mega-SSum과 CSJ-SSum 데이터셋을 활용하여 실험을 진행합니다.

**주요 결과**
- **Cascade 모델**이 E2E 모델보다 일반적으로 뛰어난 성능을 보임
- **의사 요약**을 활용한 E2E 모델이 일부 조건에서 더 나은 성능을 보임

#### 1.6. 결론 (Conclusion)

**요약**
이번 연구에서는 Sen-SSum, Mega-SSum, CSJ-SSum 데이터셋을 소개하고, Cascade 및 E2E 모델들의 성능을 지식 증류를 통해 향상시킬 수 있음을 보였습니다. 향후 연구에서는 더 효율적인 요약 방법과 문맥을 고려한 모델을 개발할 필요가 있습니다.

**주요 기여 및 혁신**
- **실시간 요약의 가능성 확인**: Sen-SSum을 통해 실시간 의사소통 상황에서도 유용한 요약 제공 가능성 입증
- **향후 연구 방향 제시**: 더 나은 지식 증류 방법 및 문맥을 고려한 요약 모델 개발 필요성 강조

### 2. 전체 요약

이번 논문은 **문장 단위 음성 요약 (Sentence-wise Speech Summarization, Sen-SSum)** 개념을 도입하고 이를 실현하기 위한 두 가지 모델, **Cascade 모델**과 **E2E 모델**을 제안합니다. 이를 위해 대규모 데이터셋인 **Mega-SSum**과 **CSJ-SSum**을 함께 소개하며, 다양한 실험을 통해 Cascade 모델이 더 나은 성능을 보임을 확인했습니다. 또한, **지식 증류 (Knowledge Distillation)** 방식을 활용하여 E2E 모델의 성능 역시 크게 향상시킬 수 있음을 보였습니다. 향후 연구에서는 문맥을 고려한 모델 개발과 더 효율적인 지식 증류 방법이 필요하다는 결론을 도출했습니다.