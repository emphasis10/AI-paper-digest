# URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.04686.pdf](https://arxiv.org/pdf/2501.04686.pdf)

1. 섹션 요약:

   - 소개 및 문제 정의:
     이 논문에서는 멀티모달 대형 언어 모델(MLLMs)에서 체인 생각 추론(CoT)을 더욱 발전시키기 위한 URSA-7B 모델을 소개합니다. 최근 연구들은 고품질의 CoT 스타일 추론을 향상시키기 위해 조사하고 있습니다. 그러나 이전 연구들은 멀티모달 수학적 추론에서 고품질 CoT 훈련 데이터의 부족으로 성능을 제한받고 있습니다.

   - 데이터 셋 및 모델 제안:
     URSA-7B는 MMathCoT-1M이라는 고품질 CoT 추론 데이터셋을 사용하여 수학적 추론 능력을 향상시킵니다. 또한, DualMath-1.1M이라는 과정을 통해 더 높은 정확도를 위한 테스트 타임 스케일링을 도입하였습니다.

   - 모델 훈련 프로세스:
     이 섹션에서는 URSA-7B의 훈련 과정을 설명합니다. 모델은 하이브리드 비전 인코더와 고급 수학 LLM인 Qwen2.5-Math-7B-Instruct를 이용하여 훈련됩니다. 이 훈련은 강력한 수학적 지식을 바탕으로 하고 있으며, 연산량을 최적화하기 위해 하이브리드 비용 절감 전략을 적용합니다.

   - 실험 및 결과:
     URSA-7B는 MathVista, MathVerse 및 DYNA-MATH 등의 여러 데이터셋에서 테스트되어, 모든 오픈 소스 MLLM 중 최고 성능을 달성합니다. 특히 수학 문제 해결 능력에서 두드러지게 뛰어난 성과를 보였으며, 다양한 모달리티의 정보를 활용할 수 있는 잠재력을 입증했습니다.

2. 논문의 전반적인 요약:

   이 논문은 MLLMs에서 수학적 추론 능력을 크게 향상시키기 위한 URSA-7B 및 관련된 데이터셋 개발을 중심으로 다룹니다. URSA-7B는 고품질의 CoT 훈련 데이터를 사용함으로써, 모델의 성능 향상을 증명하였습니다. 더불어, DualMath-1.1M이라는 혁신적인 데이터 합성 전략을 통해 모달리티 정보를 효과적으로 습득하고 관리할 수 있는 방안을 제시했습니다. 본 연구는 여러 공식 데이터셋에서 최고 성과를 달성해, MLLMs의 수학적 추론 성능을 최대로 끌어올리는 데 큰 기여를 했음을 보여줍니다.