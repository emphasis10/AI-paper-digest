# Scaling Pre-training to One Hundred Billion Data for Vision Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.07617.pdf](https://arxiv.org/pdf/2502.07617.pdf)

1. **각 섹션의 주요 내용 요약:**

   - **서론**: 비전-언어 모델(VLM)의 발전은 대규모 데이터셋의 이용 가능성에 밀접하게 연결되어 있다. 데이터의 규모가 모델의 성능에 미치는 영향을 조사하면서, 1000억 개의 데이터를 전처리하는 것의 효과를 검토한다. 전통적인 벤치마크에서 1000억 규모의 데이터가 성능 향상을 가져오지 않으나, 문화적 다양성 및 다국어 역량에서는 긍정적 영향을 미친다.

   - **기여 진술**: 본 논문은 1000억 개의 비전-언어 쌍 데이터가 VLM에 미치는 영향을 규명하고, 이 데이터가 전통적인 벤치마크 이외의 분야에서, 즉 문화적 다양성과 다국어 지원 등에서 얼마나 중요한지 강조한다. 또한, 데이터 필터링이 데이터 다양성을 설명할 수 있음을 보여준다.

   - **관련 연구**: 데이터의 크기와 품질이 모델 성능에 미치는 영향에 대한 연구가 있습니다. 특히, NLP와 컴퓨터 비전 분야에서 데이터 규모를 증가시키는 것이 성능 향상에 얼마나 기여하는지에 대한 다양한 연구 결과를 다룬다.

   - **제한사항**: 본 연구에서 사용한 벤치마크는 포괄적으로 사회적 개념을 수치화하는 데 한계가 있다. 예를 들어, 다국어 벤치마크인 Crossmodal-3600는 36개 언어만 포함하고 있다.

   - **결론**: 1000억 개의 데이터로 스케일을 늘리는 것이 전통적인 서양 중심 벤치마크에서 유의미한 성과를 보이지 않지만, 문화적 다양성과 다국어 역량 개발에는 필수적이다. 데이터 필터가 문화적 맥락의 표현을 제한할 수 있다는 점에서도 조심해야 한다.

2. **종합 요약**: 본 논문은 비전-언어 모델의 사전 훈련 데이터 규모를 1000억으로 확대하는 것이 문화적 다양성 및 다국적 지원의 향상에 기여한다고 강조한다. 데이터의 양은 해당 모델의 처리 능력에 긍정적인 영향을 미치며, 전통적인 서양 중심 벤치마크 성능을 넘어서 다양한 문화와 언어의 문제 해결에 필수적이라는 사실을 드러내고 있다. 데이터 필터링은 때때로 이러한 다양성 표현을 제한할 수 있으므로 주의해야 한다.