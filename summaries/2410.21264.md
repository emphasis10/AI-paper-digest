# LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.21264.pdf](https://arxiv.org/pdf/2410.21264.pdf)

### 1. 각 섹션 요약 - 중요 내용 요약 및 설명

**요약: 본 연구에서는 비디오 생성용 LARP 토크나이저를 소개합니다.** 
LARP는 자동 회귀적(AR) 생성 모델을 위한 새로운 비디오 토크나이저로서, 기존의 패치 기반 토크나이즈 방식의 한계를 극복하고자 합니다. LARP는 미터 등의 학습된 전체 쿼리를 사용하여 시각 콘텐츠에서 정보를 수집하는 전체적 토크나이즈 방법을 도입하여 패치 수준 정보에 국한되지 않고 더 글로벌하고 의미론적인 표현을 캡쳐합니다.

1. **서론**  
   - 최근 자동 회귀 모델의 성공에 힘입어 발생한 생성 모델링의 발전에 대해 설명합니다. LARP이 시각 콘텐츠의 글로벌 및 의미론적 표현을 포착하기 위한 새로운 비디오 토크나이저로서 도입된 배경을 소개합니다.

2. **관련 연구**  
   - 시각적 토크나이제이션 및 비주얼 생성 분야의 기존 연구를 리뷰하며, LARP의 다른점 및 장점을 보여줍니다. LARP는 패치 방식의 한계를 벗어나 보다 유연하고 더 많은 정보를 포착할 수 있으며, 시퀀스 레이아웃을 자동으로 최적화할 수 있는 모델입니다.

3. **방법론**  
   - LARP의 작용 방식과 핵심 요소를 설명합니다. AR prior 모델을 학습 과정에 통합하여 비디오 생성에 최적화된 토큰 공간을 구성하고, 머신러닝 및 비디오 생성 작업에서 뛰어난 성능을 보입니다.

4. **결론과 향후 연구**  
   - LARP의 성능에 대해 종합적으로 검토하며 그 효과성을 입증합니다. 향후 멀티모달 대규모 언어 모델(MLLM) 개발에도 적합한 잠재력을 가지고 있다고 결론지었습니다.

### 2. 전체 요약
LARP는 기존 패치 기반 토크나이저가 해결하지 못했던 문제를 다루고자 학습된 전체 쿼리를 활용해 비디오 콘텐츠에서 정보를 포착하는 새로운 접근 방법을 제안합니다. AR 모델의 성능을 최적화하기 위한 전략을 통합하여 효율성을 높이고, UCF101와 K600 같은 벤치마크에서 최첨단 성능을 입증했습니다. LARP는 비디오 생성 작업뿐만 아니라 멀티모달 랭귀지 모델에도 잠재적인 응용 가능성을 가지고 있습니다.