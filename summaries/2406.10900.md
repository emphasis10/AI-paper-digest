# AUTOHALLUSION: Automatic Generation of Hallucination Benchmarks for Vision-Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.10900.pdf](https://arxiv.org/pdf/2406.10900.pdf)

### 전체 요약

이 논문은 **대형 비전-언어 모델(Large Vision-Language Models, LVLMs)**에서 발생하는 "환각(Hallucination)" 문제를 다룹니다. 환각이란, 이미지의 특정 맥락 신호가 언어 모듈의 과도한 자신감과 잘못된 추론을 유발하여 비정상적이거나 가상의 객체를 생성하는 현상을 말합니다. 이를 해결하기 위해, 논문은 자동 벤치마크 생성 접근법인 **AUTOHALLUSION**을 제안합니다. 주요 기여는 다음과 같습니다:

- **LVLM 환각을 유도하기 위한 자동 생성 벤치마크**를 제안.
- **LVLM 환각을 유발하는 맥락적 편향**을 탐색하는 방법 개발.
- **LVLM 모델 평가**: GPT-4V, Gemini Pro Vision, Claude 3, LLaVA-1.5 등의 모델을 평가.

이 연구는 LVLM의 인지적 오류를 분석하고, 이를 해결하기 위한 방향을 제시합니다.

### 섹션별 요약

#### 1. Introduction (소개)

이 논문은 LVLM에서 발생하는 환각 문제를 다룹니다. LVLM이 강한 언어 모듈의 사전 지식을 지나치게 신뢰하여 시각적 입력을 무시할 때 발생하는 문제를 해결하기 위해 **AUTOHALLUSION**을 제안합니다. AUTOHALLUSION의 목표는 자동으로 다양한 환각 사례를 생성하여 높은 비용의 인간 노동을 최소화하는 것입니다.

#### 2. Related Work (관련 연구)

- **비전-언어 모델**: GPT-4, Flamingo, Bard 등 최근 개발된 모델들은 텍스트와 이미지 입력을 처리할 수 있습니다.
- **벤치마크**: CHAIR, POPE, OpenCHAIR 등 다양한 벤치마크가 개발되었지만, 기존 방법들은 환각 생성에 한계가 있습니다.

#### 3. Problem Formulation (문제 정의)

- **목표**: LVLM에서 환각을 유발하는 편향된 사전 정보를 찾는 것.
- **정의**: 이미지와 텍스트 모듈을 세트로 변환하여 LVLM의 환각을 유도하는 이미지와 질문 쌍을 생성합니다.

#### 4. Methodology (방법론)

- **AUTOHALLUSION**: 세 가지 주요 전략을 통해 환각을 유발하는 이미지와 질문을 자동으로 생성.
  - **비정상 객체 삽입**: 이미지에 비정상적인 객체를 추가.
  - **쌍 객체 삽입**: 두 개의 같이 나타나야 할 객체 중 하나를 제외.
  - **연관 객체 제거**: 맥락과 강하게 연결된 객체를 제거.

#### 5. Experiment Results (실험 결과)

- 주요 LVLM 모델들(GPT-4V, Claude 3 등)을 평가한 결과, AUTOHALLUSION이 환각 유도에 높은 성공률을 보임.
  - **성공률**: 97.7% (합성 데이터셋), 98.7% (실제 데이터셋).

#### 6. Conclusion (결론)

- **AUTOHALLUSION**은 LVLM의 환각 문제를 해결하기 위한 첫 자동 벤치마크 생성 접근법.
- 앞으로 이미지 품질을 개선하고, 텍스트 프로빙 방법을 확장하여 더 다양한 맥락 정보를 추출할 계획.

### 요약

이 논문은 LVLM에서 발생하는 환각 문제를 자동으로 탐지하고 해결하기 위한 AUTOHALLUSION을 제안합니다. 주요 기여는 환각을 자동으로 생성하고, 이를 통해 다양한 LVLM 모델을 평가하는 것입니다. 이 연구는 LVLM의 편향된 사전 정보에 의한 인지적 오류를 분석하고, 이를 극복하기 위한 방법을 제시하고 있습니다. 앞으로 더 나은 이미지 품질과 텍스트 프로빙 방법을 통해 연구를 확장할 계획입니다.

## Similar Papers
- [Adversarial Attacks on Multimodal Agents](2406.12814.md)
- [MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and Efficient Evaluation](2407.00468.md)
- [WildVision: Evaluating Vision-Language Models in the Wild with Human Preferences](2406.11069.md)
- [Paint by Inpaint: Learning to Add Image Objects by Removing Them First](2404.18212.md)
- [Benchmarking Multi-Image Understanding in Vision and Language Models: Perception, Knowledge, Reasoning, and Multi-Hop Reasoning](2406.12742.md)
- [MaGGIe: Masked Guided Gradual Human Instance Matting](2404.16035.md)
- [TextSquare: Scaling up Text-Centric Visual Instruction Tuning](2404.12803.md)
- [MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation](2404.05674.md)
- [Eliminating Position Bias of Language Models: A Mechanistic Approach](2407.01100.md)
