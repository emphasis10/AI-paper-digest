# VideoTetris: Towards Compositional Text-to-Video Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.04277.pdf](https://arxiv.org/pdf/2406.04277.pdf)

### 1. 섹션별 요약
#### 1. 서론(Introduction)
현대의 확산 모델(Diffusion Models)이 텍스트-비디오 생성에서 뛰어난 성과를 보여주고 있으나, 복잡한 장면 및 동적인 객체 변화를 다루는 데 있어 제한이 있다. VideoTetris는 이러한 제한을 극복하기 위해 설계되었으며, 복잡한 텍스트 지시에 따라 장면을 조합하는 스페이시오-템포랄 합성 확산 기법을 제안한다. 또한, 향상된 비디오 데이터 전처리를 도입하여 모션 동역학과 지시어 이해를 개선하고, 일관성을 유지하기 위해 새로운 참조 프레임 주의 메커니즘을 제공한다.

#### 2. 관련 연구(Related Work)
텍스트-비디오 생성 모델은 최근 확산 모델의 발전과 대규모 비디오-텍스트 페어 데이터셋의 개발로 큰 진전을 이루었다. 초기 연구들은 2D 이미지 확산 모델을 3D U-Net으로 변환하여 비디오 데이터셋에 맞게 학습을 시도하였다. 최근에는 트랜스포머 기반의 여러 방법들이 대규모 비디오-이미지 공동 학습을 통해 생성 품질을 크게 향상시켰다. 그러나 대부분의 모델은 복잡한 다객체 장면을 생성하는 데 한계가 있다.

#### 3. 방법(Method)
- **스페이시오-템포랄 합성 확산(Spatio-Temporal Compositional Diffusion)**: 복잡한 텍스트 지시에 충실한 비디오를 생성하기 위해 교차 주의 값을 시간적, 공간적으로 조작하여 비디오를 합성한다.
- **향상된 비디오 데이터 전처리(Enhanced Video Data Preprocessing)**: 고품질 비디오 데이터를 수집하고 모션 동역학 및 지시어 이해를 개선하기 위해 데이터 전처리 파이프라인을 도입한다.
- **일관성 규제(Consistency Regularization)와 참조 프레임 주의(Reference Frame Attention)**: 길이 있는 비디오 생성 시 객체의 일관성을 유지하기 위해 참조 프레임 주의 메커니즘을 통해 일관된 객체 표현을 유지한다.

#### 4. 실험(Experiments)
- **실험 설정(Experimental Setups)**: 다양한 텍스트 지시어에 따른 비디오 생성 실험을 통해 VideoTetris의 성능을 평가한다.
- **메트릭스(Metrics)**: VBLIP-VQA, VUnidet, CLIP-SIM 등 다양한 메트릭스를 통해 성능을 평가한다.
- **합성 프롬프트 비디오 생성(Video Generation with Compositional Prompts)**: 복잡한 텍스트 지시에 따른 비디오 생성 실험에서 VideoTetris의 탁월한 성능을 입증한다.
- **장기 비디오 생성(Long Video Generation for Progressive Compositional Prompts)**: 점진적 합성 프롬프트 비디오 생성에서도 VideoTetris가 일관성과 품질 면에서 우수함을 보인다.
- **소거 연구(Ablation Study)**: 각 구성 요소의 효과를 평가하여 각 부분이 성능에 기여하는 바를 확인한다.

#### 5. 결론 및 토론(Conclusion and Discussion)
VideoTetris는 복잡한 텍스트 지시어에 따른 합성 비디오 생성과 길이 있는 비디오 생성에서 일관되고 높은 품질의 비디오 출력을 제공한다. 향후 연구에서는 비디오 생성 모델의 성능을 더욱 향상시키기 위해 더 효율적인 학습 기법을 탐구하고, 다양한 입력 조건에 따른 유연한 합성 비디오 생성 방법을 연구할 계획이다.

### 2. 전체 요약
VideoTetris는 확산 기반 프레임워크로, 복잡한 텍스트 지시에 따라 비디오를 합성할 수 있는 능력을 제공한다. 이 연구는 특히 다객체 장면 및 동적인 객체 변화를 처리하는 데 중점을 두고 있으며, 스페이시오-템포랄 합성 확산 기법과 향상된 비디오 데이터 전처리 파이프라인, 참조 프레임 주의 메커니즘을 통해 고품질의 일관된 비디오 출력을 달성한다. 실험 결과는 VideoTetris가 현재 최고의 모델들을 능가하는 성능을 보여준다. 향후 연구는 비디오 생성 과정의 효율성을 높이고 더 다양한 입력 조건을 다룰 수 있는 방법을 모색할 계획이다.

## Similar Papers
- [Image Conductor: Precision Control for Interactive Video Synthesis](2406.15339.md)
- [Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics](2408.04631.md)
- [Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models](2406.04271.md)
- [Live2Diff: Live Stream Translation via Uni-directional Attention in Video Diffusion Models](2407.08701.md)
- [DiffIR2VR-Zero: Zero-Shot Video Restoration with Diffusion-based Image Restoration Models](2407.01519.md)
- [MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding](2404.05726.md)
- [VIMI: Grounding Video Generation through Multi-modal Instruction](2407.06304.md)
- [Cinemo: Consistent and Controllable Image Animation with Motion Diffusion Models](2407.15642.md)
- [Collaborative Video Diffusion: Consistent Multi-video Generation with Camera Control](2405.17414.md)
