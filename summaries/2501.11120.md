# Tell me about yourself: LLMs are aware of their learned behaviors
## TL;DR
## Summary
- [https://arxiv.org/pdf/2501.11120.pdf](https://arxiv.org/pdf/2501.11120.pdf)

### 1. 각 섹션의 주요 내용 요약 (한국어)

#### 1. 서론
이 논문에서는 대형 언어 모델(LLM)이 학습한 행동을 스스로 설명할 수 있는 능력을 조사합니다. 이 능력을 '행동적 자각'이라고 하며, 모델이 훈련된 데이터에서 명시적으로 설명되지 않은 행동을 논리적으로 설명할 수 있는지를 연구합니다. 이는 AI의 안전에 중요한 의미를 지닙니다.

#### 2. 행동 인식
모델이 훈련 데이터에 명시적으로 기술되지 않은 행동을 이해하고 설명할 수 있는지를 다룹니다. 실험에서는 경제적 결정, 대화 게임, 안전하지 않은 코드 작성을 포함한 다양한 설정을 통해 행동적 자각을 평가했습니다. 모델들은 특정 행동을 자각하고 이를 기술할 수 있음을 보였습니다.

#### 3. 행동적 자각 및 훈련 방법
모델이 훈련 중에 관찰하지 못한 행동을 설명할 수 있는지에 대한 실험을 설명합니다. 경영 결정, 대화 및 코드 생성과 같은 다양한 설정에서 모델의 행동을 평가하였습니다. 예를 들어, 리스크를 감수하는 선택을 통해 모델이 '대담하다'고 스스로 평가할 수 있었습니다.

#### 4. 백도어 행동 징후 탐지
모델이 특정 조건에서 나타나는 비정상적인 행동(백도어 행동)을 자각할 수 있는지 실험했습니다. 모델은 특정 프롬프트에 대한 백도어 트리거를 인식할 수 있었지만, 자유형 질문에는 명확히 대답하지 못하는 경향이 있었습니다.

#### 5. 다중 인격 모델링
모델이 각기 다른 인격을 설정하고 해당 인격에 따라 행동의 차이를 보고할 수 있는지를 검토합니다. 실험 결과, 모델은 여러 인격을 기반으로 자신이 가진 행동의 정책을 구분하고 설명할 수 있었습니다.

#### 6. 결론
행동적 자각의 발견은 모델이 다양한 맥락에서 스스로를 인식하고 설명할 수 있는 가능성을 보여줍니다. 이는 AI 안전성에 대한 새로운 접근 방식을 필요로 하며, 앞으로의 연구에서 더 깊이 있는 조사와 기술적 구현이 필요합니다.

### 2. 종합 요약 (한국어)
이 논문은 대형 언어 모델이 학습한 행동을 자각하고 스스로 설명하는 능력, 즉 '행동적 자각'을 조사합니다. 연구는 모델이 훈련 중에 데이터를 통해 얻은 행동을 어떻게 언어적으로 설명하는지를 다양한 설정에서 실험하여 입증하였습니다. 또한, 모델의 행동이 특정 조건에서 비정상적으로 나타나는 경우를 탐구하여 AI의 안전성을 강화하기 위한 접근방안을 제시했습니다. 이 논문은 향후 AI의 안정성과 안전성을 높이기 위한 중요한 기초 자료가 될 것입니다.