# M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding
## TL;DR
## Summary
- [https://arxiv.org/pdf/2411.04952.pdf](https://arxiv.org/pdf/2411.04952.pdf)

### 1. 각 섹션의 요약

#### 도입과 배경
도큐먼트 비주얼 질문 응답(이하 DocVQA)은 문서 이미지 내 정보를 해석하여 텍스트 질문에 답하는 멀티모달 작업입니다. 기존 DocVQA 메소드들은 단일 페이지 문서를 중심으로 하거나, 텍스트 기반 정보 추출 방법(e.g., OCR)을 사용하지만, 여러 페이지에 걸친 정보를 요구하거나 복잡한 시각적 형식(표, 그림 등)을 처리하는 데 한계가 있었습니다. M3DOCRAG는 이러한 한계를 극복하기 위해 멀티모달 문서 맥락과 다양한 질문 홉(single-hop과 multi-hop)을 유연히 수용합니다.

#### M3DOCRAG: 멀티모달 RAG 프레임워크
M3DOCRAG는 복합 문서를 이해하기 위한 통합 프레임워크로써 텍스트, 차트, 그림 등 다양한 모달리티의 근거를 다룸으로써 문서 내 여러 페이지와 여러 문서를 효과적으로 처리하는 시스템을 제공합니다.

#### M3DOCVQA: 새로운 벤치마크
본 연구에서 제안한 M3DOCVQA는 약 3,000개 이상의 PDF 문서와 40,000 페이지 이상을 포함하고 있는 개방형 도메인 DocVQA를 평가하기 위한 최초의 벤치마크입니다. 다양한 모달리티를 통해 질문에 대한 답변을 해야 하는 것이 특징입니다.

#### 실험 설정 및 결과
M3DOCRAG는 기존 방법들과 비교하여 개방 도메인과 닫힌 도메인 DocVQA 환경 모두에서 의미 있는 성능 향상을 보여주었으며, 특히 이미지와 비문자 자료를 다루는 데 있어 현저히 우수한 성능을 보였습니다.

#### 결론
M3DOCRAG는 많은 양의 문서를 효율적으로 처리하면서 시각 정보를 유지할 수 있는 혁신적인 멀티모달 시스템입니다. 본 연구는 이는 향후 문서 이해에 있어 더욱 강력하고, 확장 가능하며, 실질적인 솔루션으로 발전하는 데 기여할 것입니다.

### 2. 전체 요약

이 논문에서는 M3DOCRAG라는 새롭고 혁신적인 멀티모달 RAG 프레임워크를 제안합니다. 이는 특히 다수의 문서 및 페이지에 걸쳐 정보를 추출하고 질문에 답하는 것을 가능하게 하여, 기존의 Text-based RAG 방법이 놓치기 쉬운 시각적 정보를 효과적으로 활용합니다. M3DOCVQA 벤치마크 평가를 통해, 본 시스템은 다양한 모달리티와 문서 환경에서 우수한 성능을 입증했으며, 실질적인 문제 해결에 있어서도 잠재력이 큼을 보였습니다. 이 연구는 AI의 문서 이해 능력을 한층 더 발전시키고, 실질적인 응용 프로그램에서 강력한 역할을 할 수 있도록 발전시킨다는 점에서 중요한 의의를 갖습니다.