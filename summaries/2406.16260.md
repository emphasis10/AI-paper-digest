# Video-Infinity: Distributed Long Video Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.16260.pdf](https://arxiv.org/pdf/2406.16260.pdf)

### 1. 섹션별 요약 (Main Contribution 및 혁신 설명 포함)

#### Abstract
이 논문은 비디오 생성에서 메모리와 처리 시간 문제를 해결해주는 "Video-Infinity"라는 프레임워크를 소개합니다. 이 프레임워크는 다수의 GPU를 활용해 장시간 비디오 생성이 가능하며, “Clip parallelism”과 “Dual-scope attention”이라는 두 가지 주요 메커니즘을 도입해 GPU 간의 소통과 일관성을 유지합니다.

#### Introduction
전통적으로 물리학 및 그래픽에 의해 지배된 디지털 세계의 재현이 데이터 기반 생성 모델의 등장으로 크게 향상되었습니다. 하지만 이들 모델은 짧은 비디오 클립 생성에 머물러 있습니다. 이를 해결하기 위해 "Video-Infinity"는 비디오를 작은 조각으로 나누어 여러 GPU에 분산시켜 병렬 처리를 가능하게 합니다.

#### Methodology
논문은 두 가지 핵심 메커니즘을 소개합니다:
1. **Clip parallelism**: GPU 간의 컨텍스트 정보를 최적화된 방식으로 공유하여 통신 오버헤드를 최소화합니다.
2. **Dual-scope attention**: 로컬 및 글로벌 컨텍스트를 조정하여 각 장치가 일관성을 유지하면서 장시간 비디오 생성을 가능하게 합니다.

#### Results
제안된 방법론은 8개의 Nvidia 6000 Ada GPU로 테스트되었으며, 2300 프레임의 비디오를 약 5분 만에 생성할 수 있었습니다. 이는 기존 방법보다 최대 100배 빠른 속도입니다.

#### Discussion
기존의 비디오 생성 방법들과 비교했을 때, Video-Infinity는 일관성과 동적 움직임에서 우수한 성능을 보였습니다. 특히, FreeNoise와 Streaming T2V 대비 더 나은 움직임과 일관성을 가지고 있음을 입증했습니다.

#### Conclusion
Video-Infinity는 다중 GPU를 활용한 장시간 비디오 생성의 효율성을 크게 개선하는 방법론을 제시합니다. Clip parallelism과 Dual-scope attention의 결합을 통해 모델의 일관성 및 속도를 증가시켰습니다. 그러나 이러한 접근법은 여러 GPU의 가용성에 의존하며, 장면 전환이 포함된 비디오 생성에는 한계가 있습니다. 이 방법은 긴 비디오 생성의 효율성을 새로운 기준으로 설정했습니다.

### 2. 전체 요약
이 논문은 "Video-Infinity"라는 새로운 분산 비디오 생성 프레임워크를 제안하여, 다수의 GPU간 병렬 처리 및 효과적인 통신 메커니즘을 통해 장시간 비디오 생성의 효율성과 속도를 극대화합니다. 주요 기여는 다음과 같습니다:
- **Clip parallelism**: GPU 간 통신 오버헤드를 최소화.
- **Dual-scope attention**: 로컬 및 글로벌 컨텍스트의 최적화를 통해 일관성 있는 비디오 생성.

이 접근법을 통해 기존 방법론보다 최대 100배 빠른 속도로 2300 프레임의 비디오를 생성할 수 있었습니다. 다만, 여러 GPU의 가용성이 필요하며 장면 전환이 포함된 비디오 생성에는 한계가 존재합니다.

## Similar Papers
- [AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising](2406.06911.md)
- [VIMI: Grounding Video Generation through Multi-modal Instruction](2407.06304.md)
- [Live2Diff: Live Stream Translation via Uni-directional Attention in Video Diffusion Models](2407.08701.md)
- [Compositional Video Generation as Flow Equalization](2407.06182.md)
- [FreeLong: Training-Free Long Video Generation with SpectralBlend Temporal Attention](2407.19918.md)
- [GFlow: Recovering 4D World from Monocular Video](2405.18426.md)
- [Hash3D: Training-free Acceleration for 3D Generation](2404.06091.md)
- [Cinemo: Consistent and Controllable Image Animation with Motion Diffusion Models](2407.15642.md)
- [ZeroSmooth: Training-free Diffuser Adaptation for High Frame Rate Video Generation](2406.00908.md)
