# A New Federated Learning Framework Against Gradient Inversion Attacks
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.07187.pdf](https://arxiv.org/pdf/2412.07187.pdf)

## 1. 각 섹션 요약 및 주요 주제 정리

### 소개
딥 뉴럴 네트워크(DNN)는 컴퓨터 비전 분야에서 큰 성공을 거두었으나, 데이터 공유의 제약으로 인해 연합 학습(FL)이 주목받고 있습니다. FL은 여러 클라이언트가 원시 데이터를 공유하지 않고 모델을 공동으로 학습할 수 있게 합니다. 그러나 FL의 모델은 그레이디언트 역전 공격(GIA)으로 인해 개인정보 유출 위험을 가지며, 이를 방어하기 위해 다양한 방식이 사용되고 있습니다.

### 관련 연구
GIA는 학습 모델의 그레이디언트를 이용해 훈련 데이터의 민감한 정보를 추론하려는 공격입니다. 이를 방어하기 위해 SMC, HE, DP 등의 방법이 사용되고 있으나, 정보 유출과 모델 성능 간의 절충이 필요합니다.

### 방법론
이 논문은 Hypernetwork Federated Learning(HyperFL)이라는 새로운 연합 학습 프레임워크를 제안합니다. HyperFL은 네트워크 분해와 하이퍼네트워크 공유 방식을 통해 공유되는 파라미터와 로컬 데이터를 직접 연결하지 않도록 하여 GIA를 방어합니다. 하이퍼네트워크는 각 클라이언트의 특징 추출기를 생성하며, 이는 클라이언트의 개인 임베딩 벡터에서 생성됩니다.

### 결과
HyperFL은 기존의 FL 방법과 유사한 성능을 유지하면서 개인정보를 효과적으로 보호합니다. 이 방법은 특히 GIA에 대한 개인정보 보호에서 뛰어난 성과를 보였으며, 제안된 설정에 따라 디지털 시대의 다양한 요구를 충족할 수 있습니다.

### 결론
이 연구는 하이퍼네트워크를 사용한 FL의 새로운 프레임워크를 검토하며, 개인정보 노출 위험을 줄이는 데 중점을 두고 있습니다.

## 2. 전체 요약
이 논문의 주요 기여는 클라이언트의 민감한 데이터와 공유 파라미터 사이의 직접 연결을 차단하는 HyperFL 프레임워크를 설계한 것입니다. 이는 연합 학습에서 개인정보 보호와 모델 성능 간의 트레이드오프 문제를 해결하며, 특히 그레이디언트 역전 공격에 대한 방어 능력을 갖춘 혁신적인 방식입니다. 연구는 이를 통해 개인정보 유출을 최소화하면서도 안정적인 학습 결과를 제공함을 보여주었습니다.