# SmolTulu: Higher Learning Rate to Batch Size Ratios Can Lead to Better Reasoning in SLMs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.08347.pdf](https://arxiv.org/pdf/2412.08347.pdf)

### 1. 섹션별 요약 

**서론**
이 논문은 소규모 언어 모델의 성능을 향상시키기 위한 새로운 최적화 기법을 다룬다. 특히 학습률과 배치 크기 사이의 관계를 통해 작은 모델에서의 성능 최적화를 추구하고 있다.

**관련 연구**
최신의 포스트 트레이닝 기술들이 대형 모델에서는 잘 적용되나, 소형 모델에서는 추가적인 최적화 전략이 필요함을 보여준다. Tulu 3 같은 오픈소스 파이프라인이 작은 모델에 어떻게 적용될 수 있는지를 설명하고 있다.

**데이터셋 및 실험**
작은 모델에서도 최적의 성능을 발휘하는 학습률과 배치 크기의 비율을 제안한다. 높은 비율은 복잡한 추론 작업에 유리하며, 낮은 비율은 패턴 인식 작업에서 더 나은 성능을 보인다.

**직접 선호 최적화(Direct Preference Optimization)**
선호 학습에 대한 간소화된 접근법인 DPO를 소개하며, 이는 별도의 보상 모델 없이도 선호 데이터를 학습할 수 있는 기법을 제시한다.

**보상 모델링**
보상 모델이 작은 아키텍처에 어떻게 더 효과적으로 활용될 수 있는지를 논의한다. 최적화 전략이 적절히 조정된 경우, 보상 모델링이 작은 모델에서도 효과적으로 작동할 수 있음을 보여준다.

**제한점**
최적화 전략의 다단계 이해와 모델 의존성 등 몇 가지 제한점을 논의하며, 향후 연구 방향을 제시한다.

### 2. 전체 요약

이 연구는 소규모 언어 모델(SmolLM)에도 최신의 포스트 트레이닝 기술을 적용하여 큰 모델만큼의 성능을 이끌어내기 위한 다양한 최적화 전략을 소개한다. 특히 학습률과 배치 크기 비율의 최적화를 통해 사용자가 원하는 작업 성능을 강화할 수 있음을 입증했다. 이를 통해 소규모 모델에서도 효율적인 학습 동역학을 통해 고품질의 언어 모델을 더욱 광범위한 환경에 배포할 수 있는 가능성을 열어두고 있다. 

이 연구는 소형 모델을 대형 모델처럼 최적화할 때 기존 방식과는 다른 접근 방법을 필요로 하며, 각기 다른 작업에 따라 최적의 학습 동역학이 달라짐을 보여준다. 따라서 작은 모델의 성능을 극대화하기 위해서는 다양한 작업별 최적화 전략을 고려해야 한다.