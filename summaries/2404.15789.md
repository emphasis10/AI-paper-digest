# MotionMaster: Training-free Camera Motion Transfer For Video Generation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.15789.pdf](https://arxiv.org/pdf/2404.15789.pdf)

이 논문에서는 카메라 모션 전송을 위한 새로운 방법, MotionMaster를 제시합니다. 이 방법은 소스 비디오에서 카메라 모션을 추출하고 새로운 비디오로 전송하는 과정을 통해 카메라와 객체의 움직임을 분리하는 데 중점을 둡니다. 다음은 각 섹션의 주요 내용 요약입니다.

1. **서론 및 관련 작업**:
   - 비디오 생성을 위한 기존 연구들은 객체 움직임 제어에 초점을 맞추었지만, 본 연구는 카메라 움직임 제어에 집중합니다.
   - 텍스트-비디오 생성, 이미지-비디오 생성 등 다양한 접근 방식이 소개되며, 이 중 확산 모델이 주요 도구로 사용됩니다.

2. **MotionMaster 방법론**:
   - 카메라와 객체 모션을 분리하기 위한 '한 번 샘플링(camera motion disentanglement)'과 '소수 샘플링(few-shot camera motion disentanglement)' 방법을 제안합니다.
   - 이 방법들은 시각적 주의 맵을 분석하여 카메라 움직임만을 추출하고, 이를 다른 비디오에 적용하는 데 사용됩니다.

3. **실험 및 결과**:
   - 다양한 카메라 모션 제어 실험을 통해 MotionMaster의 유효성을 입증합니다.
   - 특히 '카메라 모션 조합(camera motion combination)' 기능을 통해 다양한 카메라 움직임을 결합하고 특정 지역에 적용할 수 있음을 보여줍니다.

4. **결론**:
   - MotionMaster는 훈련 없이도 카메라 모션을 효과적으로 제어할 수 있는 새로운 방법을 제공합니다.
   - 비디오 생성에서 카메라 제어의 유연성과 다양성을 크게 향상시킬 수 있는 가능성을 제시합니다.

이 연구는 카메라 움직임과 객체 움직임을 분리하고, 다양한 비디오 생성 작업에 대해 보다 세밀하고 유연한 제어를 가능하게 하는 새로운 기술을 소개함으로써 비디오 생성 분야에 중요한 기여를 합니다.

## Similar Papers
- [Collaborative Video Diffusion: Consistent Multi-video Generation with Camera Control](2405.17414.md)
- [Image Conductor: Precision Control for Interactive Video Synthesis](2406.15339.md)
- [Knowledge Fusion of Chat LLMs: A Preliminary Technical Report](2402.16107.md)
- [MotionBooth: Motion-Aware Customized Text-to-Video Generation](2406.17758.md)
- [Training-free Camera Control for Video Generation](2406.10126.md)
- [VideoTetris: Towards Compositional Text-to-Video Generation](2406.04277.md)
- [Live2Diff: Live Stream Translation via Uni-directional Attention in Video Diffusion Models](2407.08701.md)
- [MotionClone: Training-Free Motion Cloning for Controllable Video Generation](2406.05338.md)
- [Reenact Anything: Semantic Video Motion Transfer Using Motion-Textual Inversion](2408.00458.md)
