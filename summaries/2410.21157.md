# M2rc-Eval: Massively Multilingual Repository-level Code Completion Evaluation
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.21157.pdf](https://arxiv.org/pdf/2410.21157.pdf)

# 섹션별 요약 및 주요 기여

1. **소개**
   - 본 논문은 M2RC-EVAL이라는 다중 언어 저장소 코드 완성 벤치마크를 제안합니다. 이 시스템은 18개 프로그래밍 언어에 대해 버킷 레벨 및 의미 레벨의 세밀한 주석을 제공합니다. 이에 더해 M2RC-INSTRUCT라는 코드 지시어 말뭉치를 소개함으로써 기존 모델의 성능을 향상시킵니다.

2. **관련 연구**
   - 본문에서는 코드 대형 언어 모델(LLM)의 최근 발전을 검토하며, 코드 생성, 코드 번역, 코드 수정 등의 다양한 분야에 걸쳐 LLM의 사용을 강조합니다. 특히, 다국어 저장소 수준의 코드 완성을 위한 새로운 벤치마크의 필요성을 제기합니다.

3. **메서드**
   - M2RC-EVAL은 구문 트리를 사용하여 코드를 여러 버킷 레벨로 분류하고, 코드는 완료 위치에 따라 서로 다른 버킷과 의미 레벨로 라벨링됩니다. 이를 통해 다양한 난이도의 코드 완성 시나리오를 제공합니다.

4. **결과 및 분석**
   - M2RC-EVAL의 평가 결과는 다양한 프로그래밍 언어에서 서로 다른 코드 LLM의 저장소 수준 코드 완성 능력을 보여줍니다. 연구 결과는 다국어 SFT가 모델 성능을 크게 향상시킬 수 있음을 제시합니다.

5. **결론**
   - 본 연구는 M2RC-EVAL과 M2RC-INSTRUCT의 효과를 실험적으로 입증합니다. 이러한 작업은 LLM의 코드 완성 능력을 이해하는 데 기여할 것이며, 코드 지능 및 소프트웨어 공학의 발전에 기여할 것입니다.

# 전반적인 요약
이 논문은 AI와 머신러닝 분야에서 다중 언어 저장소 수준 코드 완성을 다루며, 다양한 언어에서 코드 대형 언어 모델의 성능을 평가하기 위해 설계된 M2RC-EVAL 벤치마크를 제안합니다. 이 시스템은 구문 트리를 기반으로 하는 세밀한 주석과, 성능 향상을 위한 대규모 다국어 지시어 말뭉치 M2RC-INSTRUCT를 포함합니다. 이러한 연구 결과는 LLM이 코드 지능과 소프트웨어 공학을 이해하고 발전시키는 데 중요한 기여를 할 것입니다.