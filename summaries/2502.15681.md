# One-step Diffusion Models with $f$-Divergence Distribution Matching
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.15681.pdf](https://arxiv.org/pdf/2502.15681.pdf)

1. 각 섹션의 요약:

- **소개 (Introduction)**: 이 논문은 f-발산(f-divergence)을 활용하여 다단계(diffusion) 모델을 단일 단계 모델로 변환하는 새로운 접근법을 제안합니다. 일반적으로 확률 모델링에서 사용되는 역 Kullback-Leibler 발산(reverse-KL divergence)은 모드-시킹(mode-seeking) 행동이 강하지만, 다양한 f-발산을 사용하여 이를 극복하고자 합니다.

- **방법론 (Methodology)**: 제안된 f-distill 프레임워크는 다양한 f-발산을 이용해 학생(student)과 교사(teacher) 간의 분포 차이를 최소화합니다. 이 발산에는 역-KL, 전방-KL(forward-KL), 젠슨-샤논(JS) 발산 등이 포함됩니다. 각 발산의 특징과 장단점을 논의하며, 몬테카를로 샘플링을 통해 최적화합니다.

- **실험 및 결과 (Experiments and Results)**: 제안된 프레임워크는 ImageNet-64, MS-COCO 등 다양한 데이터셋에서 실험하였으며, 낮은 모드-시킹 특성을 가진 JS 발산을 사용한 모델이 가장 뛰어난 성능을 보였습니다. 특히, ImageNet-64에서 새로운 최첨단 성능을 기록하였으며, MS-COCO에서도 뛰어난 결과를 도출하였습니다.

- **기여 (Contributions)**: f-divergence를 이용한 일반화된 방식으로 감쇠(distillation)를 수행하고, 낮은 모드-시킹 행동과 그라디언트의 안정화를 도모하는 새로운 프레임워크를 제안하였습니다. 이로 인해 이미지 생성 과제에서 JS 발산을 사용한 모델이 이전의 최상위 방법들보다 뛰어난 성과를 보였습니다.

2. 전체 요약:

이 논문은 하나의 네트워크 호출만으로 다단계(diffusion) 모델을 단일 단계 모델로 전환하는 새로운 방법론을 제시합니다. 다양한 f-발산을 사용하여 교사와 학생 간의 발산을 최소화함으로써, 기존 접근 방식의 한계를 극복하였습니다. 특히, 젠슨-샤논(JS) 발산은 다양한 이미지 생성 과제에서 우수한 성능을 발휘하며, 제안된 접근법의 혁신성을 입증하였습니다.