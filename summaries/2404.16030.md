# MoDE: CLIP Data Experts via Clustering
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.16030.pdf](https://arxiv.org/pdf/2404.16030.pdf)

이 논문에서는 CLIP 모델을 개선하기 위해 데이터 전문가 클러스터(MoDE) 시스템을 제안합니다. 이 시스템은 클러스터링을 통해 데이터 전문가를 학습하고, 추론 시점에는 작업 메타데이터와 클러스터 조건 간의 상관관계를 분석하여 해당 데이터 전문가의 출력을 앙상블합니다. 각 섹션의 주요 내용은 다음과 같습니다.

1. **서론 및 관련 작업**:
   - CLIP 모델은 시각적-언어적 표현 학습에 강력하지만, 웹에서 크롤링된 데이터의 노이즈로 인해 학습에 문제가 발생합니다.
   - 기존 CLIP 모델들은 큰 데이터셋을 이용해 학습되었으나, 부정확한 캡션 때문에 모델 성능이 저하될 수 있습니다.

2. **MoDE 방법론**:
   - 각 데이터 전문가는 클러스터링을 통해 형성된 데이터 클러스터에서 독립적으로 학습됩니다.
   - 추론 시 데이터 전문가는 작업 메타데이터와의 상관관계를 분석하여 선택되고, 선택된 데이터 전문가들의 출력을 앙상블하여 최종 결과를 도출합니다.

3. **실험 및 결과**:
   - 다양한 벤치마크에서 MoDE는 기존의 여러 상태의 예술 모델들보다 뛰어난 성능을 보여줍니다.
   - 이미지 분류, 이미지-텍스트 검색 및 텍스트-이미지 검색에서 특히 높은 성능 향상을 보여줍니다.

4. **결론**:
   - MoDE는 데이터 전문가를 효율적으로 학습하고, 필요에 따라 새로운 데이터 전문가를 유연하게 추가할 수 있는 구조를 제공합니다.
   - 이 방법은 대규모 데이터셋에서 CLIP 모델의 성능을 개선하는 데 큰 잠재력을 가지고 있습니다.

이 연구는 CLIP 모델의 기존 문제점을 해결하고, 다양한 데이터셋에서 고품질의 학습과 추론 성능을 달성하기 위한 새로운 접근 방식을 제시합니다.