# MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.00765.pdf](https://arxiv.org/pdf/2408.00765.pdf)

### Section Summaries

#### 1. Introduction
MM-Vet은 큰 멀티모달 모델(LMMs)을 평가하기 위해 설계된 벤치마크로, 인식(Recognition), 지식(Knowledge), OCR, 공간 인식(Spatial Awareness), 언어 생성(Language Generation), 수학(Math) 등 여섯 가지 핵심 비전-언어(VL) 능력을 평가합니다. 기존의 평가 방식은 이미지-텍스트 쌍에 한정되었으나, 최신 LMMs의 고급 기능을 충분히 평가하지 못한다는 한계가 있었습니다. 이를 해결하기 위해, 실제 시나리오에서 자주 나타나는 이미지-텍스트 시퀀스를 처리할 수 있는 새로운 기능을 추가한 MM-Vet v2가 개발되었습니다. 이 새로운 벤치마크는 Claude 3.5 Sonnet 모델이 GPT-4o 모델을 근소한 차이로 앞서는 결과를 보여줍니다.

#### 2. Dataset and Evaluator
MM-Vet v2는 기존 MM-Vet과 유사한 방식으로 높은 품질의 평가 세트를 유지하며, 이미지-텍스트 시퀀스 이해(Seq)라는 새로운 능력을 추가합니다. 517개의 질문이 다양한 시나리오를 포함하여 연구자들이 디자인하고 수집하였으며, 이러한 질문들은 매우 간단한 것에서부터 장문의 답변이 필요한 것까지 다양합니다. 이를 통해 모델은 이미지-텍스트 시퀀스 처리 능력과 더불어 기존 여섯 가지 핵심 능력을 평가받게 됩니다.

#### 3. Experiments
실험들은 두 가지 유형의 LMM을 평가합니다: 개방형 가중치 LMMs와 폐쇄형 모델. 평가 결과는 모델의 인식, 생성, OCR, 공간 인식, 지식, 시퀀스 이해 능력 등에서의 성능을 다양한 수치로 나타내었습니다. Claude 3.5 Sonnet 모델이 71.8점으로 가장 높은 점수를 기록했으며, 이를 GPT-4o가 71.0점으로 근소한 차이로 따랐습니다. 개방형 모델 중에서는 InternVL2-Llama3-76B가 68.4점을 기록하며 가장 뛰어난 성과를 보였습니다.

#### 4. Conclusion
MM-Vet v2는 큰 멀티모달 모델의 종합적인 평가를 위해 이미지-텍스트 시퀀스 이해라는 새로운 핵심 능력을 도입함으로써 기존의 한계를 극복했습니다. 벤치마크 결과에 따르면 Claude 3.5 Sonnet 모델이 71.8점으로 최고 점수를 획득했으며, GPT-4o가 근소한 차이로 뒤따랐습니다. 개방형 모델 중에서는 InternVL2-Llama3-76B가 최고의 성과를 보였습니다.

### Overall Summary
MM-Vet v2는 기존 MM-Vet 벤치마크의 한계를 극복하여, 이미지-텍스트 시퀀스 이해를 포함한 종합적인 모델 평가 능력을 보강하였습니다. 이를 통해 현실적인 시나리오에서의 모델 성능을 정확히 평가하고, Claude 3.5 Sonnet이 71.8점으로 가장 높은 성과를 보였으며, GPT-4o가 근소하게 그 뒤를 이었습니다. 개방형 가중치 모델 중에서는 InternVL2-Llama3-76B가 최고의 점수를 기록하였습니다. 이는 최신 멀티모달 모델의 기술력을 반영한 결과로, 향후 LMM 연구와 개발에 중요한 이정표가 될 것입니다.

## Similar Papers
- [INF-LLaVA: Dual-perspective Perception for High-Resolution Multimodal Large Language Model](2407.16198.md)
- [List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs](2404.16375.md)
- [VideoGUI: A Benchmark for GUI Automation from Instructional Videos](2406.10227.md)
- [MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos](2406.08407.md)
- [Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs](2406.14544.md)
- [Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models](2404.07973.md)
- [AlignGPT: Multi-modal Large Language Models with Adaptive Alignment Capability](2405.14129.md)
- [WildVision: Evaluating Vision-Language Models in the Wild with Human Preferences](2406.11069.md)
- [AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising](2406.06911.md)
