# Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks
## TL;DR
## Summary
- [https://arxiv.org/pdf/2406.12066.pdf](https://arxiv.org/pdf/2406.12066.pdf)

### 1. 요약 (섹션별)

#### 서론
이 연구는 의료 분야에서 드러그(복용약) 이름의 상호 교체 가능성을 고려한 새로운 형태의 내구성 평가 방법을 제안합니다. 이를 위해 RABBITS(Durg Term Substitution for Language Models)라는 전문 데이터셋과 리더보드를 도입했습니다.

#### 관련 작업
- **데이터셋 오염**: 데이터셋 오염 문제는 머신러닝 모델의 성능과 일반화 능력에 부정적 영향을 미칠 수 있습니다. 특히 의료 분야에서는 정확하지 않은 정보가 환자에게 해를 끼칠 수 있기 때문에, 데이터셋 오염을 해결하는 것이 중요합니다.
- **모델 내구성 평가**: 대규모 데이터 수집으로부터 얻어진 인공지능 언어 모델은 다양한 도메인에서 일관된 성능을 보여주지 못한다는 도전과제가 있습니다.

#### 방법론
- **브랜드-일반명 쌍의 생성**: RxNorm 온톨로지를 사용하여 2,271개의 일반명과 6,961개의 브랜드명을 매핑했습니다.
- **데이터셋 변환**: 정규 표현식을 사용하여 질문과 답변에서 브랜드명과 일반명을 식별하고 교체했습니다. 최종 RABBITS 벤치마크에는 MedQA와 MedMCQA가 포함되었습니다.

#### 결과 및 논의
- **약물 교체 결과**: 대부분의 모델이 일반명을 브랜드명으로 교체했을 때 정확도가 감소했습니다.
- **모델의 약물쌍 지식**: 대규모 모델들이 더 작은 모델들보다 약물쌍 매핑에서 더 높은 정확도를 보였습니다.
- **벤치마크 및 사전 학습 데이터셋에서의 일반명과 브랜드명 언급**: 벤치마크 질문에서 일반명이 더 자주 사용되었습니다.
- **데이터셋 오염 원천 분석**: MedQA와 MedMCQA 테스트 데이터셋에서 높은 비율의 데이터셋 오염이 발견되었습니다.

#### 결론
같은 약물을 다른 이름으로 사용할 때 일반적인 의료 벤치마크에서 성능이 감소함을 발견했습니다. 이는 LLM(대규모 언어 모델)의 성능이 실제 추론 능력보다는 암기에 의해 좌우될 수 있음을 시사합니다.

### 2. 전체 요약
이 논문은 의료 분야에서 드러그 이름의 상호 교체 가능성을 고려한 새로운 내구성 평가 방법을 제안합니다. RABBITS라는 전문 데이터셋과 리더보드를 도입하여 모델의 성능을 평가했습니다. 연구 결과, 대부분의 모델이 일반명을 브랜드명으로 교체했을 때 정확도가 감소했으며, 이는 LLM의 성능이 실제 추론 능력보다는 암기에 의해 좌우될 수 있음을 시사합니다. 이 연구는 의료 분야에서 데이터셋 오염을 해결하고 모델의 내구성을 평가하는 새로운 방법을 제안함으로써, 향후 연구에 중요한 기여를 할 것입니다.