# MIVE: New Design and Benchmark for Multi-Instance Video Editing
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.12877.pdf](https://arxiv.org/pdf/2412.12877.pdf)

1. 각 섹션의 중요 내용 요약:

- **서론**: AI 기반의 비디오 편집은 텍스트 프롬프트를 통해 비디오 편집 과정을 단순화시켰습니다. 하지만, 기존의 제로샷 비디오 편집 기술들은 주로 전체 장면이나 단일 객체 편집에 중점을 두어 비디오의 다른 부분에 의도치 않은 변화를 초래할 수 있습니다. MIVE는 이러한 문제를 해결하기 위한 제로샷 다중 인스턴스 비디오 편집 프레임워크로, 두 가지 핵심 모듈인 DMS와 IPR을 도입하여 편집 누출을 방지하고 정밀한 로컬라이제이션과 신뢰성 있는 편집을 보장합니다.

- **방법론**: MIVE는 Disentangled Multi-instance Sampling (DMS)와 Instance-centric Probability Redistribution (IPR)이라는 새로운 기술을 도입합니다. DMS는 주의력 누출을 방지하기 위해 설계되었고, IPR은 개체 마스크 내에서의 편집을 지역화하기 위해 설계되었습니다. 이러한 방법은 단일 대상을 넘어서 여러 대상을 포함하는 장면에서도 정확하고 신뢰성 있는 편집을 가능하게 합니다.

- **실험결과**: 제안된 방법은 실험 결과에서 기존 최고 성능의 모델을 능가하는 성능을 보였습니다. 다양한 비디오 시나리오에서 MIVE는 편집의 신뢰성과 정확성, 그리고 누출 방지 측면에서 현저히 우수한 결과를 보여줍니다. 이는 MIVE가 다중 인스턴스 비디오 편집의 새로운 기준을 세우게 했습니다.

- **결론**: 본 연구는 편집 신뢰성과 분리 편집을 최소한의 주의력 누출로 달성하는 MIVE를 소개하며, 새롭게 제안된 MIVE Dataset을 통해 기존 방법들을 초월하는 성능을 입증합니다. 사용자 연구에서도 MIVE의 강력함과 효율성이 입증되어 참가자들은 본 방법을 선호했습니다.

2. 전체 요약:

이 논문은 MIVE라는 새로운 제로샷 다중 인스턴스 비디오 편집 프레임워크를 소개합니다. 이 프레임워크는 주의력 누출을 방지하고 정밀한 로컬라이제이션과 신뢰성 있는 편집을 가능하게 하는 DMS와 IPR 기술을 통해 기존 방법들을 능가하는 성능을 보여줍니다. 실험 결과와 사용자 연구는 MIVE의 탁월한 신뢰성과 효율성을 입증하며, 이는 다중 인스턴스 비디오 편집의 새로운 표준을 제시합니다.