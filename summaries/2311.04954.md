# Prompt Sketching for Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2311.04954.pdf](https://arxiv.org/pdf/2311.04954.pdf)

### 1. 섹션별 주요 내용 요약

#### 소개 (Introduction)
이 논문에서는 대형 언어 모델(LLM)을 여러 번 연속으로 질의하여 중간 결과를 도출하고 최종 답변을 생성하는 최근 프롬프트 전략을 다룹니다. 하지만 이러한 방법은 디코더와 모델이 후속 프롬프트를 예측하지 못하여 중간 응답이 분절되고 불필요하게 길어지는 문제를 초래합니다. 이를 해결하기 위해 프롬프트 스케치라는 새로운 프롬프트 방식을 제안합니다. LLM이 프롬프트를 완성하는 것뿐만 아니라 템플릿에서 여러 변수를 예측하도록 하여 더 나은 결과를 도출하는 방식입니다. 실험을 통해 프롬프트 스케칭이 직접 질의나 체인 오브 생각(Chain-of-Thought)보다 8개의 LLM 벤치마크 테스트 중 7개에서 더 나은 성능을 보여준다고 밝혔습니다.

#### 배경 (Background)
이 섹션에서는 프롬프트와 디코딩에 대한 배경지식을 설명합니다. 대부분의 최신 언어 모델은 왼쪽에서 오른쪽으로만 작동하며, 입력 시퀀스와 이전에 예측된 토큰을 기반으로 다음 토큰의 확률 분포를 예측합니다. 이를 해결하기 위해 다양한 디코딩 전략이 도입되었습니다.

#### 연구 방법론 (Methodology)
프롬프트 스케칭을 통해 LLM의 디코딩 절차를 템플릿을 통해 여러 변수로 분할하여 최적화된 템플릿 가능성을 찾습니다. 이 접근법은 기존의 매우 긴 질의 응답 방식보다 효율적입니다. 알려진 템플릿을 사용하여 LLM의 응답을 제어할 수 있습니다. 이 섹션에서는 템플릿 예측과 여러 변수에 대한 스코어를 제공하고 이를 통해 정확한 예측을 위한 디코딩 전략을 소개합니다.

#### 실험 (Experiments)
실험에서는 프롬프트 스케칭이 다양한 LLM 추론 과제에서 성능을 향상시키는지 평가합니다. 다양한 벤치마크 테스트를 통해 기존의 비-템플릿, 순차적 추론 방식과 비교합니다. 또한 프롬프트 스케칭을 통해 새로운 애플리케이션을 실험합니다. 결과적으로 프롬프트 스케칭이 기존 방식보다 최대 10%의 성능 향상을 보여줍니다.

#### 결과 및 토론 (Results and Discussion)
프롬프트 스케칭은 기존의 체인 오브 생각보다 일관된 추론 구조를 제공하여 더 나은 성능을 보입니다. 특히, 작은 규모의 모델에서 더 큰 효과를 나타냈습니다. 디코더를 결합하여 성능을 더욱 향상시킬 수 있으며, 새로운 애플리케이션에도 적용될 수 있습니다. 예를 들어, 스도쿠 풀기나 인터랙티브 환경에서도 성능이 향상되었습니다.

#### 결론 (Conclusion)
프롬프트 스케칭을 통해 답변뿐만 아니라 여러 변수를 함께 예측하는 새로운 프롬프트 방식을 제시했습니다. 이는 기존의 순차적 질의 응답 방식보다 더 일관된 추론 구조를 제공하여 최대 10%의 성능 향상을 보였습니다. 앞으로 프롬프트 스케칭을 활용한 새로운 응용 프로그램을 통해 더 많은 연구가 이루어질 것입니다.

### 2. 전체 요약
이 논문은 LLM의 효율적이고 일관된 응답 생성을 위해 프롬프트 스케칭 기법을 제안했습니다. 기존 방식이 각 질의마다 분절되고 길어진 반면, 프롬프트 스케칭은 템플릿을 통해 여러 변수를 예측하여 일관성을 유지합니다. 이는 벤치마크 테스트에서 최대 10% 향상된 성능을 보여줬으며, 스도쿠 같은 복잡한 문제와 인터랙티브 환경에서도 성능을 향상시켰습니다. 프롬프트 스케칭은 작은 모델에서도 큰 효과를 보이며, 다양한 응용 프로그램을 통해 더 많은 연구와 발전이 기대됩니다.

## Similar Papers
- [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](2404.02575.md)
- [Distilling System 2 into System 1](2407.06023.md)
- [LiteSearch: Efficacious Tree Search for LLM](2407.00320.md)
- [Large Language Models Are Reasoning Teachers](2212.10071.md)
- [ExoViP: Step-by-step Verification and Exploration with Exoskeleton Modules for Compositional Visual Reasoning](2408.02210.md)
- [SliceGPT: Compress Large Language Models by Deleting Rows and Columns](2401.15024.md)
- [THOUGHTSCULPT: Reasoning with Intermediate Revision and Search](2404.05966.md)
- [Leveraging Large Language Models for Multimodal Search](2404.15790.md)
- [NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?](2407.11963.md)
