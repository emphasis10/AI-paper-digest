# LLaVA-Critic: Learning to Evaluate Multimodal Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.02712.pdf](https://arxiv.org/pdf/2410.02712.pdf)

### 요약:

**1. 섹션 요약 및 주요 기여 사항:**

- **서론**: 논문은 LLaVA-Critic이라는 오픈소스 대단위 다중 모달 모델을 소개합니다. 이 모델은 여러 다중 모달 작업을 평가하기 위한 일반적 평가자로 사용됩니다. LLaVA-Critic은 신뢰할 수 있는 평가 점수를 제공하며 선호 학습에서는 보상 신호를 생성하여 모델의 정렬 기능을 강화합니다.

- **관련 연구**: 기존의 다중 모달 모델들이 개선되어 다양한 현실의 비전 작업에서 성과를 내고 있지만, 이러한 모델들이 평가자의 역할을 수행하는 것은 새로운 시도입니다. LLaVA-Critic은 오픈소스 모델로, 평가 데이터에 따라 모델 응답의 평가와 그에 해당하는 근거를 제공합니다.

- **메소드**: 이 논문은 평가지침을 따르는 데이터세트를 수집하여 다음 두 가지 주요 시나리오에 중점을 둡니다: (1) 다중 모달 모델 평가자로서 LLaVA-Critic은 신뢰할 수 있는 평가 점수를 제공하며, GPT-4 모델과 비교하여 뛰어난 평가 성능을 발휘합니다; (2) 선호 학습에서 LLaVA-Critic은 효과적인 보상 신호를 생성하여 보상 학습에서의 정렬을 향상시킵니다.

- **결론**: LLaVA-Critic은 다중 모달 시나리오에서 모델 성능을 평가하기 위해 트레이닝된 오픈소스 모델로, 다양한 평가 기준을 포함한 질 높은 데이터세트를 통해 이 모델의 효과가 입증되었습니다. 그 결과 상업적인 GPT 모델에 대한 비싼 대안으로 활용될 수 있는 가능성을 보였습니다.

**2. 전반적 요약:**

이 논문은 다중 모달 모델의 성능을 평가하도록 설계된 LLaVA-Critic이라는 새로운 오픈소스 모델을 소개합니다. 이 모델은 높은 품질의 데이터세트를 활용하여 평가자로 작동하며, 기존의 상업적 모델에 견줄 수 있는 평가 능력을 제공합니다. 또한, 이 모델은 선호 학습에서 효과적인 보상 신호를 제공하여 모델의 정렬을 개선할 수 있는 가능성을 보여줍니다. 이는 AI 모델 개발에 있어 평가 및 자기 비판 기능의 중요성을 강조하며, 오픈소스 환경에서의 스케일과 초인간적인 정렬 피드백 메커니즘을 개발하기 위한 중요한 발걸음을 내딛게 합니다.