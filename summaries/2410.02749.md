# Training Language Models on Synthetic Edit Sequences Improves Code Synthesis
## TL;DR
## Summary
- [https://arxiv.org/pdf/2410.02749.pdf](https://arxiv.org/pdf/2410.02749.pdf)

### 1. 섹션별 중요 내용 요약 및 주요 기여 부분

#### 소개 (Introduction)
이 논문은 대형 언어 모델(LLM)의 성공에도 불구하고, 모든 모델에서 일관되게 올바른 제로샷 코드 생성을 달성하기 어려운 상황을 언급합니다. 특히, 소형 모델에서 샘플링 비용과 생성 품질 간의 균형을 맞추는 것이 어려움을 지적합니다. 이 문제를 해결하기 위해, 저자들은 LLM을 사용하여 전체 프로그램을 한 번에 생성하는 대신 코드 편집 시퀀스를 예측하도록 훈련할 것을 제안합니다.

#### LintSeq 알고리즘
LintSeq는 기존 프로그램을 정적 오류가 없는 코드 편집 시퀀스로 변환하는 알고리즘입니다. 이 알고리즘은 코드 생성을 더욱 제어 가능하게 하고, 모델을 통해 전체 프로그램을 처음부터 다시 생성하지 않아도 유용하고 올바른 코드 삽입을 예측할 수 있도록 돕습니다.

#### 실험 및 결과
다양한 모델에 대해 LintSeq 데이터를 사용하여 코드 편집 시퀀스를 생성하도록 미세 조정한 결과, 코드 품질 및 다양성이 향상되었습니다. 특히, 편집 시퀀스를 통한 모델은 기존의 대규모 모델에 비해 더 적은 추론 비용으로 GPT-4와 경쟁력 있는 문제 해결 능력을 보였습니다.

#### 토론, 한계, 결론 (Discussion, Limitations, and Conclusion)
LintSeq를 통한 코드 생성의 재매개변수가 데이터 수준에서 문제를 해결하는 방법의 핵심으로서, 이는 코드 생성 문제를 순차적 편집 문제로 변경하여 효율성을 높입니다. 이 방식은 모델이 제로샷 생성 및 추론 시간 성능에서 매우 소형 모델에서도 큰 성능 향상을 이끌어낼 수 있음을 보여줍니다.

### 2. 전체 요약
이 논문은 대형 언어 모델의 코드 생성 능력을 개선하기 위해 LintSeq 알고리즘을 소개합니다. LintSeq는 기존 프로그램을 정적 오류가 없는 시퀀스로 변환하여, 모델이 전체 프로그램을 처음부터 생성하지 않고도 효율적으로 코드 편집을 수행할 수 있게 합니다. 이는 기존의 대규모 모델과 비교했을 때 더 낮은 추론 비용으로도 매우 효율적인 코드 생성이 가능하게 하며, 특히 소형 모델에서도 경쟁력 있는 성능을 보입니다.