# mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding
## TL;DR
## Summary
- [https://arxiv.org/pdf/2403.12895.pdf](https://arxiv.org/pdf/2403.12895.pdf)

### 1. 각 섹션의 중요 내용 요약

#### 1.1 Introduction
이 논문에서는 문서, 차트, 표, 자연 이미지와 같은 텍스트가 풍부한 이미지의 전반적인 구조 이해를 향상시키기 위해 '통합 구조 학습(USL)'을 제안합니다. 기존의 시각 문서 이해(VDU) 모델들은 텍스트 인식을 위해 OCR 기술을 사용하지만 문서 이미지의 구조적 정보 이해는 부족했습니다. 이를 해결하기 위해 수평 인접 패치를 합치는 방식의 비전-투-텍스트 모듈 'H-Reducer'를 설계하였으며, 다양한 도메인을 아우르는 구조 학습 데이터셋 'DocStruct4M'을 구축했습니다. 이 모델은 10개의 VDU 벤치마크에서 기존 모델을 크게 능가하는 성능을 보였습니다.

#### 1.2 Related Work
VDU 연구는 텍스트가 많이 포함된 이미지를 이해하는 것을 목표로 합니다. 여기에는 문서, 표, 차트, 웹페이지 등이 포함됩니다. 기존 연구들은 주로 OCR 시스템을 사용해 텍스트 인식을 했으나, 본 연구는 구조적 정보의 학습을 강조하면서도 다양한 도메인에서의 성과를 한층 높여주는 모델을 제안합니다.

#### 1.3 DocOwl 1.5
DocOwl 1.5는 시각적 인코더, 비전-투-텍스트 모듈, 대형 언어 모델(LLM)로 구성된 전통적인 멀티모달 대형 언어 모델(MLLM) 아키텍처를 따릅니다. 고해상도의 텍스트-리치 이미지를 처리하며, 'H-Reducer' 모듈을 통해 수평 시각 특징을 통합합니다. 이를 통해 텍스트 인식 및 구조 이해 능력을 강화하고 다양한 다운스트림 작업에서 모델을 조정하며 학습합니다.

#### 1.4 Model Architecture
논문은 고해상도 이미지를 인코딩하는 능력과 구조적 이해 능력을 강화하는 방식을 설명합니다. 이 과정에서 형태 적응형 크로핑 모듈을 사용하여 이미지를 다수의 고정 크기 하위 이미지로 자르고, 이를 시각적 인코더를 통해 독립적으로 인코딩합니다.

#### 1.5 Unified Structure Learning
논문에서는 5가지 도메인의 이미지에 대해 구조 인식을 위한 통합 학습 방식을 제안합니다. 이를 위해 문서, 표, 차트, 웹페이지 등의 구조적 정보를 인식하고 위치에 기반한 텍스트 로컬라이제이션 작업을 설계했습니다. 이를 지원하기 위해 공개 데이터셋을 기반으로 DocStruct4M을 구축했습니다.

#### 1.6 Multi-task Fine-tuning
논문은 통합 구조 학습 이후, 다양한 다운스트림 작업에 대해 모델을 조정함으로써 전체 성능을 향상시키는 멀티 태스크 파인튜닝 방법론을 설명합니다.

#### 1.7 Training Paradigm
논문은 LLM의 구조화된 텍스트 이해 능력을 활용하여 첫 번째 단계에서는 비전 인코더와 H-Reducer를 조정하고, 두 번째 단계에서는 멀티 태스크 파인튜닝을 수행하여 최종 성능을 최적화합니다.

#### 1.8 Experiments
논문에서는 제안된 DocOwl 1.5 및 DocOwl 1.5-Chat 모델이 다양한 VDU 벤치마크에서 뛰어난 성능을 보이는 실험 결과를 제시합니다.

#### 1.9 Conclusion
논문은 텍스트가 풍부한 이미지 전반에 걸쳐 구조 인식을 향상시키기 위한 통합 구조 학습 방법론을 제안합니다. H-Reducer 모듈과 구조 학습 데이터셋인 DocStruct4M을 통해 다양한 도메인에서 모델의 성능을 검증했습니다.

---

### 2. 전체 요약
이 논문은 텍스트가 많이 포함된 이미지를 효과적으로 이해하기 위해 기존의 한계를 극복한 새로운 멀티모달 대형 언어 모델인 DocOwl 1.5를 제안합니다. 이 모델은 'H-Reducer'라는 비전-투-텍스트 모듈을 사용해 수평 시각 정보를 효율적으로 통합하며, 다양한 도메인의 이미지를 학습하기 위한 방대한 데이터셋인 DocStruct4M을 구축했습니다. 둘째, 멀티 태스크 파인튜닝을 통해 각 도메인 특성에 맞게 모델을 최적화함으로써 기존 모델보다 10개 이상의 벤치마크에서 대폭 향상된 성능을 입증했습니다. 연구 결과는 문서, 표, 차트, 자연 이미지 등 여러 유형의 텍스트가 포함된 이미지를 효과적으로 분석할 수 있는 새로운 길을 열어줍니다.