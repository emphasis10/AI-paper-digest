# AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.13943.pdf](https://arxiv.org/pdf/2502.13943.pdf)

1. **각 섹션 요약 및 세부 사항**

- **서론**: 대규모 언어 모델(LLM)은 다양한 작업에서 뛰어난 성능을 보이나 복잡한 추론 문제에서는 여전히 어려움을 겪고 있다. 기존의 절차 보상 모델(PRM)은 모델의 응답을 여러 단계로 나누지만, 이는 결정 정보가 부족해 개선이 필요하다고 지적한다.

- **AdaptiveStep 소개**: 이 연구에서는 AdaptiveStep이라는 새로운 방법을 제안하는데, 이는 모델의 예측 신뢰도를 기반으로 추론 단계를 자동으로 구분하는 방법이다. 이를 통해 각 단계에서 더 많은 결정 정보를 제공하며, 보상 모델 학습 등 하위 작업에 긍정적 영향을 줄 수 있다.

- **방법론**: AdaptiveStep은 모델의 예측 신뢰도를 기준으로 응답을 여러 추론 단계로 나눈다. 이렇게 나뉜 데이터로 PRM을 학습하며, 이를 활용하여 보다 정교한 토큰 레벨 추론 결과를 도출할 수 있다.

- **실험 및 결과**: 다양한 데이터셋을 활용한 실험에서 AdaptiveStep 기반의 PRM은 기존의 공개 소스 방법들보다 상위 성능을 보여주었다. 특히, 수학적 추론 및 코드 생성 작업에서 탁월한 성과를 거두었으며, 구축 비용도 줄어들었다.

- **논의 및 결론**: AdaptiveStep의 적용으로 인해 얻어진 PRM은 높은 정보성을 가지며 다양한 도메인에 적용 가능하다. 데이터 혼합이 성능을 더욱 향상시킬 수 있음을 발견했으며, 이를 통해 추론 능력을 강화할 수 있는 방법을 제시한다.

2. **종합 요약**

AdaptiveStep은 모델 예측 신뢰도에 기반한 자동 추론 단계 구분 방법을 제안하며, 이를 통해 대규모 언어 모델의 복잡한 추론 문제 해결에서 탁월한 성능을 발휘한다. 새로운 절차 보상 모델(PRM)은 기존의 방법들보다 효율적이고 비용이 적게 들면서 높은 정보성을 제공하여 다양한 작업에 응용될 수 있다. 실험을 통해 상위 성능을 증명하며 향후 AI와 머신 러닝 발전에 기여할 수 있는 가능성을 보여준다.