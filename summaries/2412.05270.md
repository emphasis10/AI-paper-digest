# APOLLO: SGD-like Memory, AdamW-level Performance
## TL;DR
## Summary
- [https://arxiv.org/pdf/2412.05270.pdf](https://arxiv.org/pdf/2412.05270.pdf)

### 1. 각 섹션의 요약

**서론**:
- 이 논문은 APOLLO라는 최적화 기법을 제안하여 대형 언어 모델(LLM)에서의 메모리 사용을 줄이고 성능을 유지하거나 그보다 나은 성능을 발휘하는 방법에 대해 설명합니다. 이 접근 방식은 AdamW 옵티마이저의 메모리 과부하 문제를 해결하기 위해 채널 또는 텐서 수준에서의 학습률 업데이트를 구조화함으로써 메모리를 절약하는 혁신적인 방법을 제안합니다.

**관련 연구**:
- 기존 연구에서는 대형 언어 모델의 메모리 사용을 줄이기 위해 저차원 적응, 스파스 기법, 소형 모델 설계 등이 제안되었지만, 이들 방법은 주로 성능이 떨어지거나 최적화 공간을 제한한다는 한계가 있습니다.

**APOLLO의 기법**:
- APOLLO는 구조화된 학습률 업데이트와 순수 랜덤 프로젝션을 사용하여 메모리 효율을 달성합니다. APOLLO-Mini를 통해 극단적인 메모리 효율성을 제공, SGD 수준의 메모리 비용으로 Adam(W)보다 높은 성능을 달성합니다.

**실험 결과 및 결론**:
- 다양한 모델과 작업에 대한 광범위한 실험을 통해 APOLLO는 Adam(W)과 비슷하거나 더 나은 성능을 유지하면서 메모리 사용을 획기적으로 감소시킵니다. 이로 인해 시스템에서의 개선점이 아래와 같이 제공됩니다: 3배 높은 처리량, 모델 확장성 개선, 고급 GPU 없이도 LLaMA-13B 모델 학습 가능.

### 2. 전체 요약

이 논문은 대형 언어 모델의 학습 시 필요로 하는 메모리 문제를 해결하기 위해 APOLLO라는 새로운 접근법을 제시하며, 이는 학습률의 요소별 업데이트를 보다 구조적이고 효율적으로 수행하는 방법을 통해 메모리 사용을 크게 줄입니다. APOLLO는 저차원 공간에서의 순수 랜덤 프로젝션을 활용하여 성능 저하 없이 메모리 활용을 극대화하며, 구체적으로 SGD 수준의 메모리 비용으로도 Adam(W)보다 높은 성능을 제공합니다. 이로 인해 훈련 처리량과 모델 확장성이 크게 향상되고, 다양한 하드웨어 환경에서 LLM의 학습이 용이해집니다.