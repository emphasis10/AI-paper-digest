# ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.02893.pdf](https://arxiv.org/pdf/2404.02893.pdf)

이 문서는 대규모 언어 모델(Large Language Models, LLMs)이 인간의 언어를 마스터하는 데 뛰어난 능력을 보이지만, 수학 문제 해결과 같이 실제 세계의 어플리케이션을 요구하는 상황에서는 여전히 어려움을 겪고 있는 현상에 초점을 맞추고 있습니다. 최근 LLM의 수학 능력을 강화하기 위한 여러 전략과 데이터셋이 개발됐지만, 배치된 LLM 시스템에서 언어 및 수학 능력을 동시에 유지하고 개선하는 것은 여전히 도전적인 과제입니다. 이에 본 연구에서는 LLM의 정렬(alignment) 학습 단계에서 이러한 도전을 해결하기 위해 ‘자가 비판(Self-Critique) 파이프라인’을 제안합니다.

### 1. 각 절의 중요 내용 요약 및 메인 기여도/혁신성 요약
- **서론(Introduction)**: 이 섹션은 대규모 언어 모델(LLMs)이 언어 이해와 수학 문제 해결 능력을 동시에 향상시키는 것의 중요성과 그에 따른 도전을 설명합니다. 본 연구의 주목적은 자가 비판(Self-Critique) 파이프라인을 통해 LLM이 자체 생성한 피드백으로부터 배우며 언어 및 수학 능력을 모두 개선하는 것입니다.
- **관련 연구(Related Work)**: 이 부분은 기존에 LLM의 수학 문제 해결 능력을 향상시키기 위한 접근 방식들을 검토합니다. 특히 사고의 연쇄(Chain of Thought) 프롬프팅과 같은 방법들이 어떻게 수학 및 논리적 과제를 개선하는데 기여했는지 설명합니다.
- **자가 비판 파이프라인(Self-Critique Pipeline)**: 이 절은 자가 비판 모델(Math-Critique)을 통해 LLM이 자신의 수학적 출력을 평가하고, 거부적 미세조정(Rejective Fine-tuning)과 직접적 선호 최적화(Direct Preference Optimization) 단계를 거친 자가 학습 과정을 소개합니다.
- **MATHUSEREVAL 벤치마크**: 실세계 수학 문제 해결 능력을 정확히 평가하기 위해 새로운 데이터셋 MATHUSEREVAL을 개발한 점을 강조합니다. 이 데이터셋은 학문적 연습 문제를 넘어 실제 응용 시나리오를 포함하여 다양한 질문을 제시합니다.
- **실험 및 결과**: ChatGLM3-32B 모델을 기반으로 한 실험 결과, 자가 비판 파이프라인이 LLM의 수학 문제 해결 및 언어 능력을 모두 개선하는 데 효과적 임을 보여줍니다. 특히, 이전의 다른 메서드들과 비교해서도 더 나은 성능을 달성하였습니다.
- **한계점 및 미래 연구(Limitation and Future Work)**: 이 섹션에서는 연구의 한계점과 향후 발전 가능성에 대해 논의합니다. 연구자들은 자가 비판 파이프라인의 다양한 적용 가능성과 함께, 이 방법이 어떻게 더 발전될 수 있을지에 대한 통찰을 제공합니다.
- **결론(Conclusion)**: 연구진은 자가 비판 파이프라인이 LLM의 수학적 문제 해결 능력과 언어 능력을 동시에 향상시킬 수 있는 혁신적인 접근 방식임을 요약하며, 이러한 방법이 언어 모델의 미래 발전에 중요한 기여를 할 것이라 강조합니다.

### 2. 전체 요약
본 연구는 대규모 언어 모델(LLM)이 언어 이해와 수학 문제 해결 능력을 동시에 개선하는 것에 초점을 맞춘 새로운 접근 방식을 제안합니다. 연구진은 자가 비판(Self-Critique) 파이프라인을 통해 LLM이 자체적으로 생성한 피드백으로부터 학습하며 양측 능력을 향상시킨다는 개념을 소개했습니다. 이 파이프라인은 거부적 미세조정(Rejective Fine-tuning, RFT)과 직접적 선호 최적화(Direct Preference Optimization, DPO)의 두 단계로 구성되어 있습니다. 또한, 실세계 문제 해결 능력을 평가하기 위한 새로운 데이터셋 MATHUSEREVAL을 개발하였으며, 이를 통한 실험 결과는 자가 비판 파이프라인이 LLM의 수학 문제 해결 및 언어 능력 모두를 향상시키는 데 효과적임을 보여줍니다. 이 연구는 미래의 언어 모델 개선 작업에 중요한 기여를 할 것으로 기대됩니다.