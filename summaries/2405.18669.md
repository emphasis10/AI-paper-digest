# Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities
## TL;DR
## Summary
- [https://arxiv.org/pdf/2405.18669.pdf](https://arxiv.org/pdf/2405.18669.pdf)

### 섹션별 요약 및 주요 기여 요약

#### 1. 소개
Zipper는 다중 모달리티 생성을 위해 독립적으로 사전 훈련된 단일 모달리티 디코더를 결합하는 다중 타워 디코더 아키텍처입니다. 이 아키텍처는 제한된 양의 정렬된 데이터만 사용해도 강력한 성능을 발휘할 수 있습니다. 또한, Zipper는 텍스트-음성 인식(ASR) 및 텍스트-음성 변환(TTS) 작업에서 경쟁력 있는 성능을 보여줍니다.

#### 2. 관련 연구
기존의 연구들은 다중 모달리티 이해와 생성을 위해 다양한 방법을 탐구했습니다. 이들은 주로 어휘 확장 및 인코더-디코더 구성을 사용했지만, 이러한 방법들은 대량의 정렬된 데이터가 필요합니다. Zipper는 사전 훈련된 단일 모달리티 디코더를 결합하여 이 문제를 해결하고, 적은 양의 정렬된 데이터만으로도 의미 있는 표현을 학습할 수 있습니다.

#### 3. 모델
Zipper 아키텍처는 두 개의 자기 회귀 디코더 타워를 교차 주의 레이어로 결합합니다. 각 타워는 단일 모달리티에서 사전 훈련된 디코더로 구성되며, 교차 주의 레이어를 통해 다른 모달리티의 표현을 결합합니다. 이를 통해 텍스트와 음성 모달리티를 효과적으로 결합할 수 있습니다.

#### 4. 실험
Zipper는 텍스트와 음성 모달리티를 결합하여 ASR 및 TTS 작업에서 성능을 평가했습니다. 실험 결과, Zipper는 단일 디코더 대비 우수한 성능을 보였으며, 특히 음성 생성 작업에서 WER이 크게 감소했습니다. 또한, Zipper는 적은 양의 정렬된 데이터만으로도 강력한 성능을 발휘할 수 있음을 보여주었습니다.

#### 5. 결론 및 향후 연구
Zipper는 독립적으로 사전 훈련된 단일 모달리티 디코더를 결합하여 다중 모달리티 생성 능력을 갖춘 새로운 아키텍처입니다. 향후 연구에서는 더 많은 모달리티를 결합하여 Zipper의 적용 범위를 확장하고, 더 큰 모델 크기와 다양한 데이터를 사용하여 성능을 향상시키고자 합니다.

### 전체 요약
이 논문은 다중 모달리티 생성을 위해 독립적으로 사전 훈련된 단일 모달리티 디코더를 결합하는 Zipper 아키텍처를 제안합니다. Zipper는 제한된 양의 정렬된 데이터만으로도 강력한 성능을 발휘할 수 있으며, 텍스트와 음성 모달리티를 결합하여 ASR 및 TTS 작업에서 우수한 성능을 보여줍니다. 향후 연구에서는 더 많은 모달리티를 결합하고, 더 큰 모델 크기와 다양한 데이터를 사용하여 Zipper의 성능을 향상시키고자 합니다.

## Similar Papers
- [E2 TTS: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS](2406.18009.md)
- [Transferable and Principled Efficiency for Open-Vocabulary Segmentation](2404.07448.md)
- [Autoregressive Speech Synthesis without Vector Quantization](2407.08551.md)
- [SpeechVerse: A Large-scale Generalizable Audio Language Model](2405.08295.md)
- [MaGGIe: Masked Guided Gradual Human Instance Matting](2404.16035.md)
- [Language Model Can Listen While Speaking](2408.02622.md)
- [Item-Language Model for Conversational Recommendation](2406.02844.md)
- [Sentence-wise Speech Summarization: Task, Datasets, and End-to-End Modeling with LM Knowledge Distillation](2408.00205.md)
- [SHERL: Synthesizing High Accuracy and Efficient Memory for Resource-Limited Transfer Learning](2407.07523.md)
