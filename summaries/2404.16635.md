# TinyChart: Efficient Chart Understanding with Visual Token Merging and Program-of-Thoughts Learning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2404.16635](https://arxiv.org/pdf/2404.16635)

이 논문에서는 TinyChart라는 새로운 다중 모달 대규모 언어 모델(MLLM)을 소개하며, 차트 이해를 위한 효율적인 모델 구조와 학습 전략을 제안합니다. 주요 내용은 다음과 같습니다.

1. **서론 및 관련 작업**:
   - 차트는 정보 전달과 복잡한 데이터 관계의 시각화에 중요하지만, 고해상도 이미지를 처리하는 기존 모델은 많은 계산 자원을 요구합니다.
   - TinyChart는 3B의 매개변수를 가진 효율적인 MLLM으로, 차트 이해에 필요한 고해상도 이미지 인코딩과 수치 계산 학습을 개선합니다.

2. **TinyChart 방법론**:
   - **시각 토큰 병합**: 차트 이미지의 특성을 효과적으로 압축하고 인코딩 시간을 단축하기 위해 비슷한 시각 토큰을 병합하는 기법을 사용합니다.
   - **사고 과정 프로그램(PoT) 학습**: 모델이 수치 계산 문제를 효과적으로 해결할 수 있도록 Python 프로그램을 생성하게 학습합니다. 이는 차트QA-PoT 데이터셋을 활용하여 구현됩니다.

3. **실험 및 결과**:
   - TinyChart는 ChartQA, Chart-to-Text, Chart-to-Table 등 다양한 차트 이해 벤치마크에서 최고의 성능을 보여줍니다.
   - 또한, 효율적인 비전 인코딩을 통해 더 높은 추론 처리량을 달성하며, 기존의 13B 모델들과 비교하여 우수한 성능을 제공합니다.

4. **결론**:
   - TinyChart는 차트 이해 작업을 위한 경량화된 구조와 PoT 학습 방법을 통해 효율적이면서도 강력한 성능을 제공합니다.
   - 이 연구는 차트 이해를 위한 MLLM의 새로운 가능성을 보여주며, 다양한 응용 프로그램에서 활용될 수 있는 기반을 마련합니다.

TinyChart는 차트 이해를 위한 효율적인 접근 방식을 제공하며, 특히 고해상도 이미지 처리와 수치 계산 문제에서의 성능 개선이 돋보입니다.