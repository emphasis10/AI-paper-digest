# Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.06195.pdf](https://arxiv.org/pdf/2408.06195.pdf)

### 섹션별 요약 및 분석

#### 1. 서론 (Introduction)
이 연구는 소형 언어 모델(SLMs)의 추론 능력을 향상시키기 위한 새로운 접근법인 rStar를 소개합니다. 기존의 방법들은 고급 모델의 텍스트 데이터를 이용한 학습에 의존하지만, rStar는 SLM 자체의 능력을 활용해 성능을 개선합니다. 이는 Monte Carlo Tree Search(MCTS)와 상호 합의된 추론 경로를 생성하여 더 높은 정답률을 달성하는 방법입니다.

#### 2. 관련 연구 (Related Work)
여기서는 기존의 연구들을 소개합니다. MCTS, 체인 오브 생각(CoT) 같은 추론 촉진 방법, SLM의 자기 개선 방법 등이 다뤄집니다. 특히 rStar는 단일 라운드의 추론을 넘어 다중 라운드 추론 기법의 한계를 뛰어넘는다는 점을 강조합니다.

#### 3. 방법론 (Methodology)
rStar 방법론은 크게 두 단계로 나뉩니다:
1. **자기 생성 추론 경로(MCTS 롤아웃)**: 인간이 문제를 해결하는 방식에 영감을 받아 다양한 행동 집합을 사용합니다. 이는 단순하게 하나의 행동 유형만을 사용하는 기존 방식의 한계를 극복합니다.
2. **상호 일관성 검증(Mutual Consistency)**: 두 번째 SLM을 사용하여 각 추론 경로에 대해 비지도 피드백을 제공하며, 상호 합의된 경로가 보다 정확할 가능성이 높다고 봅니다.

#### 4. 실험 (Experiments)
다양한 SLMs와 여러 추론 작업에서 rStar의 효과를 검증했습니다. 실험 결과 rStar는 기존의 상태-최첨단 기법들보다 월등히 높은 정확도를 보여줍니다. 특히 GSM8K 데이터셋에서는 LLaMA2-7B 모델의 정확도를 12.51%에서 63.91%로 향상시켰습니다.

#### 5. 결론(Conclusion)
rStar는 SLM의 추론 능력을 크게 향상시키며, 기존의 다중 라운드 추론 및 자기 개선 기법을 능가하는 성능을 보입니다. 또한, 광범위한 실험과 분석을 통해 더 발전된 SLM 자기 개선 추론 개발에 기여하고자 합니다.

### 논문의 전체 요약
이 논문은 소형 언어 모델(SLMs)에서 추론 능력을 향상시키기 위한 rStar 방법론을 제안합니다. 이 접근법은 고급 모델로 학습된 데이터에 의존하지 않고, SLM 자체의 능력을 활용하여 성능을 극대화합니다. Monte Carlo Tree Search(MCTS)와 상호 일관성 검증(Mutual Consistency)을 통해 다양한 추론 작업에서 높은 정확도를 달성했습니다. rStar는 SLM의 이미 강력한 추론 능력을 바탕으로, 도메인 특화 지도 학습 없이도 성능을 극대화할 수 있는 혁신적인 접근법입니다.