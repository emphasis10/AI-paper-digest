# MuChoMusic: Evaluating Music Understanding in Multimodal Audio-Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2408.01337.pdf](https://arxiv.org/pdf/2408.01337.pdf)

### 1. 섹션 요약 및 주요 기여와 혁신 부분 요약

#### 1.1 서론
이 논문은 대형 언어 모델(LLMs)과 새로운 기계 인식 기술의 결합을 다루고 있습니다. 특히, 오디오 이해 능력을 가진 멀티모달 LLMs를 "오디오 LLMs"로 정의하고, 이를 평가하는 데 있어 다양한 문제를 탐구합니다. 현재의 평가 방법이 성능을 제대로 측정하지 못하는 점, 표준화 부족, 그리고 데이터셋에서의 품질 문제를 강조하며, 인간 평가가 고비용이고 재현이 어렵다는 문제도 언급합니다.

#### 1.2 관련 작업
본 섹션에서는 오디오 LLMs가 음악 도메인에서 어떻게 평가되는지에 대해 다룹니다. 음악 이해를 위해 다양한 평가 방법과 데이터셋을 사용하여 모델의 음악 캡션 생성 및 질문에 대한 답변 능력을 시험합니다. 기존 연구와 비교해 MuChoMusic 벤치마크의 독창적 설정과 평가 기법을 설명합니다.

#### 1.3 모델
총 다섯 가지 모델(MuLLaMA, MusiLingo, M2UGen, SALMONN, Qwen-Audio)을 평가했습니다. 이 모델들은 모두 학습된 LLM 백본, 오디오 인코더, 학습 가능한 어댑터 모듈로 구성되어 있습니다. 이 모델들은 지시 조정을 통해 학습되었으며, 다양한 지시 데이터셋을 사용해 단계적으로 학습되었습니다.

#### 1.4 결과 및 논의
모든 모델이 여러 세팅과 평가 기준에서 만족스럽지 않은 성능을 보인다는 점을 제시합니다. Qwen-Audio 모델이 상대적으로 높은 점수(51.4%)를 기록했으나, 대부분의 모델이 랜덤 성능에 근접하거나 그 이하의 성능을 보였습니다. 또한, 이러한 모델들은 적절한 답변 형식을 출력하는 데 어려움을 겪으며, 오디토리 및 언어적인 환각 또는 훈련 바이어스 때문에 성능이 감소한다고 분석합니다.

#### 1.5 실패 사례
여러 가지 실패 유형을 탐구하며, 오디토리 환각, 언어적 환각, 그리고 훈련 데이터 바이어스의 사례를 소개합니다. 이 부분은 모델들이 제시된 텍스트보다 오디오 콘텐츠에 제대로 주의를 기울이지 못하는 문제를 부각시킵니다.

#### 1.6 결론
MuChoMusic 벤치마크가 오디오 LLMs를 평가하는 데 있어 새로운 기준을 제공하며, 다섯 가지 최신 시스템을 평가한 결과, 현재 모델들이 오디오와 텍스트 모달리티를 충분히 활용하지 못한다는 결론을 도출합니다. 이는 미래 연구 방향을 제시하며, MuChoMusic이 음악 이해를 위한 보다 나은 멀티모달 통합이 필요함을 강조합니다.

### 2. 전체 요약
이 논문은 오디오 이해 능력을 가진 대형 언어 모델(LLMs), 즉 오디오 LLMs를 평가하기 위한 MuChoMusic 벤치마크를 소개합니다. MuChoMusic 벤치마크는 1,187개의 객관식 질문으로 구성되며, 644개의 음악 트랙을 기반으로 한 다양한 장르를 아우릅니다. 평가 결과, 현재 모델들이 오디오와 텍스트 모달리티를 충분히 통합하지 못하여 성능이 저조하다는 결론을 내립니다. 주요 혁신점은 인간 검수를 거친 객관식 질문을 사용하여 보다 신뢰할 수 있는 평가를 제공한다는 점입니다. 이 연구는 향후 음악 이해와 관련한 모델 개발의 방향성을 제시하며, 다중 모달리티 통합의 중요성을 강조합니다.

MuChoMusic 벤치마크는 음악 이론, 음악 스타일, 문화적/기능적 맥락 등 다양한 영역에서 모델의 지식과 추론 능력을 평가합니다. 이 벤치마크를 통해 다섯 가지 오디오 LLMs를 평가한 결과는 오디오와 텍스트 모달리티를 통합해야 할 필요성을 시사하며, 현재 모델들이 주로 텍스트에 치우쳐 있다는 점을 발견하였습니다. 논문은 이 문제를 해결하기 위한 향후 연구 방향을 제안합니다.

```markdown
이 논문은 오디오 이해 능력을 가진 대형 언어 모델(LLMs)인 오디오 LLMs의 평가 방법을 탐구하며, 이를 위해 MuChoMusic 벤치마크를 소개합니다. MuChoMusic 벤치마크는 644개의 음악 트랙을 기반으로 한 1,187개의 객관식 질문을 통해 모델을 평가하며, 주요 발견 사항으로 모델들이 오디오와 텍스트를 충분히 통합하지 못한다고 결론지었습니다. 이 연구는 향후 음악 이해와 관련한 모델 개발의 방향성을 제시하며, 다양한 평가 방법과 데이터셋 사용의 중요성을 강조합니다.
```


## Similar Papers
- [SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages](2407.19672.md)
- [MIBench: Evaluating Multimodal Large Language Models over Multiple Images](2407.15272.md)
- [Scaling Synthetic Data Creation with 1,000,000,000 Personas](2406.20094.md)
- [MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and Efficient Evaluation](2407.00468.md)
- [Imp: Highly Capable Large Multimodal Models for Mobile Devices](2405.12107.md)
- [Towards Robust Evaluation: A Comprehensive Taxonomy of Datasets and Metrics for Open Domain Question Answering in the Era of Large Language Models](2406.13232.md)
- [Multimodal Table Understanding](2406.08100.md)
- [Qwen2 Technical Report](2407.10671.md)
- [WavCraft: Audio Editing and Generation with Large Language Models](2403.09527.md)
