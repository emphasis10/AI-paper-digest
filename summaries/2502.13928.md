# Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.13928.pdf](https://arxiv.org/pdf/2502.13928.pdf)

1. 각 섹션 요약 및 주요 기여, 혁신 부분:

- 서론: 대규모 비전-언어 모델(VLMs)이 언어 모델의 의존도가 높아 시각적 내용을 무시하는 문제를 지적합니다. 이러한 문제를 해결하기 위해 S-VCO라는 새로운 파인튜닝 목표를 도입하여 시각적 세부사항을 더욱 잘 반영하도록 모델을 조정합니다.

- 데이터셋 및 방법론: S-VCO는 MVC라는 최소한의 시각적 대조를 포함한 이미지-텍스트 쌍 데이터셋을 자동으로 생성하여 모델의 훈련을 돕습니다.

- 실험 및 결과: S-VCO는 다양한 벤치마크에서 특히 시각적 환각을 줄이는 데 있어 기존 모델에 비해 상당히 뛰어난 성능을 보여주었습니다. 또한 S-VCO는 시각 중심의 과제뿐만 아니라 일반적인 벤치마크에서도 중요한 성과를 냈습니다.

- 결론 및 기여: S-VCO와 MVC의 조합은 VLM의 성능을 시각적 의존도가 높은 과제에서 특히 증가시켰고, 일반적인 능력을 대가하지 않으면서도 개선했습니다.

2. 전반적인 요약:

이 논문은 대규모 비전-언어 모델이 시각적 세부사항을 잘 인식하지 못하는 문제를 해결하기 위해 S-VCO라는 새로운 파인튜닝 방법을 제안합니다. S-VCO는 MVC라는 최소한의 시각적 대조가 있는 이미지-텍스트 쌍 데이터셋을 사용하여 모델의 시각적 인식을 강화하며, 시각적 환각을 상당히 줄이고 일반적인 작업에서도 뛰어난 성과를 나타냈습니다.