# The Art of Refusal: A Survey of Abstention in Large Language Models
## TL;DR
## Summary
- [https://arxiv.org/pdf/2407.18418.pdf](https://arxiv.org/pdf/2407.18418.pdf)

### 요약

#### Abstract (개요)
본 논문은 대형 언어 모델(LLMs)의 거부(회피) 행동을 연구합니다. LLMs가 불확실성을 직면했을 때 답변을 거부하는 능력이 환각을 줄이고 시스템의 안전성을 강화하는데 기여할 수 있음을 제안합니다. 논문은 세 가지 관점(질의, 모델, 인간 가치)에서 회피 행동을 분석하는 프레임워크를 소개하고, 문헌 연구 및 평가 지표를 통해 기존 연구의 한계와 향후 연구 방향을 제시합니다.

#### Introduction (소개)
대형 언어 모델은 수많은 자연어 처리 작업에서 우수한 성능을 보입니다. 그러나 잘못된 정보나 불완전한 답변을 제공하는 등의 문제도 나타납니다. 이러한 문제를 해결하기 위해 LLMs가 불확실한 상황에서 답변을 거부하는 능력(회피)을 갖추는 것이 중요합니다.

#### Methodology (방법론)
회피 방법론은 언어 모델의 수명 주기(사전 학습, 정렬, 추론)의 다른 단계에서 적용됩니다. 질의 분석, 모델 자신감 및 인간 가치 정렬을 통한 회피 기능을 설계합니다. 그러한 기능은 모델이 불확실성을 직면했을 때 안전하고 윤리적인 방식으로 행동하도록 합니다.

#### Experiments (실험)
다양한 실험을 통해 회피 기준을 설정하고, 회피 능력을 평가하는 방법을 연구합니다. 예를 들어, 다양한 캐시 데이터셋을 사용하여 질의 응답 작업에서 모델의 자신감과 회피 능력을 평가합니다. 또한 다른 LLM들과의 협력을 통해 다중 모델 간의 회피 능력을 강화할 수 있는 방법도 연구합니다.

#### Results (결과)
실험 결과, 안전성과 신뢰성을 높이기 위해 LLMs에서 회피 능력이 탁월하게 동작함을 확인했습니다. 특히 예측할 수 없는 상황에서 모델이 답변을 회피하는 능력은 시스템의 신뢰성을 크게 향상시켰습니다. 그 결과, 회피 기능을 포함한 모델은 보다 안정적이고 윤리적인 방식으로 작동했습니다.

#### Conclusion (결론)
본 논문은 LLMs에서 전략적 회피가 시스템의 신뢰성과 안전성을 높이는 중요한 방법임을 강조합니다. 회피 연구의 메타 기능으로서의 가능성을 탐구하고, 이러한 기능을 사용자의 요구에 맞게 커스터마이징하는 능력의 중요성을 제시합니다. 향후 연구는 이러한 회피 메커니즘을 보다 넓은 응용 분야와 더욱 역동적인 컨텍스트에 적용할 것으로 기대됩니다.

### 종합 요약
이 논문은 대형 언어 모델(LLMs)이 불확실하거나 위험한 상황에서 답변을 거부하는 능력(회피)의 중요성을 강조합니다. 회피 능력은 세 가지 관점(질의, 모델, 인간 가치)에서 분석되며, 이를 통해 모델의 신뢰성과 안전성을 높이는 전략적 방법을 제안합니다. 연구는 회피 능력이 주어진 상황에서 모델이 불완전한 정보를 제공하지 않도록 하는 데 중요하며, 이를 통해 윤리적이고 안전한 AI 시스템을 구축하는 데 기여할 것으로 기대됩니다. 향후 연구는 이 회피 메커니즘을 다양한 응용 분야와 컨텍스트에 맞게 확장하는 것을 목표로 합니다.

## Similar Papers
- [Best Practices and Lessons Learned on Synthetic Data for Language Models](2404.07503.md)
- [A Survey on Retrieval-Augmented Text Generation for Large Language Models](2404.10981.md)
- [Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models](2305.09955.md)
- [Can LLMs be Fooled? Investigating Vulnerabilities in LLMs](2407.20529.md)
- [Towards Building Specialized Generalist AI with System 1 and System 2 Fusion](2407.08642.md)
- [Poisoned LangChain: Jailbreak LLMs by LangChain](2406.18122.md)
- [A Systematic Survey of Text Summarization: From Statistical Methods to Large Language Models](2406.11289.md)
- [On the Transformations across Reward Model, Parameter Update, and In-Context Prompt](2406.16377.md)
- [SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages](2407.19672.md)
