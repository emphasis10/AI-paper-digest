# Fully-fused Multi-Layer Perceptrons on Intel Data Center GPUs
## TL;DR
## Summary
- [https://arxiv.org/pdf/2403.17607.pdf](https://arxiv.org/pdf/2403.17607.pdf)

#### I. 서론
이 논문은 Intel Data Center GPU Max 1550을 타겟으로 최적화된 SYCL 구현의 Multi-Layer Perceptrons(MLPs)를 소개합니다. MLP는 인공지능과 머신러닝의 중요한 구성 요소로, 본 연구는 연산 강도를 높여 성능을 향상시키기 위해 각 층의 연산을 완전히 결합하는 방식을 사용합니다. 이는 특히 추론에서 큰 성능 향상을 가져옵니다.

#### II. MLP의 응용 분야
MLPs는 다양한 분야에서 중요한 역할을 합니다. 주요 응용 분야는 이미지 압축, 신경 방사 필드(NeRFs), 물리 기반 머신러닝 등입니다. 본 논문에서는 이러한 응용 분야에서의 성능 개선을 시연합니다.

#### III. Intel GPU에서의 완전 융합 MLP 구현
Intel GPU에서 MLP를 완전 융합 방식으로 구현하여 성능을 극대화했습니다. 이 구현은 특히 추론과 훈련 성능을 최적화하기 위해 데이터 재사용을 최대화하고 느린 글로벌 메모리 접근을 최소화합니다. Roofline 모델을 사용하여 이 접근 방식이 연산 강도를 크게 높이고 성능을 향상시킴을 입증했습니다.

#### IV. 결과
MLP의 성능을 비선형 함수 근사, 이미지 압축, NeRF, 물리 기반 신경망의 예시에서 비교했습니다. SYCL 구현은 유사한 CUDA 구현보다 추론에서 최대 2.84배, 훈련에서 최대 1.75배 더 나은 성능을 보였습니다. 또한, PyTorch 구현보다 최대 30배 높은 성능을 기록했습니다.

#### V. 결론 및 향후 연구
본 논문은 Intel Data Center GPU에서 MLP의 완전 융합 SYCL 구현이 성능을 크게 향상시킬 수 있음을 입증했습니다. 향후 연구에서는 더 효율적인 레지스터 사용과 작은 배치 크기의 점유율을 높이기 위한 최적화를 목표로 할 것입니다.

### 전체 요약
이 논문은 Intel Data Center GPU Max 1550에서 SYCL을 사용하여 최적화된 완전 융합 Multi-Layer Perceptrons(MLPs)를 구현한 연구를 소개합니다. 이 구현은 데이터 재사용을 극대화하고 글로벌 메모리 접근을 최소화하여 연산 강도를 크게 높이고 성능을 향상시킵니다. MLP의 성능을 비선형 함수 근사, 이미지 압축, 신경 방사 필드(NeRF), 물리 기반 신경망에서 시연하며, 특히 PyTorch와 CUDA 구현보다 뛰어난 성능을 보였습니다. 향후 연구에서는 더 나은 레지스터 사용과 작은 배치 크기의 점유율 최적화를 목표로 할 것입니다.