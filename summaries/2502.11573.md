# InfiR : Crafting Effective Small Language Models and Multimodal Small Language Models in Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2502.11573.pdf](https://arxiv.org/pdf/2502.11573.pdf)

1. 각 섹션의 주요 내용 요약:

- **서론**: 최근 대형 언어 모델(LLM)과 다중 모드 대형 언어 모델(MLLM)의 발전에도 불구하고, 높은 연산 자원 요구와 비용, 개인 정보 문제 등의 한계가 있습니다. 본 연구는 경쟁력 있는 추론 능력을 가진 소형 언어 모델(SLM) 및 다중 모드 소형 언어 모델(MSLM)을 개발하여 이러한 문제를 해결하고자 합니다.

- **소형 언어 모델 사전 훈련**: 고품질의 사전 훈련 데이터를 필터링하여 소형 모델에 필요로 하는 추론 능력을 확보하기 위한 데이터 파이프라인을 제안합니다. 이는 소형 모델이 다양한 도메인에서 높은 성능을 발휘할 수 있도록 지원합니다.

- **실험 결과 및 성능**: 제안된 모델 InfiR-1B-Base 및 InfiR-VL-1.6B는 여러 벤치마크에서 최첨단 성능을 달성하며 실질적인 응용 가능성을 입증합니다.

- **결론 및 한계**: 본 연구는 소형 언어 모델과 다중 모드 언어 모델이 효율적이고 접근 가능한 인공지능 솔루션을 제시할 잠재력이 있음을 보여줍니다. 그러나 실제 환경에서 일반화 능력을 검증할 필요가 있습니다.

2. 전체 요약:
이 연구에서는 소형 언어 모델과 다중 모드 소형 언어 모델의 효율성과 실용성을 입증하면서 환경 비용과 프라이버시 문제를 해결하려고 합니다. 제안된 모델은 더 작은 크기임에도 불구하고 강력한 추론 및 논리적 사고 능력을 보여줍니다. 이를 통해 AI 시스템의 더 넓은 채택과 혁신을 촉진할 수 있는 가능성을 제시하고 있습니다.