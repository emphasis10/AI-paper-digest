# InfiMM-WebMath-40B: Advancing Multimodal Pre-Training for Enhanced Mathematical Reasoning
## TL;DR
## Summary
- [https://arxiv.org/pdf/2409.12568.pdf](https://arxiv.org/pdf/2409.12568.pdf)

### 1. 각 섹션 요약

#### 1. 도입부
최근 대형 언어 모델(LLM)은 복잡한 추론 및 다단계 수학 문제 해결에서 상당한 발전을 보였습니다. 이러한 진보는 더 큰 훈련 규모, 'Chain-of-Thought (CoT)' 추론 기법, 다양한 훈련 데이터 덕분입니다. 이 연구는 GPT-4o와 같은 독점 모델과 LLaMA 3.1과 같은 오픈 소스 모델 모두에서 그 성과를 확인할 수 있습니다.

#### 2. 관련 연구
수학적 추론 능력을 평가하고 개선하기 위해 다양한 평가 벤치마크와 훈련 데이터셋이 개발되었습니다. 예를 들어, GSM8K, MATH, MMLU, SAT, OCW 등이 있으며, 수학 추론 능력을 평가하는 데 사용됩니다.

#### 3. 기여 및 혁신점
이 논문은 InfiMM-WebMath-40B라는 첫 번째 대규모 공개 멀티모달 수학 전이 학습 데이터셋을 소개합니다. 이 데이터셋은 40억 개의 텍스트 토큰 및 8,500만 개의 이미지 URL을 포함하고 있으며, 수학적 추론 능력을 향상시키는 데 중점을 두고 있습니다. 이 데이터셋을 사용한 모델들은 MathVerse와 We-Math 벤치마크에서 탁월한 성능을 보였습니다.

#### 4. 데이터셋 구성
InfiMM-WebMath-40B의 데이터셋은 4년간(2019-2023) 축적된 CommonCrawl 자료를 기반으로 합니다. 언어 필터링과 중복 제거를 포함한 여러 단계의 필터링 과정을 거쳐 약 2천 4백만 개의 웹 문서와 40억 개의 텍스트 토큰 및 8,500만 개의 이미지 URL이 포함된 최종 데이터셋이 구성되었습니다.

#### 5. 결론 및 미래 연구 방향
이 논문의 결론으로, InfiMM-WebMath-40B는 공개 소스 커뮤니티에 중요한 기여를 하고 있으며, 향후 더 정교한 비전 인코더와 강화 학습 기법을 통합하여 MLLM의 수학적 추론 능력을 더욱 향상시킬 계획입니다.

### 2. 전체 요약

이 논문은 대규모 멀티모달 수학 전이 학습 데이터셋인 InfiMM-WebMath-40B을 소개하며, 이는 수학적 추론 능력을 강화하기 위해 고안되었습니다. InfiMM-WebMath-40B는 2천 4백만 개의 웹 문서와 8,500만 개의 이미지 URL, 40억 개의 텍스트 토큰을 포함하고 있습니다. 이 데이터셋은 CommonCrawl 자료를 기반으로 여러 단계의 필터링 과정을 거쳐 구축되었습니다. 이 데이터셋을 활용한 모델들은 MathVerse와 We-Math 벤치마크에서 뛰어난 성능을 보였으며, 이는 공개 소스 연구와 AI 커뮤니티에 큰 기여를 하고 있습니다. 향후 연구는 더 정교한 비전 인코더와 강화 학습 기법을 통합하여 MLLM의 수학적 추론 능력을 더욱 향상시키는 것을 목표로 하고 있습니다.

       